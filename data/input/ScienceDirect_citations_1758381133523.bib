@article{HAN2025131214,
title = {EC-Fake: A fake news detection model based on external knowledge and contrast-driven feature augmentation},
journal = {Neurocomputing},
volume = {653},
pages = {131214},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131214},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225018867},
author = {Mingxing Han and Jiaxuan Li and Yu Chen and Liwei Xu and Lingling Tao},
keywords = {Fake news detection, Fake news, Feature fusion, Multi-modal detection},
abstract = {Fake news has spurt with the rapid development of Internet technology and social media, causing a number of serious negative impacts on individuals and society. Aiming at the shortcomings of existing multi-modal fake news detection on cross-modal feature fusion and external knowledge features, we proposed a multi-modal fake news detection model based on external knowledge and contrast-driven feature augmentation named EC-Fake. EC-Fake employs a Semantic Information Decoupling (SID) module to separate the foreground subject and background context of news images. SID can be utilized to guide multi-level feature fusion and key feature augmentation. This enables EC-Fake to reduce uncertainty in image features and allocate more attention to foreground and background features. Then, we used Large Language Models (LLMs) to extract external knowledge from news and fused it with multi-modal features, thereby effectively improving the interpretability and accuracy of EC-Fake. The accuracy on three public datasets is improved by 1.9 %, 1.6 %, and 2.7 % over the state-of-the-art model, respectively. EC-Fake can provide technical support to social media platforms and government regulators in detecting fake news.}
}
@article{TENG2024122644,
title = {A comprehensive review of cyberbullying-related content classification in online social media},
journal = {Expert Systems with Applications},
volume = {244},
pages = {122644},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.122644},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423031469},
author = {Teoh Hwai Teng and Kasturi Dewi Varathan and Fabio Crestani},
keywords = {Online social network, Machine learning workflow, Cyberbullying, Automated classification, Comprehensive review},
abstract = {The emergence of online social networks (OSN) platforms removes communication barriers that are essential to human life, catalyzing social networking growth. However, this emergence has given rise to a negative impact when someone abuses the platform to commit cyberbullying activities. Hence, it is crucial to work on automated cyberbullying-related classification to mitigate the societal phenomena in OSN. The research on the automated classification model for cyberbullying was pioneered over the last decade with growing interest among researchers. It is helpful to track its growth over the decades to elucidate the state-of-arts techniques applied in this field. This paper presents a large amount of literature germane to cyberbullying classification from past to present to provide a comprehensive review. A total of 126 papers were reviewed. This paper emphasizes text-based cyberbullying and multi-modal cyberbullying. The review was presented around the machine learning workflow, encompassing four core sections: dataset analysis, pre-processing analysis, feature analysis, and technique analysis. Based on the critical analysis, limitations are addressed along with the future works that can be conducted to fill the gap in previous research. Furthermore, the review also examined the ethical implications associated with the implementation of these techniques. This review paper is expected to assist readers in fully comprehending the current trend, architecture, and techniques applied to the field.}
}
@article{ZHANG2025112355,
title = {Mining user privacy concern topics from app reviews},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112355},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112355},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225000238},
author = {Jianzhang Zhang and Jialong Zhou and Jinping Hua and Nan Niu and Chuang Liu},
keywords = {Privacy concerns, Topic modeling, App reviews mining, Privacy requirements, Requirements engineering},
abstract = {Context:
As mobile applications (apps) widely spread throughout our society and daily life, various personal information is constantly demanded by apps in exchange for more intelligent and customized functionality. An increasing number of users are voicing their privacy concerns through app reviews on app stores.
Objective:
The main challenge of effectively mining privacy concerns from user reviews lies in that reviews expressing privacy concerns are overridden by a large number of reviews expressing more generic themes and noisy content. In this work, we propose a novel automated approach to overcome that challenge.
Method:
Our approach first employs information retrieval and document embeddings to extract candidate privacy reviews in an unsupervised manner, which are further labeled to prepare the annotation dataset. Then, supervised classifiers are trained to automatically identify privacy reviews. Finally, an interpretable topic mining algorithm is designed to detect privacy concern topics contained in the privacy reviews.
Results:
Experimental results show that the best performing document embedding achieves an average precision of 96.80% in the top 100 retrieved candidate privacy reviews, outperforming the taxonomy-based baseline, which achieves 73.87%. All trained privacy review classifiers achieve an F1 score above 91%, surpassing the keyword-matching baseline by as much as 7.5% and the large language model baseline by up to 2.74%. For detecting privacy concern topics from privacy reviews, our proposed algorithm achieves both better topic coherence and topic diversity than three strong topic modeling baselines, including LDA.
Conclusion:
Empirical evaluation results demonstrate the effectiveness of our approach in identifying privacy reviews and detecting user privacy concerns in app reviews.}
}
@article{ASAAD2025,
title = {When Infodemic Meets Epidemic: Systematic Literature Review},
journal = {JMIR Public Health and Surveillance},
volume = {11},
year = {2025},
issn = {2369-2960},
doi = {https://doi.org/10.2196/55642},
url = {https://www.sciencedirect.com/science/article/pii/S2369296025000250},
author = {Chaimae Asaad and Imane Khaouja and Mounir Ghogho and Karim Baïna},
keywords = {epidemics, social media, epidemic surveillance, misinformation, mental health},
abstract = {Background
Epidemics and outbreaks present arduous challenges, requiring both individual and communal efforts. The significant medical, emotional, and financial burden associated with epidemics creates feelings of distrust, fear, and loss of control, making vulnerable populations prone to exploitation and manipulation through misinformation, rumors, and conspiracies. The use of social media sites has increased in the last decade. As a result, significant amounts of public data can be leveraged for biosurveillance. Social media sites can also provide a platform to quickly and efficiently reach a sizable percentage of the population; therefore, they have a potential role in various aspects of epidemic mitigation.
Objective
This systematic literature review aimed to provide a methodical overview of the integration of social media in 3 epidemic-related contexts: epidemic monitoring, misinformation detection, and the relationship with mental health. The aim is to understand how social media has been used efficiently in these contexts, and which gaps need further research efforts.
Methods
Three research questions, related to epidemic monitoring, misinformation, and mental health, were conceptualized for this review. In the first PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) stage, 13,522 publications were collected from several digital libraries (PubMed, IEEE Xplore, ScienceDirect, SpringerLink, MDPI, ACM, and ACL) and gray literature sources (arXiv and ProQuest), spanning from 2010 to 2022. A total of 242 (1.79%) papers were selected for inclusion and were synthesized to identify themes, methods, epidemics studied, and social media sites used.
Results
Five main themes were identified in the literature, as follows: epidemic forecasting and surveillance, public opinion understanding, fake news identification and characterization, mental health assessment, and association of social media use with psychological outcomes. Social media data were found to be an efficient tool to gauge public response, monitor discourse, identify misleading and fake news, and estimate the mental health toll of epidemics. Findings uncovered a need for more robust applications of lessons learned from epidemic “postmortem documentation.” A vast gap exists between retrospective analysis of epidemic management and result integration in prospective studies.
Conclusions
Harnessing the full potential of social media in epidemic-related tasks requires streamlining the results of epidemic forecasting, public opinion understanding, and misinformation detection, all while keeping abreast of potential mental health implications. Proactive prevention has thus become vital for epidemic curtailment and containment.}
}
@article{CAO2024102307,
title = {Applied AI for finance and accounting: Alternative data and opportunities},
journal = {Pacific-Basin Finance Journal},
volume = {84},
pages = {102307},
year = {2024},
issn = {0927-538X},
doi = {https://doi.org/10.1016/j.pacfin.2024.102307},
url = {https://www.sciencedirect.com/science/article/pii/S0927538X24000581},
author = {Sean Shun Cao and Wei Jiang and Lijun (Gillian) Lei and Qing (Clara) Zhou},
keywords = {Artificial intelligence, Data analytics, Machine learning, Finance},
abstract = {Big data and artificial intelligence (AI) have transformed the finance industry by altering the way data and information are generated, processed, and incorporated into decision-making processes. Data and information have emerged as a new class of assets, facilitating efficient contracting and risk-sharing among corporate stakeholders. Researchers have also increasingly embraced machine learning and AI analytics tools, which enable them to exploit empirical evidence to an extent that far surpasses traditional methodologies. In this review article, prepared for a special issue on Artificial Intelligence (AI) and Finance in the Pacific-Basin Finance Journal, we aim to provide a summary of the evolving landscape of AI applications in finance and accounting research and project future avenues of exploration. Given the burgeoning mass of literature in this field, it would be unproductive to attempt an exhaustive catalogue of these studies. Instead, our goal is to offer a structured framework for categorizing current research and guiding future studies. We stress the importance of blending financial domain expertise with state-of-the-art data analytics skills. This fusion is essential for researchers and professionals to harness the opportunities offered by data and analytical tools to better comprehend and influence our financial system.}
}
@article{YU2025112972,
title = {An intelligent marketing platform with influencer classification in social networking services},
journal = {Knowledge-Based Systems},
volume = {310},
pages = {112972},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.112972},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125000206},
author = {Xiaohong Yu and Jinyong Kim and Yoseop Ahn and Mose Gu and Jaehoon (Paul) Jeong and JinYeong Bak and Jaemin Jo},
keywords = {Social media, SNS, Influencer marketing, Korean text classification, KoELECTRA},
abstract = {Collaborations with influencers in social networking services (SNS) for online commercial advertisement has gained significant momentum in recent years. However, the existing approaches suffer from a lack of precision in matching advertisements to specific target user groups (e.g., influencers). To address the issue, in this paper we present an intelligent marketing platform that classifies influencers based on a newly built SNS post text dataset and the comprehensive performance factors. The proposed platform fine-tunes a pretrained language model with the SNS post text dataset of influencers, which can achieve a better classification accuracy. To further improve the matching accuracy for marketing partners, we integrate multiple performance features of influencers into the proposed platform. Our results show that the proposed model can provide more than 90% classification accuracy for business partners in their product advertisements. Furthermore, we used a real-world business requirement to implement and evaluate the proposed platform with a web-based system, which provides an easy way for online commercial advertisement.}
}
@article{LI2024,
title = {DGFN Multimodal Emotion Analysis Model Based on Dynamic Graph Fusion Network},
journal = {International Journal of Decision Support System Technology},
volume = {16},
number = {1},
year = {2024},
issn = {1941-6296},
doi = {https://doi.org/10.4018/IJDSST.352417},
url = {https://www.sciencedirect.com/science/article/pii/S1941629624000028},
author = {Jingwei Li and Xinyi Bai and Zhaoming Han},
keywords = {Multimodal, Graphic Fusion, Sentiment Analysis},
abstract = {ABSTRACT
In recent years, integrating text and image data for sentiment analysis in social networks has become a key approach. However, techniques for capturing complex cross-modal information and effectively fusing multimodal features still have shortcomings. We design a multimodal sentiment analysis model called the Dynamic Graph-Text Fusion Network (DGFN) to address these challenges. Text features are captured by leveraging the neighborhood information aggregation properties of Graph Convolutional Networks, treating words as nodes and integrating their features through their adjacency relationships. Additionally, the multi-head attention mechanism is utilized to extract rich semantic information from different subspaces simultaneously. For image feature extraction, a convolutional attention module is employed. Subsequently, an attention-based fusion module integrates the text and image features. Experimental results on the two datasets show significant improvements in sentiment classification accuracy and F1 scores, validating the effectiveness of the proposed DGFN model.}
}
@article{DONG2025102243,
title = {Public attitudes toward the Israeli-Palestinian conflict in China: A text mining analysis},
journal = {Telematics and Informatics},
volume = {98},
pages = {102243},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102243},
url = {https://www.sciencedirect.com/science/article/pii/S073658532500005X},
author = {Xuefan Dong and Chen Wang and Ying Lian},
keywords = {Israeli-Palestinian conflict, Public opinion, Text mining analysis, Emotion analysis},
abstract = {This paper investigates how Weibo serves as a symbolic space for Chinese public opinion on the October 2023 Israeli-Palestinian conflict through a text mining analysis of Weibo posts. Using Named Entity Recognition, emotion analysis, topic clustering, and opinion mining, the study reveals key themes, entities, and emotional responses among Chinese netizens. The analysis shows that Chinese netizens express views on humanitarian concerns, calls for peace, support for Palestinian national liberation, and demands for accurate information. Emotion-opinion cross-analysis reveals that their responses are shaped by a mix of emotions, including anger towards external geopolitical forces, fear and sadness regarding humanitarian impacts, and hope for peace and resolution. These emotions illustrate the complex interplay between humanitarian concerns, political stances, and support for diplomacy, demonstrating Weibo’s role as a platform for amplifying public sentiment. The study also examines how Chinese public opinion aligns with the Chinese government’s stance on international affairs. Findings indicate broad support for the government’s diplomatic efforts, such as calls for ceasefire, humanitarian aid, and mediation. This alignment reflects an expectation for China to actively contribute to global peace and stability. Additionally, the study uncovers critical perspectives on external influences, with many netizens criticizing perceived biases in international responses and advocating for a balanced, multilateral diplomatic approach. Overall, this research highlights how a distant geopolitical crisis is understood in China’s socio-political context, revealing an emerging global consciousness among Chinese netizens. This shift, facilitated by Weibo, reflects a movement from a state-centric narrative to an active public engagement with global issues.}
}
@article{SYKORA2022997,
title = {The power of emotions: Leveraging user generated content for customer experience management},
journal = {Journal of Business Research},
volume = {144},
pages = {997-1006},
year = {2022},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2022.02.048},
url = {https://www.sciencedirect.com/science/article/pii/S0148296322001679},
author = {Martin Sykora and Suzanne Elayan and Ian R. Hodgkinson and Thomas W. Jackson and Andrew West},
keywords = {Customer experience management, Sentiment analysis, Social media, Emotion analytics, Bot automation},
abstract = {Customer experience management (CEM) in the social media age finds itself needing to adapt to a rapidly changing digital environment and hence there is a need for innovative digital data analytical solutions. Drawing on an action case study of a large global automotive manufacturer, this study presents a digital innovation for enhanced emotion analytics on user generated content (UGC) and behaviour (UGB), to improve consumer insights for CEM. The digital innovation captures customer experience in real time, enabling measurement of a wide range of discrete emotions on the studied social media platform, which goes beyond traditional tools that capture positive or negative sentiment only. During the digital intervention, a substantial number of inauthentic and bot like behaviours was revealed, unbeknown to the case organisation. These accounts were found to be posting and amplifying highly emotional and potentially damaging content surrounding the case brand and its products. The study illustrates how emotion in the context of customer experience should go beyond typical categorisations, given the complexity of human emotion, while a distinction between bot and authentic users is imperative for CEM.}
}
@article{LIU2022178,
title = {FeatInter: Exploring fine-grained object features for video-text retrieval},
journal = {Neurocomputing},
volume = {496},
pages = {178-191},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.01.094},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222001187},
author = {Baolong Liu and Qi Zheng and Yabing Wang and Minsong Zhang and Jianfeng Dong and Xun Wang},
keywords = {Cross-modal retrieval, Video-text retrieval, Feature interaction, Visual semantic interaction, Fine-grained object feature},
abstract = {In this paper, we target the challenging task of video-text retrieval. The common way for this task is to learn a text-video joint embedding space by cross-modal representation learning, and compute the cross-modality similarity in the joint space. As videos typically contain rich information, how to represent videos in a joint embedding space is crucial for video-text retrieval. The majority of works typically depend on pre-extracted frame-level features or clip-level features for video representation, which may cause fine-grained object information in videos to be ignored. To alleviate it, we explicitly introduce more fine-grained object-level features to enrich video representation. In order to exploit the potential of the object-level features, we propose a new model named FeatInter, which jointly considers the visual and semantic features of objects. Besides, a visual-semantic interaction and a cross-feature interaction are proposed to mutually enhance object features and frame features. Extensive experiments on two challenging video datasets, i.e., MSR-VTT and TGIF, demonstrate the effectiveness of our proposed model. Moreover, our model achieves a new state-of-the-art on TGIF. While the state-of-the-art methods use seven video features on MSR-VTT, our model with just three features obtains comparable performance.}
}
@article{GUPTA2025127864,
title = {Investigating the impact of sentiments on stock market using digital proxies: Current trends, challenges, and future directions},
journal = {Expert Systems with Applications},
volume = {285},
pages = {127864},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127864},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425014861},
author = {Tapas Gupta and Shridev Devji and Ashish Kumar Tripathi},
keywords = {Stock market prediction, Social media, Digital news, Machine learning, Deep learning, Large language models},
abstract = {Social media and online news have emerged as significant sources of market sentiment, influencing stock market dynamics globally. With the growing availability of digital data, the current research focus is on leveraging advanced computational techniques for sentiment-driven stock market prediction. The era of financial forecasting has been revolutionized by integrating cutting-edge technologies such as Machine Learning, Deep Learning, and Large Language Models. In this paper, a comprehensive survey of 108 research articles has been undertaken to explore the recent advancements in these technologies, with a focus on utilizing sentiment data extracted from social media platforms and news sources. The technology-wise state-of-the-art findings, current trends, challenges, and literature gaps in this domain are analyzed, and potential future directions are proposed to address these gaps. Additionally, publicly available benchmark datasets for social media and news sentiment indices are compiled and analyzed, with insights into their limitations and potential improvements. A comparative evaluation of prediction methods across heterogeneous user-generated datasets is performed, identifying the most effective techniques for various data types and problem formulations. Recommendations are offered for selecting suitable techniques based on the nature of the data and the specific problem formulation. By incorporating the latest advancements in the field of sentiment analysis and stock market prediction, this work provides actionable insights for researchers and practitioners, advancing the understanding and development of sentiment-driven financial forecasting.}
}
@article{ZHOU2026100818,
title = {Sequential recommender systems: A methodological taxonomy and research frontiers},
journal = {Computer Science Review},
volume = {59},
pages = {100818},
year = {2026},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100818},
url = {https://www.sciencedirect.com/science/article/pii/S1574013725000942},
author = {Yanbo Zhou and Gang-Feng Ma and Xilin Wen and Xu-Hua Yang and Yi-Cheng Zhang},
keywords = {Sequential recommendation, Sequential modeling, Deep learning, Temporal dynamic, Network model, Contrastive learning, LLMs},
abstract = {In the era of information overload, sequential recommender systems have emerged as pivotal tools for modeling user preferences through dynamic behavioral pattern mining. These systems transcend conventional recommendation paradigms by explicitly modeling temporal dependencies in user–item interactions, preference evolution, and contextual dynamics. This study presents a methodologically structured taxonomy of sequential recommender systems through four analytical dimensions: (1) Sequential Modeling, which includes methods ranging from statistical techniques to deep learning architectures to understand user behavior patterns; (2) Temporal Dynamics Modeling, which involves time-aware collaborative filtering and deep temporal modeling; (3) Network-Enhanced Modeling, which leverages graph neural networks, heterogeneous graphs, dynamic graphs, and hypergraphs to explore structural dependencies; and (4) Robust Representation Learning, which encompasses contrastive mechanisms and techniques driven by large language models (LLMs). These algorithms focus on different aspects of sequential recommendation, including but not limited to capturing dynamic interests, modeling long- and short-term preferences, and addressing issues such as data sparsity, noise, and bias, which affect the performance and user experience of recommender systems in practical applications. Furthermore, we summarize and discuss promising future research directions to provide theoretical and methodological insights. The constructed taxonomy not only organizes existing methodological innovations, but also reveals fundamental limitations in current evaluation protocols, providing a roadmap for advancing both theoretical foundations and practical applications in this domain.}
}
@article{SUN2025130852,
title = {Memory-VQA: Video quality assessment of UGC based on human memory system},
journal = {Neurocomputing},
volume = {650},
pages = {130852},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130852},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225015243},
author = {Minjie Sun and Guangqian Kong and Xun Duan and Huiyun Long},
keywords = {Video quality assessment, Human memory system, Human visual system, Temporal modeling},
abstract = {The rapid expansion of user-generated content (UGC) videos poses a significant challenge to video quality assessment (VQA) algorithms. Previous research in UGC-VQA has primarily aimed to capture temporal and spatial distortions in videos or replicate the subjective perception of videos by the human visual system (HVS). However, VQA is a protracted process that requires careful observation, comparison, and memorization of video content rather than instant assessment. This paper proposes the Memory-VQA method, drawing on insights from the human memory system (HMS). The method integrates five stages related to memory and is an early attempt to bring the process of memory formation to the VQA domain. At the outset of memory perception, theories of memory formation and reconstruction were used to segment the video into sequences with varying frame rates. Following segmentation, the video’s motion and spatial attributes were isolated during the memory encode phase, taking into account their influence on memory consolidation. To simulate memory loss, the encode features undergo a linear transformation, and their configurations are modified during the memory storage process. Subsequently, keyframes are integrated with previously stored features based on cue-driven theory, facilitating the extraction of spatio-temporal characteristics during the memory retrieval phase. Additionally, the introduction of a novel attention module enhances the nuanced perception of details in the memory retrieval process. In the final phase of the memory reconstruction module, subliminal effects integrate encode and retrieval characteristics to predict quality. The experimental results demonstrate that the proposed method achieves the best performance on five popular UGC-VQA datasets. The code is available at https://github.com/luoshui123/Memory-vqa.}
}
@article{ELROY2024100256,
title = {Cyber-echoes of climate crisis: Unraveling anthropogenic climate change narratives on social media},
journal = {Current Research in Environmental Sustainability},
volume = {7},
pages = {100256},
year = {2024},
issn = {2666-0490},
doi = {https://doi.org/10.1016/j.crsust.2024.100256},
url = {https://www.sciencedirect.com/science/article/pii/S2666049024000161},
author = {Or Elroy and Nadejda Komendantova and Abraham Yosipof},
keywords = {Climate change, Clustering, Natural language processing, Social media, Policy, Misinformation},
abstract = {Social media platforms have a key role in spreading narratives about climate change, and therefore it is crucial to understand the discussion about climate change in social media. The discussion on anthropogenic climate change in general, and social media specifically, has multiple different narratives. Understanding the discourses can assist efforts of mitigation, adaptation, and policy measures development. In this work, we collected 333,635 tweets in English about anthropogenic climate change. We used Natural Language Processing (NLP) and machine learning methods to embed the semantic meaning of the tweets into vectors, cluster the tweets, and analyze the results. We clustered the tweets into four clusters that correspond to four narratives in the discussion. Analyzing the behavioral dynamics of each cluster revealed that the clusters focus on the discussion of whether climate change is caused by humans or not, scientific arguments, policy, and conspiracy. The research results can serve as input for media policy and awareness-raising measures on climate change mitigation and adaptation policies, and facilitating future communications related to climate change.}
}
@article{SHEN2026129566,
title = {Forecasting tourism stock index dynamics: a multiscale deep learning framework integrating emerging media data},
journal = {Expert Systems with Applications},
volume = {298},
pages = {129566},
year = {2026},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.129566},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425031811},
author = {Feng Shen and Shuai Huang and Wanqing Zhao and Dao Lan},
keywords = {Tourism stock index, Time series forecasting, Emerging media data, Multiscale decomposition, Deep learning},
abstract = {This study introduces a novel multiscale and multivariable deep learning framework for tourism stock index forecasting. To address the research gap concerning emerging media’s impact on the tourism sector, our study innovatively integrate multi-source data, including Douyin (China’s prominent short video platform), into our predictive model. Our methodology employs a multiscale decomposition strategy to streamline feature extraction complexity, coupled with an enhanced temporal convolutional network model incorporating soft-thresholding denoising to mitigate noise interference. Furthermore, we implement an adaptive differentiated prediction strategy to optimize model flexibility. Empirical analysis utilizing the CSI Tourism Stock Index demonstrates that our proposed model outperforms benchmark models in both predictive accuracy and stability, thereby validating its efficacy in tourism stock index forecasting.}
}
@article{MAHAJAN2024121228,
title = {EnsMulHateCyb: Multilingual hate speech and cyberbully detection in online social media},
journal = {Expert Systems with Applications},
volume = {236},
pages = {121228},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.121228},
url = {https://www.sciencedirect.com/science/article/pii/S095741742301730X},
author = {Esshaan Mahajan and Hemaank Mahajan and Sanjay Kumar},
keywords = {Hate speech detection, Cyberbully detection, Ensemble deep learning, BiLSTM, Bi-GRU, Multilingual data streams},
abstract = {Nowadays, users across the globe interact with one another for information exchange, communication, and association on various online social media. However, some individuals exploit these venues for malicious practices like hate speech and cyberbully. In this paper, we present an improved multilingual hate speech and cyberbully detection model using bagging-stacking based hybrid ensemble deep learning techniques. The proposed model utilizes Bi-directional Long Short-Term Memory (BiLSTM), Bi-directional Gated Recurrent Unit (Bi-GRU), Convolutional Neural Network (CNN), and Long Short-Term Memory (LSTM) techniques to enhance the overall performance. We first preprocess the multilingual data streams followed by adoption of Global vectors for word Representation (GloVe) embeddings to convert words to a vector representation in parallel enabling the data streams for binary classification task. In order to construct an architecture for the detection of hate speech and cyberbully, we introduce a heterogeneous fusion of multiple effective models in a unique approach such that CNN-LSTM utilizes a stacking approach with stochastic gradient descent to achieve optimal weights, whereas all the base learners used bagging ensemble approach with cross-validation to reach optimal weights. The final output layer of the proposed ensemble deep learning architecture is achieved using a super learner approach on base learners. To show the efficacy of the proposed model, we conduct the simulation on a total of nine real-world social media datasets in different languages and compared the results with other contemporary hate speech and cyberbully detection methods. The collected findings show that the proposed model outperforms other models on considered datasets and shows an improvement of at least 4.44% in F1 scores.}
}
@article{PICKETT2024,
title = {Social Media Discourse Related to Caregiving for Older Adults Living With Alzheimer Disease and Related Dementias: Computational and Qualitative Study},
journal = {JMIR Aging},
volume = {7},
year = {2024},
issn = {2561-7605},
doi = {https://doi.org/10.2196/59294},
url = {https://www.sciencedirect.com/science/article/pii/S2561760524000537},
author = {Andrew C Pickett and Danny Valdez and Kelsey L Sinclair and Wesley J Kochell and Boone Fowler and Nicole E Werner},
keywords = {caregiving, dementia, social support, social media, Reddit},
abstract = {Background
In the United States, caregivers of people living with Alzheimer disease and Alzheimer disease–related dementias (AD/ADRD) provide >16 billion hours of unpaid care annually. These caregivers experience high levels of stress and burden related to the challenges associated with providing care. Social media is an emerging space for individuals to seek various forms of support.
Objective
We aimed to explore the primary topics of conversation on the social media site Reddit related to AD/ADRD. We then aimed to explore these topics in depth, specifically examining elements of social support and behavioral symptomology discussed by users.
Methods
We first generated an unsupervised topic model from 6563 posts made to 2 dementia-specific subreddit forums (r/Alzheimers and r/dementia). Then, we conducted a manual qualitative content analysis of a random subset of these data to further explore salient themes in the corpus.
Results
The topic model with the highest overall coherence score (0.38) included 10 topics, including caregiver burden, anxiety, support-seeking, and AD/ADRD behavioral symptomology. Qualitative analyses provided added context, wherein users sought emotional and informational support for many aspects of the care experience, including assistance in making key care-related decisions. Users expressed challenging and complex emotions on Reddit, which may be taboo to express in person.
Conclusions
Reddit users seek many different forms of support, including emotional and specific informational support, from others on the internet. Users expressed a variety of concerns, challenges, and behavioral symptoms to manage as part of the care experience. The unique (ie, anonymous and moderated) nature of the forum allowed for a safe space to express emotions free from documented caregiver stigma. Additional support structures are needed to assist caregivers of people living with AD/ADRD.}
}
@article{ZHANG2024102719,
title = {Subjective and objective quality evaluation of UGC video after encoding and decoding},
journal = {Displays},
volume = {83},
pages = {102719},
year = {2024},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2024.102719},
url = {https://www.sciencedirect.com/science/article/pii/S0141938224000830},
author = {Yuheng Zhang and Jia Wang and Yucheng Zhu and Rong Xie},
keywords = {Video quality assessment, User-generated-content, Encoding and decoding},
abstract = {The development of the Internet and new media technology has given rise to various forms of media to meet users’ usage needs and expectations. User-Generated-Content (UGC) videos have become a way for users to maximize their participation and express themselves. A large number of UGC videos are uploaded every day on platforms such as Tiktok, Kwai, and Station B. However, the quality of UGC videos is also mixed, with videos with poor image quality providing viewers with a lower user experience. Media service providers need to compress videos uploaded by users to reduce transmission bit rates. How to evaluate the quality of compressed UGC videos is crucial for selecting an appropriate bit rate. In this paper, we have established a UGC database called UGC-New. Concretely, 405 UGC source videos are collected from major video platforms and we encoded the original video using H.264 and H.265 to obtain 2430 distorted videos, resulting in a total of 2835 videos in the dataset. We conducted a subjective human study on this database and obtained 56700 human quality ratings recorded by 100 subjects. At the same time, we also tested a series of VQA models on the dataset for objective analysis and evaluation, including a new one, called New-VQA.}
}
@article{YU2025105245,
title = {Multimodality in tourism and hospitality: A critical and narrative review},
journal = {Tourism Management},
volume = {111},
pages = {105245},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105245},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001153},
author = {Xiaoxi Yu and Mingming Cheng},
keywords = {Multimodal data analytics, Multimodal fusion, Validity, Narrative review, Machine learning},
abstract = {Although multimodal data offers valuable insights for tourism and hospitality research and practice, it also poses significant theoretical and methodological challenges. Through a narrative and critical literature review, this research develops the multimodal data analytics methodological framework as a novel guiding principle to theoretically engage with multimodal data. The research identifies a number of critical issues to consider when approaching multimodal data, particularly multimodal fusion and analytical validity. It also highlights how multimodal data can be used to test, extend and develop theories in tourism, providing a roadmap for future research in pushing the boundaries of multimodal data in tourism and hospitality.}
}
@article{WANG2024110685,
title = {An empirical study on the robustness of the segment anything model (SAM)},
journal = {Pattern Recognition},
volume = {155},
pages = {110685},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.110685},
url = {https://www.sciencedirect.com/science/article/pii/S0031320324004369},
author = {Yuqing Wang and Yun Zhao and Linda Petzold},
keywords = {Segment anything model, Model robustness, Prompting techniques},
abstract = {The Segment Anything Model (SAM) is a foundation model for general image segmentation. Although it exhibits impressive performance predominantly on natural images, understanding its robustness against various image perturbations and domains is critical for real-world applications where such challenges frequently arise. In this study we conduct a comprehensive robustness investigation of SAM under diverse real-world conditions. Our experiments encompass a wide range of image perturbations. Our experimental results demonstrate that SAM’s performance generally declines under perturbed images, with varying degrees of vulnerability across different perturbations. By customizing prompting techniques and leveraging domain knowledge based on the unique characteristics of each dataset, the model’s resilience to these perturbations can be enhanced, addressing dataset-specific challenges. This work sheds light on the limitations and strengths of SAM in real-world applications, promoting the development of more robust and versatile image segmentation solutions. Our code is available at https://github.com/EternityYW/SAM-Robustness/.}
}
@article{ZHANG2024105478,
title = {Have we found a solution for health misinformation? A ten-year systematic review of health misinformation literature 2013–2022},
journal = {International Journal of Medical Informatics},
volume = {188},
pages = {105478},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105478},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001412},
author = {Shiyi Zhang and Huiyu Zhou and Yimei Zhu},
keywords = {Misinformation, Health misinformation, Trust, Solutions to health misinformation},
abstract = {Background
Health misinformation (HM) has emerged as a prominent social issue in recent years, driven by declining public trust, popularisation of digital media platforms and escalating public health crisis. Since the Covid-19 pandemic, HM has raised critical concerns due to its significant impacts on both individuals and society as a whole. A comprehensive understanding of HM and HM-related studies would be instrumental in identifying possible solutions to address HM and the associated challenges.
Methods
Following the PRISMA procedure, 11,739 papers published from January 2013 to December 2022 were retrieved from five electronic databases, and 813 papers matching the inclusion criteria were retained for further analysis. This article critically reviewed HM-related studies, detailing the factors facilitating HM creation and dissemination, negative impacts of HM, solutions to HM, and research methods employed in those studies.
Results
A growing number of studies have focused on HM since 2013. Results of this study highlight that trust plays a significant while latent role in the circuits of HM, facilitating the creation and dissemination of HM, exacerbating the negative impacts of HM and amplifying the difficulty in addressing HM.
Conclusion
For health authorities and governmental institutions, it is essential to systematically build public trust in order to reduce the probability of individuals acceptation of HM and to improve the effectiveness of misinformation correction. Future studies should pay more attention to the role of trust in how to address HM.}
}
@article{HU2025129756,
title = {Homophone-Aware Offensive Language Detection via Semantic-Phonetic Collaboration},
journal = {Expert Systems with Applications},
pages = {129756},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.129756},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425033718},
author = {Jiahao Hu and Shanliang Pan},
keywords = {Chinese offensive language detection, homophone substitution, Multi-view Learning, pinyin feature, Dual-Branch Interactive Training},
abstract = {The increasing use of implicit and obfuscated expressions poses significant challenges to offensive language detection in Chinese online platforms. In particular, users often exploit homophone substitutions to bypass keyword-based moderation, making traditional detection systems inadequate. This study addresses the problem of detecting offensive content masked through homophonic substitutions, which retain aggressive intent while altering character representations. Existing methods fall into two main categories: (1) semantic-only models, which struggle with phonetic manipulations due to their reliance on text features alone, and (2) auxiliary-enhanced models, which incorporate phonetic or syntactic signals but lack deep integration between modalities. To overcome these limitations, we propose a lightweight dual-branch model that separately encodes textual semantics and pinyin phonetics under a multi-view learning framework. A Dual-Branch Interactive Training strategy is introduced to enable dynamic cross-modal alignment via contrastive objectives, allowing each modality to mutually refine the other and enhance robustness to adversarial inputs. We conduct experiments on two benchmark datasets, COLD and SWSR, both of which are augmented with varying levels of homophone noise to simulate real-world evasion strategies. The proposed model outperforms all baseline models, achieving an average F1-score improvement of 6.3% under high-noise conditions, while reducing inference latency and memory usage by more than 60%, demonstrating both effectiveness and efficiency for real-time deployment. We will release the source code for further use by the communityhttps://github.com/hjhhlc/DBIT.}
}
@article{MA2025100418,
title = {Exploring Food Safety Emergency Incidents on Sina Weibo: Using Text Mining and Sentiment Evolution},
journal = {Journal of Food Protection},
volume = {88},
number = {1},
pages = {100418},
year = {2025},
issn = {0362-028X},
doi = {https://doi.org/10.1016/j.jfp.2024.100418},
url = {https://www.sciencedirect.com/science/article/pii/S0362028X24002023},
author = {Biao Ma and Ruihan Zheng},
keywords = {Deep learning, Food safety, Sentiment analysis, Text mining},
abstract = {Food safety remains a crucial concern in both public health and societal stability. In the age of information technology, social media has emerged as a pivotal channel for shaping public opinion and disseminating information, exerting a substantial influence on how the public perceives incidents related to food safety. This study specifically focuses on the “Rat-Headed Duck Neck” incident as a case study, conducting a comprehensive analysis of extensive social media data to investigate how online public discourse molds perceptions of such events. To accomplish this research, data were initially gathered using a custom web crawler technology. These data encompassed various aspects, including user interactions, emotional expressions, and the evolution of topics. Subsequently, the study employed an innovative approach by combining BERT-TextCNN and BERTopic models for a thorough analysis of sentiment and thematic aspects of the textual data. This analysis provided insights into the intricate emotions and primary concerns of the public regarding incidents related to food safety. Furthermore, the research harnessed Gephi, a network analysis tool, to scrutinize the dissemination of information within the network and to monitor dynamic shifts in public opinion. The findings from this study not only shed light on the role of online public sentiment in the propagation of food safety events but also provide fresh perspectives for policymakers and business leaders when responding to similar crises, taking into account the subtleties of online public sentiment. These innovative methodologies and findings significantly enhance our comprehension of public responses to food safety incidents within the realm of social media.}
}
@article{LI2024103624,
title = {Let model keep evolving: Incremental learning for encrypted traffic classification},
journal = {Computers & Security},
volume = {137},
pages = {103624},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103624},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823005345},
author = {Xiang Li and Jiang Xie and Qige Song and Yafei Sang and Yongzheng Zhang and Shuhao Li and Tianning Zang},
keywords = {Encrypted traffic classification, Evolve, Incremental learning, Multi-view sequences, Cross-view information, Exemplar selection},
abstract = {Encrypted Traffic Classification (ETC) is valuable for many network management and security solutions as it provides insights into applications active on the network. However, the network environment constantly evolves, and new applications emerge in an endless stream daily, which gradually makes well-trained ETC models ineffective. The conventional approach to adapting new applications is to re-train the models on a re-formed dataset with both pre-existing and new application samples. The major limitation is that requiring redundant computing resources and sufficient storage spaces. In this work, we propose an Incremental Learning (IL) framework based on multi-view sequences fusion, MISS, to keep ETC models evolving with new applications. The key novelty of MISS is three-fold: extract cross-view information from multi-view sequences to capture sufficient knowledge; propose an exemplar selection algorithm from communication patterns to reduce redundant consumption; design a pair of branches from the learnability of parameters to mitigate accuracy loss during evolution. MISS outperforms the existing IL methods of ETC, and the state-of-the-art ETC models using the classic IL framework, on the real-world network traffic datasets, which achieves satisfactory improvements of 11.37%↑ and 1.58%↑. Furthermore, we comprehensively perform incremental experiments to evaluate the evolution ability of MISS, which is able to select representative exemplars of old applications, counteract the adverse effects of homogeneous applications, and keep evolving with unknown applications.}
}
@article{WANG2026103559,
title = {MotionAnimate: Animate human images with pose motion for vivid and temporally consistent video generation},
journal = {Information Fusion},
volume = {126},
pages = {103559},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103559},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525006311},
author = {Ruoyu Wang and Shaowei Wang and Rui Gong and Chen Cai and Jianjun Gao and Wenqian Wang and Wenyang Liu and Kim-Hui Yap},
keywords = {Video generation, Human image animation, Diffusion model},
abstract = {Human image animation involves generating a video by animating a static image conditioned on a sequence of human poses. Existing methods typically rely only on frame-level poses for guidance, overlooking the critical motion patterns and temporal dependencies embedded within the pose sequence. Consequently, insufficient control over motion dynamics results in poor temporal consistency and degraded visual quality in generated videos. To address these limitations, we propose MotionAnimate, a novel framework enabling image animation through explicit sequence-level motion control. This control is realized by coupled Motion Transfer Modules that operate seamlessly across MotionNet and a denoising UNet, effectively extracting and integrating pose motion patterns into generated videos. Within MotionNet, the Motion Transfer Modules leverage temporal layers to capture temporal dependencies in pose sequences, enhancing motion representation. The representations are then transferred via coupled modules, where a dynamic motion attention mechanism adaptively deforms temporal attention in the UNet to reconstruct aligned motion dynamics. To further enhance generation capability, we propose a motion-aware pose masking strategy during training, significantly benefiting temporal dynamics modeling. Extensive qualitative experiments demonstrate that our method substantially enhances motion consistency and video coherence, and quantitative results indicate that our approach achieves state-of-the-art performance, with a 30.8% improvement in FID-VID.}
}
@article{RAZA2024e35812,
title = {An improved deep convolutional neural network-based YouTube video classification using textual features},
journal = {Heliyon},
volume = {10},
number = {16},
pages = {e35812},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35812},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024118439},
author = {Ali Raza and Faizan Younas and Hafeez Ur Rehman Siddiqui and Furqan Rustam and Monica Gracia Villar and Eduardo Silva Alvarado and Imran Ashraf},
keywords = {YouTube video categorization, Convolutional neural network, Text categorization, Text features},
abstract = {Video content on the web platform has increased explosively during the past decade, thanks to the open access to Facebook, YouTube, etc. YouTube is the second-largest social media platform nowadays containing more than 37 million YouTube channels. YouTube revealed at a recent press event that 30,000 new content videos per hour and 720,000 per day are posted. There is a need for an advanced deep learning-based approach to categorize the huge database of YouTube videos. This study aims to develop an artificial intelligence-based approach to categorize YouTube videos. This study analyzes the textual information related to videos like titles, descriptions, user tags, etc. using YouTube exploratory data analysis (YEDA) and shows that such information can be potentially used to categorize videos. A deep convolutional neural network (DCNN) is designed to categorize YouTube videos with efficiency and high accuracy. In addition, recurrent neural network (RNN), and gated recurrent unit (GRU) are also employed for performance comparison. Moreover, logistic regression, support vector machines, decision trees, and random forest models are also used. A large dataset with 9 classes is used for experiments. Experimental findings indicate that the proposed DCNN achieves the highest receiver operating characteristics (ROC) area under the curve (AUC) score of 99% in the context of YouTube video categorization and 96% accuracy which is better than existing approaches. The proposed approach can be used to help YouTube users suggest relevant videos and sort them by video category.}
}
@article{ZHANG2024100124,
title = {Co-creating with ChatGPT for tourism marketing materials},
journal = {Annals of Tourism Research Empirical Insights},
volume = {5},
number = {1},
pages = {100124},
year = {2024},
issn = {2666-9579},
doi = {https://doi.org/10.1016/j.annale.2024.100124},
url = {https://www.sciencedirect.com/science/article/pii/S2666957924000065},
author = {Yaozhi Zhang and Nina Katrine Prebensen},
keywords = {Tourism marketing, Generative AI, ChatGPT, Turing test, Co-creation},
abstract = {The launch of ChatGPT has the potential to disrupt conventional approaches to tourism marketing. In this context, the present research explores the distinguishability between marketing content created by ChatGPT and that by tourism marketers, while also comparing their respective effects on downstream tourism marketing outcomes. Drawing on two online experiments aligned with realistic destination marketing endeavors, the findings reveal that tourism marketing materials created by ChatGPT successfully pass the Turing Test and achieve textual fluency and perceived attractiveness that are no lower than those yielded by tourism marketers. This study provides preliminary experimental evidence showing the efficacy of applying generative AI like ChatGPT in creating tourism marketing materials, advocating a co-creation relationship between generative AI and tourism marketers.}
}
@article{KIM2025111130,
title = {A hybrid detection method for YouTube fake news using related video data},
journal = {Engineering Applications of Artificial Intelligence},
volume = {156},
pages = {111130},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111130},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625011315},
author = {Junho Kim and Yongjun Shin and Gyeongho Jung and Hyunchul Ahn},
keywords = {Hybrid fake news detection, YouTube fake news, Related videos, Word embedding, Convolutional neural network},
abstract = {Fake news has rapidly evolved from simple textual forms to complex multimedia content, with YouTube emerging as a major platform for its dissemination. However, most existing detection techniques focus solely on content-based features, often overlooking the contextual signals embedded in related video data. We propose a novel hybrid detection framework that integrates content- and context-based approaches to address this limitation. Our method combines multimodal features extracted from textual and visual components of the original video, along with contextual information from related videos. Text data is processed using word embedding techniques, while image and visual elements are analyzed through Convolutional Neural Networks. To evaluate our framework's robustness and generalizability, we conducted experiments on two complementary datasets: a publicly available multilingual dataset and a newly constructed Korean dataset. The results show that the proposed method achieves a 0.1–9.7 % improvement in detection accuracy compared to traditional content-only approaches. These findings underscore the value of leveraging related video information for more reliable fake news detection, and they confirm that our hybrid method can be effectively applied across diverse language and regional contexts. Our work contributes to mitigating the societal harm caused by misinformation on video-sharing platforms and offers practical insights into developing more robust multimedia fake news detection systems.}
}
@article{JING2024127905,
title = {An empirical study of excitation and aggregation design adaptions in CLIP4Clip for video–text retrieval},
journal = {Neurocomputing},
volume = {596},
pages = {127905},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127905},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224006763},
author = {Xiaolun Jing and Genke Yang and Jian Chu},
keywords = {CLIP4Clip, Excitation-and-aggregation design, Aggregation design, Excitation design, Video–text retrieval},
abstract = {CLIP4Clip model transferred from the CLIP has been the de-factor standard to solve the video clip retrieval task from frame-level input, triggering the surge of CLIP4Clip-based models in the video–text retrieval domain. In this work, we rethink the inherent limitation of widely-used mean pooling operation in the frame features aggregation and investigate the adaptions of excitation and aggregation design for discriminative video representation generation. We present a novel excitation-and-aggregation design, including (1) The excitation module is available for capturing non-mutually-exclusive relationships among frame features and achieving frame-wise features recalibration, and (2) The aggregation module is applied to learn exclusiveness used for frame representations aggregation. Similarly, we employ the cascade of sequential module and aggregation design to generate discriminative video representation in the sequential type. Besides, we adopt the excitation design in the tight type to obtain representative frame features for multi-modal interaction. The proposed modules are evaluated on three benchmark datasets of MSR-VTT, ActivityNet and DiDeMo, achieving MSR-VTT (43.9 R@1), ActivityNet (44.1 R@1) and DiDeMo (31.0 R@1). They outperform the CLIP4Clip results by +1.2% (+0.5%), +4.5% (+1.9%) and +9.5% (+2.7%) relative (absolute) improvements, demonstrating the superiority of our proposed excitation and aggregation designs. We hope our work will serve as an alternative for frame representations aggregation and facilitate future research.}
}
@article{HUANG2025114529,
title = {Decoding LLMs' verbal deception in online reviews},
journal = {Decision Support Systems},
pages = {114529},
year = {2025},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2025.114529},
url = {https://www.sciencedirect.com/science/article/pii/S0167923625001307},
author = {Yinghui Huang and Jinyi Zhou and Wanghao Dong and Weiqing Li and Maomao Chi and Changbin Jiang and Weijun Wang and Shasha Deng},
keywords = {LLM evaluation, Fake review detection, Online review, Deep learning, eXplainable artificial intelligence, Deception detection theories},
abstract = {The proliferation of fake online reviews, a long-standing threat to platform trust, is now exacerbated by Large Language Models (LLMs) capable of generating highly convincing deceptive text. Understanding the linguistic strategies LLMs employ is crucial for developing effective mitigation. To address this, this study develops an eXplainable Artificial Intelligence (XAI)-based computational framework, grounded in deception detection theories,to analyze and distinguish the deceptive patterns of LLMs. A core component of methodology is a novel Turing Test designed for LLMs-generated online fake reviews. When applied to three purpose-built datasets, our framework not only achieves high detection accuracy for both human- (96.57 %) and LLM-generated fakes (96.13 %)—substantially outperforming current general-purpose detectors—but also confirms that LLMs possess a human-level deceptive capability (all metric discrepancies <0.72 %). The analysis reveals that while cues related to cognitive load and perceptual details are powerful discriminators for both human and machine deception, certainty uniquely signals LLM-generated text, whereas emotion is a significant predictor only for human fakes. These findings support a central dissociation hypothesis between linguistic generation and cognitive representation: LLM deception is characterized by strategies like a-cognitive fluency in syntax, disembodied realism in content, and pathological positivity in tone. This study probes the mechanistic differences between human and machine deception, delivers a robust computational detection framework, and advances the theoretical discourse on AI's capacity for deceit.}
}
@article{ZHOU2025104179,
title = {Classification and severity assessment of disaster losses based on multi-modal information in social media},
journal = {Information Processing & Management},
volume = {62},
number = {5},
pages = {104179},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104179},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325001207},
author = {Wei Zhou and Lu An and Ruilian Han and Gang Li},
keywords = {Multi-modal information, Social media, Disaster loss classification, Severity assessment},
abstract = {Capture and fine-grained classification of disaster loss information, combined with severity assessment are essential for emergency management departments to carry out effective emergency rescue measures. With the rapid development of social media platforms, the vast amount of user posts on social media provides critical disaster loss information during disasters. In this study, a fine-grained multimodal information-based disaster losses classification (MIDLC) model is proposed to identify the different types of disaster losses from massive social media data. This model uses three datasets, i.e., microblogging posts, government announcements about public events, and microblogging images. The disaster losses are divided into five types, i.e., casualties, houses and buildings collapse, municipal infrastructure damage, public service facilities damage, and impact on production and daily activities. Subsequently, this study proposes a disaster loss severity assessment system to evaluate the severity of different types of disaster loss reflected by social media, guiding targeted rescue response activities. The severity assessment system measures the severity from four dimensions: event information characteristics, information dissemination strength, official response, and user emotional volatility. Finally, the proposed MIDLC model and the severity assessment system are illustrated by investigating three disaster events. Results show that the MIDLC model proposed in this study significantly improves the performance of disaster losses classification. In these five disaster loss types, positive correlation exists between the casualty losses and houses and buildings collapse losses.}
}
@article{XIU2026103472,
title = {Dual-layer cross-modal alignment recommendation based on the diffusion model},
journal = {Information Fusion},
volume = {125},
pages = {103472},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103472},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525005457},
author = {Yuhan Xiu and Xiangrong Tong},
keywords = {Multimodal recommendation, Cross-modal alignment, Imbalanced data, Self-supervised learning, Graph convolution network},
abstract = {Multimodal recommendation systems have attracted attention for effectively integrating multimodal information, such as user behavior, product images, and text. Existing methods usually mitigate the issue of multimodal data imbalance and inconsistency through data augmentation and alignment strategies. However, they fail to fully mine the information of each modality and introduce semantic bias during the alignment process, resulting in the loss of user behavior information and the difficulty of capturing modality associations and user preferences. To address that, this paper proposes a dual-layer cross-modal alignment recommendation based on the diffusion model (DCAR-DM). Specifically, the approach uses the diffusion model to generate a user-item interaction graph with the same number of interactions for each modality and then reconstructs it by filtering the interactions that best match the user’s interests for each modality through the modality contribution regulation mechanism. Then, DCAR-DM generates final user and item embeddings by aggregating modality information through graph convolutional networks (GCN). In addition, DCAR-DM uses a dual-layer cross-modal alignment mechanism to guide modality alignment. The feature alignment layer represents modalities as Gaussian distributions and minimizes the mean and standard deviation to align the inter-modal features. The behavior alignment layer further aligns the modality features by leveraging the real user-item interaction behaviors through contrastive learning to correct the semantic bias generated during the feature alignment process. The experimental results demonstrate the effectiveness of DCAR-DM on three public datasets.}
}
@article{MURA2025100314,
title = {Is it fake or not? A comprehensive approach for multimodal fake news detection},
journal = {Online Social Networks and Media},
volume = {47},
pages = {100314},
year = {2025},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2025.100314},
url = {https://www.sciencedirect.com/science/article/pii/S2468696425000151},
author = {Davide Antonio Mura and Marco Usai and Andrea Loddo and Manuela Sanguinetti and Luca Zedda and Cecilia {Di Ruberto} and Maurizio Atzori},
keywords = {Computer vision, Natural language processing, Deep learning, LLM, Fake news detection},
abstract = {In recent years, the proliferation of fake news has posed significant challenges to information integrity and public trust, paving the way for the development of artificial intelligence-based models that can analyze information and determine its veracity. This study comprehensively evaluates the Themis architecture in the context of fake news detection on two distinct public datasets: Fakeddit and ReCoVery. To enhance model performance, we systematically investigate various customizations of Themis, including the integration of Low-Rank Adaptation, diverse data augmentation techniques, and multiple configurations, employing the TinyLlama Large Language Model and CLIP ViT image encoders while tuning key parameters to optimize results. Our findings reveal that while the standard Themis model performed adequately, significant improvements were observed by incorporating LoRA and specific data augmentation strategies, particularly in the ReCoVery dataset. Comparisons with existing literature indicate that Themis achieves competitive performance, especially in the ReCoVery dataset, where it outperforms existing solutions.}
}
@article{GONG2025113594,
title = {A Survey of Video Action Recognition Based on Deep Learning},
journal = {Knowledge-Based Systems},
volume = {320},
pages = {113594},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113594},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125006409},
author = {Ping Gong and Xudong Luo},
keywords = {Video action recognition, Deep learning, Multi-modal learning, AI-powered human behaviour analysis, Action recognition benchmark dataset},
abstract = {Video Action Recognition (VAR) involves identifying and classifying human actions from video data. Deep Learning (DL) has revolutionised VAR, significantly enhancing its accuracy and efficiency. However, large-scale practical applications of VAR using DL remain limited, underscoring the need for further research and innovation. Thus, this survey provides a comprehensive overview of recent advancements in DL-based VAR. Specifically, we summarise the key DL architectures for VAR, including two-stream networks, 3D-CNNs, RNNs, LSTMs, and Attention Mechanisms, and analyse their strengths, limitations, and benchmark performances. The survey also explores the diverse applications of DL-based VAR, such as surveillance, human–computer interaction, sports analytics, healthcare, and education, while presenting a detailed summary of commonly used datasets and evaluation metrics. Moreover, critical challenges, such as computational demands and the need for robust temporal modelling, are identified, along with potential future directions. This paper is a valuable resource for researchers and practitioners striving to advance VAR using DL techniques by systematically presenting concepts, methodologies, and trends.}
}
@article{ZHAO2025113035,
title = {Graph attention contrastive learning with missing modality for multimodal recommendation},
journal = {Knowledge-Based Systems},
volume = {311},
pages = {113035},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113035},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125000826},
author = {Wenqian Zhao and Kai Yang and Peijin Ding and Ce Na and Wen Li},
keywords = {Multimodal recommendation, Missing modality, Contrastive learning, Graph neural network},
abstract = {Multimodal recommendation plays an important role in many online content-sharing platforms. Most existing reported approaches of multimodal recommendation employ user-interaction graphs or auxiliary graphs (e.g., user–user or item–item relation graphs) to augment user and/or item representations. However, real-world data suffer the problem of missing modality which affects recommendation performance. In this paper, we propose the Graph Attention Contrastive Learning with Missing Modality (MMGACL) model utilizing modality complementation and modality fusion of modality-aware user–item graphs to enhance recommendations. In particular, we construct user–item bipartite graphs for each modality and extract item subgraphs, leveraging contextual information to enhance item representations. Thereafter, we employ a bimodal attention mechanism to provide complementary information across modalities and fuse different modalities. The fused item representations are combined with user–item interactions to complement user information. Finally, we perform graph contrastive learning on the completed global graph to maximize mutual information between users and items and learn more accurate embedding representations. Extensive experiments on four benchmark datasets demonstrate the effective performance of our proposed model versus several state-of-the-art methods in scenarios with missing modality.}
}
@article{SINHA2025101877,
title = {Harnessing machine learning in contemporary tobacco research},
journal = {Toxicology Reports},
volume = {14},
pages = {101877},
year = {2025},
issn = {2214-7500},
doi = {https://doi.org/10.1016/j.toxrep.2024.101877},
url = {https://www.sciencedirect.com/science/article/pii/S2214750024002609},
author = {Krishnendu Sinha and Nabanita Ghosh and Parames C. Sil},
keywords = {Machine learning, Algorithms, Smoking, Tobacco, Vapes, Cancer},
abstract = {Machine learning (ML) has the potential to transform tobacco research and address the urgent public health crisis posed by tobacco use. Despite the well-documented health risks, cessation rates remain low. ML techniques offer innovative solutions by analyzing vast datasets to uncover patterns in smoking behavior, genetic predispositions, and effective cessation strategies. ML can predict smoking-induced non-communicable diseases (SiNCDs) like lung cancer and postmenopausal osteoporosis by identifying biomarkers and genetic profiles, generating personalized predictions, and guiding interventions. It also improves prediction of infant tobacco smoke exposure, distinguishes secondhand and thirdhand smoke, and enhances protection strategies for children. Data-driven, personalized approaches using ML track real-time data for personalized feedback and offer timely interventions, continuously improving cessation strategies. Overall, ML provides sophisticated predictive models, enhances understanding of complex biological mechanisms, and enables personalized interventions, demonstrating significant potential in the fight against the tobacco epidemic.}
}
@article{HU2024110656,
title = {Online network traffic classification based on external attention and convolution by IP packet header},
journal = {Computer Networks},
volume = {252},
pages = {110656},
year = {2024},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110656},
url = {https://www.sciencedirect.com/science/article/pii/S1389128624004882},
author = {Yahui Hu and Ziqian Zeng and Junping Song and Luyang Xu and Xu Zhou},
keywords = {IP packet header, External attention, Network traffic classification, Online classification},
abstract = {Network traffic classification is an important part of network monitoring and network management. Three traditional methods for network traffic classification are flow-based, session-based, and packet-based, while flow-based and session-based methods cannot meet the real-time requirements and existing packet-based methods will violate user’s privacy. To solve the above problems, we propose a network traffic classification method only by the IP packet header, which satisfies the requirements of both the user’s privacy protection and online classification performances. Through statistical analyses, we find that IP packet header information is effective on the network traffic classification tasks and this conclusion is also demonstrated by experiments. Furthermore, we propose a novel external attention and convolution mixed (ECM) model for online network traffic classification. This model adopts both low-computational complexity external attention and convolution to respectively extract the byte-level and packet-level characteristics for traffic classification. Therefore, it can achieve high classification accuracy and low time consumption. The experiments show that ECM can reach over 96% classification accuracy on four datasets and the classification time is 0.36 ms per packet which can meet the real-time requirements. The code is available at https://github.com/CNZZQ1030/ECM-for-Network-Traffic-Classification.}
}
@article{ISHIKURA20243908,
title = {Between Information Diffusion Trends and Emotions for TV Anime Works on Twitter},
journal = {Procedia Computer Science},
volume = {246},
pages = {3908-3917},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.164},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924021720},
author = {Naoki Ishikura and Masatoshi Tsuchiya and Mitsuo Yoshida},
keywords = {social media, Twitter, sentiment analysis, information Diffusion, anime},
abstract = {Various information Diffusion trends can be found on Twitter (now know as X) for TV anime works, with some works experiencing an increase in the counts of weekly tweeting users and others experience a decrease. Given these differing trends, user behavior is also expected to vary. Among these behaviors, we hypothesize that particularly notable differences will manifest in the emotions expressed within users’ posts. Therefore, this paper’s analysis focusing on the differences in emotions expressed in tweets, attributable to various information Diffusion trends, with TV anime works as the subject of study. Initially, the types of information Diffusion trends were define through clustering based on the transition data of counts of weekly tweeting users and clustering based on the average counts of weekly tweeting users. In the clustering based on the transition data of counts of weekly tweeting users, four clusters were identified: rising, declining, peak-shaped, and stable. In the clustering based on the average counts of weekly tweeting users, three clusters were identified: high, medium, and low. Subsequently, a sentiment analysis of the tweet content was conducted for each type of information Diffusion trend. As a result, differences in information Diffusion trends were confirmed to give rise to differences in the emotions expressed in tweets. For instance, in cases with a rising cluster in the counts of weekly tweeting users, the proportion of negative tweets was higher compared to other clusters.}
}
@article{QI2024102158,
title = {Excitements and concerns in the post-ChatGPT era: Deciphering public perception of AI through social media analysis},
journal = {Telematics and Informatics},
volume = {92},
pages = {102158},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102158},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000625},
author = {Weihong Qi and Jinsheng Pan and Hanjia Lyu and Jiebo Luo},
keywords = {Generative AI, Public opinion, Social media},
abstract = {As AI systems become increasingly prevalent in various aspects of daily life, gaining a comprehensive understanding of public perception towards these AI systems has become increasingly essential for several reasons such as ethical considerations, user experience, fear, disinformation, regulation, collaboration, and co-creation. In this study, we investigate how mass social media users perceive the recent rise of AI frameworks such as ChatGPT. We collect a total of 33,912 comments in 388 unique subreddits spanning from November 30, 2022 to June 8, 2023 using a list of AI-related keywords. We employ a combination of thematic and sentiment analysis, using advanced natural language processing techniques. Specifically, we use BERTopic to uncover the major themes regarding AI on Reddit. Our findings indicate that technology-focused subreddits primarily discuss the technical dimensions of AI, while non-technical subreddits more often address societal impacts, such as job displacement concerns. The disparity in focus between subreddits suggests a gap in the public understanding of AI. We leverage GPT-3.5 with zero-shot prompting and LIWC to analyze the sentiment and perception of AI among individual users. Through a comprehensive sentiment and emotion analysis, we discover that tech-centric communities exhibit greater polarization compared to non-tech communities when discussing AI topics. This suggests that individuals with a deeper understanding or familiarity with AI technologies might have more divided opinions, possibly reflecting a mix of optimism about technological advancements and skepticism about potential impacts. This research contributes to our broader understanding of public opinion surrounding artificial intelligence.}
}
@article{PINAGARCIA2025100232,
title = {In-context learning for propaganda detection on Twitter Mexico using large language model meta AI},
journal = {Telematics and Informatics Reports},
volume = {19},
pages = {100232},
year = {2025},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2025.100232},
url = {https://www.sciencedirect.com/science/article/pii/S2772503025000465},
author = {C.A. Piña-García},
keywords = {Misinformation, Propaganda, LLM, Twitter, ICL, LLaMA 3},
abstract = {This study explores the application of Large Language Models (LLMs) for detecting political propaganda on Twitter, focusing on manipulative political narratives during the 2018 Mexican presidential election. Using LLaMA 3.2, we implement a few-shot prompting within an In-Context Learning framework to classify tweets as propagandist or non-propagandist. Using a dataset of over 800,000 tweets mentioning the leading candidate, our model identifies linguistic patterns, sentiment dynamics, and adversarial tactics, including emotive language, personal attacks, and the strategic use of hashtags. Results indicate that 58.4 % of the analyzed tweets exhibited propagandist characteristics, with a predominance of negative sentiment and aggressive tone, indicating a significant presence of information manipulation and polarization. Hierarchical clustering and word frequency analyses reveal coordinated messaging patterns, reinforcing the role of social media as a tool for political discourse manipulation. Our findings demonstrate the performance of LLMs in automating misleading communication detection and provide a replicable AI-driven framework for analyzing manipulative political narratives in digital environments.}
}
@article{LI2024124236,
title = {Hierarchical denoising representation disentanglement and dual-channel cross-modal-context interaction for multimodal sentiment analysis},
journal = {Expert Systems with Applications},
volume = {252},
pages = {124236},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124236},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424011023},
author = {Zuhe Li and Zhenwei Huang and Yushan Pan and Jun Yu and Weihua Liu and Haoran Chen and Yiming Luo and Di Wu and Hao Wang},
keywords = {Multimodal sentiment analysis, Hierarchical disentanglement, Inter-modal enhancement, Cross-modal context interaction},
abstract = {Multimodal sentiment analysis aims to extract sentiment cues from various modalities, such as textual, acoustic, and visual data, and manipulate them to determine the inherent sentiment polarity in the data. Despite significant achievements in multimodal sentiment analysis, challenges persist in addressing noise features in modal representations, eliminating substantial gaps in sentiment information among modal representations, and exploring contextual information that expresses different sentiments between modalities. To tackle these challenges, our paper proposes a new Multimodal Sentiment Analysis (MSA) framework. Firstly, we introduce the Hierarchical Denoising Representation Disentanglement module (HDRD), which employs hierarchical disentanglement techniques. This ensures the extraction of both common and private sentiment information while eliminating interference noise from modal representations. Furthermore, to address the uneven distribution of sentiment information among modalities, our Inter-Modal Representation Enhancement module (IMRE) enhances non-textual representations by extracting sentiment information related to non-textual representations from textual representations. Next, we introduce a new interaction mechanism, the Dual-Channel Cross-Modal Context Interaction module (DCCMCI). This module not only mines correlated contextual sentiment information within modalities but also explores positive and negative correlation contextual sentiment information between modalities. We conducted extensive experiments on two benchmark datasets, MOSI and MOSEI, and the results indicate that our proposed method offers state-of-the-art approaches.}
}
@article{GUO2024109213,
title = {Dual-view multi-modal contrastive learning for graph-based recommender systems},
journal = {Computers and Electrical Engineering},
volume = {116},
pages = {109213},
year = {2024},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109213},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624001411},
author = {Feipeng Guo and Zifan Wang and Xiaopeng Wang and Qibei Lu and Shaobo Ji},
keywords = {Multi-modal, Self-supervised learning, Recommender systems, Contrastive learning, Graph neural network},
abstract = {Personalized recommender systems play a crucial role in various online content-sharing platforms (e.g., TikTok). The learning of representations for multi-modal content is pivotal in current graph-based recommender systems. Existing works aim to enhance recommendation accuracy by leveraging multi-modal features (e.g., image, sound, text) as side information for items. However, this approach falls short in fully discerning users' fine-grained preferences across different modalities. To tackle this limitation, this paper introduces the Dual-view Multi-Modal contrastive learning Recommendation model (DMM-Rec). DMM-Rec employs self-supervised learning to guide the learning of user and item representations within the multi-modal context. Specifically, to capture users' preferences for different modalities, we propose specific-modal contrastive learning. Simultaneously, to capture users' cross-modal preferences, cross-modal contrastive learning is introduced to uncover interdependencies in users' preferences across modalities. The contrastive learning tasks not only adaptively explore potential relations between modalities but also address the data sparsity challenge in recommender systems. Extensive experiments conducted on three datasets and compared against ten baselines demonstrate that DMM-Rec outperforms the strongest baseline by an average of 6.81%. These results underscore the effectiveness of considering multi-modal content in improving recommender systems.}
}
@article{FONG2024100157,
title = {Ozempic (Glucagon-like peptide 1 receptor agonist) in social media posts: Unveiling user perspectives through Reddit topic modeling},
journal = {Emerging Trends in Drugs, Addictions, and Health},
volume = {4},
pages = {100157},
year = {2024},
issn = {2667-1182},
doi = {https://doi.org/10.1016/j.etdah.2024.100157},
url = {https://www.sciencedirect.com/science/article/pii/S2667118224000163},
author = {Seraphina Fong and Alessandro Carollo and Lambros Lazuras and Ornella Corazza and Gianluca Esposito},
keywords = {Ozempic, Topic modeling, Natural language processing, Reddit, BERTopic, Addiction science},
abstract = {Semaglutide, a Glucagon-like peptide 1 (GLP-1) receptor agonist marketed under the brand name Ozempic, is originally prescribed for diabetes treatment and obesity management. However, healthy individuals without a medical cause use Ozempic without medical supervision to improve their physical appearance - a trend that has proliferated through social media, news coverage, and relevant celebrity endorsements. Thus, exploring social media posts can provide insight into understanding individuals’ experiences, beliefs, motivation, as well as misconceptions about Ozempic. To do so, this study utilizes BERTopic, a natural language processing approach for topic modeling, to analyze 46,491 Reddit posts from three subreddits (r/ozempic, r/ozempicforweightloss, r/semaglutide) dated between April 2019 and December 2023. The analysis revealed various discussion topics, including using Ozempic for weight loss, dosaging, insurance denial due to lack of a diabetes diagnosis, weight loss tracking, and side effect management. Overall, the overarching theme centered on the off-label use of Ozempic and its GLP-1 agonist counterparts for weight loss purposes. Moreover, awareness on the health hazards associated with the off-label and unsupervised use of Ozempic as an image enhancer do not frequently appear in the social media discussions. These findings, supported by a dynamic topic modeling analysis, offer ecological insights into the experiences and opinions of community members in Ozempic-related subreddits, reinforcing the growing evidence of the drug's increasing popularity for weight management as well as the role played by social media. The study also shows how information campaigns about the health risks associated with the off-label use of Ozempic by healthy individuals without a medical cause may help counterbalance the lack of risk awareness detected in social media discussions.}
}
@article{RAJESH2026129357,
title = {Generalizable deepfake detection framework using hybrid convolution-based EfficientNetB7 with attention mechanism},
journal = {Expert Systems with Applications},
volume = {297},
pages = {129357},
year = {2026},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.129357},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425029720},
author = {Tirupathi Rajesh and S. Maruthupermal},
keywords = {Deepfake detection, Video frames, Facial landmark extraction, Hybrid convolution network, EfficientNetB7 with attention mechanism, Updated random parameter-based Fennec fox optimization},
abstract = {The highly realistic fake videos have been created by the deepfake technology in recent years. The political and societal consequences occurred because of the misinformation disseminated by the fake videos. To prevent these issues, automated approaches for deep fake detection are necessary. The deep fake video is detected in this work using hybrid deep learning. The main contribution of the proposed research is to determine deepfakes from videos, which aims to avoid the spread of malicious rumours. The differences between the real and deepfake videos are effectively identified through this developed approach, as they utilize the different features from the facial landmarks along with the eye blinks for determining the sophisticated fakes from the authenticated visual contents. The required videos are collected from the public databases. The frames are extracted from the collected videos. The attained video frames are given to the facial landmark detection process, where the coordinates of the eyes, lips, and nose are extracted. From these detected facial landmarks, the texture features, shape features, and the number of eye blinks are obtained for better detection purposes. The extracted features are integrated with the optimized weights for attaining the weighted fused feature, where the Updated Random Parameter-aided Fennec Fox Optimization (URP-FFO) is used for tuning the weights optimally. Each frame of 1-dimensional data forms 2-dimensional original video frames, which are taken as feature set 1 from the weighted fused features. The 3-dimensional data from the facial images is considered as feature set 2. The attained features are given to the Hybrid 2D-3D Convolution-based EfficientNetB7 with Attention Mechanism (HC-EB7AM) for differentiating the real and fake videos. The manipulated contents are easily identified by this approach. Finally, several measures are used for validating the performance. The potential strength of the proposed model is validated by the experimentation with the accuracy of 93.66% using dataset 1 and 94.38% using dataset 2, respectively.}
}
@article{WANG2024103675,
title = {A cross modal hierarchical fusion multimodal sentiment analysis method based on multi-task learning},
journal = {Information Processing & Management},
volume = {61},
number = {3},
pages = {103675},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103675},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324000359},
author = {Lan Wang and Junjie Peng and Cangzhi Zheng and Tong Zhao and Li’an Zhu},
keywords = {Multi-modality, Sentiment analysis, Cross-modal interactions, Multi-task learning},
abstract = {Humans often express affections and intentions through multiple forms when communicating, involving text, audio, and vision modalities. Using a single modality to determine the sentiment state may be biased, but combining multiple clues can fully explore more comprehensive information. Effective fusion of heterogeneous data is one of the core problems of multimodal sentiment analysis. Most cross-modal fusion strategies inevitably bring noisy information, resulting in low-quality joint feature representations and impacting the accuracy of sentiment classification. Considering the unique cues of modality-specific, common information between modalities, and sentiment variability among different layers, we introduce multi-task learning and propose a cross-modal hierarchical fusion method for multimodal sentiment analysis. The model combines unimodal, bimodal, and trimodal tasks to enhance multimodal feature representation for the final sentiment prediction. We conduct extensive experiments on CH-SIMS, CMU-MOSI, and CMU-MOSEI, where the first one is in Chinese and the last two are in English. The results demonstrate the generalizability of the proposed method. It effectively improves the accuracy of sentiment analysis while reducing the adverse impact of the noise compared to the existing models.}
}
@article{LIU2025128687,
title = {FMG-locator: Fusion SegFormer with facial mask guidance for multi-person forgery localization},
journal = {Expert Systems with Applications},
volume = {293},
pages = {128687},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128687},
url = {https://www.sciencedirect.com/science/article/pii/S095741742502305X},
author = {Jiatong Liu and Lina Wang and Run Wang and Xi Ye},
keywords = {DeepFakes, Multi-person forgery localization, Fusion SegFormer, Facial mask guidance},
abstract = {The growing prevalence of AI-generated images has intensified the risk of malicious forgeries, posing serious threats to personal identity security. While previous researches have achieved reasonable performance in detecting prominent forgeries in single-face images without backgrounds, their accuracy significantly degrades when identifying small tampered areas in multi-person scene images. To address this limitation, we propose FMG-Locator, a novel forgery localization model based on fusion Segformer architecture. Our method incorporates a facial mask guidance module to suppress background interference and emphasize facial regions. It also employs a three-channel feature extraction module and a dual attention mechanism for robust feature fusion. The superiority of our FMG-Locator is verified by extensive experiments with existing baselines in three multi-person scene datasets and two emerging forgery datasets. The results demonstrate that FMG-Locator is effective in localizing multi-person scene images, especially in the small region facial forgeries. Furthermore, it remains strong robustness under six post-processing attacks and six social media platforms.}
}
@article{LU2025126969,
title = {Cultural ecosystem services in China’s national parks and their impact on public online engagement − Analysis of Douyin short videos data based on BERTopic modeling},
journal = {Journal for Nature Conservation},
volume = {87},
pages = {126969},
year = {2025},
issn = {1617-1381},
doi = {https://doi.org/10.1016/j.jnc.2025.126969},
url = {https://www.sciencedirect.com/science/article/pii/S1617138125001463},
author = {Juan Lu and Huiying Zhang and Xingnian Zhang},
keywords = {Cultural ecosystem services (CES), Natural language processing, National parks, Online engagement, Douyin short videos, Tourism seasonality},
abstract = {This study aims to explore the types of cultural ecosystem services (CES) in China’s national parks and their impact on online engagement of the public, using data from Douyin short videos. First, we conducted text analysis and applied BERTopic modelling to identify the main types of CES in China’s national parks: ecological value, educational value, social value and cultural value. Then, based on the theory of public participation and organizational communication, we constructed an ’information-behaviour’ framework and explored the effects of the types of CES on public online engagement using a fixed effects model. We also examined the moderating mechanism of tourism seasonality and the potential heterogeneous effects of the Consumer Price Index (CPI). The results showed that ecological and educational value types played a significant moderating role in promoting public online engagement, and the impact of cultural value showed a lagged effect. The peak tourist season (May-October) significantly enhanced the positive effects of environmental and cultural values on public online engagement. This study innovatively combines BERTopic modelling and panel data fixed effects model analysis methods to analyse the problem, providing a technical way that can be used for CES identification and impact analysis, and demonstrating the potential of social media data in CES research. The results provide a scientific basis and practical guidance for national park managers to improve public engagement, optimise CES communication strategies and adapt to seasonal changes in tourism.}
}
@incollection{NAYYAR2025161,
title = {Chapter 7 - Tools and platforms for prompt engineering},
editor = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
booktitle = {Mastering Prompt Engineering},
publisher = {Morgan Kaufmann},
pages = {161-210},
year = {2025},
isbn = {978-0-443-33904-2},
doi = {https://doi.org/10.1016/B978-0-443-33904-2.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339042000082},
author = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
keywords = {FlowGPT, GIMP, GPT-Neo, Jasper AI, Prompt engineering, PromptBase},
abstract = {Prompt engineering has surfaced as a crucial strategy in how we interact with language models while using generative artificial intelligence (AI) over the last years. This chapter aims to introduce the range of tools and platforms fielded for prompt engineering, offering an exhaustive survey of resources that can be leveraged in order to shape more sophisticated prompts on various applications. Starting with prompt engineering tools, we are going to analyze the software/platforms that have been built specifically for trying out prompt generation across many different types of AI models. The tools provide certain features, such as prompt refinement, integration with AT models, and evaluation of results, that can help a wide variety of users, from novices to experts, in designing prompts. The chapter also touches on online resources to create powerful prompts, providing details about sites where you can learn about creating prompts, download prompt examples, and interactively fine-tune input from the user to obtain the desired output from AI systems. Then we are presented with a big picture of online resources for image generation, which are web interfaces made to convert textual prompts into sample images through advanced generative models. The Online Resources for Video Generation section is most exciting in considering tools designed around prompts to make and edit video content — a far more dynamic world full of possibilities. This chapter also offers a comprehensive resource for those interested in working with generative AI to be able to tap into such power across domains.}
}
@article{REN2025104108,
title = {Temporal-spatial hierarchical contrastive learning for misinformation detection: A public-behavior perspective},
journal = {Information Processing & Management},
volume = {62},
number = {4},
pages = {104108},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104108},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325000500},
author = {Gang Ren and Li Jiang and Tingting Huang and Ying Yang and Taeho Hong},
keywords = {Misinformation detection, Hierarchical contrastive learning, Graph convolutional networks, Cross-view fusion},
abstract = {The widespread dissemination of misinformation on social media platforms significantly affects public security. Current methods for detecting misinformation predominantly rely on semantic information and social context features. However, they often neglect the intricate noise issues and unreliable information interactions resulting from diverse public behaviors, such as cognitive biases, user prejudices, and bot activity. To tackle these challenges, we propose an approach named TSHCL (temporal-spatial hierarchical contrastive learning) for automatic misinformation detection from the public-behavior perspective. First, the integration of a graph convolutional network (GCN)-based autoencoder architecture with a hybrid augmentation method is designed to model typical public behaviors. Next, node-level contrastive learning is designed to maintain the heterogeneity of comments in the spatial view under the influence of complex public behaviors. Finally, cross-view graph-level contrastive learning is designed to promote collaborative learning between the temporal sequence view of events and the spatial propagation structure view. By conducting temporal-spatial hierarchical contrastive learning, the model effectively retains crucial node information and facilitates the interaction of temporal-spatial information. Extensive experiments conducted on real datasets from MCFEND and Weibo demonstrate that our model surpasses the state-of-the-art models. Our proposed model can effectively alleviate the noise and unreliable information interaction caused by public behavior, and enrich the research perspective of misinformation detection.}
}
@article{THOPPIL2025386,
title = {Leveraging Social Media Analytics For Student Project Allocation Using Deep Learning},
journal = {Procedia Computer Science},
volume = {258},
pages = {386-397},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.275},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925013778},
author = {Indu Joseph Thoppil and Jayita Saha and Arunkumar Gopu},
keywords = {Convolutional Neural Networks, Social Media Analytics, LinkedIn profiles, Project allocation, Word2Vec embedding},
abstract = {The integration of data-driven initiatives and technology has received substantial interest in the educational domain. Capstone projects significantly influence the career trajectories of students. Rather than merely allocating projects, the utilization of social media data to determine the domain interests of students in student project allocation has gained significant attention. This study explores the potential of social media analytics to revolutionize student project allocation using LinkedIn profiles. The proposed CNN model with Word2Vec embeddings demonstrated a superior performance of 96% in classifying the students based on LinkedIn profiles. The effectiveness of CNN utilizing the power of Word2Vec word embedding is employed to to capture syntactic and semantic relationships within text data. This high efficiency underscores the potential of Convolutional Neural Networks(CNN) as a text classification tool for facilitating smooth collaboration in project-based learning environments for quality education.}
}
@article{MONTEJORAEZ2024100654,
title = {A survey on detecting mental disorders with natural language processing: Literature review, trends and challenges},
journal = {Computer Science Review},
volume = {53},
pages = {100654},
year = {2024},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2024.100654},
url = {https://www.sciencedirect.com/science/article/pii/S1574013724000388},
author = {Arturo Montejo-Ráez and M. Dolores Molina-González and Salud María Jiménez-Zafra and Miguel Ángel García-Cumbreras and Luis Joaquín García-López},
keywords = {Mental disorders detection, Natural language processing, Machine learning, Survey},
abstract = {For years, the scientific community has researched monitoring approaches for the detection of certain mental disorders and risky behaviors, like depression, eating disorders, gambling, and suicidal ideation among others, in order to activate prevention or mitigation strategies and, in severe cases, clinical treatment. Natural Language Processing is one of the most active disciplines dealing with the automatic detection of mental disorders. This paper offers a comprehensive and extensive review of research works on Natural Language Processing applied to the identification of some mental disorders. To this end, we have identified from a literature review, which are the main types of features used to represent the texts, the machine learning algorithms that are preferred or the most targeted social media platforms, among other aspects. Besides, the paper reports on scientific forums and projects focused on the automatic detection of these problems over the most popular social networks. Thus, this compilation provides a broad view of the matter, summarizing main strategies, and significant findings, but, also, recognizing some of the weaknesses in the research works published so far, serving as clues for future research.}
}
@article{HOU2025105533,
title = {Understanding residents' responses towards disaster-related urban emergency management: A case study of typhoons in Shenzhen, China},
journal = {International Journal of Disaster Risk Reduction},
volume = {124},
pages = {105533},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2025.105533},
url = {https://www.sciencedirect.com/science/article/pii/S2212420925003577},
author = {Huiqiao Hou and Pengjun Zhao and Chenyang Wu and Bo Wang and Fen Li},
keywords = {Emergency response, Typhoon hazard, Emergency management, Social media data, Response time, Emotional states},
abstract = {A comprehensive understanding of residents' responses to disaster emergencies is crucial for developing effective emergency strategies, whilst this critical problem remains underexplored in the existing literature. This study proposes an analytical framework that leverages publicly available social media data to model residents' behaviours in response to disaster emergencies and capture their underlying determinants. The framework integrates a hazard-based model and a binomial logistic regression model to examine how residents' response time and emotional states are associated with emergency measures, hazard characteristics and demographic factors. The framework is applied to examine public responses to five typhoons that affected Shenzhen, China, from 2018 to 2023. Our findings reveal notable heterogeneity in response patterns across different typhoon events, with behaviours primarily determined by hazard characteristics and emergency measures, rather than gender. Specifically, residents' responses are closely linked to typhoon-induced meteorological characteristics, underscoring the need to tailor emergency strategies to these features rather than relying solely on typhoon intensity metrics. In addition, emergency measures, including early disaster warnings, work suspension and increasing emergency funding, are found to improve response efficiency and reduce negative emotional reactions. The empirical insights from this study inform the development of context-specific, adaptive emergency strategies for Shenzhen and similar regions, while the proposed framework offers a scalable approach for analysing public responses more broadly.}
}
@article{RUI2023104851,
title = {Exploring the association between the settlement environment and residents’ positive sentiments in urban villages and formal settlements in Shenzhen},
journal = {Sustainable Cities and Society},
volume = {98},
pages = {104851},
year = {2023},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2023.104851},
url = {https://www.sciencedirect.com/science/article/pii/S2210670723004626},
author = {Jin Rui},
keywords = {Settlement environment, Residents’ sentiments, Natural language processing, XGBoost, Bayesian network},
abstract = {The promotion of residents’ positive sentiments is essential for achieving the Sustainable Development Goals. However, there is limited evidence on the effect of the settlement environment (SE) on sentiment, especially in urban villages (UVs). By combining affective geography and social media data, this study aims to analyze the residents’ sentiments in UVs and formal settlements (FSs) in Shenzhen, while exploring the underlying mechanisms of SE variables that influence the positive sentiment index (PSI). The Weibo text data was analyzed using Natural Language Processing to obtain the PSI. Furthermore, we employed an XGBoost model, Shapley Additive Explanations and Partial Dependence Plots to explore relationships between SE variables and the PSI. We utilized the Interpretative Structural Modeling and Bayesian Network to analyze and verify the interdependencies and probabilistic results. The results revealed that the PSI exhibited spatial heterogeneity, with a trend of medium-high-low from central to suburban areas, and a clustering effect of high and low values. For FSs, we recommend enhancing health and well-being by increasing metro facilities, commercial density and fostering walkable neighborhoods. For UVs, prioritizing micro walk accessibility can improve settlement circulation. Additionally, we identified the potential of marginalized UVs to integrate with e-trade and transform into “special economic zones.”}
}
@article{MORITA2023,
title = {Tweeting for Health Using Real-time Mining and Artificial Intelligence–Based Analytics: Design and Development of a Big Data Ecosystem for Detecting and Analyzing Misinformation on Twitter},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/44356},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123004260},
author = {Plinio Pelegrini Morita and Irfhana {Zakir Hussain} and Jasleen Kaur and Matheus Lotto and Zahid Ahmad Butt},
keywords = {big data, deep learning, infodemics, misinformation, social media, infoveillance},
abstract = {Background
Digital misinformation, primarily on social media, has led to harmful and costly beliefs in the general population. Notably, these beliefs have resulted in public health crises to the detriment of governments worldwide and their citizens. However, public health officials need access to a comprehensive system capable of mining and analyzing large volumes of social media data in real time.
Objective
This study aimed to design and develop a big data pipeline and ecosystem (UbiLab Misinformation Analysis System [U-MAS]) to identify and analyze false or misleading information disseminated via social media on a certain topic or set of related topics.
Methods
U-MAS is a platform-independent ecosystem developed in Python that leverages the Twitter V2 application programming interface and the Elastic Stack. The U-MAS expert system has 5 major components: data extraction framework, latent Dirichlet allocation (LDA) topic model, sentiment analyzer, misinformation classification model, and Elastic Cloud deployment (indexing of data and visualizations). The data extraction framework queries the data through the Twitter V2 application programming interface, with queries identified by public health experts. The LDA topic model, sentiment analyzer, and misinformation classification model are independently trained using a small, expert-validated subset of the extracted data. These models are then incorporated into U-MAS to analyze and classify the remaining data. Finally, the analyzed data are loaded into an index in the Elastic Cloud deployment and can then be presented on dashboards with advanced visualizations and analytics pertinent to infodemiology and infoveillance analysis.
Results
U-MAS performed efficiently and accurately. Independent investigators have successfully used the system to extract significant insights into a fluoride-related health misinformation use case (2016 to 2021). The system is currently used for a vaccine hesitancy use case (2007 to 2022) and a heat wave–related illnesses use case (2011 to 2022). Each component in the system for the fluoride misinformation use case performed as expected. The data extraction framework handles large amounts of data within short periods. The LDA topic models achieved relatively high coherence values (0.54), and the predicted topics were accurate and befitting to the data. The sentiment analyzer performed at a correlation coefficient of 0.72 but could be improved in further iterations. The misinformation classifier attained a satisfactory correlation coefficient of 0.82 against expert-validated data. Moreover, the output dashboard and analytics hosted on the Elastic Cloud deployment are intuitive for researchers without a technical background and comprehensive in their visualization and analytics capabilities. In fact, the investigators of the fluoride misinformation use case have successfully used the system to extract interesting and important insights into public health, which have been published separately.
Conclusions
The novel U-MAS pipeline has the potential to detect and analyze misleading information related to a particular topic or set of related topics.}
}
@article{DUTTA2025103460,
title = {Exploring discrete speech units for privacy-preserving and efficient speech recognition for school-aged and preschool children},
journal = {International Journal of Human-Computer Studies},
volume = {199},
pages = {103460},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103460},
url = {https://www.sciencedirect.com/science/article/pii/S1071581925000175},
author = {Satwik Dutta and Dwight Irvin and John H.L. Hansen},
keywords = {Automatic speech recognition, Discrete speech representation, Child speech processing, Speaker privacy, Early childhood, Educational technology, Preschool children, Developmental delay},
abstract = {Organizations across the world, including NATO, OECD, the WHO, and the United Nations, as well as many governments, are now employing guidelines for safe, secure, and trustworthy Artificial Intelligence (AI). While technology policies are still being formulated, many AI applications catered toward children have already been developed or are still developing. While designing any child-centered AI, it is utmost importance to keep the children’s privacy at the forefront. One modality for child-centered AI is speech/language communication, which has found applications in various educational technologies, tutoring services, as well as interactive learning and social robots. Although, short of a full de-identification of speech segments, longer duration sentences and audio content could reveal partial neutral identifying information (e.g., gender of a child, etc.), but if taken in longer duration context with sequenced longitudinal data (e.g., audio recordings over full days at home or in classrooms, and linked over time), privacy concerns will grow and be critical. Motivated by a privacy-preserving design, this study explores the use of discrete speech units as a form of anonymous encoding, to develop Automatic Speech Recognition (ASR) systems for children that better ensure privacy protection. The primary goal here is to ascertain that discrete speech units retain the key linguistic information for the ASR task of output text creation, but simultaneously lack identifying speaker-specific information, or the ability to potentially re-generate the original speech waveform given the available sequence of discrete speech units. Here, a Discrete ASR model trained on the My Science Tutor Children’s Conversational Speech Corpus (MyST) archives an output word-error-rate (WER) of 15.7%. Our Discrete ASR model achieves similar performance in terms of WER when compared to state-of-the-art End-to-End (E2E) ASR models trained using features extracted from large-scale self-supervised pre-trained speech processing model (such as WavLM), although it is noted that E2E ASR models are almost 10 times larger in model checkpoint memory size and number of model parameters and takes 3x the amount of time to train. In addition, open-domain testing on other popular child speech corpora confirms that the proposed Discrete ASR models perform equal to E2E ASR models for corpora containing children speech in the same age range as MyST (e.g., CMU corpus) and slightly lower performance for a corpus containing a wider age range of children (e.g., OGI corpus). Finally, this study also shows that child ASR using the proposed discrete speech units achieves promising performance in recognizing WH-Words, Nouns, Verbs, and Pronouns in an early childhood case study of teacher–child interactions in a childcare facility, involving preschool children with and without speech/language delays which is an extremely vulnerable and challenging speech/language assessment population.}
}
@article{BAI2024104857,
title = {Semantics-enriched spatiotemporal mapping of public risk perceptions for cultural heritage during radical events},
journal = {International Journal of Disaster Risk Reduction},
volume = {113},
pages = {104857},
year = {2024},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.104857},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924006198},
author = {Nan Bai and Pirouz Nourian and Tao Cheng and Ana {Pereira Roders}},
keywords = {User-generated content, Social media, Natural language processing, Topic modelling, World heritage, Heritage risk management},
abstract = {Cultural heritage, especially those inscribed on the UNESCO World Heritage List, is meant to be valued by mankind and protected for future generations. Triggered by radical and sometimes disastrous Heritage-Related Events (HREs), communities around the world are actively involved on social media to share their opinions and emotional attachments. This paper presents exploratory data analyses on a dataset collected from Twitter concerning HREs in World Heritage that triggered global concerns, with cases of the Notre Dame Paris fire and the Venice flood, both in 2019. The spatiotemporal patterns of tweeting behaviours of online communities before, during, and after the event demonstrate a clear distinction of activation levels caused by the HREs. The dominant emotions and topics of people during the online debate are detected and visualized with pre-trained deep-learning models and unsupervised clustering algorithms. Clear spatiotemporal dynamics can be observed from the data collected in both case studies, while each case also demonstrated its specific characteristics due to the different severity. The methodological framework proposed and the analytical outcomes obtained in this paper could be used both in urban studies to mine the public opinions about HREs and other urban events for reducing risks, and by the Geo-AI community to test spatiotemporal clustering algorithms.}
}
@article{GUPTA2025100294,
title = {HaRNaT - A dynamic hashtag recommendation system using news},
journal = {Online Social Networks and Media},
volume = {45},
pages = {100294},
year = {2025},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2024.100294},
url = {https://www.sciencedirect.com/science/article/pii/S2468696424000193},
author = {Divya Gupta and Shampa Chakraverty},
keywords = {Deep learning, Hashtag recommendation, Micro-blogging, News articles, Spectral clustering, Word embedding},
abstract = {Microblogging platforms such as X and Mastadon have evolved into significant data sources, where the Hashtag Recommendation System (HRS) is being devised to automate the recommendation of hashtags for user queries. We propose a context-sensitive, Machine Learning based HRS named HaRNaT, that strategically leverages news articles to identify pertinent keywords and subjects related to a query. It interprets the fresh context of a query and tracks the evolving dynamics of hashtags to evaluate their relevance in the present context. In contrast to prior methods that primarily rely on microblog content for hashtag recommendation, HaRNaT mines contextually related microblogs and assesses the relevance of co-occurring hashtags with news information. To accomplish this, it evaluates hashtag features, including pertinence, popularity among users, and association with other hashtags. In performance evaluation of HaRNaT trained on these features demonstrates a macro-averaged precision of 84% with Naive Bayes and 80% with Logistic Regression. Compared to Hashtagify- a hashtag search engine, HaRNaT offers a dynamically evolving set of hashtags.}
}
@article{KIM2025128240,
title = {Graph-based technology recommendation system using GAT-NGCF},
journal = {Expert Systems with Applications},
volume = {288},
pages = {128240},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128240},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425018597},
author = {Min-Seung Kim and Yong-Ju Jang and Tae-Eung Sung},
keywords = {GAT, NGCF, Representation learning, Technology management, Technology recommendation system},
abstract = {This study proposes a GAT-NGCF-based technology recommendation system to improve firms’ technological innovation capabilities and facilitate technology transfer. The system leverages Graph Attention Networks (GAT) to generate optimal representations of firms and patents, which are then applied in a firm–patent interaction graph using Neural Graph Collaborative Filtering (NGCF) to recommend the most suitable patents for transfer. Experiments conducted on 6,797 technology transfer and valuation cases demonstrated high performance, achieving a Recall@5 of 0.9984 and NDCG@5 of 0.9972. Notably, the proposed system outperformed State-Of-The-Art (SOTA) models in collaborative filtering, reinforcing its effectiveness. The system offers customized technology recommendations that align with firms’ technological needs and is expected to play a key role in supporting technology transfer and commercialization strategies through open innovation.}
}
@incollection{COKER2025101,
title = {Chapter 6 - Social media and the response to mpox},
editor = {Rajkumar Rajendram and Vinood B. Patel and Victor R. Preedy},
booktitle = {The Scientific Basis of Mpox (Monkeypox)},
publisher = {Academic Press},
pages = {101-113},
year = {2025},
isbn = {978-0-443-22123-1},
doi = {https://doi.org/10.1016/B978-0-443-22123-1.00028-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443221231000284},
author = {David C. Coker and Tareq Al-Ahdal},
keywords = {Mpox, infodemic, social media, qualitative research, machine learning, public health policy},
abstract = {Social media is a major vehicle for news, public health information, and conversations. Following corona virus 2019 (COVID-19), monkeypox (mpox) became a fear and topic of interest in social media. Research in mpox on social media revealed the public had three major issues: lesbian, gay, bisexual, transgender, and queer (LGBTQ) issues, cases/spread, and public health interventions. Reviewing the corpus of social media research on mpox suggested there are many limitations, such as lack of representativeness of the population, decontextualization, and an unknown impact. Improving research by building better research platforms, timing, and collecting demographics could inform public health campaigns. COVID-inspired skepticism affects the public response, and a strategic approach with robust marketing and scientific verification could improve future responses to outbreaks and epidemics. Developing a rating system of health measures could increase the public’s credibility in science.}
}
@article{PITAKASO2025102011,
title = {AI-driven cultural urbanism: A data-integrated model for learning city development in emerging heritage contexts},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {102011},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.102011},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125007399},
author = {Rapeepan Pitakaso and Surajet Khonjan and Thanatkij Srichok and Natthapong Nanthasamroeng and Paweena Khampukka and Arunrat Sawettham and Sairoong Dinkoksung and Chawapot Supasarn and Kanya Jungvimutipan and Yong Boonarree and Ganokgarn Jirasirilerd and Pornpimol Mongkhonngam},
keywords = {Learning cities, Generative AI, Cultural heritage Design, Persona-based planning, Participatory urbanism},
abstract = {This study introduces an AI-enhanced framework for designing culturally rooted Learning Cities, demonstrated through Warinchamrap, Thailand—a heritage-rich secondary city overlooked by conventional urban development. Addressing gaps in smart city models that neglect symbolic landscapes, community narratives, and intergenerational learning, this research merges AI modeling with participatory cultural mapping and spatial analytics to create eight location-specific learning nodes.The methodology comprised five phases: (1) integrating multi-source data (archival, oral history, geospatial, social media); (2) applying AI clustering and natural language processing to identify user personas and spatial patterns; (3) employing generative AI (GPT-4, diffusion models) for culturally appropriate design concepts; (4) evaluating designs via a Design Suitability Score (DSS) framework combining AI metrics and stakeholder validation; and (5) refining architectural designs based on community feedback.Initial AI concepts achieved DSS scores averaging 0.866. After prompt refinement, version 2 designs improved to 0.908. Final architectural designs, informed by AI outputs, maintained strong community alignment with a DSS of 0.893. Projects like Songsarn x Rails of Memory and Warin Light Avenue successfully integrated spatial storytelling, cultural heritage, and adaptive learning design. Findings demonstrate that culturally embedded AI can serve as an effective co-designer for inclusive, memory-driven urban learning environments. This research provides a replicable framework for Learning Cities discourse, synthesizing generative AI, local heritage, and spatial intelligence. It offers valuable insights for developing culturally sustainable smart cities, adaptive tourism, and community-driven urban design, establishing AI as a responsive tool when anchored in cultural semantics and participatory engagement.}
}
@article{ZHANG2025130393,
title = {Multimodal misinformation detection based on the multi-granularity consistency},
journal = {Neurocomputing},
volume = {644},
pages = {130393},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130393},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225010653},
author = {Shibo Zhang and Hongchang Chen and Shuxin Liu and Ran Li and HaoCong Jiang and Liang Dong},
keywords = {Multimodal misinformation detection, Multimodal content analysis, Multimodal feature fusion, Social media analysis},
abstract = {In the current era of information proliferation, social media platforms frequently present multimodal data that may propagate misinformation. To address this challenge, computer vision techniques have been increasingly applied to online misinformation detection. Existing approaches often concentrate on learning deep semantic features from text and images without sufficiently exploring coherent alignments across multiple granular levels. This could hinder the construction of a comprehensive multimodal detection framework for misinformation detection. To overcome these issues, in this paper, we propose a three-level granularity consistency detection framework that explores image-text alignments at fine-grained, medium-grained, and coarse-grained levels. Meanwhile, we delve into the hierarchical structures of two modalities as well as the intricate semantic relationships between them. Specifically, our framework models token-level consistency through a multi-head cross-attention mechanism, phrase-level consistency via a graph neural network (GNN), and global-level consistency using a contrastive language-image pre-training model (CLIP), respectively. An adaptive fusion module then integrates these consistency features across all three granularities, enabling more nuanced and robust multimodal misinformation detection. Extensive experiments conducted on multiple benchmark datasets demonstrate that our approach substantially improves the performance of multimodal misinformation detection.}
}
@article{KANG2025,
title = {Converging Representations of Attention-Deficit/Hyperactivity Disorder and Autism on Social Media: Linguistic and Topic Analysis of Trends in Reddit Data},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/70914},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125007150},
author = {Jemima Kang and Nick Haslam and Mike Conway},
keywords = {ADHD, autism, Reddit, social media, natural language processing, machine learning},
abstract = {Background
Social media platforms have witnessed a substantial increase in mental health–related discussions, with particular attention focused on attention-deficit/hyperactivity disorder (ADHD) and autism. This heightened interest coincides with growing neurodiversity advocacy. The impact of these changes in the conceptualization of ADHD and autism, and the relationship between the 2 conditions, remains underexplored.
Objective
We aim to characterize and understand how the relationship between ADHD and autism has evolved in public discourse over the past decade and explore reasons for their growing alignment.
Methods
Using Reddit data from 2012 to 2022, we investigated the frequency of ADHD mentions in r/autism and autism mentions in r/ADHD, compared to commonly mentioned conditions. We analyzed user overlap between the 2 subreddits to track cross-subreddit discussions. Following this, we assessed changes in semantic similarity between ADHD and autism using Word2Vec embedding models, alongside commonly mentioned conditions. Finally, thematic changes in subreddit discussions were explored using BERT-based topic modeling across 2 time periods.
Results
Our analysis revealed that ADHD and autism have become progressively more associated across these multiple dimensions. In r/ADHD, there was a steep rise in the proportion of posts mentioning “autism” in 2021, overtaking “bipolar” and “OCD” (obsessive-compulsive disorder) to become the most frequently mentioned condition. Similarly, ADHD mentions increased steadily in r/autism, while the frequency of posts mentioning “OCD,” “PTSD” (posttraumatic stress disorder), and “bipolar” remained stable and low. User overlap between these subreddits grew substantially beginning in 2020. Semantic analysis showed ADHD and autism becoming more closely related from 2019 onward, compared to other conditions. Last, topic modeling indicated growing thematic convergence in ADHD- and autism-related discussions, which reflected an increasing shared emphasis on the experiences of adults with ADHD and autism, challenges in accessing diagnostic assessments, and interpersonal difficulties.
Conclusions
Our study clarifies how discourse around these 2 conditions has converged during a period when they have both attracted rising public attention. These findings contribute to wider discussions about the impacts of rising public interest in mental health concepts. They illustrate that public understandings of relationships between conditions are dynamic and changing in ways that diverge from diagnostic frameworks. Future research should continue investigating changing mental health conceptualizations on social media, as these dynamics are becoming increasingly important for the future of psychiatric practice.}
}
@article{BANSAL2024109417,
title = {A hybrid filtering for micro-video hashtag recommendation using graph-based deep neural network},
journal = {Engineering Applications of Artificial Intelligence},
volume = {138},
pages = {109417},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109417},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624015756},
author = {Shubhi Bansal and Kushaan Gowda and Mohammad Zia Ur Rehman and Chandravardhan Singh Raghaw and Nagendra Kumar},
keywords = {Hashtag recommendation, Micro-videos, Graph neural network, Multimodal data analysis},
abstract = {Due to the growing volume of user-generated content, hashtags are employed as topic indicators to manage content efficiently on social media platforms. However, finding these vital topics is challenging in micro-videos since they contain substantial information in a short duration. Existing methods that recommend hashtags for micro-videos primarily focus on content and personalization while disregarding user’s modality-specific tagging preferences. Moreover, the cold-start user issue prevails in hashtag recommendation systems. Considering the above, we propose a hybrid filtering-based MIcro-video haSHtag recommendatiON (MISHON) system to recommend hashtags for micro-videos. We construct a heterogeneous graph to model user’s modality-specific tagging patterns by establishing links with constituent modalities of previous micro-videos, further encompassing user-to-user and modality-to-modality interactions. We then refine modality-specific and user representations using message-passing strategy to recommend pertinent hashtags for micro-videos. The empirical results on three real-world datasets demonstrate that MISHON attains a comparative enhancement of 3.6%, 2.8%, and 6.5% concerning the F1-score, respectively. To address cold-start problem, we propose a content and social influence-based technique to recommend hashtags that are not only relevant to content but also popular, thereby empowering cold-start users to broaden their network and content visibility. The proposed solution shows a relative improvement of 15.8% in the F1-score over its content-only counterpart.}
}
@article{CHAN2025100759,
title = {An AI-powered solution for detecting and categorising sponsored ad segments in YouTube videos},
journal = {Software Impacts},
volume = {24},
pages = {100759},
year = {2025},
issn = {2665-9638},
doi = {https://doi.org/10.1016/j.simpa.2025.100759},
url = {https://www.sciencedirect.com/science/article/pii/S2665963825000193},
author = {Johnny Chan and Brice Valentin Kok-Shun},
keywords = {Ad detection, Keyword extraction, Large language model, Online advertising, YouTube},
abstract = {This paper presents an AI-powered software solution for detecting and categorising sponsored advertisement segments in YouTube videos. By combining GPT-4 for ad identification, KeyBERT for keyword extraction, and custom prompts for grouping keywords into concise categories, the software provides a scalable and efficient alternative to traditional ad detection methods. It processes both auto-generated and manual transcripts, ensuring adaptability across varied contexts. The tool enables a deeper understanding of advertising strategies and ad-content alignment while maintaining ease of use and reproducibility. This work highlights the potential of AI in transforming digital advertisement analysis.}
}
@article{LI2025128940,
title = {Multimodal sentiment analysis based on disentangled representation learning and cross-modal-context association mining},
journal = {Neurocomputing},
volume = {617},
pages = {128940},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128940},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224017119},
author = {Zuhe Li and Panbo Liu and Yushan Pan and Weiping Ding and Jun Yu and Haoran Chen and Weihua Liu and Yiming Luo and Hao Wang},
keywords = {Multimodal sentiment analysis, Multimodal representation learning, Multimodal fusion, Multimodal association mining, Linguistic guided-multihead attention},
abstract = {Multimodal sentiment analysis aims to extract sentiment information expressed by users from multimodal data, including linguistic, acoustic, and visual cues. However, the heterogeneity of multimodal data leads to disparities in modal distribution, thereby impacting the model’s ability to effectively integrate complementarity and redundancy across modalities. Additionally, existing approaches often merge modalities directly after obtaining their representations, overlooking potential emotional correlations between them. To tackle these challenges, we propose a Multiview Collaborative Perception (MVCP) framework for multimodal sentiment analysis. This framework consists primarily of two modules: Multimodal Disentangled Representation Learning (MDRL) and Cross-Modal Context Association Mining (CMCAM). The MDRL module employs a joint learning layer comprising a common encoder and an exclusive encoder. This layer maps multimodal data to a hypersphere, learning common and exclusive representations for each modality, thus mitigating the semantic gap arising from modal heterogeneity. To further bridge semantic gaps and capture complex inter-modal correlations, the CMCAM module utilizes multiple attention mechanisms to mine cross-modal and contextual sentiment associations, yielding joint representations with rich multimodal semantic interactions. In this stage, the CMCAM module only discovers the correlation information among the common representations in order to maintain the exclusive representations of different modalities. Finally, a multitask learning framework is adopted to achieve parameter sharing between single-modal tasks and improve sentiment prediction performance. Experimental results on the MOSI and MOSEI datasets demonstrate the effectiveness of the proposed method.}
}
@article{ANTISDEL2025,
title = {Data Mining Trauma: AI-Assisted Qualitative Study of Cyber Victimization on Reddit},
journal = {JMIR Infodemiology},
volume = {5},
year = {2025},
issn = {2564-1891},
doi = {https://doi.org/10.2196/75493},
url = {https://www.sciencedirect.com/science/article/pii/S2564189125000532},
author = {J'Andra Antisdel and Wendy R Miller and Doyle Groves},
keywords = {cyber victimization, word adjacency graphing, cyberbullying, artificial intelligence, data mining, thematic analysis},
abstract = {Background
Cyber victimization exposes individuals to numerous risks. Developmental and psychological factors may leave some users unaware of the potential dangers, increasing their susceptibility to psychological distress. Despite this vulnerability, methods for identifying those at risk of cyber victimization within health care settings are limited, as is research that explores their experiences of cyber victimization. The purpose of this study was to analyze how users describe experiences of cyber victimization on the social media platform Reddit (Reddit, Inc) using data mining.
Objective
This study aimed to analyze and describe how users on Reddit describe and discuss their experience of cyber victimization using data mining and computational analysis of unsolicited data.
Methods
This computational qualitative study used data mining, Word Adjacency Graph (WAG) modeling, and thematic analysis to analyze discussions of Reddit users surrounding cyber victimization. Inclusion criteria included posts from 2012 to 2023 from subreddits r/cyberbullying and r/bullying. GPT-4 (OpenAI), an advanced artificial intelligence language model, summarized posts and assisted in cluster labeling. Posts were reviewed to remove irrelevant content and duplicates. User anonymity was maintained throughout the study.
Results
A total of 13,381 posts from 3283 Reddit were analyzed, with approximately 5.1% (n=678) originating between 2012 and 2018 and 94.9% (n=12,703) from 2019 to 2023. The WAG modeling approach identified 38 clusters, with 35 deemed to be relevant to cyber victimization experiences. Two clusters containing irrelevant material were excluded. Six overarching themes emerged: (1) psychological impact, (2) coping and healing, (3) protecting yourself online, (4) protecting yourself offline, (5) victimization across various settings, and (6) seeking meaning and understanding.
Conclusions
The study highlights the effectiveness of data mining and AI in analyzing large public datasets for qualitative research. These methods can inform future studies on risky internet behavior, victimization, and assessment strategies in health care settings.}
}
@article{GILGA2025105441,
title = {Legal and ethical considerations for demand-driven data collection and AI-based analysis in flood response},
journal = {International Journal of Disaster Risk Reduction},
volume = {122},
pages = {105441},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2025.105441},
url = {https://www.sciencedirect.com/science/article/pii/S2212420925002651},
author = {Carolin Gilga and Christoph Hochwarter and Luisa Knoche and Sebastian Schmidt and Gudrun Ringler and Marc Wieland and Bernd Resch and Ben Wagner},
keywords = {Disaster response, Artificial intelligence, Ethics, Data privacy},
abstract = {During a disaster, the timely provision of customised and relevant data is of utmost importance. In the case of floods, data from remote sensing (satellite-based or airborne) is often used, but in recent years data from social media platforms has also been increasingly utilised. Focusing on these data sources, this study provides an in-depth assessment of requirements by emergency responders. Furthermore, the paper sheds light on the legal and ethical considerations that need to be taken into account during data collection and processing. A particular focus lies on the use of artificial intelligence (AI) for data analysis in disaster response. Topics such as privacy preservation and AI-informed decision making are highlighted throughout the paper. The investigation was carried out based on expert interviews with scientists, an extensive literature review, and workshops with emergency responders.}
}
@article{LI2024,
title = {Impact of Artificial Intelligence–Generated Content Labels On Perceived Accuracy, Message Credibility, and Sharing Intentions for Misinformation: Web-Based, Randomized, Controlled Experiment},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/60024},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24007443},
author = {Fan Li and Ya Yang},
keywords = {generative AI, artificial intelligence, ChatGPT, AIGC label, misinformation, perceived accuracy, message credibility, sharing intention, social media, health information},
abstract = {Background
The proliferation of generative artificial intelligence (AI), such as ChatGPT, has added complexity and richness to the virtual environment by increasing the presence of AI-generated content (AIGC). Although social media platforms such as TikTok have begun labeling AIGC to facilitate the ability for users to distinguish it from human-generated content, little research has been performed to examine the effect of these AIGC labels.
Objective
This study investigated the impact of AIGC labels on perceived accuracy, message credibility, and sharing intention for misinformation through a web-based experimental design, aiming to refine the strategic application of AIGC labels.
Methods
The study conducted a 2×2×2 mixed experimental design, using the AIGC labels (presence vs absence) as the between-subjects factor and information type (accurate vs inaccurate) and content category (for-profit vs not-for-profit) as within-subjects factors. Participants, recruited via the Credamo platform, were randomly assigned to either an experimental group (with labels) or a control group (without labels). Each participant evaluated 4 sets of content, providing feedback on perceived accuracy, message credibility, and sharing intention for misinformation. Statistical analyses were performed using SPSS version 29 and included repeated-measures ANOVA and simple effects analysis, with significance set at P<.05.
Results
As of April 2024, this study recruited a total of 957 participants, and after screening, 400 participants each were allocated to the experimental and control groups. The main effects of AIGC labels were not significant for perceived accuracy, message credibility, or sharing intention. However, the main effects of information type were significant for all 3 dependent variables (P<.001), as were the effects of content category (P<.001). There were significant differences in interaction effects among the 3 variables. For perceived accuracy, the interaction between information type and content category was significant (P=.005). For message credibility, the interaction between information type and content category was significant (P<.001). Regarding sharing intention, both the interaction between information type and content category (P<.001) and the interaction between information type and AIGC labels (P=.008) were significant.
Conclusions
This study found that AIGC labels minimally affect perceived accuracy, message credibility, or sharing intention but help distinguish AIGC from human-generated content. The labels do not negatively impact users’ perceptions of platform content, indicating their potential for fact-checking and governance. However, AIGC labeling applications should vary by information type; they can slightly enhance sharing intention and perceived accuracy for misinformation. This highlights the need for more nuanced strategies for AIGC labels, necessitating further research.}
}
@article{GREEN2025,
title = {Collecting and Sharing Person-Centered AI Clinical Summaries Across Frailty Services Provided by the National Health Service and Voluntary, Community, and Social Enterprise: Protocol for a Co-Design and Feasibility Study},
journal = {JMIR Research Protocols},
volume = {14},
year = {2025},
issn = {1929-0748},
doi = {https://doi.org/10.2196/68511},
url = {https://www.sciencedirect.com/science/article/pii/S1929074825006006},
author = {Kieran Green and Sheena Asthana and Oscar Josue Ponce-Ponte and John Downey and Joanne Watson},
keywords = {artificial intelligence, AI, health care, future, medical documentation, data interoperability, person-centered care, multidisciplinary team, care coordination},
abstract = {Background
Due to its association with multimorbidity, frailty gives rise to multidimensional needs for different services. Too often, patient preferences and service encounter information are not adequately shared.
Objective
This developmental study aims to co-design, collect, and analyze encounter data from multiple community and primary-based multidisciplinary teams (MDTs) providing services for people with frailty to develop prototype large language models that can generate clinical and person-centered care summaries.
Methods
Engaging stakeholders in 2 primary care networks, we will co-design the large language model to ensure it meets local needs and preferences as well as infrastructure, information governance, and regulation requirements. General practitioners will identify 50 patients with frailty requiring MDT engagement. Three consecutive encounters between the patients and different members of MDTs will then be audio-recorded. Recordings will be transcribed into text for concept design and model pretraining. These data combine stakeholder engagement insights to develop sensitive artificial intelligence (AI) models responding to stakeholders’ needs, workflows, and preferences. To generate the person-centered summaries, we will test 2 approaches to modeling the encounter data: graph-based modeling and hierarchical transformers. The AI-generated summaries will be compared to human-written summaries of the same encounter data and assessed for accuracy, quality, fluency, and person-centeredness. They will also be shared with the original MDT members for validation. We will capture inputs, processes, and outcomes across all key phases of the implementation journey to identify capability requirements, determinants of implementation (including key challenges and best practices to overcome them), and the value added by the technology.
Results
This protocol aims to review implementation evidence and engage stakeholders in co-design. This work package will aid the development of contextually sensitive, longitudinal, and AI-generated person-centered summarization tools. Model development will aim to achieve longitudinal person-centered summaries tested against MDT standards. If deemed suitable for deployment, optimum ways of integrating these summaries into shared care records will be explored with local key system leaders. Model evaluations will provide conclusive insights into such technologies’ benefits and risks. As of August 2025, this study has not yet been funded, nor has ethical approval for the project been obtained. Consequently, dates of data collection and numbers of recruited participants are not applicable at this time.
Conclusions
Our protocol provides a robust method of co-designing, evaluating, and implementing a longitudinal AI medical summary tool. Including key stakeholders at multiple stages facilitates an iterative development strategy that is designed to solve implementation challenges as they emerge. This project fits within our long-term vision to deliver a multimodal AI tool that saves clinicians time and deepens the health care professional–patient relationship. Future studies should include a larger patient sample, video-recorded health care professional–patient encounters, and a more extensive longitudinal evaluation.
International Registered Report Identifier (IRRID)
PRR1-10.2196/68511}
}
@article{WU2025113057,
title = {CoT-driven framework for short text classification: Enhancing and transferring capabilities from large to smaller model},
journal = {Knowledge-Based Systems},
volume = {311},
pages = {113057},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113057},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125001042},
author = {Hui Wu and Yuanben Zhang and Zhonghe Han and Yingyan Hou and Lei Wang and Siye Liu and Qihang Gong and Yunping Ge},
keywords = {Short text classification, Large language models, Chain-of-thought},
abstract = {Short Text Classification (STC) is crucial for processing and understanding the brief but substantial content prevalent on contemporary digital platforms. The STC encounters difficulties in grasping the semantic and syntactic intricacies, an issue that is apparent in traditional pre-trained language models. Although Graph Convolutional Networks enhance performance by integrating external knowledge bases, these methods are limited by the quality and extent of the knowledge applied. Recently, the emergence of Large Language Models (LLMs) and Chain-of-Thought (CoT) has significantly improved the performance of complex reasoning tasks. However, some studies have highlighted the limitations of their application in fundamental NLP tasks. Consequently, this study first employs CoT to investigate and enhance the capabilities of LLMs in STC tasks. We propose the Syntactic and Semantic Enrichment CoT (SSE-CoT) method, effectively decomposing the STC tasks into four distinct steps: (i) essential concept identification, (ii) common-sense knowledge retrieval, (iii) text rewriting, and (iv) classification. Furthermore, recognizing resource constraints in sectors like finance and healthcare, we then introduce the CoT-Driven Multi-Task Learning (CDMT) framework to extend these capabilities to smaller models. This framework begins by extracting rationales from LLMs and subsequently fine-tunes smaller models to optimize their performance. Extensive experimentation across six short-text benchmarks validated the efficacy of the proposed methods. In particular, SSE-CoT achieved state-of-the-art performance with substantial improvements on all datasets, particularly on the Ohsumed and TagMyNews datasets.}
}
@article{LUNGREN20241151,
title = {More Is Different: Large Language Models in Health Care},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {7},
pages = {1151-1154},
year = {2024},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2023.11.021},
url = {https://www.sciencedirect.com/science/article/pii/S1546144023009626},
author = {Matthew P. Lungren and Elliot K. Fishman and Linda C. Chu and Ryan C. Rizk and Steven P. Rowe}
}
@article{JAVED2024110808,
title = {Towards the future of bot detection: A comprehensive taxonomical review and challenges on Twitter/X},
journal = {Computer Networks},
volume = {254},
pages = {110808},
year = {2024},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110808},
url = {https://www.sciencedirect.com/science/article/pii/S1389128624006406},
author = {Danish Javed and NZ Jhanjhi and Navid Ali Khan and Sayan Kumar Ray and Alanoud Al Mazroa and Farzeen Ashfaq and Shampa Rani Das},
keywords = {Harmful Twitter Bots (HTB), Twitter, X, Bot detection},
abstract = {Harmful Twitter Bots (HTBs) are widespread and adaptable to a wide range of social network platforms. The use of social network bots on numerous social network platforms is increasing. As the popularity and utility of social networking bots grow, the attacks using social network-based automated accounts are getting more coordinated, resulting in crimes that might endanger democracy, the financial market, and public health. HTB designers develop their bots to elude detection while academics create several algorithms to identify social media bot accounts. This field is active and necessitates ongoing improvement due to the never-ending cat-and-mouse game. X, previously known as Twitter, is among the biggest social network platforms that has been plagued by automated accounts. Even though new research is being conducted to tackle this issue, the number of bots on Twitter keeps on increasing. In this research, we establish a robust theoretical foundation in the continuously evolving domain of Harmful Twitter Bot (HTB) detection by analyzing the existing HTB detection techniques. Our research provides an extensive literature review and introduces an enhanced taxonomy that has the potential to help the scientific community form better generalizations for HTB detection. Furthermore, we discuss this domain's obstacles and open challenges to direct and improve future research. As far as we are aware, this study marks the first comprehensive examination of HTB detection that includes articles published between June 2013 and August 2023. The review's findings include a more thorough classification of detection approaches, a spotlight on ways to spot Twitter bots, and a comparison of recent HTB detection methods. Moreover, we provide a comprehensive list of publicly available datasets for HTB detection. As bots evolve, efforts must be made to raise awareness, equip legitimate users with information, and help future researchers in the field of social network bot detection.}
}
@article{NGO2024106558,
title = {Discovering child sexual abuse material creators' behaviors and preferences on the dark web},
journal = {Child Abuse & Neglect},
volume = {147},
pages = {106558},
year = {2024},
issn = {0145-2134},
doi = {https://doi.org/10.1016/j.chiabu.2023.106558},
url = {https://www.sciencedirect.com/science/article/pii/S014521342300546X},
author = {Vuong M. Ngo and Rahul Gajula and Christina Thorpe and Susan Mckeever},
keywords = {Child sexual abuse material, Forums, Artificial intelligence, Child victim, Abuser},
abstract = {Background
Producing, distributing or discussing child sexual abuse materials (CSAM) is often committed through the dark web to stay hidden from search engines and to evade detection by law enforcement agencies. Additionally, on the dark web, the CSAM creators employ various techniques to avoid detection and conceal their activities. The large volume of CSAM on the dark web presents a global social problem and poses a significant challenge for helplines, hotlines and law enforcement agencies.
Objective
Identifying CSAM discussions on the dark web and uncovering associated metadata insights into characteristics, behaviors and motivation of CSAM creators.
Participants and Setting
We have conducted an analysis of more than 353,000 posts generated by 35,400 distinct users and written in 118 different languages across eight dark web forums in 2022. Out of these, approximately 221,000 posts were written in English and contributed by around 29,500 unique users.
Method
We propose a CSAM detection intelligence system. The system uses a manually labeled dataset to train, evaluate and select an efficient CSAM classification model. Once we identify CSAM creators and victims through CSAM posts on the dark web, we proceed to analyse, visualize and uncover information concerning the behaviors of CSAM creators and victims.
Result
The CSAM classifier, based on Support Vector Machine model, exhibited good performance, achieving the highest precision of 92.3 % and accuracy of 87.6 %. While, the Naive Bayes combination is the best in term of recall, achieving 89 %. Across the eight forums in 2022, our Support Vector Machine model detected around 63,000 English CSAM posts and identified near 10,500 English CSAM creators. The analysis of metadata of CSAM posts revealed meaningful information about CSAM creators, their victims and social media platforms they used. This included: (1) The topics of interest and the preferred social media platforms for the 20 most active CSAM creators (For example, two top creators were interested in topics like video, webcam and general content in forums, and they frequently used platforms like Omegle and Skype); (2) Information about the ages and nationalities of the victims typically mentioned by CSAM creators, such as victims aged 12 and 13 with nationalities including British and Russian; (3) social media platforms preferred by CSAM creators for sharing or uploading CSAM, include Omegle, YouTube, Skype, Instagram and Telegram.
Conclusion
Our CSAM detection system exhibits high performance in precision, recall, and accuracy in real-time when classifying CSAM and non-CSAM posts. Additionally, it can extract and visualize valuable and unique insights about CSAM creators and victims by employing advanced statistical methods. These insights prove beneficial to our partners, i.e. national hotlines and child agencies.}
}
@article{YUAN2024112076,
title = {Video and audio are images: A cross-modal mixer for original data on video–audio retrieval},
journal = {Knowledge-Based Systems},
volume = {299},
pages = {112076},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112076},
url = {https://www.sciencedirect.com/science/article/pii/S095070512400710X},
author = {Zichen Yuan and Qi Shen and Bingyi Zheng and Yuting Liu and Linying Jiang and Guibing Guo},
keywords = {Pre-train model, Audio–video retrieval, Modality fusion},
abstract = {Cross-modal retrieval has become popular in recent years, particularly with the rise of multimedia. Generally, the information from each modality exhibits distinct representations and semantic information, which makes feature tends to be in separate latent spaces encoded with dual-tower architecture and makes it challenging to establish semantic relationships between modalities, resulting in poor retrieval performance. To address this issue, we propose a novel framework for cross-modal retrieval consisting of a cross-modal mixer, a masked autoencoder for pre-training, and a cross-modal retriever for downstream tasks. Specifically, we first adopt cross-modal mixer and mask modeling to fuse the original modality and eliminate redundancy. Then, an encoder–decoder architecture is applied to achieve a fuse-then-separate task in the pre-training phase. We feed masked fused representations into the encoder and reconstruct them with the decoder, ultimately separating the original data of two modalities. We use the pre-trained encoder in downstream tasks to build the cross-modal retrieval method. Extensive experiments on 2 real-world datasets show that our approach outperforms previous state-of-the-art methods in video–audio matching tasks, improving retrieval accuracy by up to 2×. Furthermore, we prove our model performance by transferring it to other downstream tasks as a universal model.}
}
@article{WANG2022109335,
title = {Sentiment Lexical Strength Enhanced Self-supervised Attention Learning for sentiment analysis},
journal = {Knowledge-Based Systems},
volume = {252},
pages = {109335},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109335},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122006694},
author = {Xi Wang and Mengmeng Fan and Mingming Kong and Zheng Pei},
keywords = {Sentiment lexical strength, Attention supervision information, Sentiment analysis},
abstract = {In Natural Language Processing (NLP), attention mechanism is often used to quantify the importance of the context word in sentiment prediction. However, it tends to focus on high-frequency words, while ignoring low-frequency words that have an active effect in some positions. In this paper, we propose a Sentiment Lexical Strength Enhanced Self-supervised Attention Learning (SLS-ESAL) approach. Specifically, we iteratively mine attention supervision information from all input sentences. Then we use weights quantified by sentiment lexical strength to enhance attention learning in final training, which enables our model to continue to focus on the active context words in different positions and eliminate the effects of the misleading context ones. Experiments on three datasets show that our approach can improve sentiment analysis performance and verify attention weights can be used as an explanation for text classification.}
}
@article{HUANG2024100348,
title = {D2MNet for music generation joint driven by facial expressions and dance movements},
journal = {Array},
volume = {22},
pages = {100348},
year = {2024},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2024.100348},
url = {https://www.sciencedirect.com/science/article/pii/S2590005624000146},
author = {Jiang Huang and Xianglin Huang and Lifang Yang and Zhulin Tao},
keywords = {Facial expressions, Dance movements, Style feature, Music generation, D2MNet},
abstract = {In general, dance is always associated with music to improve stage performance effect. As we know, artificial music arrangement consumes a lot of time and manpower. While automatic music arrangement based on input dance video perfectly solves this problem. In the cross-modal music generation task, we take advantage of the complementary information between two input modalities of facial expressions and dance movements. Then we present Dance2MusicNet (D2MNet), an autoregressive generation model based on dilated convolution, which adopts two feature vectors, dance style and beats, as control signals to generate real and diverse music that matches dance video. Finally, a comprehensive evaluation method for qualitative and quantitative experiment is proposed. Compared to baseline methods, D2MNet outperforms better in all evaluating metrics, which clearly demonstrates the effectiveness of our framework.}
}
@article{ZHANG2025,
title = {Research on Media Text Translation Based on Information Retrieval},
journal = {International Journal of e-Collaboration},
volume = {21},
number = {1},
year = {2025},
issn = {1548-3673},
doi = {https://doi.org/10.4018/IJeC.370405},
url = {https://www.sciencedirect.com/science/article/pii/S1548367325000146},
author = {Jiuquan Zhang and Yan Meng},
keywords = {Information Retrieval, Media, Text, Translation},
abstract = {ABSTRACT
This paper focuses on the research of media knowledge text translation based on information retrieval, and discusses how information retrieval technology can affect and optimize the translation process and results of media texts. By combining the basic principles of information retrieval technology and its practical application scenarios, this paper analyzes the characteristics of media texts and their special requirements for translation. Through the design experiment, the effect of information retrieval technology on improving translation quality, efficiency and reaction cost is evaluated. The experimental results show that this technology can significantly improve the accuracy and fluency of translation, shorten the translation cycle and reduce the cost. The application prospect of information retrieval in the field of translation will be broader. This study can not only provide a new perspective and method for the translation of media texts, but also contribute to the improvement of cross-cultural communication and information dissemination efficiency.}
}
@article{JHA2026104480,
title = {Stop sabotaging your Influencers: How language formality undermines engagement in sponsored content},
journal = {Journal of Retailing and Consumer Services},
volume = {88},
pages = {104480},
year = {2026},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104480},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925002590},
author = {Abhishek Kumar Jha and Ronak Singhania and Samrat Bagchi},
keywords = {Influencer marketing, Consumer engagement, Language formality, Media naturalness theory, Control paradox, Agentic AI},
abstract = {Influencer marketing has rapidly become a cornerstone of modern advertising, yet sponsored posts often underperform compared to organic content in terms of consumer engagement. This study investigates how brand-imposed language constraints affect engagement in sponsored influencer content. Drawing on Media Naturalness Theory and the control paradox, we hypothesize that language formality disrupts the authenticity of influencer communication, leading to lower engagement. Using a dataset of 1.4 million Instagram posts, including around 200,000 sponsored postings, our analysis reveals that formal language reduces engagement, while informal language features, specifically higher use of netspeak and emojis, enhance engagement. To further validate these findings, we conducted a controlled experiment examining the effect of language style on engagement and perceived authenticity. These findings suggest that informal language fosters a more genuine connection between influencers and their audiences, increasing interaction in sponsored content. The paper provides practical recommendations for brands, urging them to co-create flexible language strategies with influencers, allowing for more authentic expression and boosting consumer engagement. The current study also uses the latest agentic AI models to replicate similar results through additional experiments, contributing to the theoretical understanding of influencer marketing and the practical strategies for optimizing influencer collaborations.}
}
@article{LI2025100707,
title = {Analysis of social networks content to identify fake news using stacked combination of deep neural networks},
journal = {Egyptian Informatics Journal},
volume = {30},
pages = {100707},
year = {2025},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2025.100707},
url = {https://www.sciencedirect.com/science/article/pii/S1110866525001008},
author = {Yujie Li and Yushui Xiao and Yong Huang and Rui Ma},
keywords = {Fake News Identification, Social Networks Analysis, Stacked Ensemble Learning, Deep Neural Networks},
abstract = {In today’s fast-paced world, the unprecedented expansion of social networks and the huge volume of information has made automatic detection of fake news an undeniable necessity. The dissemination of fake news and misinformation can have a devastating impact on public opinion and social decision-making. This challenge requires new and powerful approaches in the fields of deep learning and natural language processing to accurately and quickly identify fake news and prevent its dissemination. For that purpose, this current work presents a new and efficient solution to detecting and spotting spurious news on social media. This method, through deep text content analysis and the employment of advanced deep learning techniques, aims to provide an expansive and accurate response to solve this problem. The proposed method consists of three determining steps: 1) The input data is initially prepared for the next steps using preprocessing techniques. This is done through noise removal, text normalization, and data conversion into a format that can be processed by deep learning models. 2) A hybrid method is then used to extract text features, which is a combination of a list of statistical features (e.g., text length, word count, and links), GloVe-based semantic features (to represent the word relationships), and Character N-Grams (CNG) (to improve misspelling and linguistic anomaly robustness). 3) Finally, for each set of features, a particular deep model is trained to predict based on each component. Specifically, a Multilayer Perceptron (MLP) model is used for statistical feature analysis, and Convolutional Neural Network (CNN) models are used for GloVe and CNG features. Both models generate individual predictions from the input features presented to them, and the predicted labels and the posterior probability vector for each of the models are combined to output a vector to be forwarded to the meta-learner (a MLP model). By learning patterns in the combinations of outputs and the probability vectors of the individual base models, the MLP model can correctly identify fake news or real news. Experimental results conducted on two authentic datasets, GossipCop and Politifact, show that our proposed method achieves 99.45 % and 97.40 % accuracies, respectively. This achievement indicates the very good and effective performance of our method in detecting fake news on both datasets.}
}
@article{RAVI2024200456,
title = {Ideological orientation and extremism detection in online social networking sites: A systematic review},
journal = {Intelligent Systems with Applications},
volume = {24},
pages = {200456},
year = {2024},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2024.200456},
url = {https://www.sciencedirect.com/science/article/pii/S2667305324001303},
author = {Kamalakkannan Ravi and Jiann-Shiun Yuan},
keywords = {Extremism detection, Machine learning, Natural language processing, Predictive models, Social media, User-generated content},
abstract = {The rise of social networking sites has reshaped digital interactions, becoming fertile grounds for extremist ideologies, notably in the United States. Despite previous research, understanding and tackling online ideological extremism remains challenging. In this context, we conduct a systematic literature review to comprehensively analyze existing research and offer insights for both researchers and policymakers. Spanning from 2005 to 2023, our review includes 110 primary research articles across platforms like Twitter (X), Facebook, Reddit, TikTok, Telegram, and Parler. We observe a diverse array of methodologies, including natural language processing (NLP), machine learning (ML), deep learning (DL), graph-based methods, dictionary-based methods, and statistical approaches. Through synthesis, we aim to advance understanding and provide actionable recommendations for combating ideological extremism effectively on online social networking sites.}
}
@article{MULYANI2024140233,
title = {Analyzing public discourse on photovoltaic (PV) adoption in Indonesia: A topic-based sentiment analysis of news articles and social media},
journal = {Journal of Cleaner Production},
volume = {434},
pages = {140233},
year = {2024},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2023.140233},
url = {https://www.sciencedirect.com/science/article/pii/S0959652623043913},
author = {Yun Prihantina Mulyani and Anas Saifurrahman and Hilya Mudrika Arini and Arwindra Rizqiawan and Budi Hartono and Dhanan Sarwo Utomo and Agnessa Spanellis and Macarena Beltran and Kevin Marojahan {Banjar Nahor} and Dhyana Paramita and Wira Dranata Harefa},
keywords = {Solar PV, Discourse, Perception, Mainstream media, Social media},
abstract = {The importance of integrating renewable energy, such as solar PV, in the global energy mix for mitigating carbon emissions is increasing. Despite the global drive towards renewable energy, the limited uptake of solar PV particularly in developing nations, such as Indonesia, poses significant challenges for transition to sustainable energy. This study analyses public discourse to comprehend the obstacles for widespread adoption of solar PV technologies. This study employs topic modelling and sentiment analysis of mainstream and social media data to comprehensively capture public discourse and perceptions concerning PV and residential PV adoption in Indonesia. The findings reveal shared thematic areas in both mainstream and social media. Nonetheless, the two media types diverge significantly in their focal points. Our findings support previous survey-based research while introducing three new topics found in both media channels. These topics are: (1) knowledge, misconceptions, and skepticism, (2) economically viable alternative PV technologies; and (3) government regulations and policies. Social and visual impressions such as aesthetics, hedonic motivation, and social influence are notably absent. Public perception varies, with mainstream media portraying PV technology more positively than social media. From both media, the public generally holds favorable views of PV, particularly in terms of its practicality, installation, safety, and information accessibility. Nevertheless, negative perceptions arise regarding investment costs, regulations, governmental policies, and the adequacy of government support.}
}
@article{QIAN2026104520,
title = {Sports, politics, and social media: A Human-AI collaborative analysis of consumer reactions to Trump's break 50 appearance},
journal = {Journal of Retailing and Consumer Services},
volume = {88},
pages = {104520},
year = {2026},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104520},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925002991},
author = {Tyreal Yizhou Qian and Hua Gong and Chenglong Xu},
keywords = {User-generated content, Marketing, Framing, Stereotype, Machine learning, Artificial intelligence, Natural language processing},
abstract = {This study investigates consumer engagement on social media platforms in response to Donald Trump's participation in Bryson DeChambeau's Break 50 golf series, focusing on audience interpretation of politically infused sports entertainment. Drawing on framing theory and stereotype content model (SCM), we systematically examined YouTube and Instagram comments through an innovative human-AI collaboration pipeline integrating BERTopic, reasoning-enhanced large language models (LLMs), LLM fine-tuning, and embedding-based semantic evaluations. Our analysis identified three distinct generic frames, entertainment, politics/controversy, and athletics, each eliciting unique warmth and competence evaluations. Entertainment frames consistently occupied SCM's admiration quadrant, whereas political discourse more often aligned with contempt. However, several issue-specific frames deviated from traditional SCM profiles, revealing nuanced audience perceptions such as warm-but-incompetent and cold-but-competent stereotypes. Cross-platform comparisons uncovered evaluative reversals, indicating that perceptions of Trump shifted with platform norms and audience composition. Theoretically, the findings extend framing theory by illustrating how audiences actively co-construct meaning in politically salient entertainment contexts, while reaffirming SCM's utility in analyzing spontaneous digital discourse. Methodologically, we demonstrate a scalable, replicable human-AI workflow for large-scale, theory-driven social media analysis. Practically, the results offer insights for content creators, sports marketers, and political strategists seeking to navigate the reputational opportunities and risks of aligning with polarizing figures in cross-platform media environments.}
}
@article{OLAWADE2025105987,
title = {Artificial intelligence in tobacco control: A systematic scoping review of applications, challenges, and ethical implications},
journal = {International Journal of Medical Informatics},
volume = {202},
pages = {105987},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.105987},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625002047},
author = {David B. Olawade and Charity A. Aienobe-Asekharen},
keywords = {Artificial Intelligence, Tobacco Control, Smoking, Cessation, Public Health, Predictive Modelling, Machine Learning, Language Models},
abstract = {Background
Tobacco use remains a significant global health challenge, contributing substantially to preventable morbidity and mortality. Despite established interventions, outcomes vary due to scalability issues, resource constraints, and limited reach.
Objective
To systematically explore current artificial intelligence (AI) applications within tobacco control, highlighting their usefulness, benefits, limitations, and ethical implications.
Method
This scoping review followed the Arksey and O’Malley framework and PRISMA-ScR guidelines. Five major databases (PubMed, Scopus, Web of Science, IEEE Xplore, and PsycINFO) were searched for articles published between January 2010 and March 2025. From 1,172 initial records, 57 studies met inclusion criteria after screening.
Results
AI-driven tools, including machine learning and natural language processing, effectively monitor social media for emerging tobacco trends and personalize smoking cessation interventions. Applications were predominantly focused on predictive modelling (using algorithms like XGBoost and SVM to predict e-cigarette use and relapse risk), cessation support (employing chatbots and reinforcement learning to improve accessibility), and social media surveillance (detecting synthetic nicotine promotions and analysing vaping trends). Approximately 22% of studies aligned with WHO FCTC Article 13 (tobacco advertising regulation), while 45% supported Article 14 (cessation services). However, tobacco industry interference remains a critical challenge, with AI technologies exploited to undermine public health initiatives, target vulnerable populations, and manipulate policy discussions. Critical issues including algorithmic bias, privacy concerns, interpretability challenges, and data quality must be addressed to ensure positive impact.
Conclusion
AI holds considerable promise for extending tobacco control if implemented ethically, transparently, and collaboratively. Future directions emphasize explainable AI development, integration of real-time intervention systems, global data inclusion, and robust cross-sector collaboration. While the current landscape shows a laudable start, it reflects the need for more diverse skill sets to fully harness AI’s extensive prospects for tobacco control and achieving tobacco endgame goals.}
}
@article{EZIKE2022,
title = {Exploring Factors That Predict Marketing of e-Cigarette Products on Twitter: Infodemiology Approach Using Time Series},
journal = {JMIR Infodemiology},
volume = {2},
number = {2},
year = {2022},
issn = {2564-1891},
doi = {https://doi.org/10.2196/37412},
url = {https://www.sciencedirect.com/science/article/pii/S2564189122000597},
author = {Nnamdi C Ezike and Allison {Ames Boykin} and Page D Dobbs and Huy Mai and Brian A Primack},
keywords = {tobacco, electronic cigarettes, social media, marketing, time series, youth, young adults, infodemiology, infoveillance, digital marketing, advertising, Twitter, promote, e-cigarette},
abstract = {Background
Electronic nicotine delivery systems (known as electronic cigarettes or e-cigarettes) increase risk for adverse health outcomes among naïve tobacco users, particularly youth and young adults. This vulnerable population is also at risk for exposed brand marketing and advertisement of e-cigarettes on social media. Understanding predictors of how e-cigarette manufacturers conduct social media advertising and marketing could benefit public health approaches to addressing e-cigarette use.
Objective
This study documents factors that predict changes in daily frequency of commercial tweets about e-cigarettes using time series modeling techniques.
Methods
We analyzed data on the daily frequency of commercial tweets about e-cigarettes collected between January 1, 2017, and December 31, 2020. We fit the data to an autoregressive integrated moving average (ARIMA) model and unobserved components model (UCM). Four measures assessed model prediction accuracy. Predictors in the UCM include days with events related to the US Food and Drug Administration (FDA), non-FDA-related events with significant importance such as academic or news announcements, weekday versus weekend, and the period when JUUL maintained an active Twitter account (ie, actively tweeting from their corporate Twitter account) versus when JUUL stopped tweeting.
Results
When the 2 statistical models were fit to the data, the results indicate that the UCM was the best modeling technique for our data. All 4 predictors included in the UCM were significant predictors of the daily frequency of commercial tweets about e-cigarettes. On average, brand advertisement and marketing of e-cigarettes on Twitter was higher by more than 150 advertisements on days with FDA-related events compared to days without FDA events. Similarly, more than 40 commercial tweets about e-cigarettes were, on average, recorded on days with important non-FDA events compared to days without such events. We also found that there were more commercial tweets about e-cigarettes on weekdays than on weekends and more commercial tweets when JUUL maintained an active Twitter account.
Conclusions
e-Cigarette companies promote their products on Twitter. Commercial tweets were significantly more likely to be posted on days with important FDA announcements, which may alter the narrative about information shared by the FDA. There remains a need for regulation of digital marketing of e-cigarette products in the United States.}
}
@article{LEITER2024100541,
title = {ChatGPT: A meta-analysis after 2.5 months},
journal = {Machine Learning with Applications},
volume = {16},
pages = {100541},
year = {2024},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2024.100541},
url = {https://www.sciencedirect.com/science/article/pii/S2666827024000173},
author = {Christoph Leiter and Ran Zhang and Yanran Chen and Jonas Belouadi and Daniil Larionov and Vivian Fresen and Steffen Eger},
keywords = {ChatGPT, Sentiment analysis, Emotion analysis, Science, Large language models},
abstract = {ChatGPT, a chatbot developed by OpenAI, has gained widespread popularity and media attention since its release in November 2022. However, little hard evidence is available regarding its perception in various sources. In this paper, we analyze over 300,000 tweets and more than 150 scientific papers to investigate how ChatGPT is perceived and discussed. Our findings show that ChatGPT is generally viewed as of high quality, with positive sentiment and emotions of joy dominating social media. Its perception has slightly decreased since its debut, however, with joy decreasing and (negative) surprise on the rise, and it is perceived more negatively in languages other than English. In recent scientific papers, ChatGPT is characterized as a great opportunity across various fields including the medical domain, but also as a threat concerning ethics and receives mixed assessments for education. Our comprehensive meta-analysis of ChatGPT’s perception after 2.5 months since its release can contribute to shaping the public debate and informing its future development. We make our data available.11https://github.com/NL2G/ChatGPTReview.}
}
@article{GUO2025130152,
title = {Video-text retrieval based on multi-grained hierarchical aggregation and semantic similarity optimization},
journal = {Neurocomputing},
volume = {638},
pages = {130152},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130152},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225008240},
author = {Jie Guo and Shujie Lan and Bin Song and Mengying Wang},
keywords = {Video-text retrieval, Multi-grained hierarchical aggregation, Semantic similarity optimization, Temporal correlation},
abstract = {Current video-text retrieval approaches face two major challenges. Firstly, the semantic information imbalance between modalities, primarily caused by differences in granularity of inter-modal feature correlations, poses challenges for accurate alignment. Secondly, the presence of irrelevant content, which can be considered as noise, within videos and texts frequently leads to incorrect retrieval results. To address these issues, we propose the multi-grained hierarchical aggregation and semantic similarity optimization network for VTR, which is named as MSNet. MSNet employs a multi-grained hierarchical aggregation module (MHA) we designed to integrate global and local information. It introduces the expectation–maximization contrastive learning (EMCL) strategy and the interactive noise reduction (INR) technique to effectively reduce the impact of noise. Moreover, MHA extracts the optimized frame feature by a contextual frame encoder we designed to mitigate semantic imbalance. Additionally, the proposed semantic similarity optimization module (SSO) refines multi-scale feature interactions. Extensive experiments on benchmark datasets, including MSR-VTT, MSVD and DiDeMo, demonstrate the superior performance and effectiveness of MSNet in VTR.}
}
@article{MACKENZIE20239,
title = {Surprising Advances in Generative Artificial Intelligence Prompt Amazement—and Worries},
journal = {Engineering},
volume = {25},
pages = {9-11},
year = {2023},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2023.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095809923001613},
author = {Dana Mackenzie}
}
@article{YOO2024e36392,
title = {The impact of AI-enabled CRM systems on organizational competitive advantage: A mixed-method approach using BERTopic and PLS-SEM},
journal = {Heliyon},
volume = {10},
number = {16},
pages = {e36392},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e36392},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024124231},
author = {Joon Woo Yoo and Junsung Park and Heejun Park},
keywords = {Customer relationship management, Resource-based view, Artificial intelligence, BERT, Topic modeling},
abstract = {The recent advances in machine learning and deep learning algorithms, along with the advent of generative AI, have led AI to become the “new normal” in organizations. This trend has extended to CRM, resulting in the development of AI-enabled CRM systems, or AI-CRM. Despite the growing adoption of AI as part of competitive strategies, many firms report minimal or no positive effect of AI on performance. This study addresses the research questions: “What are the critical features of AI-CRM systems?” and “How do these features impact organizational competitive advantage?” To explore this, we aim to identify key characteristics of AI-CRM and assess their impact on organizational performance. In Study 1, we utilize BERTopic topic modeling to extract critical features of AI-CRM from user reviews. Study 2 employs PLS-SEM to examine how these features influence organizational competitive advantage. Study 1 reveals four main characteristics of AI-CRM (general, marketing, sales, and service/support), each comprising distinct features. Study 2 shows that these characteristics differentially impact CRM capability, significantly affecting performance and competitive advantage. The findings offer valuable insights for both theory and practice regarding the effective use of AI in organizations.}
}
@article{RUSSELL2022,
title = {Using Natural Language Processing to Explore “Dry January” Posts on Twitter: Longitudinal Infodemiology Study},
journal = {Journal of Medical Internet Research},
volume = {24},
number = {11},
year = {2022},
issn = {1438-8871},
doi = {https://doi.org/10.2196/40160},
url = {https://www.sciencedirect.com/science/article/pii/S1438887122007269},
author = {Alex M Russell and Danny Valdez and Shawn C Chiang and Ben N Montemayor and Adam E Barry and Hsien-Chang Lin and Philip M Massey},
keywords = {alcohol, drinking, social media, Twitter, Dry January, infodemiology, infoveillance, natural language processing},
abstract = {Background
Dry January, a temporary alcohol abstinence campaign, encourages individuals to reflect on their relationship with alcohol by temporarily abstaining from consumption during the month of January. Though Dry January has become a global phenomenon, there has been limited investigation into Dry January participants’ experiences. One means through which to gain insights into individuals’ Dry January-related experiences is by leveraging large-scale social media data (eg, Twitter chatter) to explore and characterize public discourse concerning Dry January.
Objective
We sought to answer the following questions: (1) What themes are present within a corpus of tweets about Dry January, and is there consistency in the language used to discuss Dry January across multiple years of tweets (2020-2022)? (2) Do unique themes or patterns emerge in Dry January 2021 tweets after the onset of the COVID-19 pandemic? and (3) What is the association with tweet composition (ie, sentiment and human-authored vs bot-authored) and engagement with Dry January tweets?
Methods
We applied natural language processing techniques to a large sample of tweets (n=222,917) containing the term “dry january” or “dryjanuary” posted from December 15 to February 15 across three separate years of participation (2020-2022). Term frequency inverse document frequency, k-means clustering, and principal component analysis were used for data visualization to identify the optimal number of clusters per year. Once data were visualized, we ran interpretation models to afford within-year (or within-cluster) comparisons. Latent Dirichlet allocation topic modeling was used to examine content within each cluster per given year. Valence Aware Dictionary and Sentiment Reasoner sentiment analysis was used to examine affect per cluster per year. The Botometer automated account check was used to determine average bot score per cluster per year. Last, to assess user engagement with Dry January content, we took the average number of likes and retweets per cluster and ran correlations with other outcome variables of interest.
Results
We observed several similar topics per year (eg, Dry January resources, Dry January health benefits, updates related to Dry January progress), suggesting relative consistency in Dry January content over time. Although there was overlap in themes across multiple years of tweets, unique themes related to individuals’ experiences with alcohol during the midst of the COVID-19 global pandemic were detected in the corpus of tweets from 2021. Also, tweet composition was associated with engagement, including number of likes, retweets, and quote-tweets per post. Bot-dominant clusters had fewer likes, retweets, or quote tweets compared with human-authored clusters.
Conclusions
The findings underscore the utility for using large-scale social media, such as discussions on Twitter, to study drinking reduction attempts and to monitor the ongoing dynamic needs of persons contemplating, preparing for, or actively pursuing attempts to quit or cut down on their drinking.}
}
@article{IHNAINI2024102263,
title = {Semantic similarity on multimodal data: A comprehensive survey with applications},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {10},
pages = {102263},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102263},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824003525},
author = {Baha Ihnaini and Belal Abuhaija and Ebenezer Atta Mills and Massudi Mahmuddin},
keywords = {Semantic Similarity, Similarity Measures, Multimodal Semantic Similarity, Semantic Similarity Applications, Machine Learning, And Deep Learning},
abstract = {Recently, the revival of the semantic similarity concept has been featured by the rapidly growing artificial intelligence research fueled by advanced deep learning architectures enabling machine intelligence using multimodal data. Thus, semantic similarity in multimodal data has gained substantial attention among researchers. However, the existing surveys on semantic similarity measures are restricted to a single modality, mainly text, which significantly limits the capability to understand the intelligence of real-world application scenarios. This study critically reviews semantic similarity approaches by shortlisting 223 vital articles from the leading databases and digital libraries to offer a comprehensive and systematic literature survey. The notable contribution is to illuminate the evolving landscape of semantic similarity and its crucial role in understanding, interpreting, and extracting meaningful information from multimodal data. Primarily, it highlights the challenges and opportunities inherent in different modalities, emphasizing the significance of advancements in cross-modal and multimodal semantic similarity approaches with potential application scenarios. Finally, the survey concludes by summarizing valuable future research directions. The insights provided in this survey improve the understanding and pave the way for further innovation by guiding researchers in leveraging the strength of semantic similarity for an extensive range of real-world applications.}
}
@article{MUSLEH20241033,
title = {A Machine Learning Approach to Cyberbullying Detection in Arabic Tweets},
journal = {Computers, Materials and Continua},
volume = {80},
number = {1},
pages = {1033-1054},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.048003},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824004570},
author = {Dhiaa Musleh and Atta Rahman and Mohammed Abbas Alkherallah and Menhal Kamel Al-Bohassan and Mustafa Mohammed Alawami and Hayder Ali Alsebaa and Jawad Ali Alnemer and Ghazi Fayez Al-Mutairi and May Issa Aldossary and Dalal A. Aldowaihi and Fahd Alhaidari},
keywords = {Supervised machine learning, ensemble learning, cyberbullying, Arabic tweets, NLP},
abstract = {With the rapid growth of internet usage, a new situation has been created that enables practicing bullying. Cyberbullying has increased over the past decade, and it has the same adverse effects as face-to-face bullying, like anger, sadness, anxiety, and fear. With the anonymity people get on the internet, they tend to be more aggressive and express their emotions freely without considering the effects, which can be a reason for the increase in cyberbullying and it is the main motive behind the current study. This study presents a thorough background of cyberbullying and the techniques used to collect, preprocess, and analyze the datasets. Moreover, a comprehensive review of the literature has been conducted to figure out research gaps and effective techniques and practices in cyberbullying detection in various languages, and it was deduced that there is significant room for improvement in the Arabic language. As a result, the current study focuses on the investigation of shortlisted machine learning algorithms in natural language processing (NLP) for the classification of Arabic datasets duly collected from Twitter (also known as X). In this regard, support vector machine (SVM), Naïve Bayes (NB), Random Forest (RF), Logistic regression (LR), Bootstrap aggregating (Bagging), Gradient Boosting (GBoost), Light Gradient Boosting Machine (LightGBM), Adaptive Boosting (AdaBoost), and eXtreme Gradient Boosting (XGBoost) were shortlisted and investigated due to their effectiveness in the similar problems. Finally, the scheme was evaluated by well-known performance measures like accuracy, precision, Recall, and F1-score. Consequently, XGBoost exhibited the best performance with 89.95% accuracy, which is promising compared to the state-of-the-art.}
}
@article{MA2025104382,
title = {Mining online reviews by deep learning-based UIE-ERNIE for AI-empowered live streaming product selection},
journal = {Journal of Retailing and Consumer Services},
volume = {87},
pages = {104382},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104382},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925001614},
author = {Yanfang Ma and Jialei Li and Zongmin Li and Yu Gong and Zhao Zhao and Xiaoyu Wang},
keywords = {Live streaming product selection, Large-scale group decision-making problem (LSGDM), Universal information extraction with ERNIE (UIE-ERNIE)},
abstract = {In recent years, live streaming selling has experienced rapid growth, and become a widely adopted online sales way. The selection of products for live streaming is critical to attracting and retaining customers, thereby enhancing the reputation of live streaming rooms. However, given the frequent concerns about product quality in live streaming, a product selection approach that incorporates consumer preferences and the characteristics of live streaming room is essential. To address this challenge, this study introduces an AI-empowered large-scale group decision making (LSGDM) approach for live streaming product selection. Firstly, online reviews about live streaming products from e-commerce platforms, such as “JD.com” and “Taobao”, are collected by utilizing the Octopus crawler software. Then, a deep learning-based Universal Information Extraction with ERNIE (UIE-ERNIE) is firstly introduced to mine online reviews, which can automatically identify product attributes that consumers care about, and can clearly classify sentiments in the reviews. Furthermore, linguistic hesitant-Z-numbers (LHZNs) are employed to concisely represent evaluation information. Finally, an online reviews-driven case study is formulated to illustrate the applicability of the proposed method. Compared with the LDA and TF-IDF, mining reviews by UIE-ERNIE offers higher accuracy and efficiency without complex preprocessing. Sensitivity analysis is performed to explore the effects of the number of experts, online reviews and consensus threshold for the decision process. Comparative analysis indicates that the LHZNs significantly improve consensus degree. Overall, this study proposes an AI-empowered approach for live streaming product selection, combining real customer online reviews with expert evaluations to support decision-making.}
}
@article{ZHU2022694,
title = {Recognizing irrelevant faces in short-form videos based on feature fusion and active learning},
journal = {Neurocomputing},
volume = {501},
pages = {694-704},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.06.064},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222008013},
author = {Mingcheng Zhu and Rongchuan Zhang and Haizhou Wang},
keywords = {Face protection, Feature fusion, Loss function, Domain adaptation},
abstract = {In recent years, short-form videos spread rapidly around the world and became a popular way of entertainment for people to share their daily lives. However, many videos record behaviors of other people without their awareness and are uploaded onto the short-form video platforms. Such behavior severely invades personal privacy and can even bring risks of personal information leakage. At present, few studies focus on detecting privacy violations in short-form videos. Meanwhile, due to the difficulty in transferring existing models to the scenario of short-form videos and the lack of reliable datasets, it is very challenging to recognize irrelevant faces in short-form videos. To deal with this problem, we constructed and published an irrelevant faces dataset (IF-Dataset) with 43,965 irrelevant face images and 89,924 relevant face images based on the videos collected from Douyin (the Chinese version of TikTok). In addition, we constructed a framework that implemented our proposed deep learning model Multi-features Multi-head Fusion Network (MMFNet) to recognize irrelevant faces from short-form videos. The experimental results show that the F1 score of the MMFNet can reach 87.03%. We also proposed a novel loss function as well as an active learning system to improve the generalization ability of models, which can reach the Relative Error Reduction (RER) up to 29.58%. Our work provides both theoretical and practical support for face protection in short-form videos.}
}
@article{LIU202237,
title = {Chinese named entity recognition: The state of the art},
journal = {Neurocomputing},
volume = {473},
pages = {37-53},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.10.101},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221016581},
author = {Pan Liu and Yanming Guo and Fenglei Wang and Guohui Li},
keywords = {CNER, Character representation, Context encoder, Tag decoder, Attention mechanism, Adversarial transfer learning},
abstract = {Named Entity Recognition(NER), one of the most fundamental problems in natural language processing, seeks to identify the boundaries and types of entities with specific meanings in natural language text. As an important international language, Chinese has uniqueness in many aspects, and Chinese NER (CNER) is receiving increasing attention. In this paper, we give a comprehensive survey of recent advances in CNER. We first introduce some preliminary knowledge, including the common datasets, tag schemes, evaluation metrics and difficulties of CNER. Then, we separately describe recent advances in traditional research and deep learning research of CNER, in which the CNER with deep learning is our focus. We summarize related works in a basic three-layer architecture, including character representation, context encoder, and context encoder and tag decoder. Meanwhile, the attention mechanism and adversarial-transfer learning methods based on this architecture are introduced. Finally, we present the future research trends and challenges of CNER.}
}
@article{WANG2022101588,
title = {Sentiment analysis from Customer-generated online videos on product review using topic modeling and Multi-attention BLSTM},
journal = {Advanced Engineering Informatics},
volume = {52},
pages = {101588},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101588},
url = {https://www.sciencedirect.com/science/article/pii/S147403462200060X},
author = {Zheng Wang and Peng Gao and Xuening Chu},
keywords = {Sentiment analysis, Online video, Topic modeling, Deep learning, Product improvement},
abstract = {With the popularity of social websites and mobile applications including Instagram, YouTube, TikTok, etc., online videos shared by customers presenting their thoughts and reviews on products are posted daily in increasing numbers. Such online videos containing Voice of Customer (VOC) are precious for product designers or managers to capture customer sentiment and understand customer preference. For this purpose, we propose a novel method for analyzing customer sentiment from online videos on product review. Firstly, latent Dirichlet allocation (LDA) modeling is applied to identify the topics from the online videos after data preprocessing. Then sentiment polarity corresponding to each topic of each speaker in videos can be identified using our newly designed multi-attention bi-directional LSTM (BLSTM(MA)), which can better mine complex relationships among a speaker’s sentiments on different topics. This paper is of great practical value for company managers and researchers to better understand a large number of customer opinions on specific products. To explain the application of this method and prove its effectiveness, two cases respectively on smartphones and several published datasets are developed finally.}
}
@article{SITTAR2025100368,
title = {BAR-analytics: A web-based platform for analyzing information spreading barriers in news: Comparative analysis across multiple barriers and events},
journal = {International Journal of Information Management Data Insights},
volume = {5},
number = {2},
pages = {100368},
year = {2025},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2025.100368},
url = {https://www.sciencedirect.com/science/article/pii/S2667096825000503},
author = {Abdul Sittar and Dunja Mladenić and Alenka Guček and Marko Grobelnik},
keywords = {News propagation, News spreading barriers, Propagation analysis, Trends analysis, Sentiment analysis, Temporal analysis, Russian–Ukrainian war, Israeli–Palestinian},
abstract = {This paper presents BAR-Analytics, a web-based, open-source platform designed to analyze news dissemination across geographical, economic, political, and cultural boundaries. Using the Russian–Ukrainian and Israeli–Palestinian conflicts as case studies, the platform integrates four analytical methods: propagation analysis, trend analysis, sentiment analysis, and temporal topic modeling. Over 350,000 articles were collected and analyzed, with a focus on economic disparities and geographical influences using metadata enrichment. We evaluate the case studies using coherence, sentiment polarity, topic frequency, and trend shifts as key metrics. Our results show distinct patterns in news coverage: the Israeli–Palestinian conflict tends to have more negative sentiment with a focus on human rights, while the Russia–Ukraine conflict is more positive, emphasizing election interference. These findings highlight the influence of political, economic, and regional factors in shaping media narratives across different conflicts.}
}
@article{SHI20235932,
title = {Understanding public opinions on Chinese short video platform by multimodal sentiment analysis using deep learning-based techniques},
journal = {Kybernetes},
volume = {53},
number = {12},
pages = {5932-5950},
year = {2023},
issn = {0368-492X},
doi = {https://doi.org/10.1108/K-04-2023-0723},
url = {https://www.sciencedirect.com/science/article/pii/S0368492X23000361},
author = {Wei Shi and Jing Zhang and Shaoyi He},
keywords = {Multimodal sentiment analysis, Chinese short video, Convolutional neural network, Cross attention, Feature fusion},
abstract = {Purpose
With the rapid development of short videos in China, the public has become accustomed to using short videos to express their opinions. This paper aims to solve problems such as how to represent the features of different modalities and achieve effective cross-modal feature fusion when analyzing the multi-modal sentiment of Chinese short videos (CSVs).
Design/methodology/approach
This paper aims to propose a sentiment analysis model MSCNN-CPL-CAFF using multi-scale convolutional neural network and cross attention fusion mechanism to analyze the CSVs. The audio-visual and textual data of CSVs themed on “COVID-19, catering industry” are collected from CSV platform Douyin first, and then a comparative analysis is conducted with advanced baseline models.
Findings
The sample number of the weak negative and neutral sentiment is the largest, and the sample number of the positive and weak positive sentiment is relatively small, accounting for only about 11% of the total samples. The MSCNN-CPL-CAFF model has achieved the Acc-2, Acc-3 and F1 score of 85.01%, 74.16 and 84.84%, respectively, which outperforms the highest value of baseline methods in accuracy and achieves competitive computation speed.
Practical implications
This research offers some implications regarding the impact of COVID-19 on catering industry in China by focusing on multi-modal sentiment of CSVs. The methodology can be utilized to analyze the opinions of the general public on social media platform and to categorize them accordingly.
Originality/value
This paper presents a novel deep-learning multimodal sentiment analysis model, which provides a new perspective for public opinion research on the short video platform.}
}
@article{FU20251103,
title = {Interest-aware joint caching, computing, and communication optimization for mobile VR delivery in MEC networks},
journal = {Digital Communications and Networks},
volume = {11},
number = {4},
pages = {1103-1113},
year = {2025},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2024.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S2352864824001469},
author = {Baojie Fu and Tong Tang and Dapeng Wu and Ruyan Wang},
keywords = {VR service performance, Edge-terminal cooperative system, Interest analysis, User fairness},
abstract = {In the upcoming B5G/6G era, Virtual Reality (VR) over wireless has become a typical application, which is an inevitable trend in the development of video. However, in immersive and interactive VR experiences, VR services typically exhibit high delay, while simultaneously posing challenges for the energy consumption of local devices. To address these issues, this paper aims to improve the performance of VR service in the edge-terminal cooperative system. Specifically, we formulate a joint Caching, Computing, and Communication (3C) VR service policy problem by optimizing the weighted sum of the total VR delivery delay and the energy consumption of local devices. To design the optimal VR service policy, the optimization problem is decoupled into three independent subproblems to be solved separately. To improve the caching efficiency within the network, a Bert-based user interest analysis method is first proposed to accurately characterize the content request behavior. Based on this, a service cost minimum-maximization problem is formulated under the consideration of performance fairness among users. Then, the joint caching and computing scheme is derived for each user with a given allocation of communication resources while a bisection-based communication scheme is acquired with the given information on the joint caching and computing policy. With alternative optimization, an optimal policy for joint 3C based on user interest can be finally obtained. Simulation results are presented to demonstrate the superiority of the proposed user interest-aware caching scheme and the effectiveness of the joint 3C optimization policy while considering user fairness. Our code is available at https://github.com/mrfuqaq1108/Interest-Aware-Joint-3C-Optimization.}
}
@article{HENRY2024953,
title = {Automatic question generation for bahasa indonesia examination using copynet},
journal = {Procedia Computer Science},
volume = {245},
pages = {953-962},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.323},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031314},
author = {Matthew Martianus Henry and Gregorius Natanael Elwirehardja and Bens Pardamean},
keywords = {Automatic question generation, Bahasa Indonesia, Copying mechanism, Natural language generation, Sequence-to-sequence},
abstract = {In educational institutions, an educator is responsible for assessing the student's knowledge grasp through examination. Creating exam questions, even the low-level factoid questions, is time-consuming, especially for inexperienced educators. Therefore, this study aims to create a sequence-to-sequence model using CopyNet by exploiting its copying mechanism advantage to automatically generate Bahasa Indonesia factoid questions to ease the educator's burden. Indonesian records in the TyDi QA dataset are used as the model input. GRU and Bi-GRU are employed as the CopyNet encoder, while LSTM is used as the CopyNet decoder. The model that utilizes GRU as the encoder achieves BLEU1, BLEU2, BLEU3, BLEU4, and ROUGE-L scores of 0.28, 0.19, 0.14, 0.1, and 0.32, respectively. Bi-GRU utilization as the model encoder achieves BLEU1, BLEU2, BLEU3, BLEU4, and ROUGE-L scores of 0.26, 0.17, 0.12, 0.09, and 0.30, respectively. Models using either encoder still achieve low scores. However, compared with the previous work, the result is still on par regarding the BLEU score. Further examination found that the generated questions do not adhere to semantic and syntactical correctness. Adding more records to the dataset and utilizing a more advanced architecture like CopyBERT are encouraged to improve the model performance in future work. Despite the result, this study has shown that CopyNet, primarily designed for text summarization or single-turn dialogue, can be tailored for factoid question generation.}
}
@article{GOEL2023,
title = {Users’ Concerns About Endometriosis on Social Media: Sentiment Analysis and Topic Modeling Study},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/45381},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123006179},
author = {Rahul Goel and Vijayachitra Modhukur and Katrin Täär and Andres Salumets and Rajesh Sharma and Maire Peters},
keywords = {endometriosis, latent Dirichlet allocation, pain, Reddit, sentiment analysis, social media, surgery, topic modeling, user engagement},
abstract = {Background
Endometriosis is a debilitating and difficult-to-diagnose gynecological disease. Owing to limited information and awareness, women often rely on social media platforms as a support system to engage in discussions regarding their disease-related concerns.
Objective
This study aimed to apply computational techniques to social media posts to identify discussion topics about endometriosis and to identify themes that require more attention from health care professionals and researchers. We also aimed to explore whether, amid the challenging nature of the disease, there are themes within the endometriosis community that gather posts with positive sentiments.
Methods
We retrospectively extracted posts from the subreddits r/Endo and r/endometriosis from January 2011 to April 2022. We analyzed 45,693 Reddit posts using sentiment analysis and topic modeling–based methods in machine learning.
Results
Since 2011, the number of posts and comments has increased steadily. The posts were categorized into 11 categories, and the highest number of posts were related to either asking for information (Question); sharing the experiences (Rant/Vent); or diagnosing and treating endometriosis, especially surgery (Surgery related). Sentiment analysis revealed that 92.09% (42,077/45,693) of posts were associated with negative sentiments, only 2.3% (1053/45,693) expressed positive feelings, and there were no categories with more positive than negative posts. Topic modeling revealed 27 major topics, and the most popular topics were Surgery, Questions/Advice, Diagnosis, and Pain. The Survey/Research topic, which brought together most research-related posts, was the last in terms of posts.
Conclusions
Our study shows that posts on social media platforms can provide insights into the concerns of women with endometriosis symptoms. The analysis of the posts confirmed that women with endometriosis have to face negative emotions and pain daily. The large number of posts related to asking questions shows that women do not receive sufficient information from physicians and need community support to cope with the disease. Health care professionals should pay more attention to the symptoms and diagnosis of endometriosis, discuss these topics with patients to reduce their dissatisfaction with doctors, and contribute more to the overall well-being of women with endometriosis. Researchers should also become more involved in social media and share new science-based knowledge regarding endometriosis.}
}