@article{ZHANG2024120069,
title = {SimRE: Simple contrastive learning with soft logical rule for knowledge graph embedding},
journal = {Information Sciences},
volume = {661},
pages = {120069},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.120069},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523016559},
author = {Dong Zhang and Zhe Rong and Chengyuan Xue and Guanyu Li},
keywords = {Knowledge graph completion, Knowledge graph embedding, Contrastive learning, Logical rule},
abstract = {Knowledge graphs serve as a pivotal framework for the structured representation of information regarding entities and relations. However, in the real world, these knowledge graphs are often incomplete and harboring missing facts. Knowledge graph completion (KGC) has emerged as a central research focus, entailing the automated prediction of these missing facts and garnering substantial scholarly attention in recent years. Text-based knowledge graph embedding methods have demonstrated considerable potential for tackling the challenges associated with KGC by employing pre-trained language models. However, their limitation lies in the lack of logical features, which constrains the efficacy of capturing intricate patterns within knowledge graphs. This paper proposed SimRE, a straightforward contrastive learning framework augmented with soft logic rules. SimRE introduces a self-supervised framework that leverages the input rule bodies to predict the corresponding rule heads through a contrastive objective. We introduced two rule sampling techniques to enhance the efficiency and accuracy of the model: in-batch rule negatives and pre-batch rule negatives. SimRE employs a simple method for integrating logical features with the text-based model. The experimental results on benchmark datasets demonstrate that the proposed approach outperforms state-of-the-art methods.}
}
@incollection{DEY2025177,
title = {10 - A brief study on evaluation metrics for knowledge graph embeddings},
editor = {Rajesh Kumar Dhanaraj and M. Nalini and Malathy Sathyamoorthy and Manar Mohaisen},
booktitle = {Knowledge Graph-Based Methods for Automated Driving},
publisher = {Elsevier},
pages = {177-204},
year = {2025},
isbn = {978-0-443-30040-0},
doi = {https://doi.org/10.1016/B978-0-443-30040-0.00010-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443300400000102},
author = {Sudeepa Roy Dey and Gambhire Swati Sampatrao and Sandesh Bananki Jayanth and Kulachi Thapar},
keywords = {Knowledge graph, Knowledge graph embeddings, Evaluation metrics, Link prediction, Clustering metrics, Quality metrics},
abstract = {Knowledge graphs (KG) have evolved as the latest solution to solve many real-life complex systems. The inherent nature of a KG ensures the integration of varied data sources into a highly cohesive and simplified interconnected representation. Some major applications of KG include recommendation systems, natural language processing, and health informatics. The simplified representation of the KG elements into a vector space is achieved through knowledge graph embeddings (KGE). These embeddings are pivotal in improving the predictive and manipulative powers of any KG elements and thereby improving the quality of KG’s. Nevertheless, the evaluation of these embeddings has been a recent area of study. Many researchers have proposed a variety of metrics to evaluate the KGE that are based on various parameters. This chapter explores the various existing evaluation metrics for KGE to ensure the quality and efficiency of any model. The structured encoded information facilitates suitable applications in the machine learning domain. The evaluation of these embeddings becomes crucial in explaining their effectiveness in capturing complicated relationships within knowledge graphs. To better understand knowledge graph embeddings and their importance in diverse applications, including entity categorization and link prediction, the chapter examines many assessment metrics. The reader obtains an understanding of the complex world of knowledge graph embeddings through this investigation, enabling them to meet obstacles and make use of these embeddings' potential in a variety of machine-learning applications.}
}
@article{WANG2025114336,
title = {Knowledge attention via radial basis functions for temporal knowledge graphs completion},
journal = {Knowledge-Based Systems},
volume = {329},
pages = {114336},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114336},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125013759},
author = {Enqiang Wang and Jin Liu and Xiao Liu and Bo Huang and Xu Huang},
keywords = {Temporal knowledge graphs completion, Ranking model, Knowledge sequences, Radial basis functions},
abstract = {In recent years, leveraging Large Language Models (LLMs) for Temporal Knowledge Graph Completion (TKGC) based on given queries and corresponding knowledge sequences has emerged as a novel architecture. The quality of knowledge sequences plays a decisive role in prediction performance. Previous studies directly generated knowledge sequences through manually defined rules, which we term Original Knowledge Sequences (OKS). However, due to the inherent complexity of Temporal Knowledge Graphs (TKGs), OKS tend to be overly cumbersome. In contrast, a comprehensive yet concise knowledge sequence (CCKS) proves crucial. To address this challenge, we propose a knowledge ranking model. First, we use the target training quadruples, along with the OKS corresponding to the head and tail entities in those quadruples, as the training samples for the model. Then, the model considers the global graph structure and temporal context of the knowledge in the OKS using a Relational Graph Convolutional Network (R-GCN) and a Transformer Encoder. Finally, the model uses Knowledge Attention via Radial Basis Functions (KA-RBF) to calculate the overall weighted similarity of all knowledge pairs in the OKS corresponding to the head and tail entities, and simplifies the OKS into CCKS by sorting the weights. We conducted experimental analysis from four different perspectives on five datasets, and the experimental results demonstrated the feasibility and effectiveness of the model. Code is available at https://github.com/foundation000/KA-RBF.}
}
@article{BORREGO2025113280,
title = {Research hypothesis generation over scientific knowledge graphs},
journal = {Knowledge-Based Systems},
volume = {315},
pages = {113280},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113280},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125003272},
author = {Agustín Borrego and Danilo Dessì and Daniel Ayala and Inma Hernández and Francesco Osborne and Diego {Reforgiato Recupero} and Davide Buscaldi and David Ruiz and Enrico Motta},
keywords = {Hypothesis generation, Knowledge graphs, Link prediction, Scholarly domain, Scientific facts, Artificial Intelligence},
abstract = {Generating research hypotheses is a crucial step in scientific investigation that involves the creation of precise, verifiable, and logically valid statements that can be empirically examined. Therefore, many efforts have been made to automate or assist this process through the use of various Artificial Intelligence solutions. However, most existing methods are tailored to very specific domains, particularly within the biomedical field. There have been recent attempts to formalize hypothesis generation as a link prediction task over knowledge graphs. This solution is potentially domain-independent and applicable across diverse disciplines. Nevertheless, current approaches for link prediction, which typically rely on embedding models or path-based methods, have shown limited success in accurately predicting new hypotheses. To address these limitations, this paper introduces ResearchLink, an innovative and domain-independent methodology for hypothesis generation over knowledge graphs. ResearchLink combines path-based features and knowledge graph embeddings with text embeddings, capturing the semantic context of entities within a given corpus, and integrates additional information from bibliometric databases to improve research collaboration predictions. To conduct a rigorous evaluation of ResearchLink, we constructed CSKG-600, a new dataset for hypothesis generation, consisting of 600 statements that were manually labeled by domain experts. ResearchLink achieved outstanding performance (78.7% P@20), significantly outperforming alternative approaches such as TransH (71.8%), TransD (71.7%), and RotatE (70.7%).}
}
@article{GU20222497,
title = {Knowledge Graph Representation Learning Based on Automatic Network Search for Link Prediction},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {135},
number = {3},
pages = {2497-2514},
year = {2022},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2023.024332},
url = {https://www.sciencedirect.com/science/article/pii/S1526149222002521},
author = {Zefeng Gu and Hua Chen},
keywords = {Knowledge graph embedding, link prediction, automatic network search},
abstract = {Link prediction, also known as Knowledge Graph Completion (KGC), is the common task in Knowledge Graphs (KGs) to predict missing connections between entities. Most existing methods focus on designing shallow, scalable models, which have less expressive than deep, multi-layer models. Furthermore, most operations like addition, matrix multiplications or factorization are handcrafted based on a few known relation patterns in several well-known datasets, such as FB15k, WN18, etc. However, due to the diversity and complex nature of real-world data distribution, it is inherently difficult to preset all latent patterns. To address this issue, we propose KGE-ANS, a novel knowledge graph embedding framework for general link prediction tasks using automatic network search. KGE-ANS can learn a deep, multi-layer effective architecture to adapt to different datasets through neural architecture search. In addition, the general search space we designed is tailored for KG tasks. We perform extensive experiments on benchmark datasets and the dataset constructed in this paper. The results show that our KGE-ANS outperforms several state-of-the-art methods, especially on these datasets with complex relation patterns.}
}
@article{ZHAO2024104725,
title = {Community knowledge graph abstraction for enhanced link prediction: A study on PubMed knowledge graph},
journal = {Journal of Biomedical Informatics},
volume = {158},
pages = {104725},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104725},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001436},
author = {Yang Zhao and Danushka Bollegala and Shunsuke Hirose and Yingzi Jin and Tomotake Kozu},
keywords = {PKG, CKG, KGE, Entity distance-based method, Link prediction, Backtracking process},
abstract = {Objective:
As new knowledge is produced at a rapid pace in the biomedical field, existing biomedical Knowledge Graphs (KGs) cannot be manually updated in a timely manner. Previous work in Natural Language Processing (NLP) has leveraged link prediction to infer the missing knowledge in general-purpose KGs. Inspired by this, we propose to apply link prediction to existing biomedical KGs to infer missing knowledge. Although Knowledge Graph Embedding (KGE) methods are effective in link prediction tasks, they are less capable of capturing relations between communities of entities with specific attributes (Fanourakis et al., 2023).
Methods:
To address this challenge, we proposed an entity distance-based method for abstracting a Community Knowledge Graph (CKG) from a simplified version of the pre-existing PubMed Knowledge Graph (PKG) (Xu et al., 2020). For link prediction on the abstracted CKG, we proposed an extension approach for the existing KGE models by linking the information in the PKG to the abstracted CKG. The applicability of this extension was proved by employing six well-known KGE models: TransE, TransH, DistMult, ComplEx, SimplE, and RotatE. Evaluation metrics including Mean Rank (MR), Mean Reciprocal Rank (MRR), and Hits@k were used to assess the link prediction performance. In addition, we presented a backtracking process that traces the results of CKG link prediction back to the PKG scale for further comparison.
Results:
Six different CKGs were abstracted from the PKG by using embeddings of the six KGE methods. The results of link prediction in these abstracted CKGs indicate that our proposed extension can improve the existing KGE methods, achieving a top-10 accuracy of 0.69 compared to 0.5 for TransE, 0.7 compared to 0.54 for TransH, 0.67 compared to 0.6 for DistMult, 0.73 compared to 0.57 for ComplEx, 0.73 compared to 0.63 for SimplE, and 0.85 compared to 0.76 for RotatE on their CKGs, respectively. These improved performances also highlight the wide applicability of the extension approach.
Conclusion:
This study proposed novel insights into abstracting CKGs from the PKG. The extension approach indicated enhanced performance of the existing KGE methods and has applicability. As an interesting future extension, we plan to conduct link prediction for entities that are newly introduced to the PKG.}
}
@article{JI2025113469,
title = {STSE: Spatio-temporal state embedding for knowledge graph completion},
journal = {Knowledge-Based Systems},
volume = {317},
pages = {113469},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113469},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125005167},
author = {Xiaoyu Ji and Yibing Cao and Jiangshui Zhang and Xinke Zhao},
keywords = {Spatio-temporal knowledge graph completion, Spatio-temporal entity, Spatio-temporal state embedding, Transformer, ResNet},
abstract = {The explicit integration of temporal and geospatial features into knowledge graphs enables more precise characterization of knowledge dynamics across temporal and geographic dimensions, while simultaneously amplifying the complexity of inferring missing facts in spatio-temporal knowledge graphs (STKGs). To address these dual challenges in Spatio-Temporal Knowledge Graph Completion (STKGC), we present STSE (Spatio-Temporal State Embedder), an innovative embedding framework that systematically coordinates relational semantics with spatial-temporal continuum modeling. Our technical contributions manifest through three key innovations: (1) A novel descriptive form that enhances practicality by distinguishing head/tail entity locations in tuples; (2) A geometry-aware embedding space that dynamically fuses spatial grids and temporal slices through spatio-temporal states, enabling robust reasoning on heterogeneous graphs; (3) An enhanced encoder that captures complex spatio-temporal contextual relationships between entities using modified Transformer and ResNet architectures. Experimental validation across three benchmark datasets (YAGO11k-ST, Wikidata12k-ST, ICEWS05-ST) demonstrates STSE's superiority, achieving 3.8 % Mean Reciprocal Rank (MRR) improvement in time prediction and 7.1 % Hits@10 enhancement in spatial location reasoning compared to state-of-the-art baselines. This methodological breakthrough establishes three implementable principles for STKGC: (1) geometric consistency constraints during fusion operations, (2) spatio-temporal difference capturing across heterogeneous relationships, (3) cross-domain applications ranging from epidemiological spread prediction to urban mobility pattern mining. © 2025 Elsevier Science. All rights reserved}
}
@article{LIN202557,
title = {Multi-relation-pattern knowledge graph embeddings for link prediction in hyperbolic space},
journal = {International Journal of Intelligent Networks},
volume = {6},
pages = {57-64},
year = {2025},
issn = {2666-6030},
doi = {https://doi.org/10.1016/j.ijin.2025.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S266660302500003X},
author = {Longxin Lin and Huaibin Qin and Quan Qi and Rui Gu and Pengxiang Zuo and Yongqiang Cheng},
keywords = {Intelligent networks, Knowledge graph embedding, Hyperbolic geometry, Poincaré ball, Link prediction},
abstract = {The aim of Knowledge Graph Embedding (KGE) is to acquire low-dimensional representations of entities and relationships for the purpose of predicting new valid triples, thereby enhancing the functionality of intelligent networks that rely on accurate data representation. In recommendation systems, for example, the model can enhance personalized suggestions by better understanding user-item relationships, especially when the relationships are hierarchical, such as in the case of user preferences across different product categories. Existing KGE models mostly learn embeddings in Euclidean space, which perform well in high-dimensional settings. However, in low-dimensional scenarios, these models struggle to accurately capture the hierarchical information of relationships in knowledge graphs (KG), a limitation that can adversely affect the performance of intelligent network systems where structured knowledge is critical for decision making and operational efficiency. Recently, the MuRP model was proposed, introducing the use of hyperbolic space for KG embedding. Using the properties of hyperbolic space, where the space near the center is small and the space away from the center is large, the MuRP model achieves effective KG embedding even in low-dimensional training conditions, making it particularly suitable for dynamic environments typical of intelligent networks. Therefore, this paper proposes a method that utilizes the characteristics of hyperbolic geometry to create an embedding model in hyperbolic space, combining translation and multi-dimensional rotation geometric transformations. This model accurately represents various relationship patterns in knowledge graphs, including symmetry, asymmetry, inversion, composition, hierarchy, and multiplicity, which are essential for enabling robust interactions in intelligent network frameworks. Experimental results demonstrate that the proposed model generally outperforms Euclidean space embedding models under low-dimensional training conditions and performs comparably to other hyperbolic KGE models. In experiments using the WN18RR dataset, the Hits@10 metric improved by 0.3% compared to the baseline model, and in experiments using the FB15k-237 dataset, the Hits@3 metric improved by 0.1% compared to the baseline model, validating the reliability of the proposed model and its potential contribution to advancing intelligent network applications.}
}
@article{LEE2024119857,
title = {Learning to compensate for lack of information: Extracting latent knowledge for effective temporal knowledge graph completion},
journal = {Information Sciences},
volume = {654},
pages = {119857},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119857},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523014421},
author = {Yeon-Chang Lee and JaeHyun Lee and Dongwon Lee and Sang-Wook Kim},
keywords = {Temporal knowledge graph, Graph embedding, Graph convolutional networks, Self-supervised learning},
abstract = {The goal of temporal knowledge graph embedding (TKGE) is to represent the entities and relations in a given temporal knowledge graph (TKG) as low-dimensional vectors (i.e., embeddings), which preserve both semantic information and temporal dynamics of the factual information. In this paper, we posit that the intrinsic difficulty of existing TKGE methods lies in the lack of information in KG snapshots with timestamps, each of which contains the facts that co-occur at a specific timestamp. To address this challenge, we propose a novel self-supervised TKGE approach, THOR (Three-tower grapH cOnvolution netwoRks (GCNs)), which extracts latent knowledge from TKGs by jointly leveraging both temporal and atemporal dependencies between entities and the structural dependency between relations. THOR learns the embeddings of entities and relations, obtained from three-tower GCNs by (1) maximizing the likelihood of the facts in a TKG and (2) addressing the lack of information in a TKG based on the auxiliary supervision signals of each entity. Our experiments on three real-world datasets demonstrate that THOR significantly outperforms 17 competitors in terms of TKG completion tasks. THOR yields up to 9.37% higher accuracy than the best competitor.}
}
@article{LIU2022117361,
title = {Learning structured embeddings of knowledge graphs with generative adversarial framework},
journal = {Expert Systems with Applications},
volume = {204},
pages = {117361},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117361},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422007138},
author = {Lu Liu and Jiehang Zeng and Xiaoqing Zheng},
keywords = {Structured embedding learning, Knowledge graph, Generative adversarial network, Triple classification, Link prediction},
abstract = {Many large knowledge graphs are now available and ready to provide semantically structured information that is regarded as an important resource for question answering and decision support tasks. However, they are built on rigid symbolic frameworks which makes them hard to be used in other intelligent systems. Knowledge graph embedding approaches are gaining increasing attention, which embeds symbolic entities and relations into continuous vector spaces. Such graph embeddings are often learned by training a model to distinguish true triples from negative ones. Unfortunately, the negative triples created by replacing their heads or tails with randomly selected entities are easily identified by the model, which makes them insufficient to train useful models. To this end, we propose a method under a generative adversarial architecture to learn graph embeddings, in which a generative network is trained to provide continually improved “plausible” triples whereas a discriminative network learns to distinguish truth triples from the others by competing with the generator in a two-player minimax game. When arriving at a convergence, the generative network recovers the training data and can be used for knowledge graph completion, while the discriminative network is trained to be a good triple classifier. Extensive experiments demonstrate our method can improve multiple graph embedding models with a significant margin on both link prediction and triple classification tasks.}
}
@article{WANG2024112218,
title = {TracKGE: Transformer with Relation-pattern Adaptive Contrastive Learning for Knowledge Graph Embedding},
journal = {Knowledge-Based Systems},
volume = {301},
pages = {112218},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112218},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124008529},
author = {Mingjie Wang and Zijie Li and Jun Wang and Wei Zou and Juxiang Zhou and Jianhou Gan},
keywords = {Knowledge graph embedding, Transformer, Contrastive learning, Link prediction},
abstract = {Knowledge Graphs, fundamental to intelligent applications, are increasingly critical in various domains, enhancing tasks like precise searching and personalized recommendation. Effectively representing entities and relationships in these graphs is key, especially as the Transformer model, despite its representational prowess, faces challenges in adapting to the graph’s structure and complex relations. In this work, we present the Transformer with Relation-pattern Adaptive Contrastive Learning for Knowledge Graph Embedding (TracKGE). Specifically, TracKGE transforms the structural information of the knowledge graph into a sequence format that is more manageable for Transformers. In addition, we employ a relation-pattern adaptive contrastive learning module to capture a richer semantic and complex relationship pattern information of the knowledge graph. Lastly, by introducing a mask node model, it addresses the issue of incomplete information in the knowledge graph, further enhancing the model’s capability to capture implicit relationships within it. To evaluate the performance of our model, we have chosen well-established models as baselines and executed link prediction tasks on four renowned datasets. Our experimental results reveal that our model excels in representing the semantics and intricate structures of Knowledge Graphs. It outperforms other advanced baseline models, showcasing its superior capability in handling complex data representations.}
}
@article{YU2025210,
title = {Positionally restricted masked knowledge graph completion via multi-head mutual attention},
journal = {Journal of Information and Intelligence},
volume = {3},
number = {3},
pages = {210-222},
year = {2025},
issn = {2949-7159},
doi = {https://doi.org/10.1016/j.jiixd.2025.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S2949715925000095},
author = {Qiang Yu and Liang Bao and Peng Nie and Lei Zuo},
keywords = {Knowledge graph, Link prediction, Attention mechanism, Information aggregation},
abstract = {Knowledge graph completion aims to enhance the completeness of knowledge graphs by predicting missing links. Link prediction is a common approach for this task, but existing methods, particularly those based on similarity computation, are often computationally expensive, especially for large models. To address this, we propose a novel method, positionally restricted masked knowledge graph completion (PR-MKGC), which reduces inference time by leveraging masked prediction and relying solely on structural information from the knowledge graph, without using textual data. We introduce a multi-head mutual attention mechanism that aggregates neighbor information more effectively, improving the model's ability to predict missing links. Experimental results demonstrate that PR-MKGC outperforms existing models in terms of both predictive performance and inference time on the FB15K-237 dataset.}
}
@article{ZHANG2022109,
title = {Structural context-based knowledge graph embedding for link prediction},
journal = {Neurocomputing},
volume = {470},
pages = {109-120},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.10.088},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221016192},
author = {Qianjin Zhang and Ronggui Wang and Juan Yang and Lixia Xue},
keywords = {Knowledge graph embedding, Link prediction, Relational structure-context, Edge structure-context},
abstract = {Knowledge graph embedding, which aims to address the limitation of symbolic representation of knowledge, has become an effective method for many AI downstream tasks, such as relation extraction, question answering. Existing knowledge graph embedding models mainly consider triples individually, and ignore the structural information connected with other entities. However, the connectivity between entities not only provides explicit structural information represented in triples, but also embodies a lot of implicit structure information. In this paper, a new knowledge graph embedding model is proposed, which can capture both the information of relational structure-context and edge structure-context by two-interaction. In addition, in order to model complex relations, we define different score function for different relation types. Moreover, the four relation connectivity types in knowledge graph (i.e. symmetry/antisymmetry, inversion, and composition) also can be modeled and inferred by StructurE. We evaluate our StructurE for knowledge graph link prediction task. Benefiting from the structural context and the relation-type-specific score function, compared with conventional geometric transformation-based knowledge graph embedding models StructurE achieves state-of-the-art results for link prediction. Moreover, compared with GCN-based models StructurE also achieves state-of-the-art results on more challenging dataset WN18RR which contains more symmetric relations.}
}
@article{LAKSHIKA2025102511,
title = {ASF: A Novel Associative Scoring Function for Embedded Knowledge Graph Reasoning},
journal = {Data & Knowledge Engineering},
pages = {102511},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102511},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25001065},
author = {MVPT Lakshika and HA Caldera},
keywords = {Association rule mining, FP-Growth, Knowledge graph embedding, Scoring Function, Triplet plausibility},
abstract = {One of the most important tools for knowledge management is the Knowledge Graph (KG), a multi-relational graph that depicts rich factual information across entities. A KG represents entities as nodes and relations as edges, with each edge represented by a triplet: (head entity, relation, tail entity). The Scoring Function (SF) in a KG quantifies the plausibility of these triplets and is often derived from KG embeddings. However, due to the distinct relational patterns across KGs, an SF that performs well on one KG might fail on another, making the design of optimal SFs a challenging task. This study introduces the concept of an Associative Scoring Function (ASF), which leverages Association Rule Mining (ARM) to discover and incorporate patterns and characteristics of symmetric, asymmetric, inverse, and other relational types within embedded KGs. The ARM technique in ASF uses the FP-Growth algorithm to extract meaningful associations, which is enhanced further through hyperparameter tuning. Extensive experiments on benchmark datasets demonstrate that ASF is KG-independent and performs better than state-of-the-art SFs. These results highlight ASF's potential to generalize across diverse KGs, offering a significant advancement in the KG link prediction task.}
}
@article{CHOI2023122161,
title = {Exploring a technology ecology for technology opportunity discovery: A link prediction approach using heterogeneous knowledge graphs},
journal = {Technological Forecasting and Social Change},
volume = {186},
pages = {122161},
year = {2023},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2022.122161},
url = {https://www.sciencedirect.com/science/article/pii/S0040162522006825},
author = {Jaewoong Choi and Changyong Lee and Janghyeok Yoon},
keywords = {Technology opportunity discovery, Knowledge graphs, Link prediction, Technology ecology, Machine learning},
abstract = {When a firm discovers and introduces new technology opportunities, it considers external context, such as technological changes, as well as internal context of technology capability and collaborators. These two contexts are separately considered in prior studies, despite their interaction. This study proposes a novel approach for technology opportunity discovery with a hybrid perspective using a technology ecology. It reflects technological contexts such as collaboration, competition, or technological association. We represent interactive relations between assignees, inventors, patents and technology areas via knowledge graphs, which are merged into a technology ecology. We focus on the relation between assignee and technology area nodes which indicates the assignee adopted technology opportunities related to the area. Further, to find the clues on new links, we analyze common neighboring nodes and position of the two nodes with network metrics. Next, we use them in a machine learning-based link prediction model, thereby identifying new technology areas likely to be linked to a firm of interest as technology opportunity candidates. They are evaluated in terms of the firm's internal context and external context and ranked via the TOPSIS method. The case study covering a technology-based firm in the biotechnology domain showed the applicability and feasibility of our approach.}
}
@article{SINGH2025102414,
title = {Evaluating diabetes dataset for knowledge graph embedding based link prediction},
journal = {Data & Knowledge Engineering},
volume = {157},
pages = {102414},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102414},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000096},
author = {Sushmita Singh and Manvi Siwach},
keywords = {Link prediction, Knowledge graphs, Knowledge graph embeddings, Knowledge graph completion, Translational embeddings, Diabetes},
abstract = {For doing any accurate analysis or prediction on data, a complete and well-populated dataset is required. Medical based data for any disease like diabetes is highly coupled and heterogeneous in nature, with numerous interconnections. This inherently complex data cannot be analysed by simple relational databases making knowledge graphs an ideal tool for its representation which can efficiently handle intricate relationships. Thus, knowledge graphs can be leveraged to analyse diabetes data, enhancing both the accuracy and efficiency of data-driven decision-making processes. Although substantial data exists on diabetes in various formats, the availability of organized and complete datasets is limited, highlighting the critical need for creation of a well-populated knowledge graph. Moreover while developing the knowledge graph, an inevitable problem of incompleteness is present due to missing links or relationships, necessitating the use of knowledge graph completion tasks to fill in this absent information which involves predicting missing data with various Link Prediction (LP) techniques. Among various link prediction methods, approaches based on knowledge graph embeddings have demonstrated superior performance and effectiveness. These knowledge graphs can support in-depth analysis and enhance the prediction of diabetes-associated risks in this field. This paper introduces a dataset specifically designed for performing link prediction on a diabetes knowledge graph, so that it can be used to fill the information gaps further contributing in the domain of risk analysis in diabetes. The accuracy of the dataset is assessed through validation with state-of-the-art embedding-based link prediction methods.}
}
@article{HAN20251951,
title = {Cyclical Training Framework with Graph Feature Optimization for Knowledge Graph Reasoning},
journal = {Computers, Materials and Continua},
volume = {83},
number = {2},
pages = {1951-1971},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.060134},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825004011},
author = {Xiaotong Han and Yunqi Jiang and Haitao Wang and Yuan Tian},
keywords = {Knowledge graph, reinforcement learning, transformer},
abstract = {Knowledge graphs (KGs), which organize real-world knowledge in triples, often suffer from issues of incompleteness. To address this, multi-hop knowledge graph reasoning (KGR) methods have been proposed for interpretable knowledge graph completion. The primary approaches to KGR can be broadly classified into two categories: reinforcement learning (RL)-based methods and sequence-to-sequence (seq2seq)-based methods. While each method has its own distinct advantages, they also come with inherent limitations. To leverage the strengths of each method while addressing their weaknesses, we propose a cyclical training method that alternates for several loops between the seq2seq training phase and the policy-based RL training phase using a transformer architecture. Additionally, a multimodal data encoding (MDE) module is introduced to improve the representation of entities and relations in KGs. The MDE module treats entities and relations as distinct modalities, processing each with a dedicated network specialized for its respective modality. It then combines the representations of entities and relations in a dynamic and fine-grained manner using a gating mechanism. The experimental results from the knowledge graph completion task highlight the effectiveness of the proposed framework. Across five benchmark datasets, our framework achieves an average improvement of 1.7% in the Hits@1 metric and a 0.8% average increase in the Mean Reciprocal Rank (MRR) compared to other strong baseline methods. Notably, the maximum improvement in Hits@1 exceeds 4%, further demonstrating the effectiveness of the proposed approach.}
}
@article{ZHU2024127857,
title = {PRGNN: Modeling high-order proximity with relational graph neural network for knowledge graph completion},
journal = {Neurocomputing},
volume = {594},
pages = {127857},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127857},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224006283},
author = {Danhao Zhu},
keywords = {Knowledge graph completion, Knowledge graph embedding, Graph neural network},
abstract = {Relational Graph Neural Networks (RGNNs) are designed to extract structural information from relational graphs and have garnered attention in the domain of Knowledge Graph Completion (KGC). However, recent empirical investigations have indicated that some prominent RGNN-based methodologies have not significantly enhanced precision, prompting questions regarding the efficacy of RGNNs in KGC applications. In this paper, we introduce a novel RGNN-based KGC approach, the Proximity Relational Graph Neural Network (PRGNN), which excels at modeling high-order proximities among entities. PRGNN is founded on a notably straightforward yet effective RGNN framework that discards unnecessary components commonly incorporated in previous approaches, such as attention layers, and linear and non-linear mappings. We demonstrate that PRGNN empowers traditional KGC techniques to apprehend high-order proximities among entities more effectively. Through extensive experimentation on benchmark datasets, we establish that PRGNN consistently outperforms conventional KGC methods and achieves state-of-the-art results. Furthermore, we show that PRGNN necessitates considerably less training time (ranging from one-third to one-fifth) and fewer parameters (ranging from half to two-thirds), rendering it an exceptionally efficient approach. All data and code have been made available at 11https://github.com/zhudanhao/PRGNN..}
}
@article{CHOI2023110245,
title = {Knowledge graph extension with a pre-trained language model via unified learning method},
journal = {Knowledge-Based Systems},
volume = {262},
pages = {110245},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.110245},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122013417},
author = {Bonggeun Choi and Youngjoong Ko},
keywords = {Knowledge graph completion, Open-world knowledge graph completion, Pre-trained language model, Entity representation learning, Multi-task learning},
abstract = {Knowledge graphs (KGs) are collections of real-world knowledge that is represented by a structured form of triples. Since they are manually built in their nascent stage, there is a common problem that some links (triples) are missing. Knowledge graph completion (KGC) aims to find those missing links and thereby complete the KGs. However, as knowledge increases through diverse sources, new entities have explosively emerged and they are needed to be connected to existing KGs. Thus, open-world KGC is targeted on extending KGs to those new entities. Dealing with those new entities is challenging because they do not have any connection with entities in the existing KGs. One way to handle the new ones is to embed them with their textual descriptions with pre-trained word embeddings and score them in the graph-vector space with the existing typical KGC models. These models have resulted in meaningful results but there is still a lack of studies on utilizing the latest neural networks, such as pre-trained language models which are known to be better at capturing contexts than pre-trained word embeddings. This paper proposes a novel model that effectively connects new entities and existing KGs through a pre-trained language model. To effectively handle the problem, we utilize two learning methods; one is the classification method of the masked language model (MLM) that predicts a word among a huge vocabulary set with a given context, and the other is multi-task learning based on the Multi-Task for Deep Neural Networks (MT-DNN). Based on the methods, the model first generates an embedding of a new entity using its textual description and then uses the embedding to find one of the existing entities from a KG where the new entity can be connected. The experimental results on three benchmark datasets, DBPedia50k, FB15k-237-OWE, and FB20k, show that the proposed model improves performances by 9.2%p, 4.4%p, and 11.1%p, respectively, and achieves new state-of-the-art performance for all datasets.}
}
@article{SU2025131067,
title = {Temporal knowledge graph multi-hop path reasoning method based on reinforcement learning},
journal = {Neurocomputing},
volume = {652},
pages = {131067},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131067},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225017394},
author = {Yingping Su and Jianjun Cao and Dechang Pi},
keywords = {Reinforcement Learning, Temporal knowledge graph, Attention Mechanism, Multi-hop Path Reasoning},
abstract = {Temporal Knowledge Graphs (TKGs) extend traditional knowledge graphs by incorporating temporal information, enabling reasoning over time-dependent facts. However, many real-world knowledge graphs are incomplete, requiring effective reasoning methods to infer missing information and improve their overall quality. Multi-hop reasoning is a promising method for this task, but existing methods often fail to fully utilize temporal information and relationship modeling, resulting in less accurate inference. Additionally, many approaches lack interpretability, making it difficult to explicitly trace the reasoning pathways. To address these challenges, this paper proposes reinforcement learning-based multi-hop path reasoning for TKGs (RLPR), a novel model designed to enhance inference accuracy and interpretability by integrating temporal and relational information. RLPR introduces a timestamp decomposition strategy to better capture temporal dependencies while reducing model complexity. Unlike conventional entity-focused attention mechanisms, RLPR applies attention at the relationship level, allowing for more precise modeling of relational interactions. Furthermore, RLPR employs a reinforcement learning-based strategy network that explicitly constructs multi-hop reasoning pathways, improving both the interpretability and adaptability of the inference process. Compared to SOAT methods, the RLPR model achieved the best results on open-source datasets. For the link prediction results, the metrics improved by 15.07 %, 13.56 %, 4.26 % on the ICEWS14 datasets. When the path length setting for the RLPR model during reasoning is set to 2, the RLPR model improved various metrics on the ICEWS14–2 datasets by 13.04 %, 60.61 %, 38.67 %, and 27.08 %.}
}
@article{HOU2025112622,
title = {Low-resource knowledge graph completion based on knowledge distillation driven by large language models},
journal = {Applied Soft Computing},
volume = {169},
pages = {112622},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112622},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624013966},
author = {Wenlong Hou and Weidong Zhao and Ning Jia and Xianhui Liu},
keywords = {Knowledge graph completion, Knowledge reasoning, Link prediction, Large language models},
abstract = {Knowledge graph completion (KGC) refines the existing knowledge graph (KG) by predicting missing entities or relations. Existing methods are mainly based on embeddings or texts but only perform better with abundant labeled data. Hence, KGC in resource-constrained settings is a significant problem, which faces challenges of data imbalance across relations and lack of relation label semantics. Considering that Large Language Models (LLMs) demonstrate powerful reasoning and generation capabilities, this work proposes an LLM-driven Knowledge Graph Completion Distillation (KGCD) model to address low-resource KGC. A two-stage framework is developed, involving teacher-student distillation by using LLM to improve reasoning, followed by fine-tuning on real-world low-resource datasets. To deal with data imbalance, a hybrid prompt design for LLM is proposed, which includes rethink and open prompts. Furthermore, a virtual relation label generation strategy enhances the model’s understanding of triples. Extensive experiments on three benchmarks have shown that KGCD’s effectiveness for low-resource KGC, achieving improvements in Mean Reciprocal Rank (MRR) by 11% and Hits@1 by 10% on the WN18, MRR by 10% and Hits@1 by 14% on the WN18RR, and MRR by 12% and Hits@1 by 11% on the YAGO3-10.}
}
@article{ONG2025126648,
title = {Dynamic link prediction: Using language models and graph structures for temporal knowledge graph completion with emerging entities and relations},
journal = {Expert Systems with Applications},
volume = {272},
pages = {126648},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126648},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425002702},
author = {Ryan Ong and Jiahao Sun and Yi-Ke Guo and Ovidiu Serban},
keywords = {Dynamic knowledge graphs, Language models, Link prediction},
abstract = {Knowledge graphs (KGs) represent real-world facts through entities and relations. However, static KGs fail to capture continuously emerging entities and relations over time. Temporal knowledge graphs address this by incorporating time information or providing multiple sequential snapshots of a static knowledge graph. Most existing work focuses on static KGs with fixed sets of entities and relations, meaning existing methods still struggle to encode emerging entities and relations. Therefore, we propose a novel methodology of combining language models and graph structure to enable the encoding of unseen entities and relations for temporal KG completion. Specifically, we encode relations with RoBERTa and entities using neighbouring relations alongside the entity’s relation type to provide contextual information. We evaluate our methodology on three datasets with emerging entities and relations over temporal snapshots: LKGE-Hybrid, FB-MBE, and the mergers and acquisitions domain TKGQA dataset. Our experiments show that our model achieves new state-of-the-art results on FB-MBE and LKGE-Hybrid while providing strong benchmark results for the TKGQA dataset. Our ablation studies show us that graph structure information is only beneficial if there is sufficient connectivity with the knowledge graph since sparser knowledge graphs can lead to noisy signals. We also explore the performance of Llama v2 on temporal link prediction, and the results show that current LLMs struggle with domain-specific temporal link prediction. Overall, our work provides an essential advance around effectively encoding continuously emerging entities and relations for temporal link prediction across evolving knowledge graphs over time.}
}
@article{XIAO2023107274,
title = {BugRadar: Bug localization by knowledge graph link prediction},
journal = {Information and Software Technology},
volume = {162},
pages = {107274},
year = {2023},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107274},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923001283},
author = {Xi Xiao and Renjie Xiao and Qing Li and Jianhui Lv and Shunyan Cui and Qixu Liu},
keywords = {Bug localization, Knowledge graph, Collaborative filtering},
abstract = {Context
: Information Retrieval-based Bug Localization (IRBL) aims to design automatic systems that find buggy files according to bug reports, which can reduce the time consumption to fix bugs for programmers. There has been extensive research on IRBL techniques in recent years. However, these methods cannot make full use of the structure information in bug reports and source files.
Objective
: In this paper, we propose a novel scheme BugRadar. It combines text features and structure features from bug reports and source files for bug localization. Especially, BugRadar leverages a knowledge graph to make use of structure features.
Method
: We originally propose a knowledge graph named TriGraph based on structure features and apply hyperbolic attention embedding to get the link prediction scores. For text features, we propose Partial Text Similarity which improves traditional Text Similarity and Method Level Text Similarity. We also propose Word Collaborative Filtering Score which leverages historical bug reports with more attention on important terms. Finally, we calculate the final suspicious scores based on the structure features, text features, and fixing time information from bug fixing history with a neural network.
Results
: We apply our scheme to four projects (Tomcat, SWT, JDT, and Birt) in a popular dataset and get approving results. BugRadar gets better results than other state-of-the-art methods on three projects out of the four. It achieves a relative improvement of 8.8% in SWT and 9.8% in JDT for Mean Average Precision compared to the previous best scheme KGBugLocator and 11.4% in Birt compared to Adaptive Regression.
Conclusions
: BugRadar can achieve approving performance on large-scale projects with enough historical bug reports. It verifies that knowledge graphs are capable of representing the structure features for bug localization. The novel Partial Text Similarity and Word Collaborative Filtering Score are both effective improvements for using text features.}
}
@article{FENG2025332,
title = {Temporal Knowledge Graph Embedding with Pre-trained Language Model},
journal = {Procedia Computer Science},
volume = {264},
pages = {332-345},
year = {2025},
note = {International Neural Network Society Workshop on Deep Learning Innovations and Applications 2025},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.07.144},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925021945},
author = {Wenying Feng and Jianming Li and Haiyan Wang and Zhaoquan Gu},
keywords = {Knowledge graph, knowledge graph representation, temporal knowledge graph, pre-trained language model},
abstract = {Large language models (LLMs) have demonstrated exceptional performance in natural language processing. This also leads to extensive research on knowledge extraction, knowledge fusion, knowledge representation, and knowledge completion using pre-trained language models (PLMs). Most of the existing works focus on static multi-relational knowledge graphs (KGs). In contrast, temporal knowledge graphs (TKGs) incorporate temporal information, whereas lack of research utilizing PLMs or LLMs. In this paper, we introduce PT2KGC, a temporal knowledge graph embedding model which employs the pre-trained language model for TKG completion and extrapolation. We present three modeling approaches of PT2KGC to model temporal knowledge: original knowledge embedding, explicit time modeling, and implicit time modeling. PT2KGC(Org.) relies solely on static knowledge; PT2KGC(Exp.) explicitly incorporates timestamps into quadruples; and PT2KGC(Imp.) models time implicitly through dataset reconstruction. We conduct experiments on two public TKG datasets. The results demonstrate the effectiveness of pre-trained language models for TKG embedding. Experiment results on three types of tasks show that all three modeling methods of PT2KGC outperform existing models. Additionally, we compare the performance of PT2KGC under different time modeling approaches.}
}
@article{LI2024103797,
title = {Text-enhanced knowledge graph representation learning with local structure},
journal = {Information Processing & Management},
volume = {61},
number = {5},
pages = {103797},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103797},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001560},
author = {Zhifei Li and Yue Jian and Zengcan Xue and Yumin Zheng and Miao Zhang and Yan Zhang and Xiaoju Hou and Xiaoguang Wang},
keywords = {Knowledge graph, Representation learning, Text encoder, Link prediction},
abstract = {Knowledge graph representation learning entails transforming entities and relationships within a knowledge graph into vectors to enhance downstream tasks. The rise of pre-trained language models has recently promoted text-based approaches for knowledge graph representation learning. However, these methods often need more structural information on knowledge graphs, prompting the challenge of integrating graph structure knowledge into text-based methodologies. To tackle this issue, we introduce a text-enhanced model with local structure (TEGS) that embeds local graph structure details from the knowledge graph into the text encoder. TEGS integrates k-hop neighbor entity information into the text encoder and employs a decoupled attention mechanism to blend relative position encoding and text semantics. This strategy augments learnable content through graph structure information and mitigates the impact of semantic ambiguity via the decoupled attention mechanism. Experimental findings demonstrate TEGS’s effectiveness at fusing graph structure information, resulting in state-of-the-art performance across three datasets in link prediction tasks. In terms of Hit@1, when compared to the previous text-based models, our model demonstrated improvements of 2.1% on WN18RR, 2.4% on FB15k-237, and 2.7% on the NELL-One dataset. Our code is made publicly available on https://github.com/HubuKG/TEGS.}
}
@article{XU2024120477,
title = {Spatiotemporal knowledge graph completion via diachronic and transregional word embedding},
journal = {Information Sciences},
volume = {667},
pages = {120477},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120477},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524003906},
author = {Xiaobei Xu and Wei Jia and Li Yan and Xiaoping Lu and Chao Wang and Zongmin Ma},
keywords = {Knowledge graph, Spatiotemporal information, Knowledge completion, Knowledge embedding},
abstract = {Knowledge Graph Completion (KGC) is an essential application in the field of knowledge graphs (KGs) that attempts to fill in the missing information in the process of KG modelling. With the popularity of temporal knowledge graphs (TKGs), a wide range of techniques based on temporal knowledge graph completion (TKGC) have appeared, solving the issue of real-world knowledge with temporal properties. However, there is little study on KGC with spatiotemporal attributes, some real-world data include both spatial and temporal attributes. Effectively handling the completion of missing entities or predicates in spatiotemporal knowledge graphs (STKGs) is an important challenge. Our study fills the gap in knowledge completion techniques in the field of STKG. We present a model for completion based on the well-known tensor factorization canonical polyadic (CP) decomposition. It introduces temporal and spatial attributes into the decomposition vector to achieve entity and link predictions. We name it diachronic and transregional word embedding (DT-WE), which includes two different modules: the embedding framework and the scoring module. Firstly, send the vectors to the embedding framework to get the new vector representation, then, we send it to the scoring module to compute, and finally, the resulting values are added together to compute the prediction probability. We conducted extensive experiments on three real-world STKGs: YAGO10K, Wikidata40K and Opensky. The results indicate that the newly introduced spatiotemporal attributes not only improve accuracy in predicting entities and predicates compared to temporal models but also achieve state-of-the-art performance with lower spatial complexity.}
}
@article{SHEN2022109597,
title = {A comprehensive overview of knowledge graph completion},
journal = {Knowledge-Based Systems},
volume = {255},
pages = {109597},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109597},
url = {https://www.sciencedirect.com/science/article/pii/S095070512200805X},
author = {Tong Shen and Fu Zhang and Jingwei Cheng},
keywords = {Knowledge Graph Completion (KGC), Classification, Comparisons and analyses, Performance evaluation, Overview},
abstract = {Knowledge Graph (KG) provides high-quality structured knowledge for various downstream knowledge-aware tasks (such as recommendation and intelligent question-answering) with its unique advantages of representing and managing massive knowledge. The quality and completeness of KGs largely determine the effectiveness of the downstream tasks. But in view of the incomplete characteristics of KGs, there is still a large amount of valuable knowledge is missing from the KGs. Therefore, it is necessary to improve the existing KGs to supplement the missed knowledge. Knowledge Graph Completion (KGC) is one of the popular technologies for knowledge supplement. Accordingly, there has a growing concern over the KGC technologies. Recently, there have been lots of studies focusing on the KGC field. To investigate and serve as a helpful resource for researchers to grasp the main ideas and results of KGC studies, and further highlight ongoing research in KGC, in this paper, we provide a all-round up-to-date overview of the current state-of-the-art in KGC. According to the information sources used in KGC methods, we divide the existing KGC methods into two main categories: the KGC methods relying on structural information and the KGC methods using other additional information. Further, each category is subdivided into different granularity for summarizing and comparing them. Besides, the other KGC methods for KGs of special fields (including temporal KGC, commonsense KGC, and hyper-relational KGC) are also introduced. In particular, we discuss comparisons and analyses for each category in our overview. Finally, some discussions and directions for future research are provided.}
}
@article{LI2025128614,
title = {Decoupled semantic graph neural network for knowledge graph embedding},
journal = {Neurocomputing},
volume = {611},
pages = {128614},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128614},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224013857},
author = {Zhifei Li and Wei Huang and Xuchao Gong and Xiangyu Luo and Kui Xiao and Honglian Deng and Miao Zhang and Yan Zhang},
keywords = {Knowledge graphs, Knowledge graph embedding, Knowledge graph completion, Graph neural network},
abstract = {Knowledge graph embedding (KGE) learns an embedding space for a more accurate representation of entities and relations. Although the KGE model has proliferated, it often fails to fully capture the rich semantics in knowledge graphs. Some studies attempt to apply decoupling methods to decompose node representations, yet they neglect the semantic noise generated during the decoupled process. To address these issues, we introduce the decoupled semantic graph network for KGE (named DSGNet), which employs a novel approach that combines semantic decoupling with structural awareness. DSGNet begins by projecting the knowledge graph into distinct semantic spaces, ensuring minimal correlation between them to achieve effective semantic decoupling. To mitigate semantic noise, a top-k sampling technique is applied to the decoupled graphs. DSGNet then aggregates these different semantic graphs using a relation-aware aggregation module, followed by a multi-layer aggregation process for enhanced node representation. The extensive experiments demonstrate that DSGNet performs competitively on two popular datasets. We make our code publicly available at https://github.com/HubuKG/DSGNet.}
}
@article{ZHANG2023100414,
title = {Knowledge graph completion method based on hyperbolic representation learning and contrastive learning},
journal = {Egyptian Informatics Journal},
volume = {24},
number = {4},
pages = {100414},
year = {2023},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2023.100414},
url = {https://www.sciencedirect.com/science/article/pii/S1110866523000701},
author = {Xiaodong Zhang and Meng Wang and Xiuwen Zhong and Feixu An},
keywords = {Knowledge graph completion, Hyperbolic representation learning, Comparison learning, Adversarial samples},
abstract = {Knowledge graph completion employs existing triples to deduce missing data, thereby enriching and enhancing graph completeness. Recent research has revealed that using hyperbolic representation learning in knowledge graph completion yields superior expressive and generalization capabilities. However, the long-tail problem and the presence of hyperbolic metrics make it challenging to effectively learn low-frequency entities or relations, resulting in embedding space distortion and impacting the original semantic relationships. Therefore, this paper proposes a knowledge graph completion method (Att-CL) that integrates hyperbolic representation learning and contrastive learning. In this approach, knowledge is embedded into a hyperbolic space, and samples with limited hierarchical characteristics and insufficient feature information are enhanced by introducing adversarial noise. The loss function of the embedded samples is backpropagated into embedding vectors, perturbations are adjusted in the gradient direction to promote smoothness and locality, and hyperparameters are introduced for fine-tuning the adversarial strength in the construction of adversarial samples for data augmentation to enhance model robustness. To mitigate data distortion due to hyperbolic metrics, a penalty term is introduced in the contrastive loss function to control the distances of the embedding vectors from the origin, thereby reducing the impact of the metrics and further improving the model's completion ability. Experimental results on the WN18RR and FB15K-237 benchmark datasets demonstrate significant improvements in metrics such as MRR, Hits@1, and Hits@3 compared to traditional knowledge graph completion models, providing ample evidence of the model's effectiveness.}
}
@article{CHEN2025131230,
title = {Knowledge graph and large language model integration with focus on educational applications: A survey},
journal = {Neurocomputing},
volume = {654},
pages = {131230},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131230},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225019022},
author = {Guanyu Chen and Tao Song and Quanyu Wang and Zheng Ma and Jun Hu and Qi Li and Chunming Wu},
keywords = {Knowledge graph, Large language model, Educational application, Retrieval augmented generation, Pre-training},
abstract = {In recent years, artificial intelligence (AI) technology has made significant advancements, particularly in the areas of large language models (LLMs) and knowledge graphs (KGs). KGs excel at structured knowledge representation and reasoning, offering interpretability; however, they are costly to construct, have limited coverage, and lack natural language processing capabilities. Conversely, LLMs possess powerful language understanding and generation abilities, but they rely heavily on vast amounts of data, are prone to “hallucinations," and lack interpretability. The integration of these two approaches is an inevitable trend for achieving stronger and more reliable AI applications, and has become a hot topic of research. Simultaneously, the combination of LLMs and KGs perfectly aligns with the pressing needs of the education field for precise reasoning and personalized services, addressing the shortcomings of traditional teaching methods and providing support for intelligent education. In light of this, this paper undertakes work in the following three key areas. Firstly, the concepts and technologies of both LLMs and KGs, along with their applications in education, are introduced. On this basis, the paper then delves into a discussion of the methods for integrating LLMs and KGs, and reviews related research progress. Finally, the paper focuses on specific educational scenarios, such as intelligent tutoring systems, intelligent learning companions, and intelligent evaluation systems, to explore the collaborative application of LLMs and KGs. The aim of this paper is to provide researchers in the field with a systematic understanding of LLMs and KGs, and to offer valuable references for future AI-driven educational innovation.}
}
@article{WANG2026100223,
title = {A position-aware attention model based on double-level contrastive learning for hyper-relational knowledge graph representation in emergency management},
journal = {Journal of Safety Science and Resilience},
volume = {7},
number = {1},
pages = {100223},
year = {2026},
issn = {2666-4496},
doi = {https://doi.org/10.1016/j.jnlssr.2025.100223},
url = {https://www.sciencedirect.com/science/article/pii/S266644962500057X},
author = {Xinzhi Wang and Weijian Zhu and Jiang Kai and Xiangfeng Luo and Jianqiang Huang},
keywords = {Emergency management, Link prediction, Hyper-relational knowledge graph, Contrastive learning, Position information},
abstract = {Effective emergency management relies on timely risk identification and decision-making, wherein natural language processing plays a vital role. Hyper-relational knowledge graph (HKG) representation, which embeds entities and their complex relations into latent space, provides a strong foundation for supporting emergency responses. Existing methods consider either inter-entity or inter-fact dependencies, leading to the loss of interaction information at the unconsidered level (fact level or entity level). To address the above issue, we propose a position-aware attention model based on dual-level contrastive learning (PDCL) for HKG representation. First, the complete and co-occurrence graphs were constructed and encoded using different graph convolutional networks, generating different embedding views for entities and facts. Second, entity-level and fact-level contrastive objectives were designed to enhance information exchange between the two levels in a self-supervised manner. Finally, a linear transformation corresponding to the ordinal information of each element was used to integrate positional constraints into the representation of the HKG. Experimental results for three benchmark datasets showed that the PDCL model outperformed existing state-of-the-art methods. Especially, MRR and Hits@1 values could be improved by up to 1.8% and 3.3%, respectively.}
}
@article{GUO2025107366,
title = {Semantic information-based attention mapping network for few-shot knowledge graph completion},
journal = {Neural Networks},
volume = {187},
pages = {107366},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2025.107366},
url = {https://www.sciencedirect.com/science/article/pii/S089360802500245X},
author = {Fan Guo and Xiangmao Chang and Yunqi Guo and Guoliang Xing and Yunlong Zhao},
keywords = {Knowledge graph, Link prediction, Few-shot learning, Text semantics, Attention mechanism, Contrast learning},
abstract = {Few-shot Knowledge Graph Completion (FKGC), an emerging technology capable of inferring new triples using only a few reference relation triples, has gained significant attention in recent years. However, existing FKGC methods primarily focus on structural information while failing to effectively utilize the textual semantic information inherent in triples. To address this limitation, we propose an innovative Semantic Information-based Attention Mapping Network (SI-AMN). This novel model significantly enhances knowledge graph completion accuracy through a unique dual-information fusion mechanism that effectively integrates both structural and textual semantic information. The core innovation of SI-AMN lies in its two key components: a semantic encoder for extracting high-quality textual features and an attention mapping network that learns semantic interactions between entity and relation types. Experimental results on benchmark datasets demonstrate SI-AMN’s superior performance, achieving a 40% improvement in prediction accuracy compared to state-of-the-art methods. Ablation studies further validate the effectiveness of each component in our proposed model. This research not only provides a novel solution for knowledge graph completion but also reveals the crucial value of semantic information in graph completion tasks, paving the way for future research directions in this field.}
}
@article{MISHRA2025104045,
title = {PageLLM: Incremental approach for updating a Security Knowledge Graph by using Page ranking and Large language model},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {104045},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.104045},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324004047},
author = {Chinmaya Mishra and Himangshu Sarma and Saravanan M.},
keywords = {Security knowledge graph, Knowledge graph, Knowledge representation learning, Page ranking, Embedding, Generative AI, Large language models (LLMs), Static knowledge graph (SKG), Incremental knowledge graph (IKG), Full knowledge graph (FKG)},
abstract = {Due to increase in cyber crime and evolution of sophisticated tools and techniques, Threat Intelligence plays a critical role. It helps defenders to stay ahead of attackers by developing the right defense mechanism to invade those attacks. In this regards security knowledge graph plays a critical role which can be used to signify complex entities and their relationship in a graphical structure. Further projecting those entities and relationships in to the lower dimension using several embedding techniques such as TransE help in many down streaming task. The learned embedding can be used to predict new cyber threat which is very helpful for defenders to stay alert and develop necessary weapons to stay ahead of an attack. One of the major challenge security knowledge graph has its dynamic nature of changing intelligence. Active learning can be used to only update the substantial portion of embedding rather than retraining the knowledge graph from scratch which has higher time and space complexity. Also given the rise in generative AI and large language models which are super rich in context, there is a scope of utilizing those for building a robust and good quality security knowledge graph. We will discuss a novel methodology called PageLLM which utilizes page ranking and LLMs to enable active learning in an incremental way and will improve the quality of knowledge graph through enriched context.}
}
@article{NGUYEN2025109717,
title = {FTPComplEx: A flexible time perspective approach to temporal knowledge graph completion},
journal = {Engineering Applications of Artificial Intelligence},
volume = {139},
pages = {109717},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109717},
url = {https://www.sciencedirect.com/science/article/pii/S095219762401875X},
author = {Ngoc-Trung Nguyen and Thuc Ngo and Nguyen Hoang and Thanh Le},
keywords = {Temporal knowledge graph reasoning, Tensor decomposition, Representation learning, Time perspective},
abstract = {The dynamic nature of interconnected data evolving over time poses significant challenges for graph representation and reasoning, particularly as temporal knowledge graphs scale in size and complexity. Existing models like TPComplEx (Time Perspective Complex Embedding) leverage tensor decomposition techniques to capture temporal dynamics, but their static weighting approach often lacks the flexibility needed to adapt to the nuanced evolution of relationships and entities. This rigidity can lead to missed temporal dependencies and loss of valuable insights, especially in large-scale graphs comprising millions or even billions of factual entries. To overcome these limitations, we propose FTPComplEx (Flexible Time Perspective Complex Embedding), a novel embedding model that introduces adjustable weights to dynamically modulate the influence of temporal information. This flexibility enables FTPComplEx to more accurately capture the intricate interactions between entities, relations, and time, providing a more robust understanding of temporal dynamics within knowledge graphs. Our extensive evaluations on benchmark datasets, including YAGO15k, ICEWS, and GDELT, demonstrate that FTPComplEx achieves state-of-the-art results, outperforming TPComplEx and other existing models. Notably, on the YAGO15k dataset, FTPComplEx achieves a 9.04% improvement in Mean Reciprocal Rank (MRR) and an 11.35% increase in Hits@1, demonstrating its effectiveness in managing complex temporal relationships. Further analysis shows that FTPComplEx maintains strong performance even with lower-rank embeddings, significantly reducing computational costs while maintaining accuracy.}
}
@article{HE2025113144,
title = {Jointly leveraging 1D and 2D convolution on diachronic entity embedding for temporal knowledge graph completion},
journal = {Applied Soft Computing},
volume = {176},
pages = {113144},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113144},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625004557},
author = {Mingsheng He and Lin Zhu and Luyi Bai},
keywords = {Temporal knowledge graph, Temporal knowledge graph completion, Diachronic embedding, Convolutional neural network},
abstract = {Temporal knowledge graphs (TKGs) model knowledge that dynamically changes over time in the real world, providing effective support for temporal-aware artificial intelligence (AI) applications. However, existing TKGs are far from complete, and their incompleteness significantly affects the performance of downstream applications. Therefore, Temporal Knowledge Graph Completion (TKGC) has become a current research hotspot, which aims to reason potential missing facts based on existing ones. In the widely studied TKGC methods with the implicit representation of temporal information, existing methods that embed temporal information into entity representations can capture the temporal evolution of entities. However, they fail to take the behavioral characteristics of entities across different time units into account, making them challenging to precisely model the fine-grained dynamics of entities. Furthermore, given the powerful expressiveness of Convolutional Neural Networks (CNNs), some TKGC methods have employed the 1D convolution operation to capture global relationships within the embedded quadruple, enabling the learning of explicit knowledge in TKGs and attaining competitive performance for TKGC. Nevertheless, the non-linear and deep features embedded in the entity-relation interaction have not been insufficiently explored. To address these challenges, this paper proposes JointDE, a TKGC model that applies both 1D and 2D convolution operations to the generated diachronic entity embedding, which simultaneously learns the explicit and implicit knowledge in TKGs. The new diachronic entity embedding method explicitly models the inherent attributes of entities and integrates temporal features across different time units, thereby possessing the ability to capture fine-grained entity evolution. More importantly, we construct feature matrices and filters using diachronic entity embeddings and relation embeddings, leveraging an internal 2D convolution mechanism to expand their interactions. This is the first work to learn implicit knowledge embedded in TKGs from a local relationship perspective for TKGC. Experimental results demonstrate that JointDE surpasses several TKGC baseline methods and achieves state-of-the-art performance on three event-based benchmark datasets: ICEWS14, ICEWS05–15, and GDELT. Specifically, JointDE improves Mean Reciprocal Rank (MRR) by 3.17 % and Hits@1 by 5.87 % over the state-of-the-art baseline for entity reasoning.}
}
@article{SHEN20251793,
title = {TarIKGC: A Target Identification Tool Using Semantics-Enhanced Knowledge Graph Completion with Application to CDK2 Inhibitor Discovery},
journal = {Journal of Medicinal Chemistry},
volume = {68},
number = {2},
pages = {1793-1809},
year = {2025},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.4c02543},
url = {https://www.sciencedirect.com/science/article/pii/S1520480425000080},
author = {Xiaojuan Shen and Shijia Yan and Tao Zeng and Fei Xia and Dejun Jiang and Guohui Wan and Dongsheng Cao and Ruibo Wu},
abstract = {Target identification is a critical stage in the drug discovery pipeline. Various computational methodologies have been dedicated to enhancing the classification performance of compound–target interactions, yet significant room remains for improving the recommendation performance. To address this challenge, we developed TarIKGC, a tool for target prioritization that leverages semantics enhanced knowledge graph (KG) completion. This method harnesses knowledge representation learning within a heterogeneous compound–target–disease network. Specifically, TarIKGC combines an attention-based aggregation graph neural network with a multimodal feature extractor network to simultaneously learn internal semantic features from biomedical entities and topological features from the KG. Furthermore, a KG embedding model is employed to identify missing relationships among compounds and targets. In silico evaluations highlighted the superior performance of TarIKGC in drug repositioning tasks. In addition, TarIKGC successfully identified two potential cyclin-dependent kinase 2 (CDK2) inhibitors with novel scaffolds through reverse target fishing. Both compounds exhibited antiproliferative activities across multiple therapeutic indications targeting CDK2.
}
}
@article{ZHU2025102463,
title = {RankT: Ranking-Triplets-based adversarial learning for knowledge graph link prediction},
journal = {Data & Knowledge Engineering},
volume = {160},
pages = {102463},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102463},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000588},
author = {Jinlei Zhu and Xin Zhang and Xin Ding},
keywords = {Knowledge graph, Link prediction, Triplet ranking, Adversarial loss, Consistency loss},
abstract = {Aiming at completing the missing edges between entities in the knowledge graph, many state-of-the-art models are proposed to predict the links. Those models mainly focus on predicting the link score between source and target entities with certain relations, but ignore the similarities or differences of the whole meanings of triplets in different subgraphs. However, the triplets interact with each other in different ways and the link prediction model may lack interaction. In other word, the link prediction is superimposed with potential triplet uncertainties. To address this issue, we propose a Ranking-Triplet-based uncertainty adversarial learning (RankT) framework to improve the embedding representation of triplet for link prediction. Firstly, the proposed model calculates the node and edge embeddings by the node-level and edge-level neighborhood aggregation respectively, and then fuses the embeddings by a self-attention transformer to gain the interactive embedding of the triplet. Secondly, to reduce the uncertainty of the probability distribution of predicted links, a ranking-triplet-based adversarial loss function based on the confrontation of highest certainty and highest uncertainty links is designed. Lastly, to strengthen the stability of the adversarial learning, a ranking-triplet-based consistency loss is designed to make the probability of the highest positive links converge in the same direction. The ablation studies show the effectiveness of each part of the proposed model. The comparison of experimental results shows that our model significantly outperforms the state-of-the-art models. In conclusion, the proposed model improves the link prediction performance while discovering the similar or different meanings of triplets.}
}
@article{XUE2025114320,
title = {HSAE: Hierarchical structure augment embedding for various knowledge graph completion},
journal = {Knowledge-Based Systems},
volume = {329},
pages = {114320},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114320},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125013607},
author = {Yifan Xue and Wanqiang Cai and Yingyao Ma and Lotfi Senhadji and Huazhong Shu and Jiasong Wu},
keywords = {Knowledge graph completion, Knowledge hypergraph, Generative language model},
abstract = {Knowledge Graph Completion (KGC) addresses the task of reasoning over existing facts to predict missing relationships, serving as a fundamental component for downstream applications including question answering systems and personalized recommendation engines. Over the years, the KGC field has evolved into specialized tasks, including static KGC, temporal KGC, hyper KGC, and few-shot KGC, each requiring specialized methodologies. Although previous methods have utilized Generative Language Models (GLMs) to theoretically support multi task compatibility, their performance remains suboptimal compared to task-specific models. This limitation stems from their inability to effectively integrate structural and textual information, leading to a fine-grained structure-text gap. To address this challenge, we propose HSAE, a novel two-stage framework that hierarchically aligns structural and textual modalities, first at the coarse-grained entity level and then at the fine-grained token level. In the first stage, Entity-Level Structure Augment, we transform structural embeddings into tree-shaped entity classifications, enriching entity representations with explicit structural information. This augmentation provides global structural guidance during beam search, ensuring that generated sequences adhere to the underlying knowledge graph topology. In the second stage, Token-Level Structure Augment, we introduce a cross-modal alignment module that dynamically fuses structural embeddings with token-level predictions. By aligning structural and textual representations at the token level, HSAE ensures that each decoding step is informed by both structural and textual coherence. Experiments on eight benchmarks demonstrate that HSAE outperforms competitive baselines across multiple KGC tasks. The data and code are released at https://anonymous.4open.science/r/HSAE-main/README.md.}
}
@article{ZHANG2024119770,
title = {Edge propagation for link prediction in requirement-cyber threat intelligence knowledge graph},
journal = {Information Sciences},
volume = {653},
pages = {119770},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119770},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523013555},
author = {Yang Zhang and Jiarui Chen and Zhe Cheng and Xiong Shen and Jiancheng Qin and Yingzheng Han and Yiqin Lu},
keywords = {Critical information infrastructure, Cyber threat intelligence, Graph neural network, Link prediction, Knowledge graph},
abstract = {Critical information infrastructure (CII) is a critical component of national socioeconomic systems and one of the primary targets of cyberattacks. Unfortunately, CII's security administration struggles to keep up with the rapidly evolving and complex cyber threats. In this research, we combine cybersecurity threat intelligence (CTI) with management security requirements (SR) data to construct a knowledge graph (KG) named RCTI and predict new knowledge on the heterogeneous graph. In addition, we propose EGNN, a novel GNN-based model that defines the representation of edges and develop an algorithm for propagating edge information. Experiments on three public datasets and the RCTI graph show that the EGNN achieves state-of-the-art performance. Finally, we use the EGNN model to predict new links on the RCTI graph, which by manual analysis achieves a 97% connectivity rate between the CTI and SR entities. Therefore, the EGNN can effectively detect management vulnerabilities and enhance CII's cybersecurity capability in the event of cybersecurity incidents.}
}
@article{XU2025103976,
title = {Advancing rule learning in knowledge graphs with structure-aware graph transformer},
journal = {Information Processing & Management},
volume = {62},
number = {2},
pages = {103976},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103976},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324003352},
author = {Kang Xu and Miqi Chen and Yifan Feng and Zhenjiang Dong},
keywords = {Rule learning, Knowledge graph reasoning, Graph neural networks},
abstract = {In knowledge graphs (KGs), logic rules offer interpretable explanations for predictions and are essential for reasoning on downstream tasks, such as question answering. However, a key challenge remains unresolved: how to effectively encode and utilize the structural features around the head entity to generate the most applicable rules. This paper proposes a structure-aware graph transformer for rule learning, namely Structure-Aware Rule Learning (SARL), which leverages both local and global structural information of the subgraph around the head entity to generate the most suitable rule path. SARL employs a generalized attention mechanism combined with replaceable feature extractors to aggregate local structural information of entities. It then incorporates global structural and relational information to further model the subgraph structure. Finally, a rule decoder utilizes the comprehensive subgraph representation to generate the most appropriate rules. Comprehensive experiments on four real-world knowledge graph datasets reveal that SARL significantly enhances performance and surpasses existing methods in the link prediction task on large-scale KGs, with Hits@1 improvements of 6.5% on UMLS and 4.5% on FB15K-237.}
}
@article{YIN2024111828,
title = {Disentangled Relational Graph Neural Network with Contrastive Learning for knowledge graph completion},
journal = {Knowledge-Based Systems},
volume = {295},
pages = {111828},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111828},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124004623},
author = {Hong Yin and Jiang Zhong and Rongzhen Li and Xue Li},
keywords = {Knowledge graph completion, Disentangled representation learning, Graph neural network, Contrastive learning},
abstract = {Learning disentangled entity representations has garnered significant attention in the field of knowledge graph completion (KGC). However, the existing methods inherently overlook the indicative role of relations and the correlation between latent factors and relations, leading to suboptimal entity representations for KGC tasks. In the current study, we introduce the Disentangled Relational Graph Neural Network with Contrastive Learning (DRGCL) method, designed to acquire disentangled entity representations guided by relations. In particular, we first devise the factor-aware relational message aggregation approach to learn entity representations under each semantic subspace and obtain latent factor representations by attention mechanisms. Subsequently, we propose a discrimination objective for factor-subspace pairs using a contrastive learning approach, which compels the factor representations to distinctly capture the information associated with different latent factors and promote the consistency between factor representations and semantic subspaces. Through disentanglement, our model can generate relation-aware scores tailored to the provided scenario. Extensive experiments have been conducted on three benchmark datasets and the results demonstrate the superiority of our method compared with strong baseline models.}
}
@article{MA2024123793,
title = {GLSEC: Global and local semantic-enhanced contrastive framework for knowledge graph completion},
journal = {Expert Systems with Applications},
volume = {250},
pages = {123793},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123793},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424006596},
author = {Ruixin Ma and Xiaoru Wang and Cunxi Cao and Xiya Bu and Hao Wu and Liang Zhao},
keywords = {Knowledge graph completion, Global semantic, Contrastive learning, Graph neural networks},
abstract = {Knowledge graph completion (KGC) aims to infer missing links between entities in knowledge graphs (KGs). Recently, models based on graph neural networks (GNNs) have gained widespread attention due to their effectiveness in leveraging the topological structure information of entities. Meanwhile, contrastive learning (CL) has been employed in GNNs-based models to provide more supervised signals for better entity representation in a self-supervised manner. However, existing methods overlook the potential global semantic collaboration among entities within the entire KG. And the application of CL in KGC models often adopt random graph augmentation or basic node structure contrast, leading to suboptimal performance. To tackle them, we propose a Global and Local Semantic-Enhanced Contrastive Framework (GLSEC) for KGC. Specifically, we develop a global Attribute-aware encoder to capture the global semantic features of entities based on an entity-entity Attribute Interaction Graph (AIG). Additionally, we design a Light Graph Aggregation Network (Light-GAN) that innovatively updates the global semantic features using the AIG, combining both efficiency and a lightweight design. Furthermore, we introduce a Global-Local cross-view Contrastive Learning (GLCL) method that contrasts embeddings from global and local views, thereby improving contrastive sample quality and boosting the model’s understanding of entities in various contexts. Extensive experiments show that our model outperforms state-of-the-art KGC methods on benchmark datasets FB15k-237 and WN18RR.}
}
@article{MA2025114426,
title = {Provide explainable clues: A generative traceable method for knowledge graph completion},
journal = {Knowledge-Based Systems},
volume = {330},
pages = {114426},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114426},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125014650},
author = {Ziqi Ma and Jinpeng Li and Hang Yu},
keywords = {Knowledge graph, Knowledge graph completion, Generative model, Information traceability, Explainability analysis},
abstract = {Improving the quality of Knowledge Graph Completion (KGC) results is an essential topic in the field of knowledge graphs. Recently, generative models (GMs) have gained widespread attention for addressing the generalization issues of traditional approaches. However, the black-box nature of generative models often leads to hallucinations, which reduce the model’s performance. Most methods attempt to mitigate this issue through retrieval enhancement and decoding constraints. However, they overlook one major cause of hallucinations–poor explainability. Based on this concept, we propose a Generative Traceable Method, namely GTM, which aims to improve the KGC capability of GMs by exploring the inhibitory effect of explainability on hallucinations. In GTM, a clue tracker is used to find contextual evidence for explainability. In addition, to measure explainability clues, we propose a context-aware analyzer, which enhances the understanding of context through group analogy. In the reasoning phase, we ensure the validity of the generated results by integrating the interpretive capability of clues. Extensive experiments have demonstrated that GTM can adapt to various KGC tasks and significantly enhance the performance of KGC models.}
}
@article{HU2024110783,
title = {A knowledge graph completion model based on triple level interaction and contrastive learning},
journal = {Pattern Recognition},
volume = {156},
pages = {110783},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.110783},
url = {https://www.sciencedirect.com/science/article/pii/S003132032400534X},
author = {Jie Hu and Hongqun Yang and Fei Teng and Shengdong Du and Tianrui Li},
keywords = {Knowledge graph completion, Link prediction, Semantic matching, Contrastive learning, Negative sampling},
abstract = {Knowledge graphs provide credible and structured knowledge for downstream tasks such as information retrieval. Nevertheless, the ubiquitous incompleteness of knowledge graphs often limits the performance of applications. To address the incompleteness, people have proposed the knowledge graph completion task to supplement the facts of incomplete triplets. Recently, researchers have proposed introducing text descriptions to enrich entity representations. Existing methods based on triple decoupling with text description solve the combinatorial explosion problem well. Nevertheless, they still suffer from a lack of global characteristics of factual triples. In addition, the success of contrastive learning research has improved such methods, but they are still limited by existing negative sampling, which is usually more costly than embedding-based methods. In order to solve these limitations, this paper proposes an innovative triple-level interaction model for knowledge graph completion named InCL-KGC. Concretely, the proposed model employs an on-verge interaction method to reduce text redundancy information for entity representation and capture the global semantics of factual triplets. Furthermore, we design an effective hard negative sampling strategy to improve contrast learning. Additionally, we perform an improved Harbsort algorithm for the purpose of reducing the adverse impact of candidate entity sparsity on inference. Extensive experiment consequences exhibit that our model transcends recent baselines with MRR, Hit@3, and Hits@10 increased by 1.2%, 3.2%, and 6.8% on WN18RR, while the index MRR, Hit@1, Hit@3, and Hits@10 were enhanced by 2.8%, 1%, 3.3%, 4.3% on FB15K-237.}
}
@article{XUE2025113750,
title = {Make your choice for multimodal knowledge graph completion},
journal = {Knowledge-Based Systems},
volume = {323},
pages = {113750},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113750},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125007968},
author = {Yifan Xue and Shuoyan Ren and Wanqiang Cai and Yingyao Ma and Lotfi Senhadji and Huazhong Shu and Jiasong Wu},
keywords = {Knowledge graph, Knowledge graph completion, Link prediction, Multimodal, Transformer},
abstract = {Knowledge graph completion (KGC) aims to predict missing entities in knowledge graphs by learning effective representations of entities and their relations. Recent advances have explored multimodal KGC by incorporating structural, textual, and visual information. However, two critical challenges remain unresolved: (1) modal heterogeneity, where significant differences in feature distributions across modalities hinder effective fusion; and (2) spatial heterogeneity, where embedding knowledge graphs in a single geometric space fails to capture their complex topological structures. To address these challenges, we propose ChoicE, a unified framework that leverages a mixture of experts (MoE) design for both encoding and decoding. In the encoder, the multimodal chooser preprocesses multiple modalities to derive embedding representations for each modality. These representations are then processed by distinct experts specialized for structural, textual, and visual features, facilitating effective fusion while preserving modality-specific information. In the decoder, the geometric chooser projects the unified multimodal embeddings into Euclidean, complex, or hyperbolic space, dynamically selecting the most appropriate space to model the inference patterns inherent to each query. Extensive experiments on multiple benchmark datasets demonstrate that ChoicE effectively overcomes these dilemmas and achieves state-of-the-art performance in multimodal KGC. The data and code are released at https://anonymous.4open.science/r/ChiocE-master/.}
}
@article{YIN2023120380,
title = {GS-InGAT: An interaction graph attention network with global semantic for knowledge graph completion},
journal = {Expert Systems with Applications},
volume = {228},
pages = {120380},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120380},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423008825},
author = {Hong Yin and Jiang Zhong and Chen Wang and Rongzhen Li and Xue Li},
keywords = {Knowledge graph completion, Global semantic, Semantic graph, Interaction information, Graph attention network},
abstract = {Knowledge graph completion (KGC) aims to infer missing links between entities based on the observed ones. Current KGC methods primarily focus on KG embedding models, which project entities and relations as low-dimensional vectors. Recently, the combination of textual information with graph neural network models has drawn extensive attention due to their superiority in utilizing topological structures, benefiting from the message passing mechanism, and their effectiveness in supplementing structural information. Nevertheless, previous methods suffer from the following two limitations. First, they always treat the textual information as an independent instance to enhance the corresponding entities, without considering the global semantic within the KG. Second, Graph Neural Networks (GNNs) typically assume that the neighbors of a node are independent of each other, ignoring the possible interactions between them. To eliminate these limitations, we creatively propose a KGC method called GS-InGAT (Interaction Graph ATtention Network with Global Semantic). Concretely, we utilize a semantic graph to model the semantic relationships and obtain the global semantic representations for entities based on it. Furthermore, we introduce an efficient Interaction Graph ATtention network (InGAT) that can simultaneously capture both the interaction and local information of entities, which can be fused to generate structural representations. Finally, we feed the combination of the semantic and structural representations, along with relation representations, into the decoder to score triples. Experimental results demonstrate that the GS-InGAT consistently attains comparable performance on benchmark datasets, verifying the effectiveness of considering the global semantic and interactions between neighbors.}
}
@article{LI2022109889,
title = {A knowledge graph completion model based on contrastive learning and relation enhancement method},
journal = {Knowledge-Based Systems},
volume = {256},
pages = {109889},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109889},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122009820},
author = {LinYu Li and Xuan Zhang and YuBin Ma and Chen Gao and Jishu Wang and Yong Yu and Zihao Yuan and Qiuying Ma},
keywords = {Knowledge graph, Knowledge graph completion, Contrastive learning, Graph attention network, Link prediction},
abstract = {The rapid development in knowledge graph (KG) technology and its popularity in the field of artificial intelligence (AI) have significantly increased the support for similar KG-based applications. However, there is a concerning problem regarding KGs; most of them are often incomplete. This motivated us to study knowledge graph completion (KGC). Some recent studies have used graph neural networks (GNN) such as graph convolutional networks (GCN) to model graph-structured data, providing good results on KGC tasks. However, the edge weights in GCN models are controlled by degree, a measure that moderately ignores the differences among relation information. To address the above limitations and obtain better KGC, we propose a model based on graph attention networks (GATs) and contrastive learning (CL), called the CLGAT-KGC model. This model introduces the graph attention mechanism and adds different representations of entities under the same entity corresponding to different relations to enhance the entity-relation message function. Additionally, a new CL method is proposed under the CLGAT-KGC model to better learn the embedding of entities and relations in the KG domain. We have completely verified the effectiveness of this model through extensive experiments.}
}
@article{XU202371,
title = {Boosting BERT-Based Knowledge Graph Completion with Contrastive Learning and Hard Sample Training},
journal = {Procedia Computer Science},
volume = {222},
pages = {71-80},
year = {2023},
note = {International Neural Network Society Workshop on Deep Learning Innovations and Applications (INNS DLIA 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.145},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923009109},
author = {Yuan Xu and Qinliang Su},
keywords = {Knowledge Graph Completion, Contrastive Learning, Link Prediciton},
abstract = {Knowledge graph (KG), which is often described by a set of triplets (head, relation, tail), has shown to be very useful for many downstream applications, but suffers from the issue of incomplete connections. Knowledge graph completion (KGC) is to predict the missing connections among entities. Driven by recent advances of BERT in extracting meaningful textual representations, some recent KGC methods have been proposed to leverage the associated texts of triplets to assist the completion. Under the BERT-based framework, we argue that if more meaningful representations can be learned from the texts, better performance can be expected. Following this framework, inspired by recent successes of contrastive learning, we propose to adapt it to the KGC task by introducing a novel dual-encoder architecture to produce semantic-similar positive pairs, which have been widely shown to be pivotal in inducing semantic-rich representations for contrastive learning. To further improve the performance, a hard negative sampling strategy is developed to train the model. Extensive experimental results on three public datasets show that the proposed techniques can improve the performance of existing KGC methods effectively.}
}
@article{LI2025131182,
title = {Time-enhanced compound geometric operations for temporal knowledge graph embedding},
journal = {Neurocomputing},
volume = {654},
pages = {131182},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131182},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225018545},
author = {Wenhao Li and Dong Zhang and Guanyu Li and Yingqi Zou},
keywords = {Temporal knowledge graph, Temporal knowledge graph embedding, Compound geometric operation, Link prediction task},
abstract = {Temporal knowledge graph embedding aims to represent entities, relations, and timestamps in a continuous vector space while preserving their temporal evolutionary patterns. TCompoundE is a recently proposed temporal knowledge graph embedding model that uses compound operations involving translation and scaling as the relation-specific and time-specific operations. However, this model has the following three problems: (1) The model only employs traditional geometric transformations and does not explore more complex transformation relationships. (2) The model fails to enhance the head entity with time-awareness, which weakens the model’s ability to model dynamic changes. (3) The model neglects the influence of the head entity and the relation in the modeling process. We propose the TTComE, a time-enhanced compound geometric temporal knowledge graph embedding model, to tackle these questions. Here are three improvement points: (1) We introduced the Spatiotemporal Rotation Operation for modeling, which enables the model to better capture complex relationships and temporal evolution patterns. (2) We performed the Temporal-aware Enhancement Operation on the head entities and relations respectively, to enhance the model’s ability to capture dynamic changes. (3) We introduced the Weight-adaptive Translation Operation, which assigns learnable weights to both the head entity and the relation, followed by a translation operation. This enables the model to adaptively adjust the contributions of the head entity and the relation in prediction tasks. Finally, we experimentally validated the model on multiple datasets, complemented by ablation studies, and the results demonstrated significant improvements over other baseline models.}
}
@article{XIAO2024104730,
title = {FuseLinker: Leveraging LLM’s pre-trained text embeddings and domain knowledge to enhance GNN-based link prediction on biomedical knowledge graphs},
journal = {Journal of Biomedical Informatics},
volume = {158},
pages = {104730},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104730},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001485},
author = {Yongkang Xiao and Sinian Zhang and Huixue Zhou and Mingchen Li and Han Yang and Rui Zhang},
keywords = {Link Prediction, Knowledge graph, Graph Neural Network, Large Language Model, Drug Repurposing},
abstract = {Objective
To develop the FuseLinker, a novel link prediction framework for biomedical knowledge graphs (BKGs), which fully exploits the graph’s structural, textual and domain knowledge information. We evaluated the utility of FuseLinker in the graph-based drug repurposing task through detailed case studies.
Methods
FuseLinker leverages fused pre-trained text embedding and domain knowledge embedding to enhance the graph neural network (GNN)-based link prediction model tailored for BKGs. This framework includes three parts: a) obtain text embeddings for BKGs using embedding-visible large language models (LLMs), b) learn the representations of medical ontology as domain knowledge information by employing the Poincaré graph embedding method, and c) fuse these embeddings and further learn the graph structure representations of BKGs by applying a GNN-based link prediction model. We evaluated FuseLinker against traditional knowledge graph embedding models and a conventional GNN-based link prediction model across four public BKG datasets. Additionally, we examined the impact of using different embedding-visible LLMs on FuseLinker’s performance. Finally, we investigated FuseLinker’s ability to generate medical hypotheses through two drug repurposing case studies for Sorafenib and Parkinson’s disease.
Results
By comparing FuseLinker with baseline models on four BKGs, our method demonstrates superior performance. The Mean Reciprocal Rank (MRR) and Area Under receiver operating characteristic Curve (AUROC) for KEGG50k, Hetionet, SuppKG and ADInt are 0.969 and 0.987, 0.548 and 0.903, 0.739 and 0.928, and 0.831 and 0.890, respectively.
Conclusion
Our study demonstrates that FuseLinker is an effective novel link prediction framework that integrates multiple graph information and shows significant potential for practical applications in biomedical and clinical tasks. Source code and data are available at https://github.com/YKXia0/FuseLinker.}
}
@article{WAN2023240,
title = {Sub-Entity Embedding for inductive spatio-temporal knowledge graph completion},
journal = {Future Generation Computer Systems},
volume = {148},
pages = {240-249},
year = {2023},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2023.05.030},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X23002108},
author = {Guojia Wan and Zhengyun Zhou and Zhigao Zheng and Bo Du},
keywords = {Knowledge graph, Knowledge graph embedding, Knowledge graph completion, Spatio-temporal data},
abstract = {Existing large-scale knowledge graphs generally contain rich spatial and temporal information. Knowledge graph completion has gained wide attention with a massive number of models proposed for inferring missing knowledge. Despite the fact that numerous approaches to knowledge graph completion exist, they often overlook the importance of simultaneously modeling spatial and temporal information, resulting in limited capacity to infer knowledge related to time and location. An intuitive solution to this issue is to use quintuple representation for spatio-temporal facts. To reduce the complexity of learning quintuples, in this paper, we propose sub-entity to tokenize every entity, relation, time stamp and location with a fixed-size vocabulary. Meanwhile, we design Spatio-Temporal Message Passing layer to learn the latent feature vectors of a knowledge graph. We conducted entity link prediction, relation link prediction, time prediction and location prediction experiments. The quantitative results demonstrate the effectiveness of our model in both predicting missing knowledge under both transductive link prediction and inductive link prediction. The visualization results also show that our model can capture meaningful time and location information.}
}
@article{ZHANG2023119616,
title = {Graph attention network with dynamic representation of relations for knowledge graph completion},
journal = {Expert Systems with Applications},
volume = {219},
pages = {119616},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.119616},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423001173},
author = {Xin Zhang and Chunxia Zhang and Jingtao Guo and Cheng Peng and Zhendong Niu and Xindong Wu},
keywords = {Knowledge graph completion, Dynamic representation of relation, Global information embedding, Transformer encoder, Graph attention network},
abstract = {Knowledge graph completion (KGC) aims to predict the missing element in a triple based on known triples or facts. Recently, plenty of representation learning methods for KGC have achieved the promising performance, especially ones based on graph neural networks and their variants. Those methods exploit local neighborhood information to update the embedding of target entities. However, the existing works have the following two problems. First, those approaches focus on the representation learning of entities, while the relation representation usually adopts a simple linear transformation, which cannot capture the distinctive semantic intensions of the same relation in different triples. Second, different types of entity information are simply combined together, resulting in the loss of global properties including the type and the global importance of entities, which is prone to cause over-smoothing phenomenon. To address these two problems, we propose a Graph Attention Network with Dynamic Representation of Relations and global information (DRR-GAT) for knowledge graph completion. Specifically, the task of dynamic representation of relations is to learn the distinctive representation of the same relation in different triples. This goal is achieved via a path Transformer. To this end, path Transformer is designed to take the path information as its input, where only those paths from the target entity to the neighborhood relations with the same type as the target relation are considered. Sequentially, the mechanism of global embeddings is incorporated into graph attention network to capture the global information of entities and relations. Experimental performance outperforms the state-of-the-art methods, indicating the effectiveness of our proposed approach.}
}
@article{WEI2025110873,
title = {The use of knowledge graphs for drug repurposing: From classical machine learning algorithms to graph neural networks},
journal = {Computers in Biology and Medicine},
volume = {196},
pages = {110873},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110873},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525012247},
author = {Siqi Wei and Christo Sasi and Jelle Piepenbrock and Martijn A. Huynen and Peter A.C. {’t Hoen}},
keywords = {Drug repositioning, Knowledge graph, Graph convolutional networks, Machine learning, Deep learning},
abstract = {Drug repurposing, the development of new therapeutic indications for existing drugs, is a promising strategy in drug development. Computational methods and artificial intelligence may be used to identify new drug repurposing candidates. Knowledge graph (KG) based methods have emerged as powerful tools for modeling and predicting drug–disease relationships, because of their intuitive way of exploiting biomedical knowledge and data. This review provides an overview of computational drug repurposing methods based on KGs. The motivation for adopting KG-based knowledge representations, traditional machine learning and deep learning approaches are discussed, followed by an analysis of selected tools, their construction, link prediction capabilities, and inherent advantages and limitations.}
}
@article{GENG2025126175,
title = {Prompting disentangled embeddings for knowledge graph completion with pre-trained language model},
journal = {Expert Systems with Applications},
volume = {268},
pages = {126175},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.126175},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424030422},
author = {Yuxia Geng and Jiaoyan Chen and Yuhang Zeng and Zhuo Chen and Wen Zhang and Jeff Z. Pan and Yuxiang Wang and Xiaoliang Xu},
keywords = {Knowledge graph completion, Pre-trained language model, Prompt tuning, Disentangled embedding},
abstract = {Both graph structures and textual information play a critical role in Knowledge Graph Completion (KGC). With the success of Pre-trained Language Models (PLMs) such as BERT, they have been applied for text encoding for KGC. However, the current methods mostly prefer to fine-tune PLMs, leading to huge training costs and limited scalability to larger PLMs. In contrast, we propose to utilize prompts and perform KGC on a frozen PLM with only the prompts trained. Accordingly, we propose a new KGC method named PDKGC with two prompts — a hard task prompt which is to adapt the KGC task to the PLM pre-training task of token prediction, and a disentangled structure prompt which learns disentangled graph representation so as to enable the PLM to combine more relevant structure knowledge with the text information. With the two prompts, PDKGC builds a textual predictor and a structural predictor, respectively, and their combination leads to more comprehensive entity prediction. Solid evaluation on three widely used KGC datasets has shown that PDKGC often outperforms the baselines including the state-of-the-art, and its components are all effective. Our codes and data are available at https://github.com/genggengcss/PDKGC.}
}
@article{SHEN2025112315,
title = {A self-supervised method for learning path-augmented knowledge graph embedding},
journal = {Engineering Applications of Artificial Intelligence},
volume = {162},
pages = {112315},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112315},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625023231},
author = {Tong Shen and Fu Zhang and Jingwei Cheng},
keywords = {Knowledge graph, Knowledge graph embedding, Self-supervised learning},
abstract = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.}
}
@article{ZHAO2023110772,
title = {KE-X: Towards subgraph explanations of knowledge graph embedding based on knowledge information gain},
journal = {Knowledge-Based Systems},
volume = {278},
pages = {110772},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110772},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123005221},
author = {Dong Zhao and Guojia Wan and Yibing Zhan and Zengmao Wang and Liang Ding and Zhigao Zheng and Bo Du},
keywords = {Knowledge graph, Knowledge graph embedding, Explainability},
abstract = {Over the past years, knowledge graph embedding approaches have proven effective for knowledge graph completion tasks. However, most existing models are either built on a certain embedding space or black-box neural networks, making it hard to access explanations for prediction results and resulting in limited explainability. In this paper, we propose to leverage information entropy to quantify the importance of explanation candidates, then build a framework KE-X, for explaining results from knowledge graph embedding approaches by generating explainable subgraphs. Specifically, by performing a modified message passing mechanism on a partially masked knowledge subgraph and maximizing knowledge information gain, KE-X can extract the most valuable subgraph explanation for a link prediction query. To evaluate KE-X, we conduct experiments on three real-world knowledge graphs with two representative KGE models, TransE and DistMult. Both quantitative and case study results show that our framework can extract high-quality explanations.}
}
@article{MA2022103004,
title = {GAFM: A Knowledge Graph Completion Method Based on Graph Attention Faded Mechanism},
journal = {Information Processing & Management},
volume = {59},
number = {5},
pages = {103004},
year = {2022},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.103004},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322001169},
author = {Jiangtao Ma and Duanyang Li and Haodong Zhu and Chenliang Li and Qiuwen Zhang and Yaqiong Qiao},
keywords = {Knowledge graph completion, Neighborhood nodes, Path length, Graph attention fade mechanism},
abstract = {Although the Knowledge Graph (KG) has been successfully applied to various applications, there is still a large amount of incomplete knowledge in the KG. This study proposes a Knowledge Graph Completion (KGC) method based on the Graph Attention Faded Mechanism (GAFM) to solve the problem of incomplete knowledge in KG. GAFM introduces a graph attention network that incorporates the information in multi-hop neighborhood nodes to embed the target entities into low dimensional space. To generate a more expressive entity representation, GAFM gives different weights to the neighborhood nodes of the target entity by adjusting the attention value of neighborhood nodes according to the variation of the path length. The attention value is adjusted by the attention faded coefficient, which decreases with the increase of the distance between the neighborhood node and the target entity. Then, considering that the capsule network has the ability to fit features, GAFM introduces the capsule network as the decoder to extract feature information from triple representations. To verify the effectiveness of the proposed method, we conduct a series of comparative experiments on public datasets (WN18RR and FB15k-237). Experimental results show that the proposed method outperforms baseline methods. The Hits@10 metric is improved by 8% compared with the second-place KBGAT method.}
}
@article{YANG2024100824,
title = {Improving static and temporal knowledge graph embedding using affine transformations of entities},
journal = {Journal of Web Semantics},
volume = {82},
pages = {100824},
year = {2024},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100824},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000106},
author = {Jinfa Yang and Xianghua Ying and Yongjie Shi and Ruibin Wang},
keywords = {Knowledge graph, Static knowledge graph embedding, Temporal knowledge graph embedding, Link prediction},
abstract = {To find a suitable embedding for a knowledge graph (KG) remains a big challenge nowadays. By measuring the distance or plausibility of triples and quadruples in static and temporal knowledge graphs, many reliable knowledge graph embedding (KGE) models are proposed. However, these classical models may not be able to represent and infer various relation patterns well, such as TransE cannot represent symmetric relations, DistMult cannot represent inverse relations, RotatE cannot represent multiple relations, etc.. In this paper, we improve the ability of these models to represent various relation patterns by introducing the affine transformation framework. Specifically, we first utilize a set of affine transformations related to each relation or timestamp to operate on entity vectors, and then these transformed vectors can be applied not only to static KGE models, but also to temporal KGE models. The main advantage of using affine transformations is their good geometry properties with interpretability. Our experimental results demonstrate that the proposed intuitive design with affine transformations provides a statistically significant increase in performance with adding a few extra processing steps and keeping the same number of embedding parameters. Taking TransE as an example, we employ the scale transformation (the special case of an affine transformation). Surprisingly, it even outperforms RotatE to some extent on various datasets. We also introduce affine transformations into RotatE, Distmult, ComplEx, TTransE and TComplEx respectively, and experiments demonstrate that affine transformations consistently and significantly improve the performance of state-of-the-art KGE models on both static and temporal knowledge graph benchmarks.}
}
@article{PUROHIT2025113939,
title = {VANILLA: Validated knowledge graph completion—A Normalization-based framework for Integrity, Link prediction, and Logical Accuracy},
journal = {Knowledge-Based Systems},
volume = {325},
pages = {113939},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113939},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125009840},
author = {Disha Purohit and Yashrajsinh Chudasama and Maria-Esther Vidal},
keywords = {Knowledge graphs, Knowledge graph completion, Symbolic learning, Symbolic constraint validation, Numerical learning},
abstract = {Knowledge graphs (KGs) are expressive data structures for integrating and describing heterogeneous data by unifying factual information and domain knowledge. However, under the Open World Assumption (OWA), the absence of facts does not imply falsity—only incompleteness. Inductive learning methods, particularly numerical techniques such as Knowledge Graph Embeddings (KGEs) and Graph Neural Networks (GNNs), are widely used for link prediction and classification tasks in KGs. These models excel at capturing latent patterns and exploiting structural properties at scale. Nevertheless, their performance can be significantly degraded by anomalies in KG representations—semantic inconsistencies and modeling artifacts that arise from unconstrained data integration. Such anomalies obscure the intended meaning of relations, introduce noise, and mislead numerical learning models. To address this issue, we introduce a normalization theory for KGs that enforces semantic consistency through normal forms. These forms restructure KGs to eliminate representational anomalies, ensuring that the data adheres to well-defined semantic constraints. We present VANILLA, a neuro-symbolic framework that combines symbolic rule learning, numerical inductive models, and constraint-based validation. By aligning inductive predictions with normalized, ontology-aware KG structures, VANILLA enables accurate and semantically grounded KG completion. Experimental results show that our approach significantly improves predictive performance while maintaining semantic integrity, demonstrating the value of normalization in hybrid KG learning systems. VANILLA is publicly available on GitHub https://github.com/SDM-TIB/VANILLA.}
}
@article{YAN2024,
title = {Improvement of Web Semantic and Transformer-Based Knowledge Graph Completion in Low-Dimensional Spaces},
journal = {International Journal on Semantic Web and Information Systems},
volume = {20},
number = {1},
year = {2024},
issn = {1552-6283},
doi = {https://doi.org/10.4018/IJSWIS.336919},
url = {https://www.sciencedirect.com/science/article/pii/S1552628324001133},
author = {Xiai Yan and Yao Yi and Weiqi Shi and Hua Tian and Xin Su},
keywords = {knowledge graph completion, low-dimensional spaces, transformer},
abstract = {ABSTRACT
In recent years, knowledge graph completion (KGC) has garnered significant attention. However, noise in the graph poses numerous challenges to the completion of tasks, including error propagation, missing information, and misleading relations. Many existing KGC methods utilize the multi-head self-attention mechanism (MHA) in transformers, which yields favorable results in low-dimensional space. Nevertheless, employing MHA introduces the risk of overfitting due to a large number of additional parameters, and the choice of model loss function is not comprehensive enough to capture the semantic discriminatory nature between entities and relationships and the treatment of RDF indicates that the dataset contains only positive (training) examples, and the error facts are not encoded, which tends to cause overgeneralization.}
}
@article{LIANG202361,
title = {TransAM: Transformer appending matcher for few-shot knowledge graph completion},
journal = {Neurocomputing},
volume = {537},
pages = {61-72},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.03.049},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223002965},
author = {Yi Liang and Shuai Zhao and Bo Cheng and Hao Yang},
keywords = {Knowledge graph, Link prediction, Relation learning, Few-shot learning, Transformer},
abstract = {Few-shot knowledge graph completion (FSKGC) refers to predicting new facts for a new relation with only few-shot observed entity pairs (triples) as support set. Existing solutions to FSKGC mainly conduct the matching process over entity pair representations. Although effective, a major concern of these models is that the entity interactions are not fully explored, based on the observation that they usually generate the pair representation before the matching stage. Such a design inherently overlooks the fine-grained information from entity interactions, leading to performance decrements in one or three shot, which require matching models to capture more sufficient semantic meanings for prediction. To remedy this issue, in this paper, we explore the entity interactions within and between different instances, i.e., the co-occurrence of two entities, for FSKGC and propose our model named TransAM, Transformer Appending Matcher. TransAM solves the FSKGC problem by computing the probability of entity sequence with a well-designed transformer matching network. Specifically, TransAM appends query entity pair to serialized reference entity sequence and utilizes transformer to calculate the probability by capturing intra- and inter- triple entity interactions. To bridge the gap between transformer and the triple structure, TransAM introduces rotary operation to preserve the head and tail roles of entity within the triple and distinguishes different triples by a separated triple position encoding. Empirical studies on two public benchmark datasets NELL-One and Wiki-One show that TransAM outperforms existing metric-learning solutions in MRR and Hits@1 with both one- and three- shot settings, and achieves comparable results on five-shot setting. Datasets and code will be public available at https://github.com/gawainx/TransAM.}
}
@article{XUE2024127242,
title = {Relation-oriented few-shot knowledge graph prototype networks},
journal = {Neurocomputing},
volume = {575},
pages = {127242},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127242},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224000134},
author = {Yingying Xue and Aibo Song and Jiahui Jin and Hui Peng and Jingyi Qiu and Xiaolin Fang and Xiaorui Zhai},
keywords = {Knowledge graph embedding, Ontology, Prototype network, Relation-oriented},
abstract = {Knowledge graph (KG) embedding has been widely researched, but it suffers from some problems in the few-shot scenarios. The topological and semantic connection among entities cannot satisfy the assumption of samples’ independent identically distribution. Additionally, these relations between entity pairs are various and complex. But most of the previous methods are node-oriented, which is weak in modeling complex relations. In order to solve the above problems, we propose a few-shot relation prototype network (FRPN). In our method, each relation is regarded as a learning object, instead of just entity pairs’ concatenation. A relation-oriented two-channel embedding mechanism is designed to achieve multi-scale information aggregation at the entity level and the relation level respectively. For the entity level, it aggregates information at different scales according to the relation type and the neighbors under each relation. For the relation level, our model obtains each kind of relation’s prototype from the ontology and the entity layer. The multi-scale aggregation contributes to KG embedding in the few-shot scenario. Compared with existing models, our model has significantly improved the performance on both the link prediction and triple classification tasks in two few-shot datasets.}
}
@article{GAO2024105634,
title = {Exploring bridge maintenance knowledge graph by leveraging GrapshSAGE and text encoding},
journal = {Automation in Construction},
volume = {166},
pages = {105634},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105634},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524003704},
author = {Yan Gao and Guanyu Xiong and Haijiang Li and Jarrod Richards},
keywords = {Bridge maintenance knowledge graph, Text encoding, Graph neural networks, Node classification, Link prediction},
abstract = {Knowledge graphs (KGs) are crucial in documenting bridge maintenance expertise. However, existing KG schemas lack integration of bridge design and practical inspection insights. Meanwhile, traditional methods for node feature initialization, relying on meticulous manual encoding or word embeddings, are inadequate for real-world maintenance textual data. To address these challenges, this paper introduces a bridge maintenance-oriented KG (BMKG) schema and approaches for graph data mining, including node-layer classification and link prediction. These methods leverage large language model (LLM)-based text encoding combined with GraphSAGE, demonstrating excellent performance in semantic enrichment and KG completion on deficient BMKGs. Additionally, ablation studies reveal the superiority of the pre-trained BERT text encoder and the L2 distance pairwise scoring calculator. Furthermore, a practical implementation framework integrating these approaches is developed for routine bridge maintenance, which can facilitate various practical applications, such as maintenance planning, and has the potential to enhance the efficiency of engineers' documentation work.}
}
@article{BI2024127044,
title = {Relphormer: Relational Graph Transformer for Knowledge Graph Representations},
journal = {Neurocomputing},
volume = {566},
pages = {127044},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.127044},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223011670},
author = {Zhen Bi and Siyuan Cheng and Jing Chen and Xiaozhuan Liang and Feiyu Xiong and Ningyu Zhang},
keywords = {Knowledge graph, Knowledge graph representation, Transformer},
abstract = {Transformers have achieved remarkable performance in widespread fields, including natural language processing, computer vision and graph mining. However, vanilla Transformer architectures have not yielded promising improvements in the Knowledge Graph (KG) representations, where the translational distance paradigm dominates this area. Note that vanilla Transformer architectures struggle to capture the intrinsically heterogeneous structural and semantic information of knowledge graphs. To this end, we propose a new variant of Transformer for knowledge graph representations dubbed Relphormer. Specifically, we introduce Triple2Seq which can dynamically sample contextualized sub-graph sequences as the input to alleviate the heterogeneity issue. We propose a novel structure-enhanced self-attention mechanism to encode the relational information and keep the semantic information within entities and relations. Moreover, we utilize masked knowledge modeling for general knowledge graph representation learning, which can be applied to various KG-based tasks including knowledge graph completion, question answering, and recommendation. Experimental results on six datasets show that Relphormer can obtain better performance compared with baselines.22Code is available in https://github.com/zjunlp/Relphormer.}
}
@article{DAI2022234,
title = {MRGAT: Multi-Relational Graph Attention Network for knowledge graph completion},
journal = {Neural Networks},
volume = {154},
pages = {234-245},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002714},
author = {Guoquan Dai and Xizhao Wang and Xiaoying Zou and Chao Liu and Si Cen},
keywords = {Knowledge graph, Graph neural network, Attention mechanism},
abstract = {One of the most effective ways to solve the problem of knowledge graph completion is embedding-based models. Graph neural networks (GNNs) are popular and promising embedding models which can exploit and use the structural information of neighbors in knowledge graphs. The current GNN-based knowledge graph completion methods assume that all neighbors of a node have equal importance. This assumption which cannot assign different weights to neighbors is pointed out in our study to be unreasonable. In addition, since the knowledge graph is a kind of heterogeneous graph with multiple relations, multiple complex interactions between nodes and neighbors can bring challenges to the effective message passing of GNNs. We then design a multi-relational graph attention network (MRGAT) which can adapt to different cases of heterogeneous multi-relational connections and then calculate the importance of different neighboring nodes through a self-attention layer. The incorporation of self-attention mechanism into the network with different node weights optimizes the network structure, and therefore, significantly results in a promotion of performance. We experimentally validate the rationality of our models on multiple benchmark knowledge graphs, where MRGAT achieves the best performance on various evaluation metrics including MRR score, Hits@ score compared with other state-of-the-art baseline models.}
}
@article{WANG2024102848,
title = {Medical knowledge graph completion via fusion of entity description and type information},
journal = {Artificial Intelligence in Medicine},
volume = {151},
pages = {102848},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102848},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724000903},
author = {Xiaochen Wang and Runtong Zhang and Butian Zhao and Yuhan Yao and Hongmei Zhao and Xiaomin Zhu},
keywords = {Link prediction, Entity property set, Graph embeddings, Language embeddings, BioBERT, Information fusion},
abstract = {Medical Knowledge Graphs (MKGs) are vital in propelling big data technologies in healthcare and facilitating the realization of medical intelligence. However, large-scale MKGs often exhibit characteristics of data sparsity and missing facts. Following the latest advances, knowledge embedding addresses these problems by performing knowledge graph completion. Most knowledge embedding algorithms rely solely on triplet structural information, overlooking the rich information hidden within entity property sets, leading to bottlenecks in performance enhancement when dealing with the intricate relations of MKGs. Inspired by the semantic sensitivity and explicit type constraints unique to the medical domain, we propose BioBERT-based graph embedding model. This model represents an evolvable framework that integrates graph embedding, language embedding, and type information, thereby optimizing the utility of MKGs. Our study utilizes not only WordNet as a benchmark dataset but also incorporates MedicalKG to compare and corroborate the specificity of medical knowledge. Experimental results on these datasets indicate that the proposed fusion framework achieves state-of-art (SOTA) performance compared to other baselines. We believe that this incremental improvement provides promising insights for future medical knowledge graph completion endeavors.}
}
@article{ZEB2024120197,
title = {CoPE: Composition-based Poincaré embeddings for link prediction in knowledge graphs},
journal = {Information Sciences},
volume = {662},
pages = {120197},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120197},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524001105},
author = {Adnan Zeb and Summaya Saif and Junde Chen and James Jianqiao Yu and Qingshan Jiang and Defu Zhang},
keywords = {Knowledge graph, Link prediction, Hyperbolic geometry, Poincaré embeddings, Compositional operators},
abstract = {Knowledge graph (KG) embedding methods predict missing links by computing the similarities between entities. The existing embedding methods are designed with either shallow or deep architectures. Shallow methods are scalable to large KGs but are limited in capturing fine-grained semantics. Deep methods can capture rich semantic interactions, but they require numerous model parameters. This study proposes a novel embedding model that effectively combines the strengths of both shallow and deep models. In particular, the proposed model adopts the design principles of shallow models and incorporates an expressive compositional operator inspired by deep models. This approach maintains the scalability while significantly enhancing the expressive capacity of the proposed model. Moreover, the proposed model learns embeddings using the Poincaré ball model of hyperbolic geometry to preserve the hierarchies between entities. The experimental results demonstrated the effectiveness of learning Poincaré embeddings with an expressive compositional operator. Notably, a substantial improvement of 2.4% in the Mean Reciprocal Rank (MRR) and a 1.4% improvement in hit@1 was observed on the CoDEx-m and CoDEx-s datasets, respectively, when compared to the current state-of-the-art methods. The proposed model was implemented using PyTorch 1.8.1, and experiments were conducted on a server with an NVIDIA GeForce RTX 2080 Ti GPU.}
}
@article{LI2025100809,
title = {A review of background, methods, limitations and opportunities of knowledge graph completion},
journal = {Computer Science Review},
volume = {58},
pages = {100809},
year = {2025},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100809},
url = {https://www.sciencedirect.com/science/article/pii/S1574013725000851},
author = {Daiyi Li and Yaoyao Liang and Shenyi Qian and Huaiguang Wu and Wei Jia and Yilong Fu and Yifan Sun},
keywords = {Knowledge graph completion, Embedded-based completion, Path-based completion, Neural network-based completion, Large language model-based completion},
abstract = {Knowledge graph completion (KGC), as a pivotal technology for extracting hidden knowledge from large-scale data, has evolved into a systematic research framework through the development of knowledge graph (KG) technology in recent years. To address the many challenges faced by current research, this study systematically reviews the fundamental theories and methodological systems in the field of KGC, grouping them into four categories: embedding-based, path-based, neural network-based, and large language model (LLM)-based approaches. Current research indicates that traditional closed-domain KGC relies on standard KG embedding or relational path models, which remain effective for completing structured data. However, there are notable limitations in handling unseen entities and relations in open scenarios. With breakthroughs in neural networks and LLMs, open-domain KGC has begun to emerge, although a lack of systematic analysis and classification of model architectures still persists. To address this gap, this review conducts a multi-dimensional academic investigation, clarifying the foundational research landscape and core methodological distinctions, establishing a model classification framework that spans both closed and open domains and integrating mainstream dataset resources within the field. Furthermore, the review explores the challenges and future directions of technological development, including critical issues such as complex knowledge reasoning, improvements in domain adaptability improvement, and the deep integration of LLMs with KGs, providing theoretical foundations and practical references to guide subsequent research efforts.}
}
@article{WANG2025761,
title = {MMCSD: Multi-Modal Knowledge Graph Completion Based on Super-Resolution and Detailed Description Generation},
journal = {Computers, Materials and Continua},
volume = {83},
number = {1},
pages = {761-783},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.060395},
url = {https://www.sciencedirect.com/science/article/pii/S154622182500298X},
author = {Huansha Wang and Ruiyang Huang and Qinrang Liu and Shaomei Li and Jianpeng Zhang},
keywords = {Multi-modal knowledge graph, knowledge graph completion, multi-modal fusion},
abstract = {Multi-modal knowledge graph completion (MMKGC) aims to complete missing entities or relations in multi-modal knowledge graphs, thereby discovering more previously unknown triples. Due to the continuous growth of data and knowledge and the limitations of data sources, the visual knowledge within the knowledge graphs is generally of low quality, and some entities suffer from the issue of missing visual modality. Nevertheless, previous studies of MMKGC have primarily focused on how to facilitate modality interaction and fusion while neglecting the problems of low modality quality and modality missing. In this case, mainstream MMKGC models only use pre-trained visual encoders to extract features and transfer the semantic information to the joint embeddings through modal fusion, which inevitably suffers from problems such as error propagation and increased uncertainty. To address these problems, we propose a Multi-modal knowledge graph Completion model based on Super-resolution and Detailed Description Generation (MMCSD). Specifically, we leverage a pre-trained residual network to enhance the resolution and improve the quality of the visual modality. Moreover, we design multi-level visual semantic extraction and entity description generation, thereby further extracting entity semantics from structural triples and visual images. Meanwhile, we train a variational multi-modal auto-encoder and utilize a pre-trained multi-modal language model to complement the missing visual features. We conducted experiments on FB15K-237 and DB13K, and the results showed that MMCSD can effectively perform MMKGC and achieve state-of-the-art performance.}
}
@article{WANG2025125407,
title = {Exploring multi-granularity contextual semantics for fully inductive knowledge graph completion},
journal = {Expert Systems with Applications},
volume = {260},
pages = {125407},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125407},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424022747},
author = {Jingchao Wang and Weimin Li and Alex Munyole Luvembe and Xiao Yu and Xinyi Zhang and Fangyu Liu and Fangfang Liu and Hao Wang and Zhenhai Wang and Qun Jin},
keywords = {Knowledge graph, Knowledge reasoning, Graph neural network, Graph embedding},
abstract = {Fully inductive knowledge graph completion (KGC) aims to predict triplets involving both unseen entities and relations. Recent several approaches transform paths between entities into descriptions and modeling semantic correlations between paths using pre-trained language models (PLMs), have emerged as a promising solution for fully inductive reasoning. However, these methods often adopt a simplistic concatenation strategy for path-to-sentence transformation, which impedes PLMs’ ability to capture subtle nuances in context, resulting in sub-optimal path context embeddings. Furthermore, they ignore the high-order semantics underlying the complete context, which can provide richer information for inductive reasoning. To address these issues, we propose a Multi-Granularity Contextual Semantic (MGCS) modeling framework, utilizing a Path Modeling Network (PMN) and a Subgraph Modeling Network (SMN) to extract two granularity levels of contextual semantics from single paths and complete subgraphs, for fully inductive KGC. The PMN extracts paths between head and tail entities and employs reasoning patterns from similar cases to filter out unreliable paths. Then two innovative path conversion strategies are designed to significantly enhance the pre-trained language model’s understanding of specific path contexts. The SMN employs a neighbor interactive graph neural network to extract high-order semantics from the complete subgraph context with a concept-enhanced relation encoding, and optimizes it through a contrastive learning method. Finally, the confidence of the triples is evaluated from the perspective of global complete context by comparing the semantics between the subgraphs surrounding the target triplet and the subgraphs surrounding similar cases. Experimental results on benchmark datasets demonstrate the effectiveness of MGCS.}
}
@article{GUO2025121409,
title = {EHPR: Learning evolutionary hierarchy perception representation based on quaternion for temporal knowledge graph completion},
journal = {Information Sciences},
volume = {688},
pages = {121409},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.121409},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524013239},
author = {Jiujiang Guo and Mankun Zhao and Jian Yu and Ruiguo Yu and Jianhang Song and Qifei Wang and Linying Xu and Mei Yu},
keywords = {Temporal knowledge graph, Quaternion, Evolutionary hierarchy information},
abstract = {Research on temporal knowledge graphs garners attention due to the intricate connection between facts and dynamic temporal factors. However, existing research uses timestamp as auxiliary data for representation learning and directly integrate it into facts, resulting in the inability to capture the intrinsic connections between relations under time evolution. To handle these challenges, we propose the Evolutionary Hierarchy Perception Representation (EHPR), which first leverages the Hamilton product to perform rotational transformations on relation and entity over time, aiming to learn temporal relation and temporal entity with close interactions with time information. Later, EHPR is divided into two modules: (a) Rotating the head entity towards the tail entity using temporal relation through Hamilton product to model complex patterns with quaternion rotation capabilities. (b) Adopting an evolutionary hierarchical factor to capture the differences in modulus distribution between the temporal head entity and the temporal tail entity, aiming to manage the evolutionary hierarchical information between different temporal entities. In this way, EHPR not only utilizes the rich quaternion rotation capabilities to model various relation patterns but also further enables modeling of evolutionary hierarchical patterns through evolutionary hierarchy factors. Experiments show that EHPR achieves remarkable performance on six mature benchmarks compared to state-of-the-art models. Furthermore, we successfully transferred the core idea of EHPR into complex embeddings, showcasing the framework's adaptability. Compared to complex embedding models, EHPR also demonstrates stronger expressive abilities with the Hamilton operator, surpassing the performance of complex Hermitian operator.}
}
@article{LI2025121639,
title = {Aggregation or separation? Adaptive embedding message passing for knowledge graph completion},
journal = {Information Sciences},
volume = {691},
pages = {121639},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.121639},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524015536},
author = {Zhifei Li and Lifan Chen and Yue Jian and Han Wang and Yue Zhao and Miao Zhang and Kui Xiao and Yan Zhang and Honglian Deng and Xiaoju Hou},
keywords = {Knowledge graph, Message passing, Knowledge graph completion},
abstract = {Knowledge graph completion intends to infer information within knowledge graphs, thereby bolstering the functionality of knowledge-driven applications. Recently, there has been a significant increase in the utilization of graph convolutional networks (GCNs) for knowledge graph completion. These GCN-based models primarily focus on aggregating information from neighboring entities and relations. Nonetheless, a fundamental question arises: is it beneficial to consider all neighbor information, and should some neighbor features be separated? We tackle this issue and present an adaptive graph convolutional network (AdaGCN) for knowledge graph completion, which can adaptively aggregate or separate neighbor information for knowledge embedding learning. Specifically, AdaGCN utilizes the adaptive message-passing mechanism to determine the importance of each relation, allocating weights to neighbor entity embeddings. This adaptive approach facilitates the propagation of valuable information while effectively separating less relevant or unnecessary details. Experimental results demonstrate that AdaGCN can efficiently acquire the embeddings of various triplets within knowledge graphs, and it achieves competitive performance compared to SOTA models on six datasets for the tasks of knowledge graph completion.}
}
@article{OYELADE2025127455,
title = {SMAR + NIE IdeaGen: A knowledge graph based node importance estimation with analogical reasoning on large language model for idea generation},
journal = {Expert Systems with Applications},
volume = {279},
pages = {127455},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127455},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425010772},
author = {Olaide N. Oyelade and Hui Wang and Karen Rafferty},
keywords = {Knowledge graphs (KGs), Large language model (LLMs), Idea generation, Novelty, Analogical reasoning, Node importance estimation, Natural language processing (NLP), Isomorphic subgraphs},
abstract = {Idea generation describes a creative process involving reasoning over some knowledge to derive new information. Traditional approaches such as mind-map and brainstorming are limited and often fail due to lack of quality ideas and ineffective methods. The reasoning capability of large language models (LLMs) have been investigated for ideation tasks and have reported interesting performance. However, these models suffer from limited logical reasoning capability which hinders the use of structural and factual real-world knowledge in discovery of latent insight and predict possible outcome when applied to ideation. In addition, the possibility of LLMs regurgitating knowledge learnt from datasets might adversely impact the degree of novel ideas the models can generate. In this paper, a two-stage logical reasoning approach is applied to initiate the search for candidate idea pathways based on the knowledge graphs (KGs) to address the problem of reasoning, domain-specificity and novelty. The divergence stage this reasoning explores utilizes a new node importance estimation (NIE) technique over KGs to discover latent connections supporting idea generation. In the convergence stage of this reasoning, subgraph matching using analogical reasoning (SMAR) is applied to find matching patterns to describe a new idea. The use of SMAR + NIE and KGs helps to achieve an improvement in reasoning over KGs before transferring such reasoning to LLMs for translation of idea into natural language. To evaluate the degree of novelty of ideas generated, a relevance-to-novelty scoring metrics is proposed based on multiple premise entailment (MPE). We combined this metric with other popular metrics to evaluate the performance of SMAR + NIE on benchmark datasets, and as well on the quality of ideas generated. Findings from the study showed that this approach demonstrates competitive performance with mainstream LLMs in idea generation tasks.}
}
@article{MA2024122086,
title = {Multi-view semantic enhancement model for few-shot knowledge graph completion},
journal = {Expert Systems with Applications},
volume = {238},
pages = {122086},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.122086},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423025885},
author = {Ruixin Ma and Hao Wu and Xiaoru Wang and Weihe Wang and Yunlong Ma and Liang Zhao},
keywords = {Knowledge graph completion, Few-shot, Multi-view, Knowledge representation},
abstract = {In recent years, few-shot knowledge graph completion (FKGC) has gained popularity as a solution to the long-tail distribution problem of real-world knowledge graphs (KGs). The previous knowledge graph completion (KGC) models obtain triple representation merely relying on the structure view, ignoring the valuable semantic knowledge. In this paper, we propose a multi-view framework for few-shot relation learning to address the issue. Specifically, based the structural information of the graph obtained using the structure view, we add the text view and the commonsense view. The text view employs text descriptions of entities and relations to obtain a richer semantic representation. The commonsense view performs high-quality negative sampling based on complex relations. Moreover, commonsense semantic constraints are invoked to suppress the overfitting caused by the complexity of the relation matrix. Extensive experiments show that our model outperforms state-of-the-art FKGC methods on the frequently-used benchmark datasets FB15k237-One and NELL-One.}
}
@article{YANG2025102868,
title = {GS-KGC: A generative subgraph-based framework for knowledge graph completion with large language models},
journal = {Information Fusion},
volume = {117},
pages = {102868},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102868},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524006468},
author = {Rui Yang and Jiahao Zhu and Jianping Man and Hongze Liu and Li Fang and Yi Zhou},
keywords = {Knowledge graph, Knowledge graph completion, Large language models, Question answer},
abstract = {Knowledge graph completion (KGC) focuses on identifying missing triples in a knowledge graph (KG) , which is crucial for many downstream applications. Given the rapid development of large language models (LLMs), some LLM-based methods are proposed for KGC task. However, most of them focus on prompt engineering while overlooking the fact that finer-grained subgraph information can aid LLMs in generating more accurate answers. In this paper, we propose a novel completion framework called Generative Subgraph-based KGC (GS-KGC), which utilizes subgraph information as contextual reasoning and employs a QA approach to achieve the KGC task. This framework primarily includes a subgraph partitioning algorithm designed to generate negatives and neighbors. Specifically, negatives can encourage LLMs to generate a broader range of answers, while neighbors provide additional contextual insights for LLM reasoning. Furthermore, we found that GS-KGC can discover potential triples within the KGs and new facts beyond the KGs. Experiments conducted on four common KGC datasets highlight the advantages of the proposed GS-KGC, e.g., it shows a 5.6% increase in Hits@3 compared to the LLM-based model CP-KGC on the FB15k-237N, and a 9.3% increase over the LLM-based model TECHS on the ICEWS14.}
}
@article{LIU2025130909,
title = {SEMKR: Joint learning of semantic and topological representations for Knowledge Graph Completion},
journal = {Neurocomputing},
volume = {653},
pages = {130909},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130909},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225015814},
author = {Pengjie Liu and Wang Zhang and Yulong Ding and Jie Jiang and Shuang-Hua Yang},
keywords = {Knowledge Graph Completion, Continual pre-training, Relation prediction, Contrastive learning, Representation learning, Legal judgment prediction},
abstract = {Knowledge Graph Completion (KGC) methods concentrate on predicting unknown components in the (head entity)⟶[relation](tail entity) triplet. However, large-scale Knowledge Graphs (KGs), especially those in legal domains, often face the problem of imbalanced data distribution, which brings significant challenges to achieve accurate prediction. For instance, high-frequency criminal charges generally produce well-structured and densely connected sub-graphs, whereas low-frequency/confusing criminal charges are sparsely connected. Current KGC methods learn individual features, such as relation types or sub-graph structures, while overlooking joint embedding associations. To address these challenges, we propose a text-guided graph reasoning mechanism that integrates semantic and topological representations synergistically. Our model, SEMKR, SEMantic and topological representations for Knowledge gRaph completion, incorporate two key modules: (1) Entity Description Representation Learning enhances semantic features by pre-train and fine-tune BERT; (2) Relational Topological Representation Learning refines context representations by learning edge and path information in two stage pre-training and fine-tuning. Experimental results demonstrate that SEMKR outperforms state-of-the-art baselines in relation or link prediction tasks, achieving significant improvements, including over 7.8% H@1 on the NELL995 dataset. All implementations will be available at https://github.com/SUSTech-TP/SEMKR.git.}
}
@article{LI2024120430,
title = {SANe: Space adaptation network for temporal knowledge graph completion},
journal = {Information Sciences},
volume = {667},
pages = {120430},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120430},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524003438},
author = {Yancong Li and Xiaoming Zhang and Bo Zhang and Feiran Huang and Xiaopeng Chen and Ming Lu and Shuai Ma},
keywords = {Temporal knowledge graph, Temporal knowledge graph completion, Space adaptation network, Parameter generation, Partition tree},
abstract = {Temporal Knowledge Graphs (TKGs) model time-dependent facts as relations between entities at specific timestamps, making them well-suited for real-world scenarios. However, TKGs are susceptible to incompleteness, necessitating Temporal Knowledge Graph Completion (TKGC) to predict missing facts. Prior methods often struggle to effectively handle two critical properties of TKGs, time-variability and time-stability, simultaneously, which hinders their performance. In this paper, we propose Space Adaptation Network (SANe), a novel approach for TKGC. SANe adapts facts at different timestamps to distinct latent spaces, effectively addressing time-variability. Our model introduces Parameter Generation Network to produce separate neural networks for each snapshot, which are then encoded into different latent spaces. A dynamic convolutional neural network processes entities and relations, utilizing different learned parameters generated by parameter generation network with respect to timestamps. By handling different temporal snapshots separately, TKGC is transformed into static KGC, enabling the modeling of time-variability. Dynamic convolutional neural network efficiently learns collective knowledge over large periods and supplements more specific knowledge gradually in smaller periods, facilitating time-stability. To strike a balance between learning time-variability and time-stability, we introduce a time-aware parameter generator to produce parameters hierarchically based on year, month, and day timestamps. Long-term knowledge is effectively shared across adjacent snapshots within the same year or month, while short-term knowledge within a day is preserved in specific parameters. However, in unbalanced TKGs, where many facts occur in small intervals, the large number of parameters generated by time-aware parameter generator may remain underutilized. To address this, we propose Adaptive Parameter Generation with a partition tree, ensuring parameter load balancing while maintaining time-stability. We conduct extensive experiments on five benchmark datasets, demonstrating the superiority of SANe over existing methods for TKGC, achieving state-of-the-art performance. Our contributions include pioneering TKGC from the perspective of space adaptation, achieving a balance between time-variability and time-stability through latent space overlap constraints, and substantiating the effectiveness of our model through comprehensive experiments on rich temporal datasets.}
}
@article{WANG2024123542,
title = {Open Knowledge Graph Link Prediction with Semantic-Aware Embedding},
journal = {Expert Systems with Applications},
volume = {249},
pages = {123542},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123542},
url = {https://www.sciencedirect.com/science/article/pii/S095741742400407X},
author = {Jingbin Wang and Hao Huang and Yuwei Wu and Fuyuan Zhang and Sirui Zhang and Kun Guo},
keywords = {Open knowledge graph, Knowledge graph embedding, Link prediction, Semantic-aware, Attention mechanism},
abstract = {Link prediction in open knowledge graphs (OpenKGs) is crucial for applications like question answering and recommendation systems. Existing OpenKG models leverage the semantic information of noun phrases (NPs) to enhance the performance in the link prediction task. However, these models only extract superficial semantic information from NPs, ignoring the fact that an NP possesses diverse semantics. Furthermore, these models have not fully exploited the semantic information of the relation phrases (RPs). To address these issues, we propose a model for link prediction called Open Knowledge Graph Link Prediction with Semantic-Aware Embedding (SeAE). First, we develop an adaptive disentanglement embedding (ADE) mechanism to learn the intrinsically abundant semantics of NPs. The ADE mechanism can adaptively calculate the embedding segmentation number according to the dataset and has an ingenious method for updating embeddings. Second, we integrate the attention mechanism into the GRU encoder to obtain the distribution of importance inside RP, facilitating a more comprehensive capture of the RP’s semantic information and enhancing the model’s interpretability. Finally, we design a relation gate, which extracts the RP semantic features of tail NP from the shared edge. This gate realizes the relation constraints on entities while enhancing the interaction between entities and relations. Extensive experiments on four benchmarks demonstrate that SeAE outperforms the state-of-the-art models, resulting in improvements of approximately 5.4% and 7.4% in MRR on ReVerb45K and ReVerb45KF datasets respectively.}
}
@article{YU2023110031,
title = {Knowledge graph completion using topological correlation and multi-perspective independence},
journal = {Knowledge-Based Systems},
volume = {259},
pages = {110031},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.110031},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122011248},
author = {Mei Yu and Qianyu Zhang and Jian Yu and Mankun Zhao and Xuewei Li and Di Jin and Ming Yang and Ruiguo Yu},
keywords = {Knowledge graph completion, Graph convolutional network, Knowledge embedding},
abstract = {Knowledge graphs (KGs) are large-scale semantic networks designed to describe real-world facts. Existing KGs contain only a fraction of what is really happening in the real life. Knowledge graph completion (KGC) has attracted attention because it can automatically infer and predict missing links in the KGs. The classical geometric, tensor decomposition and convolutional neural network (CNN) based models generate expressive feature embeddings, but these models treat triples independently and thus fail to cover the hidden information that is inherently implicit in the local neighborhood surrounding a triple. Recent works have introduced Graph Convolutional Network (GCN) into KGC task for leveraging the rich structural information in complex graphs. However, existing GCN-based models have limitations in relational topology distinction and multi-perspective feature aggregation. As multi-relational graphs, KGs display intrinsic heterogeneous structures and rich entity types. Therefore, ignoring the rich structural information and perspective features will greatly limit the expressive power of these models. In this paper, we propose multi-relational GCNs for modeling topological correlation and multi-perspective independence (CorIn). Specifically, we propose a multi-integration ring relational topology to fine-grained select neighbors according to relational correlation patterns, and capture the independence of multi-perspective feature groups by mutual information minimization. Our model adaptively utilizes an embedding learning design that can leverage a variety of entity-relation composition operations from classical KGC models. We evaluate our model on the public benchmark datasets and achieve marked performance gains in comparison to state-of-the-art methods.}
}
@article{TRAN2025113541,
title = {MESN: A multimodal knowledge graph embedding framework with expert fusion and relational attention},
journal = {Knowledge-Based Systems},
volume = {318},
pages = {113541},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113541},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125005878},
author = {Ban Tran and Thanh Le},
keywords = {Multimodal knowledge graph embedding, Multimodal data fusion, Knowledge graph completion, Attention-based representation learning},
abstract = {Knowledge graph embedding is essential for knowledge graph completion and downstream applications. However, in multimodal knowledge graphs, this task is particularly challenging due to incomplete and noisy multimodal data, which often fails to capture semantic relationships between entities. While existing methods attempt to integrate multimodal features, they frequently overlook relational semantics and cross-modal dependencies, leading to suboptimal entity representations. To address these limitations, we propose MESN, a novel multimodal embedding framework that integrates relational and multimodal signals through semantic aggregation and neighbor-aware attention mechanisms. MESN selectively extracts informative multimodal features via adaptive attention and expert-driven learning, ensuring more expressive entity embeddings. Additionally, we introduce an enhanced ComplEx-based scoring function, which effectively combines structured graph interactions with multimodal information, capturing both relational and feature diversity. Extensive experiments on standard multimodal datasets confirm that MESN significantly outperforms baselines across multiple evaluation metrics. Our findings highlight the importance of relational guidance in multimodal embedding tasks, paving the way for more robust and semantically-aware knowledge representations.}
}
@article{LIN2023253,
title = {Fusing topology contexts and logical rules in language models for knowledge graph completion},
journal = {Information Fusion},
volume = {90},
pages = {253-264},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2022.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S1566253522001592},
author = {Qika Lin and Rui Mao and Jun Liu and Fangzhi Xu and Erik Cambria},
keywords = {Knowledge graph completion, Information fusion, Topology context, Logical rule, Language model},
abstract = {Knowledge graph completion (KGC) aims to infer missing facts based on the observed ones, which is significant for many downstream applications. Given the success of deep learning and pre-trained language models (LMs), some LM-based methods are proposed for the KGC task. However, most of them focus on modeling the text of fact triples and ignore the deeper semantic information (e.g., topology contexts and logical rules) that is significant for KG modeling. For such a reason, we propose a unified framework FTL-LM to Fuse Topology contexts and Logical rules in Language Models for KGC, which mainly contains a novel path-based method for topology contexts learning and a variational expectation–maximization (EM) algorithm for soft logical rule distilling. The former utilizes a heterogeneous random-walk to generate topology paths and further reasoning paths that can represent topology contexts implicitly and can be modeled by a LM explicitly. The strategies of mask language modeling and contrastive path learning are introduced to model these topology contexts. The latter implicitly fuses logical rules by a variational EM algorithm with two LMs. Specifically, in the E-step, the triple LM is updated under the supervision of observed triples and valid hidden triples verified by the fixed rule LM. And in the M-step, we fix the triple LM and fine-tune the rule LM to update logical rules. Experiments on three common KGC datasets demonstrate the superiority of the proposed FTL-LM, e.g., it achieves 2.1% and 3.1% Hits@10 improvement over the state-of-the-art LM-based model LP-BERT in the WN18RR and FB15k-237, respectively.}
}
@article{SELLAMI2025100716,
title = {Knowledge graph representation learning: A comprehensive and experimental overview},
journal = {Computer Science Review},
volume = {56},
pages = {100716},
year = {2025},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2024.100716},
url = {https://www.sciencedirect.com/science/article/pii/S1574013724000996},
author = {Dorsaf Sellami and Wissem Inoubli and Imed Riadh Farah and Sabeur Aridhi},
keywords = {Knowledge graphs, Knowledge graph embedding, Representation space, Link prediction, Scalability},
abstract = {Knowledge graph embedding (KGE) is a hot topic in the field of Knowledge graphs (KG). It aims to transform KG entities and relations into vector representations, facilitating their manipulation in various application tasks and real-world scenarios. So far, numerous models have been developed in KGE to perform KG embedding. However, several challenges must be addressed when designing effective KGE models. The most discussed challenges in the literature include scalability (KGs contain millions of entities and relations), incompleteness (missing links), the complexity of relations (symmetries, inversion, composition, etc.), and the sparsity of some entities and relations. The purpose of this paper is to provide a comprehensive overview of KGE models. We begin with a theoretical analysis and comparison of the existing methods proposed so far for generating KGE, which we have classified into four categories. We then conducted experiments using four benchmark datasets to compare the efficacy, efficiency, inductiveness, the electricity and the CO2 emission of five state-of-the-art methods in the link prediction task, providing a comprehensive analysis of the most commonly used benchmarks in the literature.}
}
@article{MA2025128760,
title = {MHEC: One-shot relational learning of knowledge graphs completion based on multi-hop information enhancement},
journal = {Neurocomputing},
volume = {614},
pages = {128760},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128760},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224015315},
author = {Ruixin Ma and Buyun Gao and Weihe Wang and Longfei Wang and Xiaoru Wang and Liang Zhao},
keywords = {One-shot, Knowledge graphs completion, Multi-hop path information, Reasoning logic, Entity concept},
abstract = {With the wide application of knowledge graphs, knowledge graph completion has garnered increasing attention in recent years. However, we find that the long tail relation is more common in the KG. These relations typically do not have a large number of triples for training and are referred to as few-shot relations. The knowledge graph completion in the few-shot scenario is a major challenge currently. The current mainstream knowledge graph completion algorithms have the following drawbacks. The metric-based methods lack interpretability of results, while the algorithms based on path interaction are not suitable for few-shot scenarios and the availability of the model is limited in sparse knowledge graphs. In this paper, we propose a one-shot relational learning of knowledge graphs completion based on multi-hop information enhancement(MHEC). Firstly, MHEC extracts entity concepts from multi-hop paths to obtain task related entity concepts and filters out noisy neighbor attributes. Then, MHEC combines multi-hop path information between head and tail to represent entity pairs. Compared to previous completion methods that only consider structural features of entities, MHEC considers the reasoning logic between entity pairs, which not only includes structural features but also possesses rich semantic features. Next, MHEC introduces a reasoning process in the completion task to address the issues of lack of interpretability in the one-shot scenario. In addition, to improve completion and reasoning quality in sparse knowledge graphs, MHEC utilizes contrastive learning to enhance pre-training vector representations of entities and relations and proposes a matching processor that leverages the semantic information of pre-training vectors to assist the reasoning model in expanding the multi-hop paths. Experiments demonstrate that MHEC outperforms the state-of-the-art completion techniques on real-world datasets NELL-One and FB15k237-One.}
}
@article{CHENG2024109361,
title = {A link prediction method for Chinese financial event knowledge graph based on graph attention networks and convolutional neural networks},
journal = {Engineering Applications of Artificial Intelligence},
volume = {138},
pages = {109361},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109361},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624015197},
author = {Haitao Cheng and Ke Wang and Xiaoying Tan},
keywords = {Chinese financial event knowledge graph, Link prediction, Graph attention network, Convolutional neural network, Large language model},
abstract = {Finance is a knowledge-intensive domain in nature, with its data containing a significant amount of interconnected information. Constructing a financial knowledge graph is an important application for transforming financial text/web content into machine-readable data. However, the complexity of Chinese financial knowledge and the dynamic and evolving nature of Chinese financial data often lead to incomplete knowledge graphs. To address this challenge, we propose a novel link prediction method for Chinese financial event knowledge graph based on Graph Attention Networks and Convolutional Neural Networks. Our method begins with the construction of the foundational Chinese financial event knowledge graph using a relational triple extraction module integrated with a large language model framework, along with a Prompting with Iterative Verification (PiVe) module for validation. To enhance the completeness of the knowledge graph, we introduce an encoder-decoder framework, where a graph attention network with joint embeddings of financial event entities and relations acts as the encoder, while a Convolutional Knowledge Base embedding model (ConvKB) serves as the decoder. This framework effectively aggregates crucial neighbor information and captures global relationships among entity and relation embeddings. Extensive comparative experiments demonstrate the utility and accuracy of this method, ultimately enabling the effective completion of Chinese financial event knowledge graphs.}
}
@article{HAN2025131027,
title = {SCR: A completion-then-reasoning framework for multi-hop question answering over incomplete knowledge graph},
journal = {Neurocomputing},
volume = {651},
pages = {131027},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131027},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225016996},
author = {Ridong Han and Jia Liu and Haijia Bi and Tao Peng and Lu Liu},
keywords = {Knowledge graph question answering, Multi-hop, Reinforcement learning, Subgraph completion, Semantic rewards},
abstract = {Reinforcement learning has become the widely adopted technique for multi-hop knowledge graph question answering task thanks to its excellent interpretability in reasoning process. However, it is severely affected by the incompleteness of knowledge graphs and the sparse rewards caused by weak supervision. In this paper, we propose a completion-then-reasoning framework, called SCR, to address these two issues. For the incompleteness of knowledge graphs, we first extract a subgraph from the given knowledge graph for a given question, and use the knowledge graph embedding model to predict and complete missing triples, followed by reinforcement learning for answer reasoning on the completed subgraph. To alleviate the sparse rewards in reinforcement learning, we introduce a semantic reward based on the semantic similarity between original question and full relational path, enabling the model to receive partial rewards for partially correct paths instead of a zero reward. Detailed experiments on PQ, PQL, MetaQA, and WebQSP datasets demonstrate that our SCR model effectively improves the performance of multi-hop knowledge graph question answering task. Particularly, under sparse KG setting, SCR model outperforms baselines by a large margin, highlighting the effectiveness of completion-then-reasoning framework in mitigating the incompleteness of knowledge graphs.}
}
@article{ZEB2022116796,
title = {Complex graph convolutional network for link prediction in knowledge graphs},
journal = {Expert Systems with Applications},
volume = {200},
pages = {116796},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.116796},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422002548},
author = {Adnan Zeb and Summaya Saif and Junde Chen and Anwar Ul Haq and Zhiguo Gong and Defu Zhang},
keywords = {Knowledge graph, Link prediction, Graph convolutional network, Complex embeddings, Tensor decomposition},
abstract = {Knowledge graph (KG) embedding models map nodes and edges to fixed-length vectors and obtain the similarity of nodes as the output of a scoring function to predict missing links between nodes. KG embedding methods based on graph convolutional networks (GCNs) have recently gained significant attention due to their ability to add information of neighboring nodes into the nodes’ embeddings. However, existing GCNs are primarily based on real-valued embeddings, which have high distortion, particularly when modeling graphs with varying geometric structures. In this paper, we propose complex graph convolutional network (ComplexGCN), a novel extension of the standard GCNs in complex space to combine the expressiveness of complex geometry with GCNs for improving the representation quality of KG components. The proposed ComplexGCN comprises a set of complex graph convolutional layers and a complex scoring function based on PARATUCK2 decomposition: the former includes information of neighboring nodes into the nodes’ embeddings, while the latter leverages these embeddings to predict new links between nodes. The proposed model demonstrates enhanced performance compared to existing methods on the two recent standard link prediction datasets.}
}
@article{GUO2024112268,
title = {TELS: Learning time-evolving information and latent semantics using dual quaternion for temporal knowledge graph completion},
journal = {Knowledge-Based Systems},
volume = {301},
pages = {112268},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112268},
url = {https://www.sciencedirect.com/science/article/pii/S095070512400902X},
author = {Jiujiang Guo and Jian Yu and Mankun Zhao and Mei Yu and Ruiguo Yu and Linying Xu and Yu Pan and Xuewei Li},
keywords = {Temporal knowledge graph completion, Dual quaternion, Evolutionary hierarchy information},
abstract = {In temporal knowledge graphs (TKGs), the status of facts is intricately tied to the dynamic and precise nature of temporal factors. Existing research merely treats time as supplementary information, without considering the latent semantic changes caused by the positional changes of entities within specific relations in a temporal context. Furthermore, due to the coarse granularity of timestamps in existing TKGs, the number of multiple relations pattern among entities significantly increases, limiting model performance. This paper proposes a Time-Evolving Information and Latent Semantics model (TELS), which represents facts as dual quaternion embeddings to provide a compact and elegant representation. Specifically, we use timestamp dual quaternions, transforming the entity and relation into temporal entity and temporal relation through dual quaternion multiplication. Besides, we introduce semantic-aware dual quaternion to capture the latent semantics arising from the positional changes of entities within specific relations. Next, TELS consists of two parts: (a) We use semantic-aware dual quaternions to perform transformations on head entity and tail entity respectively through dual quaternion multiplication. Next, we utilize temporal relation to transform head entity to tail entity through dual quaternion multiplication. (b) We adopt an evolutionary hierarchical factor to encapsulate the differences in modulus distribution between the temporal head entity and temporal tail entity. In this way, TELS not only uses dual quaternions to handle key patterns and multiple relations pattern, but also handles evolutionary hierarchical patterns by capturing the modulus distribution differences between temporal entities. Meanwhile, TELS learns semantic-aware dual quaternion embeddings to capture the latent semantics endowed by relations to entities. Empirically, TELS can boost the performance over seven temporal knowledge graph benchmarks.}
}
@article{VU2025113321,
title = {TCrossE: Cross-space interaction of bicomplex and quaternion embeddings for temporal knowledge graph completion},
journal = {Knowledge-Based Systems},
volume = {315},
pages = {113321},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113321},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125003685},
author = {Thanh Vu and Thanh Le},
keywords = {Temporal knowledge graph completion, Graph representation learning, Cross-space embeddings, Bicomplex and quaternion fusion, Hypercomplex numbers},
abstract = {Completing temporal knowledge graphs is essential to ensuring their readiness for real-world applications. Temporal knowledge graph completion addresses this challenge by predicting missing temporal facts and enriching the knowledge base over time. However, existing models face key challenges: translation-based models offer interpretability but underperform, while neural network-based models achieve high accuracy but lack transparency in how they capture structural and temporal dependencies. To address these challenges, we propose TCrossE (Temporal Cross-Space Embedding), a novel model that fuses bicomplex and quaternion spaces to enhance the representation of temporal structures. By leveraging rotations in hypercomplex spaces, TCrossE creates hybrid embeddings that effectively model both structural relationships and temporal dependencies. The fusion of bicomplex and quaternion spaces is mathematically motivated and validated through empirical studies. Unlike prior models, TCrossE balances expressiveness and interpretability, ensuring strong performance without sacrificing model transparency. Additionally, our approach optimizes training efficiency, making it more practical for large-scale TKG applications. We evaluate TCrossE on five benchmark datasets: ICEWS14, ICEWS05–15, GDELT, WIKIDATA12k, and YAGO11k, covering a diverse range of temporal knowledge graph structures. Experimental results show that TCrossE outperforms state-of-the-art models, achieving up to 18 % improvement on GDELT and YAGO11k while maintaining competitive performance on other datasets. Furthermore, TCrossE exhibits lower training times, making it suitable for real-world deployment.}
}
@article{YANG2024112155,
title = {Enhancing text-based knowledge graph completion with zero-shot large language models: A focus on semantic enhancement},
journal = {Knowledge-Based Systems},
volume = {300},
pages = {112155},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112155},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124007895},
author = {Rui Yang and Jiahao Zhu and Jianping Man and Li Fang and Yi Zhou},
keywords = {Knowledge graph, Knowledge graph completion, Large language models, Semantic enhancement},
abstract = {The design and development of text-based knowledge graph completion (KGC) methods leveraging textual entity descriptions are at the forefront of research. These methods involve advanced optimization techniques such as soft prompts and contrastive learning to enhance KGC models. The effectiveness of text-based methods largely hinges on the quality and richness of the training data. Large language models (LLMs) can utilize straightforward prompts to alter text data, thereby enabling data augmentation for KGC. Nevertheless, LLMs typically demand substantial computational resources. To address these issues, we introduce a framework termed constrained prompts for KGC (CP-KGC). This CP-KGC framework designs prompts that adapt to different datasets to enhance semantic richness. Additionally, CP-KGC employs a context constraint strategy to effectively identify polysemous entities within KGC datasets. Through extensive experimentation, we have verified the effectiveness of this framework. Even after quantization, the LLM (Qwen-7B-Chat-int4) still enhances the performance of text-based KGC methods.11Code and datasets are available at https://github.com/sjlmg/CP-KGC. This study extends the performance limits of existing models and promotes further integration of KGC with LLMs.}
}
@article{LI2025113500,
title = {KERMIT: Knowledge graph completion of enhanced relation modeling with inverse transformation},
journal = {Knowledge-Based Systems},
volume = {324},
pages = {113500},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113500},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125005465},
author = {Haotian Li and Bin Yu and Yuliang Wei and Kai Wang and Richard Yi Da Xu and Bailing Wang},
keywords = {Knowledge graph completion (KGC), Large language models (LLMs), Supervised contrastive learning},
abstract = {Knowledge graph completion (KGC) revolves around populating missing triples in a knowledge graph using available information. Text-based methods, which depend on textual descriptions of triples, often encounter difficulties when these descriptions lack sufficient information for accurate prediction, an issue inherent to the datasets and not easily resolved through modeling alone. To address this and ensure data consistency, we first use large language models (LLMs) to generate coherent descriptions, bridging the semantic gap between queries and answers. Secondly, we utilize inverse relations to create a symmetric graph, thereby providing augmented training samples for KGC. Additionally, we employ the label information inherent in knowledge graphs (KGs) to enhance the existing contrastive framework, making it fully supervised. These efforts have led to significant performance improvements on the WN18RR, FB15k-237 and UMLS datasets. According to standard evaluation metrics, our approach achieves a 3.0% improvement in Hit@1 on WN18RR and a 12.1% improvement in Hit@3 on UMLS, demonstrating superior performance.}
}
@article{LI2023100397,
title = {A Multi-View Filter for Relation-Free Knowledge Graph Completion},
journal = {Big Data Research},
volume = {33},
pages = {100397},
year = {2023},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2023.100397},
url = {https://www.sciencedirect.com/science/article/pii/S2214579623000308},
author = {Juan Li and Wen Zhang and Hongtao Yu},
keywords = {Knowledge graph, Knowledge graph embedding, Relation-free knowledge graph completion, Graph neural networks},
abstract = {As knowledge graphs are often incomplete, knowledge graph completion methods have been widely proposed to infer missing facts by predicting the missing element of a triple given the other two elements. However, the assumption that the two elements have to be correlated is strong. Thus in this paper, we investigate relation-free knowledge graph completion to predict relation-tail(r-t) pairs given a head entity. Considering the large scale of candidate relation-tail pairs, previous work proposed to filter r-t pairs before ranking them relying on entity types, which fails when entity types are missing or insufficient. To tackle the limitation, we propose a relation-free knowledge graph completion method that can cope with knowledge graphs without additional ontological information, such as entity types. Specifically, we propose a multi-view filter, including two intra-view modules and an inter-view module, to filter r-t pairs. For the intra-view modules, we construct head-relation and tail-relation graphs based on triples. Two graph neural networks are respectively trained on these two graphs to capture the correlations between the head entities and the relations, as well as the tail entities and the relations. The inter-view module is learned to bridge the embeddings of entities that appeared in the two graphs. In terms of ranking, existing knowledge graph embedding models are applied to score and rank the filtered candidate r-t pairs. Experimental results show the efficiency of our method in preserving higher-quality candidate r-t pairs for knowledge graphs and resulting in better relation-free knowledge graph completion.}
}
@article{LI2023119548,
title = {Knowledge graph completion method based on quantum embedding and quaternion interaction enhancement},
journal = {Information Sciences},
volume = {648},
pages = {119548},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119548},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523011337},
author = {LinYu Li and Xuan Zhang and Zhi Jin and Chen Gao and Rui Zhu and YuQin Liang and YuBing Ma},
keywords = {Knowledge graph completion, Link prediction, Quantum embedding, Quaternion, Knowledge graph},
abstract = {Knowledge graphs (KG) are used for many downstream tasks in artificial intelligence (AI). However, owing to accuracy issues associated with information extraction, KGs are often incomplete. This has led to the emergence of knowledge graph completion (KGC) tasks. Their purpose is to learn known facts to infer the missing entities in triples. Traditional embedding-based methods usually only focus on the information of individual triples and do not use the deep logical relationships of the KG. In this study, we propose a new KGC method referred to as QIQE-KGC. It uses quantum embedding and quaternion space interaction to capture the external logical relationship between triples in a KG and enhance the connection between entities and relations within a single triple to model and represent the KG. The proposed QIQE-KGC model can capture richer logical information and has more powerful and complex relationship modeling capabilities. Extensive experimental results using QIQE-KGC on 11 datasets demonstrate that the model achieves outstanding performance. Compared to the baseline models, QIQE-KGC produced the best results on most datasets.}
}
@article{YU2025129743,
title = {Knowledge graph embedding based on embedding permutation and high-frequency feature fusion for link prediction},
journal = {Neurocomputing},
volume = {633},
pages = {129743},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129743},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225004151},
author = {Qien Yu and Danilo Vasconcellos Vargas},
keywords = {Knowledge graph embedding, Link prediction, Feature fusion, Convolutional neural network, Embedding permutation, Projection attention},
abstract = {Knowledge graph embedding has excellent performance in capturing intrinsic relations and semantics in a wealth of information for link prediction. Knowledge graph embedding methods have achieved impressive results in recent years, especially those using convolutional neural networks. However, many previous approaches focus on interactions between relations and entities, ignoring interactions of internal data elements and the crucial role of high-frequency features. In this paper, we propose a novel approach, a knowledge graph Embedding model using 2D convolution operations integrating Embedding permutation strategy and High-frequency features fusion mechanism, named EHE, for link prediction. First, we design the embedding permutation mechanism for the embedding vectors. This mechanism leverages internal element permutation, efficiently broadening the local interactions of internal elements, especially for far-flung data elements in the one-dimensional space. Subsequently, a high-frequency feature fusion module is proposed to capture the high-frequency feature representations by using Sobel and Laplacian operators. Additionally, the projection attention mechanism is utilized to emphasize the unique semantic regions of interest in entities and relations. We assess our approach on several benchmark link prediction datasets. Considering the important metrics, MRR and H@1, our method achieves the overall best performance compared with existing state-of-the-art methods on five public datasets, showcasing its superior capacity for link prediction.}
}
@article{LI2023323,
title = {Capsule neural tensor networks with multi-aspect information for Few-shot Knowledge Graph Completion},
journal = {Neural Networks},
volume = {164},
pages = {323-334},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.04.041},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023002277},
author = {Qianyu Li and Jiale Yao and Xiaoli Tang and Han Yu and Siyu Jiang and Haizhi Yang and Hengjie Song},
keywords = {Few-shot knowledge graph completion, Few-shot learning, Knowledge graph, Capsule network, Neural tensor network},
abstract = {Few-shot Knowledge Graph Completion (FKGC) has recently attracted significant research interest due to its ability to expand few-shot relation coverage in Knowledge Graphs. Prevailing FKGC approaches focus on exploiting the one-hop neighbor information of entities to enhance few-shot relation embedding. However, these methods select one-hop neighbors randomly and neglect the rich multi-aspect information of entities. Although some methods have attempted to leverage Long Short-Term Memory (LSTM) to learn few-shot relation embedding, they are sensitive to the input order. To address these limitations, we propose the Capsule Neural Tensor Networks with Multi-Aspect Information approach (short for InforMix-FKGC). InforMix-FKGC employs a one-hop neighbor selection strategy based on how valuable they are and encodes multi-aspect information of entities, including one-hop neighbors, attributes and literal description. Then, a capsule network is responsible for integrating the support set and deriving few-shot relation embedding. Moreover, a neural tensor network is used to match the query set with the support set. In this way, InforMix-FKGC can learn few-shot relation embedding more precisely so as to enhance the accuracy of FKGC. Extensive experiments on the NELL-One and Wiki-One datasets demonstrate that InforMix-FKGC significantly outperforms ten state-of-the-art methods in terms of Mean Reciprocal Rank and Hits@K.}
}
@article{CAI2023100394,
title = {Meta-Learning Based Dynamic Adaptive Relation Learning for Few-Shot Knowledge Graph Completion},
journal = {Big Data Research},
volume = {33},
pages = {100394},
year = {2023},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2023.100394},
url = {https://www.sciencedirect.com/science/article/pii/S2214579623000278},
author = {Linqin Cai and Lingjun Wang and Rongdi Yuan and Tingjie Lai},
keywords = {Few-shot learning, Long-tail relation, Optimization-based framework, Dynamic property},
abstract = {As artificial intelligence gradually steps into cognitive intelligence stage, knowledge graphs (KGs) play an increasingly important role in many natural language processing tasks. Due to the prevalence of long-tail relations in KGs, few-shot knowledge graph completion (KGC) for link prediction of long-tail relations has gradually become a hot research topic. Current few-shot KGC methods mainly focus on the static representation of surrounding entities to explore the potential semantic features of entities, while ignoring the dynamic properties among entities and the special influence of the long-tail relation on link prediction. In this paper, a new meta-learning based dynamic adaptive relation learning model (DARL) is proposed for few-shot KGC. For obtaining better semantic information of the meta knowledge, the proposed DARL model applies a dynamic neighbor encoder to incorporate neighbor relations into entity embedding. In addition, DARL builds attention mechanism based fusion strategy for different attributes of the same relation to further enhance the relation-meta learning ability. We evaluate our DARL model on two public benchmark datasets NELL-One and WIKI-One for link prediction. Extensive experimental results indicate that our DARL outperforms the state-of-the-art models with an average relative improvement about 23.37%, 32.46% in MRR and Hits@1 on NELL-One, respectively.}
}
@article{ZHANG2025111802,
title = {Enhanced knowledge graph cascade learning model for cyber–physical systems},
journal = {Engineering Applications of Artificial Intelligence},
volume = {160},
pages = {111802},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111802},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625018044},
author = {Shumao Zhang and Jie Xu and Haodiao Xie and Qiuru Fu and Ke Miao and Shixue Cheng and Zelei Wu},
keywords = {Graph structure learning, Graph representation learning, Cyber–physical systems, Knowledge graph, Multi-level graph attention},
abstract = {Recently, the application prospects of knowledge graph technology in cyber–physical systems (CPS) have attracted considerable attention. However, knowledge graph data in various CPS domains are typically collected from sensors or through manual efforts, which inevitably results in incomplete and unreliable data, thereby impacting the performance of downstream task models. This issue is often overlooked in existing studies. This paper proposes an enhanced knowledge graph cascade learning model for CPS. The model performs cascaded and iterative learning of both graph structure and graph representation. By optimizing the graph structure and incorporating hierarchical learning of graph-structured information, the proposed model enhances feature propagation and aggregation during representation learning. Experiments show that our model achieves outstanding results: compared to the baseline models, our approach achieves an average improvement of 2.7% in accuracy on the node classification task and 1.35% in MRR on the link prediction task.}
}
@article{YE2026129199,
title = {SuKE: Structural Knowledge Extractor enhances large language model for knowledge graph completion},
journal = {Expert Systems with Applications},
volume = {297},
pages = {129199},
year = {2026},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.129199},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425028155},
author = {Yunhai Ye and Shuo Wang},
keywords = {Knowledge graph, Knowledge graph completion, Large language model, Graph neural network, Cross-modality transferability},
abstract = {Current large language model (LLM)-based knowledge graph completion (KGC) methods fail to fully leverage structural information of the knowledge graph (KG), resulting in suboptimal performance. They typically incorporate KG information into LLMs through either direct fine-tuning or employing soft prompts derived from conventional embedding-based KGC models. However, these methodologies exhibit fundamental limitations in their capacity to comprehensively encode and exploit the intricate structural information contained within KGs. To address these issues, we first develop KG-infused in-context learning and KG-infused instruction tuning by extending existing LLM paradigms to inject structural information through textual representations. Then we propose a Structural Knowledge Extractor (SuKE), a trainable encoder-decoder architecture designed to extract both structural and semantic information from KGs and incorporate it into LLMs, with the overarching goal of enhancing the structural reasoning capabilities of LLMs for KGC tasks. Specifically, in encoder, we propose a Group-wise Graph Attention Network with relation-augmented message function for entity embeddings generation and a dynamic relation representation module using subgraph relational path to produce relation embeddings. Subsequently, a global embedding mechanism is introduced to mitigate the over-smoothing issue of entity and relation embeddings. In decoder, a cross-modal projection mechanism transforms the embeddings of triples into virtual tokens within the textual space, which are then pretended as prefixes to the prompt tokens and injected into the LLM. Experimental performance outperforms the state-of-the-art methods, demonstrating that SuKE significantly boosts the performance of LLMs on KGC tasks and revealing the effectiveness of structural information.}
}
@article{WANG2025126992,
title = {Structure-Aware Transformer for hyper-relational knowledge graph completion},
journal = {Expert Systems with Applications},
volume = {277},
pages = {126992},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126992},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425006141},
author = {Junjie Wang and Huajun Chen and Wen Zhang},
keywords = {Knowledge graph, Transformer, Link prediction, Graph structure},
abstract = {Hyper-relational knowledge graph (HKG) has gradually gained attention in recent studies. Different from vanilla knowledge graph (KG) which represents connections between things in the real world in numerous triples (subject, relation, object), HKG can describe a complex event in one fact, represented as a main triple and some auxiliary key–value pairs. Recently, there have been gradually increasing efforts to use the Transformer framework for representation learning of HKG. Although these methods achieve moderate performance, they do not make good use of the structural information (i.e., connectivity and direction) in HKG, which is important for HKG representation learning. To handle these problems, we propose a novel Transformer-based and structure-aware method of HKG representation learning. Specifically, we first provide a subgraph sampling strategy that makes reasonable use of the connection information between the central fact and subgraph in the HKG. Next, we consider heterogeneous characteristics in the original HKG and binding property between key–value pairs, thus introducing the heterogeneous attention biases and key–value joint attention mechanism respectively. Beyond that, we introduce the direction information during propagation between Transformer layers. More importantly, although our model is originally designed for HKG, it can be regarded as a universal framework. It can be generalized to other types of KGs, such as triple-based and temporal KGs. We evaluate our model on the link prediction task, or so-called knowledge graph completion (KGC). Compared to existing methods, experimental results show that our model outperforms baseline models on the HKG datasets. Meanwhile, our model achieves results surpassing or on par with the baselines on triple-based KG and temporal KG even though it is not specifically designed for them, proving the great generalization ability of our approach. The code is available at https://github.com/zjukg/HyperSAT.}
}
@article{ZHANG2025130665,
title = {LDM-KGC: A low-dimensional knowledge graph completion model based on multi-head attention mechanism},
journal = {Neurocomputing},
volume = {649},
pages = {130665},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130665},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225013372},
author = {Chaoqun Zhang and Bingjie Qiu and Weidong Tang and Bicheng Liang and Danyang Cui and Haisheng Luo and Qiming Chen},
keywords = {Low dimensionality, Multi-head attention, Link prediction, Knowledge graph completion},
abstract = {Existing Transformer-based knowledge graph completion methods often rely on high-dimensional embeddings to achieve competitive performance, which to some extent limits their scalability on large-scale knowledge graphs. To address this challenge, the LDM-KGC model based on the multi-head attention mechanism is proposed. By combining QKV-layer and Update-layer, LDM-KGC can not only learn rich information but also reduce information loss during training, thereby achieving superior embedding representations in low-dimensional spaces. Specifically, QKV-layer utilizes the multi-head attention mechanism to effectively capture interactions between entities and relations, while Update-layer further refines the resulting embeddings. Experimental results on the FB15k-237 and WN18RR datasets demonstrate that LDM-KGC outperforms 14 baseline models, significantly improving mean reciprocal rank (MRR) by 12.4 percentage points and 24.4 percentage points over the worst baseline, respectively. Notably, LDM-KGC achieves MRR of 36.5%, Hits@1 of 27.1%, Hits@3 of 40.2%, and Hits@10 of 55.2% on the FB15k-237 dataset. Furthermore, LDM-KGC reaches a Hits@10 score of 65.2% on the NELL-995 dataset. These results underscore the effectiveness of LDM-KGC in generating low-dimensional embeddings, thereby offering a scalable solution for large-scale knowledge graph completion.}
}
@article{DING2025130940,
title = {EiCoM: Multi-modal knowledge graph completion with enhanced information completeness},
journal = {Neurocomputing},
volume = {650},
pages = {130940},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130940},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225016121},
author = {Lianhong Ding and Mengxiao Li and Peng Shi and Juntao Li and Ruiping Yuan},
keywords = {Knowledge graph completion, Multi-modal knowledge graph, Cross-modal semantic alignment, Multi-modal fusion},
abstract = {Knowledge graph completion (KGC) is essential for improving the integrity and quality of knowledge graphs (KGs), while multi-modal data offers a richer information source. However, multi-modal knowledge graph completion (MMKGC) faces challenges in information incompleteness and modality imbalance, limiting its performance and applicability. To address the above issues, this paper proposes a novel MMKGC method, EiCoM. Firstly, EiCoM proposes a cross-modal semantic alignment and collaboration module to efficiently align and interact with features across modalities, enhancing semantic consistency across multiple modalities. Then, EiCoM introduces a modality adversarial generation module based on the generative adversarial network (GAN) framework to generate supplementary modality information, alleviating information incompleteness and optimizing modality imbalance in MMKGC. Finally, EiCoM designs a context-aware adaptive fusion module with a dynamic weight allocation mechanism that adjusts the contribution weights of each modality based on the semantic information of a target triple and its context. Experimental results show that EiCoM achieves significant performance improvements on five public datasets, outperforming 19 state-of-the-art MMKGC baselines. Additionally, a series of experiments, including ablation studies, modal noise injection, a case study, and the analysis of the modality adversarial generation module, comprehensively validate the effectiveness of the EiCoM’s core modules and its completeness enhancement across different scenarios.}
}