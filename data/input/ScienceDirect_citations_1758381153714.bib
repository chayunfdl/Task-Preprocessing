@article{QIN2025107803,
title = {Social perceptions going online: Exploring the impact of social media food content exposure on perceptions of food norms},
journal = {Appetite},
volume = {206},
pages = {107803},
year = {2025},
issn = {0195-6663},
doi = {https://doi.org/10.1016/j.appet.2024.107803},
url = {https://www.sciencedirect.com/science/article/pii/S019566632400607X},
author = {Kaiyang Qin and Saar Mollen and Wilma Waterlander and Sixu Cai and Eline Smit},
keywords = {Social norms, Social media, Unhealthy food, Food content, Data donation},
abstract = {Social media is becoming an increasingly important environment for food-related content, however, the question of whether the food content encountered on social media contributes to the perception of food-related social norms is relatively unexplored. In the present study, we addressed this question by testing whether exposure to unhealthy food content on YouTube is related to how people perceive social norms regarding (un)healthy food consumption. Furthermore, we investigated the boundary conditions for the hypothetical link between the exposure and the norm perceptions, focusing on the type of content (i.e., ads vs. user-generated content) and individual characteristics (i.e., algorithmic media content awareness). We applied a data donation approach to collect YouTube data on users' exposure to food-related content and combined this with a survey. With the data from 102 respondents, no significant association between unhealthy food content exposure (i.e., frequency and proportion) and perceived unhealthy food norms was found. Explorative analyses revealed, however, a significant negative association between unhealthy food content exposure (i.e., frequency) and perceived healthy food norms, and this association was more pronounced when individuals encountered more user-generated food content (vs. food ads). Interestingly, this pattern emerged only for injunctive norms but not for descriptive norms. Despite these results offering limited support for the presumed link between exposure to unhealthy food content and food norm perceptions, the findings provide input for future studies in this area. Limitations of the present study and implications of employing a data donation approach for exploring social media data are discussed.}
}
@article{LI2022294,
title = {Graph convolutional network meta-learning with multi-granularity POS guidance for video captioning},
journal = {Neurocomputing},
volume = {472},
pages = {294-305},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.12.137},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221016118},
author = {Ping Li and Pan Zhang and Xianghua Xu},
keywords = {Graph convolutional networks, Meta-learning, Video captioning, Multi-granularity part-of-speech},
abstract = {Video as information carrier has gained overwhelming popularity in city surveillance and social networks, such as WeChat, Weibo, and TikTok. To bridge the semantic gap between video content (e.g., user and landmark building) and textual information (e.g., user location), video captioning has emerged as an attracting technique in recent years. Existing works mostly focus on sentence-level Part-of-Speech (POS) information and use Long Short-Term Memory (LSTM) as encoder, which neglects word or phrase-level POS information and also fails to globally consider long-range temporal relations among video frames. To address the drawbacks, we leverage multi-granularity POS guidance to learn Graph Convolutional Network (GCN) via meta-learning, abbreviated as GMMP (GCN Meta-learning with Multi-granularity POS), for generating high-quality captions for videos. It models temporal dependency by treating frames as nodes in the graph, and captures POS information of words and phrases by multi-granularity POS attention mechanism. We adopt meta-learning to better learn GCN by maximizing the reward of generated caption in a reinforcement task and also the probability of ground-truth caption in a supervised task, simultaneously. Experiments have verified the advantages of our GMMP model on several benchmark data sets.}
}
@article{JIANG20242161,
title = {A Model for Detecting Fake News by Integrating Domain-Specific Emotional and Semantic Features},
journal = {Computers, Materials and Continua},
volume = {80},
number = {2},
pages = {2161-2179},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.053762},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824005599},
author = {Wen Jiang and Mingshu Zhang and Xu'an Wang and Wei Bin and Xiong Zhang and Kelan Ren and Facheng Yan},
keywords = {Fake news detection, domain-related emotional features, semantic features, feature fusion},
abstract = {With the rapid spread of Internet information and the spread of fake news, the detection of fake news becomes more and more important. Traditional detection methods often rely on a single emotional or semantic feature to identify fake news, but these methods have limitations when dealing with news in specific domains. In order to solve the problem of weak feature correlation between data from different domains, a model for detecting fake news by integrating domain-specific emotional and semantic features is proposed. This method makes full use of the attention mechanism, grasps the correlation between different features, and effectively improves the effect of feature fusion. The algorithm first extracts the semantic features of news text through the Bi-LSTM (Bidirectional Long Short-Term Memory) layer to capture the contextual relevance of news text. Senta-BiLSTM is then used to extract emotional features and predict the probability of positive and negative emotions in the text. It then uses domain features as an enhancement feature and attention mechanism to fully capture more fine-grained emotional features associated with that domain. Finally, the fusion features are taken as the input of the fake news detection classifier, combined with the multi-task representation of information, and the MLP and Softmax functions are used for classification. The experimental results show that on the Chinese dataset Weibo21, the F1 value of this model is 0.958, 4.9% higher than that of the sub-optimal model; on the English dataset FakeNewsNet, the F1 value of the detection result of this model is 0.845, 1.8% higher than that of the sub-optimal model, which is advanced and feasible.}
}
@article{LUO2024128089,
title = {BC4LLM: A perspective of trusted artificial intelligence when blockchain meets large language models},
journal = {Neurocomputing},
volume = {599},
pages = {128089},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128089},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224008609},
author = {Haoxiang Luo and Jian Luo and Athanasios V. Vasilakos},
keywords = {Trusted AI, Blockchain, Large language model, AI-generated content, ChatGPT},
abstract = {In recent years, artificial intelligence (AI) and machine learning (ML) are reshaping society's production methods and productivity, and also changing the paradigm of scientific research. Among them, the AI language model represented by ChatGPT has made great progress. Such large language models (LLMs) serve people in the form of AI-generated content (AIGC) and are widely used in consulting, healthcare, and education. However, it is difficult to guarantee the authenticity and reliability of AIGC learning data. In addition, there are also hidden dangers of privacy disclosure in distributed AI training. Moreover, the content generated by LLMs is difficult to identify and trace, and it is difficult to cross-platform mutual recognition. The above information security issues in the coming era of AI powered by LLMs will be infinitely amplified and affect everyone's life. Therefore, we consider empowering LLMs using blockchain technology with superior security features to propose a vision for trusted AI. This survey mainly introduces the motivation and technical route of blockchain for LLM (BC4LLM), including reliable learning corpus, secure training process, and identifiable generated content. Meanwhile, this survey also reviews the potential applications and future challenges, especially in the frontier communication networks field, including network resource allocation, dynamic spectrum sharing, and semantic communication. Based on the above work combined with the prospect of blockchain and LLMs, it is expected to help the early realization of trusted AI and provide guidance for the academic community.}
}
@article{WU2025128513,
title = {Impact of alleviating misinformation: an impulsive buying-aware model for sequential recommendation},
journal = {Expert Systems with Applications},
volume = {291},
pages = {128513},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128513},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425021323},
author = {Hongchen Wu and Xiaochang Fang and Hongxuan Li and Jie Sun and Jing Jing and Lin Zhang and Yihong Meng and Zhaorong Jing and Huaxiang Zhang},
keywords = {Recommender system, Sequential recommendation, Misinformation impact, Impulsive buying, Long- and short-term preference},
abstract = {Sequential recommender systems are often misled by large-scale traffic data containing misinformation, which can trigger impulsive buying and reduce prediction accuracy. However, most existing methods either focus solely on long-term user preferences or assume a smooth evolution of user intentions, resulting in inadequate modeling and poor performance. This paper proposes an in-depth propaganda strategy by proposing an impulsive buying-aware model based on users’ long-term and short-term preference representation for sequential recommendation (INSPEQ), aiming to mitigate misinformation effects and enhance recommendation quality. INSPEQ first distinguishes long- and short-term preferences by extracting item attributes embedded in both intrinsic and extrinsic knowledge through relation paths. For long-term behavior modeling, a PATR-GRU network with apGRUs is used to learn stable user preferences by leveraging persistent item attributes and encoding temporal dependencies between adjacent and nonadjacent items along knowledge sequences, capturing both direct and indirect temporal influences. To capture short-term user preferences, a modified self-attention mechanism is introduced, enhanced with time-aware positional encoding, enabling the model to reflect recent shifts in user behavior more effectively within dynamic sessions. These dual representations are then adaptively fused via an MLP-based gated mechanism, assigning dynamic weights based on user impulsivity levels to flexibly balance stability and recency in decision-making. Extensive experiments on three real-world datasets demonstrate that INSPEQ consistently outperforms nineteen state-of-the-art methods. Specifically, it achieves up to +10.1 % in nDCG@5 and +11.4 % in HitRatio@5 over the strongest baselines, highlighting the effectiveness of jointly modeling preference dynamics while alleviating misinformation effects in practical recommendation environments.}
}
@article{VANDERVLUGT2024700,
title = {ChatGPT, MD: How AI-Empowered Patients & Doctors Can Take Back Control of American Medicine},
journal = {Annals of Emergency Medicine},
volume = {84},
number = {6},
pages = {700-703},
year = {2024},
issn = {0196-0644},
doi = {https://doi.org/10.1016/j.annemergmed.2024.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0196064424004104},
author = {Theresa M. {van der Vlugt}}
}
@article{HAGIU2025103134,
title = {Artificial intelligence and competition policy},
journal = {International Journal of Industrial Organization},
pages = {103134},
year = {2025},
issn = {0167-7187},
doi = {https://doi.org/10.1016/j.ijindorg.2025.103134},
url = {https://www.sciencedirect.com/science/article/pii/S0167718725000013},
author = {Andrei Hagiu and Julian Wright},
keywords = {Antitrust, Data, Feedback loops, Generative AI, Network effects},
abstract = {This paper examines competition policy implications of the rapidly expanding Artificial Intelligence (AI) sector. We analyze the vertical AI technology stack and data feedback loops to address three key questions: the potential for market concentration in core AI services, AI's likely impact on existing market structures, and emerging competition policy challenges. We identify key risks to competition in the AI sector, ways in which AI may disrupt some existing platforms, how AI could lead to new types of gatekeepers, and some novel competition policy concerns raised by AI.}
}
@article{FITZSIMMONS2025,
title = {Practice Management: Artificial Intelligence in Marketing—An Application for Dental Practices},
journal = {Dental Clinics of North America},
year = {2025},
issn = {0011-8532},
doi = {https://doi.org/10.1016/j.cden.2025.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0011853225000369},
author = {Kimberly A. FitzSimmons},
keywords = {Artificial intelligence, Dental marketing, ChatGPT, Practice management, Video marketing}
}
@article{LIU2024102300,
title = {Emotion detection for misinformation: A review},
journal = {Information Fusion},
volume = {107},
pages = {102300},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102300},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524000782},
author = {Zhiwei Liu and Tianlin Zhang and Kailai Yang and Paul Thompson and Zeping Yu and Sophia Ananiadou},
keywords = {Sentiment analysis, Emotion detection, Misinformation, Rumor, Fake news, Stance detection},
abstract = {With the advent of social media, an increasing number of netizens are sharing and reading posts and news online. However, the huge volumes of misinformation (e.g., fake news and rumors) that flood the internet can adversely affect people’s lives, and have resulted in the emergence of rumor and fake news detection as a hot research topic. The emotions and sentiments of netizens, as expressed in social media posts and news, constitute important factors that can help to distinguish fake news from genuine news and to understand the spread of rumors. This article comprehensively reviews emotion-based methods for misinformation detection, with a particular focus on advanced fusion methods. We begin by explaining the strong links between emotions and misinformation. We subsequently provide a detailed analysis of a range of misinformation detection methods that employ a variety of emotion, sentiment and stance-based features, and describe their strengths and weaknesses. Finally, we discuss a number of ongoing challenges in emotion-based misinformation detection based on large language models, and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability.}
}
@article{DWIVEDI2023102642,
title = {Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy},
journal = {International Journal of Information Management},
volume = {71},
pages = {102642},
year = {2023},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102642},
url = {https://www.sciencedirect.com/science/article/pii/S0268401223000233},
author = {Yogesh K. Dwivedi and Nir Kshetri and Laurie Hughes and Emma Louise Slade and Anand Jeyaraj and Arpan Kumar Kar and Abdullah M. Baabdullah and Alex Koohang and Vishnupriya Raghavan and Manju Ahuja and Hanaa Albanna and Mousa Ahmad Albashrawi and Adil S. Al-Busaidi and Janarthanan Balakrishnan and Yves Barlette and Sriparna Basu and Indranil Bose and Laurence Brooks and Dimitrios Buhalis and Lemuria Carter and Soumyadeb Chowdhury and Tom Crick and Scott W. Cunningham and Gareth H. Davies and Robert M. Davison and Rahul Dé and Denis Dennehy and Yanqing Duan and Rameshwar Dubey and Rohita Dwivedi and John S. Edwards and Carlos Flavián and Robin Gauld and Varun Grover and Mei-Chih Hu and Marijn Janssen and Paul Jones and Iris Junglas and Sangeeta Khorana and Sascha Kraus and Kai R. Larsen and Paul Latreille and Sven Laumer and F. Tegwen Malik and Abbas Mardani and Marcello Mariani and Sunil Mithas and Emmanuel Mogaji and Jeretta Horn Nord and Siobhan O’Connor and Fevzi Okumus and Margherita Pagani and Neeraj Pandey and Savvas Papagiannidis and Ilias O. Pappas and Nishith Pathak and Jan Pries-Heje and Ramakrishnan Raman and Nripendra P. Rana and Sven-Volker Rehm and Samuel Ribeiro-Navarrete and Alexander Richter and Frantz Rowe and Suprateek Sarker and Bernd Carsten Stahl and Manoj Kumar Tiwari and Wil {van der Aalst} and Viswanath Venkatesh and Giampaolo Viglia and Michael Wade and Paul Walton and Jochen Wirtz and Ryan Wright},
keywords = {Conversational agent, Generative artificial intelligence, Generative AI, ChatGPT, Large language models},
abstract = {Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT’s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT’s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.}
}
@article{YAO2025107829,
title = {Stealthy and efficient adversarial example attack on video retrieval systems},
journal = {Neural Networks},
volume = {191},
pages = {107829},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2025.107829},
url = {https://www.sciencedirect.com/science/article/pii/S0893608025007099},
author = {Xin Yao and Enlang Li and Yimin Chen and Jiawei Guo and Kecheng Huang and Fengxiao Tang and Ming Zhao},
keywords = {Targeted sparse adversarial example attack, Video retrieval system, Black-box attack, Stealthiness},
abstract = {Massive videos are released every day particularly through video-focused social media apps like TikTok. This trend has fostered the quick emergence of video retrieval systems, which provide video retrieval services using machine learning techniques. Adversarial example (AE) attacks have been shown to be effective on such systems by perturbing an unaltered video subtly to induce false retrieval results. Such AE attacks can be easily detected because the adversarial perturbations are all over pixels and frames. In this paper, we propose DUO, a stealthy targeted black-box AE attack which uses DUal search Over frame-pixel to generate sparse perturbations and improve stealthiness and query efficiency. DUO is driven by three observations: only “key video frames” decide the model predictions, and different pixels and frames contribute far differently to AEs, and pixels in a frame exhibit locality. Subsequently we propose two AE attacks: DUOP featuring pixel sparsity and DUOG featuring group sparsity. Our sequential attack pipeline consists of two components, i.e., SparseTransfer and SparseQuery. In effect, DUO utilizes SparseTransfer to generate initial perturbations and then SparseQuery to further rectify them. Meanwhile, DUOP focuses on individual pixels, whereas DUOG targets groups of pixels. Extensive evaluations on two popular datasets confirm the improved stealthiness and efficacy of DUO over existing AE attacks on video retrieval systems. Particularly, DUOP can achieve higher precision while significantly reducing adversarial perturbations by more than ×100 than state-of-the-art, and DUOG is with more than ×10 fewer queries.}
}
@article{ZHU2025,
title = {Evolutionary Trend of Dental Health Care Information on Chinese Social Media Platforms During 2018-2022: Retrospective Observational Study},
journal = {JMIR Infodemiology},
volume = {5},
year = {2025},
issn = {2564-1891},
doi = {https://doi.org/10.2196/55065},
url = {https://www.sciencedirect.com/science/article/pii/S2564189125000210},
author = {Zhiyu Zhu and Zhiyun Ye and Qian Wang and Ruomei Li and Hairui Li and Weiming Guo and Zhenxia Li and Lunguo Xia and Bing Fang},
keywords = {social media, dental health education, natural language processing, information quality assessment, dental care, dental hygiene, dentistry, orthodontic, health care information, retrospective study, observational study, user engagement, Chinese, dental practitioner, WeChat, health information, preventive care},
abstract = {Background
Social media holds an increasingly significant position in contemporary society, wherein evolving public perspectives are mirrored by changing information. However, there remains a lack of comprehensive analysis regarding the nature and evolution of dental health care information on Chinese social media platforms (SMPs) despite extensive user engagement and voluminous content.
Objective
This study aimed to probe into the nature and evolution of dental health care information on Chinese SMPs from 2018 to 2022, providing valuable insights into the evolving digital public perception of dental health for dental practitioners, investigators, and educators.
Methods
This study was conducted on 3 major Chinese SMPs: Weibo, WeChat, and Zhihu. Data from March 1 to 31 in 2018, 2020, and 2022 were sampled to construct a social media original database (ODB), from which the most popular long-text posts (N=180) were selected to create an analysis database (ADB). Natural language processing (NLP) tools were used to assist tracking topic trends, and word frequencies were analyzed. The DISCERN health information quality assessment questionnaire was used for information quality evaluation.
Results
The number of Weibo posts in the ODB increased approximately fourfold during the observation period, with discussion of orthodontic topics showing the fastest growth, surpassing that of general dentistry after 2020. In the ADB, the engagement of content on Weibo and Zhihu also displayed an upward trend. The overall information quality of long-text posts on the 3 platforms was moderate or low. Of the long-text posts, 143 (79.4%) were written by nonprofessionals, and 105 (58.3%) shared personal medical experiences. On Weibo and WeChat, long-text posts authored by health care professionals had higher DISCERN scores (Weibo P=.04; WeChat P=.02), but there was a negative correlation between engagement and DISCERN scores (Weibo tau-b [τb]=–0.45, P=.01; WeChat τb=–0.30, P=.02).
Conclusions
There was a significant increase in the dissemination and evolution of public interest in dental health care information on Chinese social media during 2018-2022. However, the quality of the most popular long-text posts was rated as moderate or low, which may mislead patients and the public.}
}
@article{ZHANG2025172,
title = {A Decade Review of Video Compressive Sensing: A Roadmap to Practical Applications},
journal = {Engineering},
volume = {46},
pages = {172-185},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2024.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2095809924005095},
author = {Zhihong Zhang and Siming Zheng and Min Qiu and Guohai Situ and David J. Brady and Qionghai Dai and Jinli Suo and Xin Yuan},
keywords = {Video compressive sensing, Computational imaging, Deep learning, Practical applications},
abstract = {It has been over a decade since the first coded aperture video compressive sensing (CS) system was reported. The underlying principle of this technology is to employ a high-frequency modulator in the optical path to modulate a recorded high-speed scene within one integration time. The superimposed image captured in this manner is modulated and compressed, since multiple modulation patterns are imposed. Following this, reconstruction algorithms are utilized to recover the desired high-speed scene. One leading advantage of video CS is that a single captured measurement can be used to reconstruct a multi-frame video, thereby enabling a low-speed camera to capture high-speed scenes. Inspired by this, a number of variants of video CS systems have been built, mainly using different modulation devices. Meanwhile, in order to obtain high-quality reconstruction videos, many algorithms have been developed, from optimization-based iterative algorithms to deep-learning-based ones. Recently, emerging deep learning methods have been dominant due to their high-speed inference and high-quality reconstruction, highlighting the possibility of deploying video CS in practical applications. Toward this end, this paper reviews the progress that has been achieved in video CS during the past decade. We further analyze the efforts that need to be made—in terms of both hardware and algorithms—to enable real applications. Research gaps are put forward and future directions are summarized to help researchers and engineers working on this topic.}
}
@article{JIANG2025125556,
title = {IFusionQuad: A novel framework for improved aspect-based sentiment quadruple analysis in dialogue contexts with advanced feature integration and contextual CloBlock},
journal = {Expert Systems with Applications},
volume = {261},
pages = {125556},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125556},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424024230},
author = {Haoyu Jiang and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Xu Gu and Peng Lu},
keywords = {Natural language processing, Aspect-based sentiment analysis, Aspect sentiment quadruple extraction, DiaASQ},
abstract = {Aspect-based sentiment analysis (ABSA) represents a crucial field of natural language processing (NLP). It focuses on deriving detailed sentiment insights from textual content. Dialogue-level aspect-based sentiment quadruple extraction (DiaASQ) is specifically concerned with pinpointing target-aspect-opinion-emotion quadruples within conversations. DiaASQ is important in industries like e-commerce, social media analytics, and customer feedback. However, Current ABSA approaches predominantly focus on single-text scenarios, often overlooking the complexities involved in sentiment analysis within conversational contexts. To fill this gap, this paper presents the IFusionQuad model, which is specifically designed for the DiaASQ task. Our contributions include the innovative integration of CloBlock in ABSA, enhancing feature representation with context-aware weights. The InteractiveNet Fusion Module further advances dialogue understanding by aggregating dialogue-specific features such as threads, speakers, and replies. Components such as CloBlock, gating mechanism, and Biaffine attention effectively mitigate data noise issues, improving the relevance of feature extraction. Empirical evaluation on standard datasets demonstrates that the IFusionQuad model outperforms baseline methods, achieving substantial improvements in quadruple extraction. Specifically, our model shows a 6.59% increase in micro F1 and a 7.05% increase in identification F1 for Chinese datasets, and a 2.65% and 4.69% increase in micro F1 and identification F1, respectively, for English datasets. The results clearly demonstrate our IFusionQuad model’s efficacy, which consistently outperforms baseline models across all evaluation datasets on the DiaASQ task.}
}
@article{POENARU2023100389,
title = {Tous soldats de la guerre psychologique ?},
journal = {In Analysis},
volume = {7},
number = {3},
pages = {100389},
year = {2023},
note = {En guerre},
issn = {2542-3606},
doi = {https://doi.org/10.1016/j.inan.2023.100389},
url = {https://www.sciencedirect.com/science/article/pii/S2542360623000598},
author = {Liviu Poenaru},
keywords = {Guerre psychologique, Psychanalyse, Neurosciences, Refoulement, Inconscient économique, Psychological warfare, Psychoanalysis, Neuroscience, Repression, Economic unconscious},
abstract = {Résumé
Contexte
La guerre totale, fractale et transversale (Alliez & Lazzarato, 2016) du cybercapitalisme n’est pas la guerre militaire ou interétatique du temps de Freud et d’Einstein, tout en conservant la part de psychose, d’anéantissement et de sacrifice que questionne Einstein dans sa correspondance avec Freud (Einstein et Freud, 1933). La guerre du capital a lieu dans-pour-contre la population afin de fabriquer l’inconscient économique et des subjectivités consommables-consuméristes-productivistes aptes à s’enrôler dans un système belliqueux indéfini et infini, se déclinant en une multiplicité de guerres qui ne répondent plus à l’équation « paix-crise-guerre-solution ». Le principal problème soulevé par ce contexte est non seulement le caractère foncièrement inconscient de cette dynamique, mais son absence des études cliniques et théoriques qui semblent être en collusion avec la propagande des pouvoirs dominants qui déterminent les pensées dominantes de toutes les époques.
Objectifs
Cette recherche est élaborée autour de quatre principaux objectifs. Le premier est d’alimenter le débat concernant notre participation involontaire (en tant que citoyens et/ou professionnels de la santé) à la guerre totale. Le second objectif est d’apporter des éléments théoriques permettant de mieux comprendre le modus operandi, l’arsenal de la guerre psychologique cybercapitaliste (GPC) ainsi que quelques mécanismes et dynamiques qui s’y attachent. Le troisième objectif souhaite articuler ce qui précède aux données médicales et épidémiologiques qui semblent prouver les ravages provoqués par la GPC. Le quatrième objectif est d’interroger des pistes cliniques permettant d’élaborer les refoulements et les conditionnements de ce contexte.
Méthode
Le cadre théorique de ce travail de nature qualitative et interprétative s’inspire des études critiques, de la psychanalyse, des neurosciences, de la médecine et de l’épidémiologie.
Résultats
Le croisement des diverses perspectives théoriques montrent : l’actualité du programme PSYOP lancé par les États-Unis au déclenchement de la Seconde Guerre mondiale ; l’immobilisation des soldats de la GPC dans la simultanéité de la triade fight-flight-freeze ; le rôle de la neuroculture et de ses modifications du complexe neuro-cognitivo-comportemental et émotionnel (qui ne respectent pas les droits de l’homme) ; l’exploitation de la matrice sociale de la guerre par les réseaux sociaux ; l’injection jusqu’à saturation d’objets « non-self » prédateurs et pathogènes provoquant des défenses psycho-somatiques auto-immunes aberrantes pouvant entraîner des maladies auto-immunes (conçues comme une « guerre contre soi ») ; la pathologisation inquiétante des jeunes générations de plus en plus exposées aux stratégies de la guerre totale.
Interprétation
Les données examinées exigent une adaptation urgente des perspectives cliniques et théoriques pour prendre en considération à la fois les effets sanitaires plus qu’inquiétants ainsi que le refoulement des mécanismes et des conséquences de la guerre totale par les professionnels de la santé. En outre, les cliniciens sont invités à contribuer aux débats publics et politiques dans l’objectif de favoriser l’avènement de nouvelles lois qui protègent efficacement la dignité humaine et les droits de l’homme.
Context
The total, fractal and transversal war (Alliez & Lazzarato, 2016) of cybercapitalism is not the military or interstate war of Freud's and Einstein's time, while preserving the share of psychosis, annihilation and sacrifice that Einstein questions in his correspondence with Freud (Einstein & Freud, 1933). Capital's war takes place in-for-against the population, in order to fabricate the economic unconscious and consumable-consumerist-productivist subjectivities capable of enrolling in an indefinite and infinite warfare system, taking the form of a multiplicity of wars that no longer respond to the “peace-crisis-war-solution” equation. The main problem raised by this context is not only the fundamentally unconscious nature of this dynamic, but its absence from clinical and theoretical studies, which seem to be in collusion with the propaganda of the dominant powers that determine the dominant thinking of all times.
Objectives
This research has four main objectives. The first is to contribute to the debate concerning our involuntary participation (as citizens and/or health professionals) in total war. The second objective is to provide theoretical elements for a better understanding of the modus operandi and arsenal of cybercapitalist psychological warfare (CPW), as well as some of its mechanisms and dynamics. The third objective is to link the foregoing to medical and epidemiological data that seem to prove the ravages caused by CPW. The fourth objective is to explore clinical approaches that could elaborate on the repressions and conditionings of this context.
Method
The theoretical framework of this qualitative and interpretative work is inspired by critical studies, psychoanalysis, neuroscience, medicine, and epidemiology.
Results
The intersection of various theoretical perspectives shows: the relevance of the PSYOP program launched by the United States at the outbreak of the Second World War; the immobilization of CPW soldiers in the simultaneity of the fight-flight-freeze triad; the role of neuroculture and its modifications of the neuro-cognitive-behavioral and emotional complex (which do not respect human rights); the exploitation of the social matrix of war by social networks; the injection to saturation point of predatory and pathogenic “non-self” objects provoking aberrant autoimmune psycho-somatic defenses that can lead to autoimmune diseases (conceived as a “war against self”); the alarming pathologization of younger generations increasingly exposed to total war strategies.
Interpretation
The data reviewed call for an urgent adaptation of clinical and theoretical perspectives to take into account both the more than disturbing health effects and the repression of the mechanisms and consequences of total war by health professionals. In addition, clinicians are invited to contribute to public and political debates, with the aim of promoting the advent of new laws that effectively protect human dignity and human rights.}
}
@article{2023A1,
title = {Table of Contents},
journal = {American Journal of Obstetrics and Gynecology},
volume = {228},
number = {6},
pages = {A1-A6},
year = {2023},
issn = {0002-9378},
doi = {https://doi.org/10.1016/S0002-9378(23)00288-0},
url = {https://www.sciencedirect.com/science/article/pii/S0002937823002880}
}
@article{CHOU2025100107,
title = {Sequential film marketing in China: The study of social platforms and their impacts},
journal = {Digital Business},
volume = {5},
number = {1},
pages = {100107},
year = {2025},
issn = {2666-9544},
doi = {https://doi.org/10.1016/j.digbus.2025.100107},
url = {https://www.sciencedirect.com/science/article/pii/S266695442500002X},
author = {Yuntsai Chou and Wei Lin},
keywords = {Broadcast marketing, Electronic word of mouth, Sequential marketing, Maoyan, Douban, Volume, Valence},
abstract = {Because the Chinese movie market is regarded as the second-largest market worldwide, with digital advertising accounting for more than 50 % of a film's total expenditure, exploring the marketing effects of social platforms on box office performance in China is crucial for Hollywood studios. In this study, we defined a sequential process consisting of two marketing modes: broadcast before theatrical release and electronic word of mouth (eWOM) after release. The broadcast and eWOM modes were proxied by the volume and valence attributes of Maoyan and Douban, the two popular and professional platforms for video entertainment. Volume and valence on Maoyan and Douban were found to influence gross revenue, but volume on Maoyan has the highest predictive power. Marketing on Maoyan is primarily broadcast marketing, whereas that on Douban is only eWOM marketing. Additionally, Hollywood hits depend on sequential marketing to succeed. Distributors should allocate resources to increase the volume on Maoyan before a movie is released and volume and valence on Douban after its release.}
}
@article{YAN2024,
title = {Characteristics, Influence, Prevention, and Control Measures of the Mpox Infodemic: Scoping Review of Infodemiology Studies},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/54874},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124005375},
author = {XiangYu Yan and Zhuo Li and Chunxia Cao and Longxin Huang and Yongjie Li and Xiangbin Meng and Bo Zhang and Maohe Yu and Tian Huang and Jiancheng Chen and Wei Li and Linhui Hao and Dongsheng Huang and Bin Yi and Ming Zhang and Shun Zha and Haijun Yang and Jian Yao and Pengjiang Qian and Chun Kai Leung and Haojun Fan and Pei Jiang and Tiejun Shui},
keywords = {mpox, infodemic, infodemiology, information search volume, content topic, digital health},
abstract = {Background
The mpox pandemic has caused widespread public concern around the world. The spread of misinformation through the internet and social media could lead to an infodemic that poses challenges to mpox control.
Objective
This review aims to summarize mpox-related infodemiology studies to determine the characteristics, influence, prevention, and control measures of the mpox infodemic and propose prospects for future research.
Methods
The scoping review was conducted based on a structured 5-step methodological framework. A comprehensive search for mpox-related infodemiology studies was performed using PubMed, Web of Science, Embase, and Scopus, with searches completed by April 30, 2024. After study selection and data extraction, the main topics of the mpox infodemic were categorized and summarized in 4 aspects, including a trend analysis of online information search volume, content topics of mpox-related online posts and comments, emotional and sentiment characteristics of online content, and prevention and control measures for the mpox infodemic.
Results
A total of 1607 articles were retrieved from the databases according to the keywords, and 61 studies were included in the final analysis. After the World Health Organization’s declaration of an mpox public health emergency of international concern in July 2022, the number of related studies began growing rapidly. Google was the most widely used search engine platform (9/61, 15%), and Twitter was the most used social media app (32/61, 52%) for researchers. Researchers from 33 countries were concerned about mpox infodemic–related topics. Among them, the top 3 countries for article publication were the United States (27 studies), India (9 studies), and the United Kingdom (7 studies). Studies of online information search trends showed that mpox-related online search volume skyrocketed at the beginning of the mpox outbreak, especially when the World Health Organization provided important declarations. There was a large amount of misinformation with negative sentiment and discriminatory and hostile content against gay, bisexual, and other men who have sex with men. Given the characteristics of the mpox infodemic, the studies provided several positive prevention and control measures, including the timely and active publishing of professional, high-quality, and easy-to-understand information online; strengthening surveillance and early warning for the infodemic based on internet data; and taking measures to protect key populations from the harm of the mpox infodemic.
Conclusions
This comprehensive summary of evidence from previous mpox infodemiology studies is valuable for understanding the characteristics of the mpox infodemic and for formulating prevention and control measures. It is essential for researchers and policy makers to establish prediction and early warning approaches and targeted intervention methods for dealing with the mpox infodemic in the future.}
}
@article{SU2025104352,
title = {Images and deep learning in human and urban infrastructure interactions pertinent to sustainable urban studies: Review and perspective},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {136},
pages = {104352},
year = {2025},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2024.104352},
url = {https://www.sciencedirect.com/science/article/pii/S1569843224007106},
author = {Pengxiang Su and Yingwei Yan and Hao Li and Hangbin Wu and Chun Liu and Wei Huang},
keywords = {Data fusion, Image data, Deep learning, Foundation models, SDG, Urban studies},
abstract = {As global urbanization intensifies, conflicts between humans and urban infrastructure increasingly affect socio-economic and environmental sustainability. Recently, using image data and deep learning to investigate the interactions between humans and urban infrastructure has been a popular approach since the fast development of Artificial Intelligence (AI). However, the convergence of data fusion, deep learning, and human-urban infrastructure interaction studies remains underexplored. Here we systematically analyze 3,552 papers from 2013 to 2023 that use image data to investigate the intersection area of data fusion, deep learning, and human and urban infrastructure interactions, aiming to elucidate the relationships among these three key elements. We found that the cross-applications of deep learning in the papers reviewed are not standardized. Given the trend of diversified data fusion, data fusion about real-world dynamic interactions is scarce. Lastly, four potential future research directions are identified: (1) understanding the dynamic and complex interaction processes; (2) exploring the potential and standards for the application of deep learning; (3) focusing more on research concerning cities in the Global South; (4) establishing suitable training datasets for the interaction between urban infrastructures and humans, which may provide valuable insights for applying foundation models in future urban studies.}
}
@article{WANG2025145911,
title = {Rising attention and shifting themes in green supply chain discourse: Evidence from Weibo (2012–2024)},
journal = {Journal of Cleaner Production},
volume = {518},
pages = {145911},
year = {2025},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2025.145911},
url = {https://www.sciencedirect.com/science/article/pii/S0959652625012612},
author = {Shi Wang and Yaxin Hu and Zhan Zhao and Jiacong Cai and Jianxun Yang and Miaomiao Liu and Wen Fang and Zongwei Ma and Jun Bi},
keywords = {Green supply chain, Social media, Topic analysis, Opinion leaders, Industries},
abstract = {Social media have become a crucial platform for public engagement and policy discourse in China, playing an increasingly important role in green supply chain development. This study analyzes 0.24 million original Weibo posts from 2012 to 2024, the longest time series to date, to examine the evolution of green supply chain discourse. We built a data analysis framework to capture spatiotemporal trends, thematic shifts, user heterogeneity across industry contexts. Our findings show that public attention to green supply chains surged after 2020, coinciding with major national strategies such as the Dual Carbon goal and the Beautiful China initiative. We identified 42 real-world social events driving these hot discussions, ranging from early environmental incidents to key policy meetings and releases in later years. The discourse is concentrated in economically developed coastal regions and is mainly shaped by enterprises, government agencies, and media actors. Over time, the thematic focus shifted from environmental protection topics to supply chain management related items, including green production, logistics, and sales. This trend reflects growing interest in practical, system-level approaches to green implementation, highlighting corporate responsibility, policy impact, and supply chain management. Industry-level analysis reveals distinct engagement patterns, with logistics and electronics sectors leading the online conversation. The six key industries also differ in their emphasis on five key topics: green manufacturing, green logistics, economic benefits, policy planning, and environmental protection and low carbon initiative. Our findings provide valuable guidance for tailoring sector-specific policy interventions to promote green supply chain management.}
}
@article{LIU2025108770,
title = {Predicting online group opinions: A hypergraph-enhanced structure deep clustering with LSTM},
journal = {Computers in Human Behavior},
volume = {172},
pages = {108770},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108770},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225002171},
author = {Jiayu Liu and Qingsheng Liu and He Li and Wang Shen and Yongqiang Sun and Lu Yu and Linlin Zhu and Qianru Shi},
keywords = {Online group opinion prediction, Hypergraph social modeling, Cognitive feature representation, Triadic reciprocal determinism, Sentiment dynamics, LSTM, Behavioral data mining},
abstract = {Understanding how group opinions form, shift, and polarize in online networks is critical for maintaining healthy public discourse and addressing the psychological drivers of digital behavior. While recent advances in computational modeling have improved prediction, most methods rely on pairwise graph structures that fail to capture higher-order dynamics and lack integration with behavioral theory. To bridge this gap, we propose a psychologically grounded deep learning framework that combines hypergraph-enhanced structural clustering (HG-SDCN) with long short-term memory (LSTM) networks. Guided by Bandura's triadic reciprocal determinism, we construct a cognitive feature set encompassing environmental context, individual cognition, and behavioral expression—framing social behavior as an emergent property of cognitive–environmental interaction. The HG-SDCN module models complex group relations through hypergraph convolution and dual self-supervision, yielding improved group detection. Subsequently, LSTM is used to capture temporal sentiment trajectories, outperforming traditional ARIMA in predictive accuracy. Beyond prediction, our model offers conceptual insights into the formation and evolution of digital group cognition. By fusing psychological theory with deep learning, this interdisciplinary framework informs the design of socially aware AI systems, platform governance strategies, and interventions to counter online polarization.}
}
@article{YIN2022,
title = {Media Data and Vaccine Hesitancy: Scoping Review},
journal = {JMIR Infodemiology},
volume = {2},
number = {2},
year = {2022},
issn = {2564-1891},
doi = {https://doi.org/10.2196/37300},
url = {https://www.sciencedirect.com/science/article/pii/S2564189122000603},
author = {Jason Dean-Chen Yin},
keywords = {review, social media, traditional media, vaccine hesitancy, natural language processing, digital epidemiology},
abstract = {Background
Media studies are important for vaccine hesitancy research, as they analyze how the media shapes risk perceptions and vaccine uptake. Despite the growth in studies in this field owing to advances in computing and language processing and an expanding social media landscape, no study has consolidated the methodological approaches used to study vaccine hesitancy. Synthesizing this information can better structure and set a precedent for this growing subfield of digital epidemiology.
Objective
This review aimed to identify and illustrate the media platforms and methods used to study vaccine hesitancy and how they build or contribute to the study of the media’s influence on vaccine hesitancy and public health.
Methods
This study followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines. A search was conducted on PubMed and Scopus for any studies that used media data (social media or traditional media), had an outcome related to vaccine sentiment (opinion, uptake, hesitancy, acceptance, or stance), were written in English, and were published after 2010. Studies were screened by only 1 reviewer and extracted for media platform, analysis method, the theoretical models used, and outcomes.
Results
In total, 125 studies were included, of which 71 (56.8%) used traditional research methods and 54 (43.2%) used computational methods. Of the traditional methods, most used content analysis (43/71, 61%) and sentiment analysis (21/71, 30%) to analyze the texts. The most common platforms were newspapers, print media, and web-based news. The computational methods mostly used sentiment analysis (31/54, 57%), topic modeling (18/54, 33%), and network analysis (17/54, 31%). Fewer studies used projections (2/54, 4%) and feature extraction (1/54, 2%). The most common platforms were Twitter and Facebook. Theoretically, most studies were weak. The following five major categories of studies arose: antivaccination themes centered on the distrust of institutions, civil liberties, misinformation, conspiracy theories, and vaccine-specific concerns; provaccination themes centered on ensuring vaccine safety using scientific literature; framing being important and health professionals and personal stories having the largest impact on shaping vaccine opinion; the coverage of vaccination-related data mostly identifying negative vaccine content and revealing deeply fractured vaccine communities and echo chambers; and the public reacting to and focusing on certain signals—in particular cases, deaths, and scandals—which suggests a more volatile period for the spread of information.
Conclusions
The heterogeneity in the use of media to study vaccines can be better consolidated through theoretical grounding. Areas of suggested research include understanding how trust in institutions is associated with vaccine uptake, how misinformation and information signaling influence vaccine uptake, and the evaluation of government communications on vaccine rollouts and vaccine-related events. The review ends with a statement that media data analyses, though groundbreaking in approach, should supplement—not supplant—current practices in public health research.}
}
@article{TRIANTAFYLLOPOULOS2024105642,
title = {Introducing the COVID-19 YouTube (COVYT) speech dataset featuring the same speakers with and without infection},
journal = {Biomedical Signal Processing and Control},
volume = {88},
pages = {105642},
year = {2024},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.105642},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423010753},
author = {Andreas Triantafyllopoulos and Anastasia Semertzidou and Meishu Song and Florian B. Pokorny and Björn W. Schuller},
keywords = {COVID-19, Speech dataset, Speech pathology, Computer audition, Disease detection, Machine learning},
abstract = {More than two years after its outbreak, the COVID-19 pandemic continues to plague medical systems around the world, putting a strain on scarce resources, and claiming human lives. From the very beginning, various AI-based COVID-19 detection and monitoring tools have been pursued in an attempt to stem the tide of infections through timely diagnosis. In particular, computer audition has been suggested as a non-invasive, cost-efficient, and eco-friendly alternative for detecting COVID-19 infections through vocal sounds. However, like all AI methods, also computer audition is heavily dependent on the quantity and quality of available data, and large-scale COVID-19 sound datasets are difficult to acquire – amongst other reasons – due to the sensitive nature of such data. To that end, we introduce the COVYT dataset – a novel COVID-19 dataset collected from public sources containing more than 8 h of speech from 65 speakers. As compared to other existing COVID-19 sound datasets, the unique feature of the COVYT dataset is that it comprises both COVID-19 positive and negative samples from all 65 speakers. We additionally provide an overview acoustic analysis and modelling baselines using different partitioning strategies. We analyse the acoustic manifestation of COVID-19 on the basis of these perfectly speaker characteristic balanced ‘in-the-wild’ data using interpretable audio descriptors, and investigate several classification scenarios that shed light into proper partitioning strategies for a fair speech-based COVID-19 detection.}
}
@article{YANG2025111195,
title = {Data-driven reinforcement learning-based optimization of shared warehouse storage locations},
journal = {Computers & Industrial Engineering},
volume = {206},
pages = {111195},
year = {2025},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2025.111195},
url = {https://www.sciencedirect.com/science/article/pii/S0360835225003419},
author = {Zeyu Yang and Peihan Wen},
keywords = {Small and medium E-commerce enterprises, Shared warehousing, Storage location optimization, Data-driven, Reinforcement learning},
abstract = {With the rise of the streaming media economy driven by short video platforms such as TikTok, small and medium-sized e-commerce enterprises are faced with the dual challenges of high-frequency iteration of user demands and the failure of demand prediction, and the requirement for the dynamism of warehousing resource allocation has significantly increased. Small and medium-sized e-commerce enterprises face high warehousing costs, weak data support, and complex operations in multi-platform placement. This paper offers a data-driven solution for optimizing shared warehouse storage locations to solve these issues. By constructing a framework for data synchronization as well as offline and real-time indicator calculation, the timely update of commodity inventory and order data is achieved, thus improving the efficiency of warehousing operations. In order to get rid of the restrictions on continuous access to computing power and professional knowledge in traditional storage location optimization research, as well as the dependence of deep learning algorithms on large-scale training sets, this paper introduces deep reinforcement learning technology to achieve the optimized allocation of warehousing storage locations. Specifically, based on the traditional DQN (Deep Q-Network) and PPO (Proximal Policy Optimization) algorithm models, a hierarchical strategy and a masking mechanism are proposed to ensure the performance of algorithm solving. Meanwhile, a reasonable state representation and a reward mechanism are designed. In the application verification stage, by classifying the real datasets from open-source platforms to simulate the optimization scenario of shared warehousing among multiple enterprises, the universality and adaptability of the deep reinforcement learning algorithm are verified. By comparing the order picking efficiency under different time granularities, offline and real-time update strategies, the adaptability of the storage location optimization model and mechanism proposed in this paper to the real-time change characteristics of the demands of e-commerce enterprises is verified, ensuring the timely fulfillment of enterprise orders and providing an efficient and flexible optimization solution for storage locations for small and medium-sized e-commerce enterprises.}
}
@article{CHEN2026104521,
title = {Instrumental vs. hedonic Affordances: Examining their impact on repurchase behavior on live commerce platforms through self-determination theory},
journal = {Journal of Retailing and Consumer Services},
volume = {88},
pages = {104521},
year = {2026},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104521},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925003005},
author = {Hongquan Chen and Shuhua Zhang and Bingjia Shao and Yong Zhang and Quanwu Zhao},
keywords = {Live streaming commerce, Repurchase behavior, IT affordances, Swift guanxi, Self-determination theory, Latent dirichlet allocation},
abstract = {As live commerce matures in various regions, platform managers face mounting pressure to retain customers in this competitive landscape. To address this challenge, understanding consumers' repurchase behavior has become crucial. While live commerce's interactive nature provides both instrumental and hedonic affordances, their distinct impacts on repurchase behavior remain underexplored. Drawing on self-determination theory (SDT), this study examines the underlying mechanisms through which affordances influence consumers' repurchase behavior in live commerce by fostering autonomy, relatedness, and swift guanxi. We adopted a mixed-methods approach with two complementary studies: Study 1 employed Latent Dirichlet Allocation (LDA) analysis of open-ended survey responses to identify and categorize live commerce affordances (instrumental vs. hedonic). Study 2 used a three-wave survey to test our hypotheses about these affordances' effects. Our results demonstrate that: (1) Instrumental affordances (guidance shopping, metavoicing, and visibility) enhance repurchase behavior by fostering autonomy; (2) hedonic affordances (visibility, novelty, and co-presence) promote repurchases through strengthened relatedness; (3) interestingly, swift guanxi negatively moderates the effect of autonomy on repurchase behavior, but not that of relatedness. These insights contribute to a deeper understanding of the dimensions and the roles of IT affordances in online marketplaces, offering actionable strategies for live commerce practitioners aiming to bolster customer retention.}
}
@incollection{2025199,
title = {Index},
editor = {Rosanna E. Guadagno},
booktitle = {Psychological Processes in Social Media},
publisher = {Academic Press},
pages = {199-207},
year = {2025},
isbn = {978-0-12-811320-2},
doi = {https://doi.org/10.1016/B978-0-12-811320-2.00014-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128113202000149}
}
@incollection{LIM2025251,
title = {Chapter 17 - Ethics and governance of generative AI},
editor = {David Lee Kuo Chuen and Robert H. Deng},
booktitle = {Handbook of Blockchain, Digital Finance, and Inclusion, Volume 3},
publisher = {Academic Press},
pages = {251-262},
year = {2025},
isbn = {978-0-443-34717-7},
doi = {https://doi.org/10.1016/B978-0-443-34717-7.00001-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443347177000015},
author = {Joseph Lim and Chongwu Xia and Adrian Yeow},
keywords = {Generative AI, Ethics, Governance, Bias, Copyright infringement, Hallucination},
abstract = {Generative AI programs such as ChatGPT have the potential to disrupt how we learn and work. Such programs could bring significant economic benefits by increasing productivity and freeing us from mundane tasks to do creative and satisfying work. Like any new technology, the excitement of new possibilities may blind us to the risks of using or deploying such programs. This chapter discusses the regulations and guidelines relating to AI in general and generative AI in particular. We also discuss some of the issues with generative AI output and the measures to mitigate the risks.}
}
@article{CRAMER2025112322,
title = {Engineering patterns for Trust and Safety on social media platforms: A case study of Mastodon and Diaspora},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112322},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112322},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224003662},
author = {Geoffrey Cramer and William P. {Maxam III} and James C. Davis},
keywords = {Empirical software engineering, Social media platforms, Trust & Safety engineering, Engineering decision-making, Risk},
abstract = {Context:
Trust & Safety (T&S) Engineering is an emerging area of software engineering that mitigates the risks of harmful interactions in online platforms. Numerous studies have explored T&S risks on social media platforms, taxonomizing threats and investigating individual issues. However, there is limited empirical knowledge about engineering efforts to promote T&S.
Methods:
This study examines T&S risks and the engineering patterns to resolve them. We conducted a case study of the two largest decentralized SMPs: Mastodon and Diaspora. These SMPs are open-source, so we analyzed T&S discussions within 60 GitHub issues. We analyzed T&S discussions that took place in their online repository and extracted T&S risks, T&S engineering patterns, and resolution rationales considered by the engineers. We integrate our findings by mapping T&S engineering patterns onto a general model of SMPs, to give SMP engineers a systematic understanding of their T&S risk treatment options.
Results:
T&S issues are a challenge throughout the feature set and lifespan of an SMP. A taxonomy of 12 solution patterns are developed, paving the way for academia and industry to standardize Trust & Safety solutions. We conclude with future directions to study and improve T&S Engineering, spanning software design, decision-making, and validation. We conclude with future directions to study and improve T&S Engineering, spanning software design, decision-making, and validation.}
}
@article{CHO2024103778,
title = {AMPS: Predicting popularity of short-form videos using multi-modal attention mechanisms in social media marketing environments},
journal = {Journal of Retailing and Consumer Services},
volume = {78},
pages = {103778},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103778},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924000742},
author = {Minhwa Cho and Dahye Jeong and Eunil Park},
keywords = {Social media, Popularity prediction, Multi-modal, Deep learning, Short-form content, Attention mechanism},
abstract = {Emerging as a dominant content format amid the shift from television to mobile, short-form videos wield immense potential across diverse domains. However, the scarcity of datasets and established metrics for their popularity evaluation poses a challenge in accurately reflecting their real-world distribution. In response, our work introduces a dataset and pioneers a cumulative distribution function-based standard tailored specifically for short-form videos. Our model, AMPS (Attention-based Multi-modal Popularity prediction model of Short-form videos) is designed to effectively forecast the popularity of these videos. Considering YouTube Shorts, typically confined to under one minute, our research capitalizes on complete video frames for a holistic prediction of popularity. AMPS harnesses BiLSTM with Self-Attention and Co-Attention mechanisms, enabling a deeper understanding of intra-modal and inter-modal relationships across various modalities. Leveraging full video frame representation, our model significantly enhances prediction accuracy. Comprehensive evaluations against baseline models and machine learning algorithms consistently showcase AMPS' superiority in metrics like G-Mean, average F1-score, and Accuracy. Furthermore, when compared with other open social media datasets, our dataset coupled with AMPS consistently outperforms, affirming its robustness and reliability. Additionally, ablation studies underscore the effectiveness of AMPS' architecture and highlight the significance of each modality in predicting popularity.}
}
@article{YAO2024104183,
title = {LCMA-Net: A light cross-modal attention network for streamer re-identification in live video},
journal = {Computer Vision and Image Understanding},
volume = {249},
pages = {104183},
year = {2024},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104183},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224002649},
author = {Jiacheng Yao and Jing Zhang and Hui Zhang and Li Zhuo},
keywords = {Live video, Streamer, Re-identification, Light cross-modal attention network, Light cross-modal pooling attention},
abstract = {With the rapid expansion of the we-media industry, streamers have increasingly incorporated inappropriate content into live videos to attract traffic and pursue interests. Blacklisted streamers often forge their identities or switch platforms to continue streaming, causing significant harm to the online environment. Consequently, streamer re-identification (re-ID) has become of paramount importance. Streamer biometrics in live videos exhibit multimodal characteristics, including voiceprints, faces, and spatiotemporal information, which complement each other. Therefore, we propose a light cross-modal attention network (LCMA-Net) for streamer re-ID in live videos. First, the voiceprint, face, and spatiotemporal features of the streamer are extracted by RawNet-SA, Π-Net, and STDA-ResNeXt3D, respectively. We then design a light cross-modal pooling attention (LCMPA) module, which, combined with a multilayer perceptron (MLP), aligns and concatenates different modality features into multimodal features within the LCMA-Net. Finally, the streamer is re-identified by measuring the similarity between these multimodal features. Five experiments were conducted on the StreamerReID dataset, and the results demonstrated that the proposed method achieved competitive performance. The dataset and code are available at https://github.com/BJUT-AIVBD/LCMA-Net.}
}
@article{MILGRIM2023A13,
title = {Artificial Intelligence’s Leap Into Emergency Medicine: The Promise and Pitfalls of ChatGPT: A look into what ChatGPT and other artificial intelligence applications mean for the future of the field.},
journal = {Annals of Emergency Medicine},
volume = {82},
number = {4},
pages = {A13-A16},
year = {2023},
issn = {0196-0644},
doi = {https://doi.org/10.1016/j.annemergmed.2023.08.378},
url = {https://www.sciencedirect.com/science/article/pii/S0196064423010351},
author = {Fred Milgrim}
}
@article{BIRHANE2024101672,
title = {Large models of what? Mistaking engineering achievements for human linguistic agency},
journal = {Language Sciences},
volume = {106},
pages = {101672},
year = {2024},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2024.101672},
url = {https://www.sciencedirect.com/science/article/pii/S0388000124000615},
author = {Abeba Birhane and Marek McGann},
keywords = {Large language models, Algospeak, Agency, Precariousness, Embodiment, Language, Enaction, Precarity},
abstract = {In this paper we argue that key, often sensational and misleading, claims regarding linguistic capabilities of Large Language Models (LLMs) are based on at least two unfounded assumptions: the assumption of language completeness and the assumption of data completeness. Language completeness assumes that a distinct and complete thing such as “a natural language” exists, the essential characteristics of which can be effectively and comprehensively modelled by an LLM. The assumption of data completeness relies on the belief that a language can be quantified and wholly captured by data. Work within the enactive approach to cognitive science makes clear that, rather than a distinct and complete thing, language is a means or way of acting. Languaging is not the kind of thing that can admit of a complete or comprehensive modelling. From an enactive perspective we identify three key characteristics of enacted language; embodiment, participation, and precariousness, that are absent in LLMs, and likely incompatible in principle with current architectures. We argue that these absences imply that LLMs are not now and cannot in their present form be linguistic agents the way humans are. We illustrate the point in particular through the phenomenon of “algospeak”, a recently described pattern of high-stakes human language activity in heavily controlled online environments. On the basis of these points, we conclude that sensational and misleading claims about LLM agency and capabilities emerge from a deep misconception of both what human language is and what LLMs are.}
}
@incollection{VIOLALEE2025127,
title = {Chapter 10 - Artificial intelligence and public health},
editor = {Chayakrit Krittanawong},
booktitle = {The Digital Doctor},
publisher = {Academic Press},
pages = {127-157},
year = {2025},
isbn = {978-0-443-15728-8},
doi = {https://doi.org/10.1016/B978-0-443-15728-8.00003-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157288000033},
author = {Kyoung A. {Viola Lee} and Bhavya Raj S. Gandhi and Jonathan Alan Tangsrivimol and Hafeez Ul {Hassan Virk} and Adham H. ElSherbini and Zhen Wang and Benjamin S. Glicksberg and Chayakrit Krittanawong},
keywords = {Artificial intelligence, Machine learning, Public health},
abstract = {As artificial intelligence (AI) can potentially enhance health outcomes, illness prevention, diagnosis, and treatment, its use in public health is gaining traction. AI can be used to personalize medical care, make data driven decisions, and expedite healthcare operations. Large datasets may be swiftly and correctly analyzed by AI systems, enabling the discovery of patterns and trends that could be challenging to identify using conventional techniques. The discovery and tracking of disease outbreaks is a notable public health use case of AI-based pattern recognition. AI can assist public health professionals in identifying impending epidemics before they transmit widely by studying social media and online sources. AI can also assist with disease diagnostics. Machine learning (ML) algorithms may analyze large volumes of patients' imaging data, enabling radiologists to identify problems more precisely and quickly. Virtual assistants and AI–powered chatbots can offer individualized care by addressing patient concerns and offering additional guidance and information to patients. These technologies may also assist patients in managing chronic diseases by keeping track of their symptoms and sending out reminders for visits and medications. AI can also be used to pinpoint groups that are most at risk for particular diseases, enabling early interventions to stop the onset of chronic ailments. With AI-driven insights, public health professionals can create targeted interventions like lifestyle coaching or assistance with medication adherence. AI can also aid in improving public health research. Before a drug is approved for usage, AI can help researchers find novel remedies and treatments and anticipate potential side effects. Although there is much potential for integrating AI into public health, there remain several risks including privacy concerns, ethical issues, algorithmic biases, and health inequities.}
}
@article{LEE2023103145,
title = {Cross-platform language learning: A spatial perspective on narratives of language learning across digital platforms},
journal = {System},
volume = {118},
pages = {103145},
year = {2023},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2023.103145},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X23001677},
author = {Yeong-Ju Lee and Peter Roger},
keywords = {Cross-platform language learning, Digital platform, Digital space, Informal digital language learning, Narrative analysis},
abstract = {In the current reality of digital activity, individuals often explore more than one digital platform for language learning. Despite increasing research on the uses of digital platforms for language learning in informal contexts, the cross-platform experience remains in need of elucidation. Drawing on spatial perspectives on digital technology and language learning to conceptualize digital platforms as digital spaces, this study examines the cross-platform experiences of two international students studying English in Australia based on narrative data collected from journal entries, stimulated recall interviews, and social media posts. A narrative approach to the analysis reveals precisely how they organized a variety of digital resources and learning opportunities in online gaming, searching, media-sharing, social networking, and language learning spaces. The learners strategically orchestrated this particular range of digital spaces in alignment with personal interest and need. In accordance with the specific affordances of technological features in these spaces, they created a shared space of interaction in which learning occurred across geographically remote, networked individuals through multimodal language practices. The narrative approach is seen to add analytical power to the issue of space in the sphere of informal digital language learning, in which unique learning pathways for navigating diverse digital spaces are important.}
}
@article{BALLONI2025104454,
title = {Made-In: An immersive human-in-the-loop analytics platform for enhancing creative processes in fashion},
journal = {Computer Vision and Image Understanding},
volume = {260},
pages = {104454},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104454},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225001778},
author = {Emanuele Balloni and Rocco Pietrini and Michele Sasso and Emanuele Frontoni and Marina Paolanti},
keywords = {Human-in-the-loop systems, Immersive analytics, Fashion design, Sustainability, Artificial Intelligence},
abstract = {The fashion industry is undergoing a digital transformation, driven by growing demands for sustainability, personalization and immersive experiences. In this paper, we present Made-In (Multimodal and Collaborative Artificial Intelligence for the Design of Inclusive and Sustainable Fashion): an immersive, human-in-the-loop analytics system designed to support fashion professionals in exploring, comparing and contextualizing product data across digital and social platforms. Unlike generative or simulation-based approaches, Made-In provides creative decision support by aggregating real-world data from luxury brand websites and social media. This enables designers and merchandisers to make informed, context-aware choices. The system comprises three core modules: a 3D configurator for visualizing product assortments; a collection grid interface for the comparative analysis of e-commerce data; and a social media trend detector based on deep learning pipelines for image classification, object detection and color clustering. Two curated datasets, one derived from Instagram and the other from fashion e-tailers, provide the system with analytics. A user study with domain experts confirms the platform’s usability and relevance for trend forecasting, sustainability evaluation and visual merchandising strategy. The results demonstrate that Made-In effectively bridges the gap between data analytics and human creativity in fashion, offering a scalable solution that aligns with EU goals for digital sustainability and inclusivity.}
}
@article{PENG2025107310,
title = {Revisiting face forgery detection towards generalization},
journal = {Neural Networks},
volume = {187},
pages = {107310},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2025.107310},
url = {https://www.sciencedirect.com/science/article/pii/S0893608025001893},
author = {Chunlei Peng and Tao Chen and Decheng Liu and Huiqing Guo and Nannan Wang and Xinbo Gao},
keywords = {Face forgery detection, Generalization ability, Cross dataset evaluation, Damaged image, Literature survey},
abstract = {Face forgery detection aims to distinguish AI generated fake faces with real faces. With the rapid development of face forgery creation algorithms, a large number of generative models have been proposed, which gradually reduce the local distortion phenomenon or the specific frequency traces in these models. At the same time, in the process of face data compression and transmission, distortion phenomenon and specific frequency cues could be eliminated, which brings severe challenges to the performance and generalization ability of face forgery detection. To promote the progress on face forgery detection research towards generalization, we present the first comprehensive overview and in-depth analysis of the generalizable face forgery detection methods. We categorize the target of generalizable face forgery detection into the robustness on novel and unknown forged images, and robustness on damaged low-quality images. We discuss representative generalization strategies including the aspects of data augmentation, multi-source learning, fingerprints detection, feature enhancement, temporal analysis, vision-language detection. We summarize the widely used datasets and the generalization performance of state-of-the-art methods in terms of robustness to novel unknown forgery as well as damaged quality forgery types. Finally, we discuss under-investigated open issues on face forgery detection towards generalization in six directions, including building a new generation of datasets, extracting strong forgery cues, considering identity features in face forgery detection, security and fairness of forgery detectors, the potential of large models in forgery detection and test-time adaptation. Our revisit of face forgery detection towards generalization will help promote the research and application of face forgery detection on real-world unconstrained conditions in the future.}
}
@article{BISCOND2022335,
title = {La mesure de l’usage des réseaux sociaux chez les adolescents: une revue systématique de la littérature},
journal = {L'Encéphale},
volume = {48},
number = {3},
pages = {335-348},
year = {2022},
issn = {0013-7006},
doi = {https://doi.org/10.1016/j.encep.2021.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0013700621002323},
author = {M. Biscond and M. Revranche and M.M. Husky},
keywords = {Réseaux sociaux, Mesure, Utilisation, Adolescents, Revue systématique, Social network sites, Measure, Usage, Adolescents, Systematic review},
abstract = {Résumé
Objectif
L’objectif de cette revue est de faire un état des lieux des différentes méthodes utilisées dans la mesure de l’utilisation des réseaux sociaux chez les adolescents. Cet état des lieux est important, du fait de la nature des réseaux sociaux d’une part, et de la prévalence de leur utilisation chez les jeunes.
Méthodes
Une revue systématique de la littérature selon la méthode PRISMA a permis d’identifier 58 études. Les études devaient évoquer la mesure de l’utilisation des réseaux sociaux et porter uniquement sur des adolescents (11-18 ans).
Résultats
Différentes méthodes sont utilisées pour opérationnaliser l’usage des réseaux sociaux: des méthodes quantitatives avec la mesure de la fréquence et du temps d’utilisation des réseaux sociaux, et une méthode qualitative pour mesurer les différentes activités qu’ils ont sur les réseaux. La plupart des études portent sur les réseaux sociaux en général, sans différencier les différents réseaux.
Conclusions
La présente revue met en lumière la grande variabilité dans les méthodes de mesure de l’usage des réseaux sociaux chez les adolescents. Le recours fréquent à une mesure centrée sur la fréquence d’utilisation sans prendre en compte les spécificités des activités ou des réseaux concernés limite l’investigation de leur impact sur le fonctionnement et le comportement des adolescents. Le développement d’échelles de mesure est nécessaire pour avancer dans ce domaine important de recherche.
Objective
The purpose of this review was to provide an overview of the methods used to measure social network site use among adolescents. Such a review is important given the number and diversity of sites and the prevalence of their use among adolescents.
Methods
A systematic review of the literature was conducted in line with PRISMA guidelines to arrive at an analysis of 58 peer-reviewed studies indexed in PubMed, PsychInfo, or Scopus. To be included in the review, articles had to be peer-reviewed, available in full text, and published in French or English. For inclusion, studies were required to pertain to adolescents aged between 11 and 18 years; to focus on social network site use and indicate how their use was estimated. Studies that simultaneously examined social network sites and general internet use or video games and only provided a combined analysis were excluded. The keywords for the search were: social media use, social media usage, social media misuse, measure, teen, and adolescents.
Results
In the literature, different methods were used to operationalize the use of social network sites: quantitative methods with the measurement of frequency and duration of use of social network sites, and qualitative methods to measure the different activities adolescents engage in on such sites. In this review, 28 articles investigated the use of social media through a measurement of frequency and 22 articles through a measurement of the duration of use. Most of the studies focused on social network sites in general, without specifying which sites in particular were considered by the respondents when answering the question. However, some articles provided cross measures of quantitative and qualitative measurements resulting in the examination of both the frequency of use and the time spent on specific activities on social network sites.
Conclusions
The present review highlights the great diversity in the methods used to measure the use of social network sites among adolescents. The reliance on frequency-based measurements without taking into account the specificities of the activities or sites involved limits the investigation of their impact on adolescent functioning and behaviors. Given the observed discrepancies in the literature concerning the measurement of social network site use among adolescents and their associated biases, the development of specific instruments is needed to advance in this important field of research.}
}
@article{HUANG2025129053,
title = {Artificial intelligence without restriction surpassing human intelligence with probability one: Theoretical insight into secrets of the brain with AI twins of the brain},
journal = {Neurocomputing},
volume = {619},
pages = {129053},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.129053},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224018241},
author = {Guang-Bin Huang and M. Brandon Westover and Eng-King Tan and Haibo Wang and Dongshun Cui and Wei-Ying Ma and Tiantong Wang and Qi He and Haikun Wei and Ning Wang and Qiyuan Tian and Kwok-Yan Lam and Xin Yao and Tien Yin Wong},
keywords = {AI Twins, Neuroscience, Artificial Intelligence, Back Propagation Algorithms, Spiking, Extreme Learning Machines, Cellular AI},
abstract = {Artificial Intelligence (AI) has apparently become one of the most important techniques discovered by humans in history while the human brain is widely recognized as one of the most complex systems in the universe. One fundamental critical question which would affect human sustainability remains open: Will artificial intelligence (AI) evolve to surpass human intelligence in the future? This paper shows that in theory new AI twins with fresh cellular level of AI techniques for neuroscience could approximate the brain and its functioning systems (e.g. perception and cognition functions) with any expected small error and AI without restrictions could surpass human intelligence with probability one in the end. This paper indirectly proves the validity of the conjecture made by Frank Rosenblatt 70 years ago about the potential capabilities of AI, especially in the realm of artificial neural networks. This paper also gives the answer to the two widely discussed fundamental questions: 1) whether AI could have potentials of discovering new principles in nature; 2) whether error backpropagation (BP) algorithm commonly and efficiently used in tuning parameters in AI applications is also adopted in the brain. Intelligence is just one of fortuitous but sophisticated creations of the nature which has not been fully discovered. Like mathematics and physics, with no restrictions artificial intelligence would lead to a new subject with its self-contained systems and principles. We anticipate that this paper opens new doors for 1) AI twins and other AI techniques to be used in cellular level of efficient neuroscience dynamic analysis, functioning analysis of the brain and brain illness solutions; 2) new worldwide collaborative scheme for interdisciplinary teams concurrently working on and modelling different types of neurons and synapses and different level of functioning subsystems of the brain with AI techniques; 3) development of low energy of AI techniques with the aid of fundamental neuroscience properties; and 4) new controllable, explainable and safe AI techniques with reasoning capabilities of discovering principles in nature.}
}
@article{WAN2025106077,
title = {An emotion-behavior perspective of understanding public and government responses to rainstorm disasters: A case study of Zhengzhou Rainstorm in China},
journal = {Cities},
volume = {164},
pages = {106077},
year = {2025},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2025.106077},
url = {https://www.sciencedirect.com/science/article/pii/S0264275125003774},
author = {Xin Wan and Xinyu Ding and Sijia Liu and Yan Zhang and Xinyi Luo and Jingfeng Yuan and Changzheng Zhang},
keywords = {Rainstorm disasters, Social media, Public emotions, Public behaviors, Government strategies, Evolution patterns},
abstract = {Understanding public emotional and behavioral response is critical for adaptive disaster management. Integrating natural language processing (NLP), econometric, and social psychological models, this study establishes an emotion-behavior framework to analyze multidimensional interactions between public and government responses. Using social media data from “7.20” Zhengzhou Rainstorm, we reveal distinct emotional drivers: social support offering (SSO) thrived on positive emotions, yet help seeking (HSK) correlated with fear, deviance (DEV) driven by anger, and avoidance & venting (A&V) sustained by multiple negative emotions. Public behavior patterns shifted from pre-disaster instrumental aid to fear-driven avoidance coupled with emotional aid arising during crises, eventually evolving into intensified post-disaster resource competition. Government strategies show asymmetric impacts on these behaviors. Most strategies yielded instantly positive effects on SSO, while all strategies responded passively to HSK and some had time-lag or limited effects in mitigating A&V and DEV. The findings advocate integrating psychosocial factors into emergency strategies, with emphases on prioritizing proactive community engagement to sustain social cohesion, embedding psychological support mechanisms, and enforcing transparent resource governance to redirect emotions like fear, anger, and sadness. This approach advances urban resilience by highlighting that adaptive climate defenses requires aligning policy interventions with community-driven collaboration and emotion-driven public behavioral dynamics.}
}
@article{LIU2025125642,
title = {Vision-based human action quality assessment: A systematic review},
journal = {Expert Systems with Applications},
volume = {263},
pages = {125642},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125642},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424025090},
author = {Jiang Liu and Huasheng Wang and Katarzyna Stawarz and Shiyin Li and Yao Fu and Hantao Liu},
keywords = {Action quality assessment, Computer vision, Human action evaluation, Deep learning},
abstract = {Human Action Quality Assessment (AQA), which aims to automatically evaluate the performance of actions executed by humans, is an emerging field of human action analysis. Although many review articles have been conducted for human action analysis fields such as action recognition and action prediction, there is a lack of up-to-date and systematic reviews related to AQA. This paper aims to provide a systematic literature review of existing papers on vision-based human AQA. This systematic review was rigorously conducted following the PRISMA guideline through the databases of Scopus, IEEE Xplore, and Web of Science in July 2024. Ninety-six research articles were selected for the final analysis after applying inclusion and exclusion criteria. This review presents an overview of various aspects of AQA, including existing applications, data acquisition methods, public datasets, state-of-the-art methods and evaluation metrics. We observe an increase in the number of studies in AQA since 2019, primarily due to the advent of deep learning methods and motion capture devices. We categorize these AQA methods into skeleton-based and video-based methods based on the data modality used. There are different evaluation metrics for various AQA tasks. SRC is the most commonly used evaluation metric, with fifty-six out of ninety-six selected papers using it to evaluate their models. Sports event scoring, surgical skill evaluation and rehabilitation assessment are the most popular three scenarios in this direction based on existing papers and there are more new scenarios being explored such as piano skill assessment. Furthermore, the existing challenges and future research directions are provided, which can be a helpful guide for researchers to explore AQA.}
}
@article{BAYOUDH2024102217,
title = {A survey of multimodal hybrid deep learning for computer vision: Architectures, applications, trends, and challenges},
journal = {Information Fusion},
volume = {105},
pages = {102217},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.102217},
url = {https://www.sciencedirect.com/science/article/pii/S156625352300533X},
author = {Khaled Bayoudh},
keywords = {Applications, Computer vision, Multimodal hybrid deep learning, Sensory modalities},
abstract = {In recent years, deep learning algorithms have rapidly revolutionized artificial intelligence, particularly machine learning, enabling researchers and practitioners to extend previously hand-crafted feature extraction procedures. In particular, deep learning uses adaptive learning processes to learn more complex and informative patterns from datasets of varying sizes. With the increasing availability of multimodal data streams and recent advances in deep learning algorithms, multimodal deep learning is on the rise. This requires the development of complex models that can process and analyze multimodal information in a consistent manner. However, unstructured data can come in many different forms (also known as modalities). Extracting relevant features from this data remains an ambitious goal for deep learning researchers. According to the literature, most deep learning systems consist of a single architecture (i.e., standalone deep learning). When two or more deep learning architectures are combined over multiple sensory modalities, the result is called a multimodal hybrid deep learning model. Since this research direction has received much attention in the field of deep learning, the purpose of this survey is to provide a broader overview of the topic. In this paper, we provide a comprehensive review of recent advances in multimodal hybrid deep learning, including a thorough analysis of the most commonly developed hybrid architectures. In particular, one of the main challenges in multimodal hybrid analysis is the ability of these architectures to systematically integrate cross-modal features in hybrid designs. Therefore, we propose a generic framework for multimodal hybrid learning that focuses mainly on fusion methods. We also identify trends and challenges in multimodal hybrid learning and provide insights and directions for future research. Our findings show that multimodal hybrid learning can perform well in a variety of challenging computer vision applications and tasks.}
}
@article{ABBAS2024124260,
title = {Unmasking deepfakes: A systematic review of deepfake detection and generation techniques using artificial intelligence},
journal = {Expert Systems with Applications},
volume = {252},
pages = {124260},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124260},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424011266},
author = {Fakhar Abbas and Araz Taeihagh},
keywords = {Deep learning, Deepfakes, Detection and generation, Artificial Intelligence (AI), Policy recommendations, Literature review},
abstract = {Due to the fast spread of data through digital media, individuals and societies must assess the reliability of information. Deepfakes are not a novel idea but they are now a widespread phenomenon. The impact of deepfakes and disinformation can range from infuriating individuals to affecting and misleading entire societies and even nations. There are several ways to detect and generate deepfakes online. By conducting a systematic literature analysis, in this study we explore automatic key detection and generation methods, frameworks, algorithms, and tools for identifying deepfakes (audio, images, and videos), and how these approaches can be employed within different situations to counter the spread of deepfakes and the generation of disinformation. Moreover, we explore state-of-the-art frameworks related to deepfakes to understand how emerging machine learning and deep learning approaches affect online disinformation. We also highlight practical challenges and trends in implementing policies to counter deepfakes. Finally, we provide policy recommendations based on analyzing how emerging artificial intelligence (AI) techniques can be employed to detect and generate deepfakes online. This study benefits the community and readers by providing a better understanding of recent developments in deepfake detection and generation frameworks. The study also sheds a light on the potential of AI in relation to deepfakes.}
}
@article{HERMSEN2023,
title = {The Effect of Social Networks on Active Living in Adolescents: Qualitative Focus Group Study},
journal = {JMIR Formative Research},
volume = {7},
year = {2023},
issn = {2561-326X},
doi = {https://doi.org/10.2196/46350},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X23004808},
author = {Sander Hermsen and Femke {Van Abswoude} and Bert Steenbergen},
keywords = {active living, adolescents, physical activity, digital health, mobile phone},
abstract = {Background
Participation in organized sports and other forms of active living have important health benefits in adolescence and adulthood. Unfortunately, the transition to secondary school has been shown to be a barrier to participation. Social networks can play important roles in activating adolescents, and information and communication technology (ICT) interventions can augment this role. To date, there are few insights into what adolescents themselves think and feel about barriers to and motivators for active living, the role of their social networks in active living, and the potential of ICT for physical activity (PA).
Objective
This study aimed to gather insights into the perspectives of adolescents aged 12 to 14 years on active living and sports participation, motivators and demotivators for active living, and the potential roles of their social network and of ICT.
Methods
A total of 26 adolescents aged 12 to 14 years from different levels of Dutch secondary schools participated in 1 of 5 semistructured focus group interviews, in which they talked about sports and PA, their social networks, their ICT use, and the role of social networks and ICT in PA. All interviews were transcribed and analyzed using a thematic qualitative approach.
Results
The study showed that all participants were physically active, although the transition to secondary school made this difficult, mostly because of time constraints. Participants saw positive physical and mental health effects as important benefits of active living. They regarded social benefits as strong motivators for active living: being together, making friends, and having fun together. However, the social network could also demotivate through negative peer judgment and negative feedback. Participants were willing to share their own positive experiences and hear about those from close peers and friends but would not share their own (and were not interested in others’) negative experiences or personal information. Participants were mainly interested in descriptive norms set by others and obtained inspiration from others for PA. With respect to using ICT for active living, participants stated a preference for social challenges among friends, personalized feedback, goals, activities, and rewards. Competition was seen as less important or even unattractive. If mentioned, participants felt that this should be with friends, or peers of a similar level, with fun being more important than the competition itself.
Conclusions
This study shows that adolescents feel that their social network is and can be a strong driver of active living. They are willing to use ICT-based solutions that make use of social networks for PA as long as these solutions involve their current (close) network and use an approach based on being together and having fun together.}
}
@article{ZHANG2026111967,
title = {M2Beats 2.0: When motion meets beats in short-form videos twice},
journal = {Pattern Recognition},
volume = {171},
pages = {111967},
year = {2026},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2025.111967},
url = {https://www.sciencedirect.com/science/article/pii/S0031320325006272},
author = {Yongchang Zhang and Ao Lv and Shuai He and Haiyang Zhang and Anlong Ming},
keywords = {Motion rhythm extraction, Motion rhythm enhancement, Human feedback, Motion and music, Short-form videos},
abstract = {In recent years, short-form videos have gained popularity and the editing of these videos, particularly when motion is synchronized with music, is highly favored due to its beat-matching effect. However, detecting motion rhythm poses a significant challenge as it is influenced by multifaceted factors that make it difficult to define using explicit rules. Traditional methods, which attempt to define motion rhythm through predefined criteria, frequently produce unsatisfactory results. Conversely, learning-based methods can extract motion rhythm without relying on explicit rules but necessitate high-quality datasets. Regrettably, motion rhythm is closely tied to human subjective perception and has not been accurately annotated: existing datasets either simply substitute music rhythm for motion rhythm, which are not equivalent, or leverage the consistency between music and motion to annotate motion rhythm while this process does not incorporate human feedback. Moreover, limbs play a crucial role in conveying motion rhythm; however, existing methods primarily depend on generic graph convolution or attention mechanisms to extract features only at the whole-body level and are insufficient for capturing the detailed movements of the limbs, which causes poor performance in limb-dominant movements. To address these challenges, we propose a new dataset and a novel method: (i) Dataset: We construct a motion rhythm dataset, AIST-M2B 2.0, integrating the human feedback mechanism into the automated annotation pipeline to improve the quality of the dataset; additionally, we employ soft labels rather than binary labels to achieve more efficient training. (ii) Method: We propose M2BNet 2.0, a novel network tailored for rhythm, which includes a hierarchical graph convolution module that captures the rhythm expression at the whole-body, inter-limb, and intra-limb levels; furthermore, we design a strategy for enhancing the motion rhythm in short-form videos. Compared to the latest work, our approach improves the F-score and PR-AUC metrics by 6.6% and 9.8% on the AIST-M2B dataset, and by 9.8% and 7.4% on the AIST-M2B 2.0 dataset, respectively. The dataset and code are available at https://zyc-cver.github.io/M2Beats-2.0/.}
}
@article{LIU2023118926,
title = {REDRL: A review-enhanced Deep Reinforcement Learning model for interactive recommendation},
journal = {Expert Systems with Applications},
volume = {213},
pages = {118926},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118926},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422019443},
author = {Huiting Liu and Kun Cai and Peipei Li and Cheng Qian and Peng Zhao and Xindong Wu},
keywords = {Recommender system, Deep reinforcement learning, Review analysis},
abstract = {Recent advances in interactive recommender systems (IRS) have received wide attention due to its flexible recommendation strategy and optimization for users’ long-term utility. Considering this interaction paradigm of IRS, researchers have made some attempts to incorporate reinforcement learning (RL) models into IRS, because of the excellent ability of RL in long-term optimizing and decision making. However, data sparsity is an intractable problem most IRS urgently need to address. Although a small amount of work has exploited reviews to address data sparsity, they ignored the varying importance of items for modeling the user. In addition, most existing RL-based approaches suffer from decision-making difficulties when the action space becomes large. To solve above problems, in this work, we present a Review-enhanced Deep Reinforcement Learning model (REDRL) for interactive recommendation. Specifically, we utilize text reviews, combined with a pretrained review representation model to acquire item review-enhanced embedding representations. Then we formalize the recommendation problem as a Markov Decision Process (MDP), and exploit deep reinforcement learning (DRL) to model the interactive recommendation. Notably, we introduce a multi-head self-attention technique to capture distinct importance of various items in the sequence behavior, which is overlooked by existing work when modeling the user preference. In this way, we can model long-term dynamic preferences of users accurately and discriminately for comprehensive interactive recommendation. Moreover, we subtly combine the semantic structure information in the user–item bipartite graph with meta-paths in heterogeneous information networks (HIN), to filter some irrelevant items and obtain candidate items dynamically. By this means, the size of the discrete action space is effectively reduced from a new anger. The experimental results based on three benchmark datasets demonstrate the efficiency of our method with significant improvement over state-of-the-art.}
}
@article{ZHANG2024128455,
title = {Perception study of urban green spaces in Singapore urban parks: Spatio-temporal evaluation and the relationship with land cover},
journal = {Urban Forestry & Urban Greening},
volume = {99},
pages = {128455},
year = {2024},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2024.128455},
url = {https://www.sciencedirect.com/science/article/pii/S161886672400253X},
author = {Wenting Zhang and Yuxin Su},
keywords = {Land cover, Landscape perception, Large language model, Sentiment analysis, Urban green spaces},
abstract = {In the current era of increasing urbanization, urban green spaces play a crucial role in enhancing human well-being. However, quantifying public perceptions from text data at spatio-temporal scales remains challenging, and the relationship between urban green space perception and spatial-physical attributes requires further exploration. This study systematically examines public perceptions of urban green spaces within Singapore's urban parks from 2018 to 2022. Utilizing Twitter data, it applies large language models to conduct textual content analysis related to urban green space. The findings reveal a positive trend, with individuals expressing favorable perceptions and satisfaction towards urban green spaces in Singapore. Specifically, this study demonstrates that people's perceptions of urban green spaces are influenced by vegetation density. Higher vegetation density heightens people's awareness of spatial presence, while shrub and grassland may lead to neglect of urban green spaces as individuals focus more on themselves. Additionally, due to the spatial heterogeneity of the area, there is no clear correlation between all land covers and public satisfaction with urban green spaces in Singapore. The results also indicate a significant decrease in public perception in 2020, followed by a subsequent recovery. This fluctuation is attributed to the substantial impact of the COVID-19 pandemic, suggesting that external socio-political, economic, and public health events can impact public green space needs and spatial perceptions. In conclusion, this study contributes to the understanding of urban green spaces by effectively analyzing textual content extracted from social media data using large language models. The insights gained contribute valuable to the following discussions regarding the planning and design of urban green spaces and urban parks.}
}
@article{PILAR2023118817,
title = {A novel flexible feature extraction algorithm for Spanish tweet sentiment analysis based on the context of words},
journal = {Expert Systems with Applications},
volume = {212},
pages = {118817},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118817},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422018358},
author = {García-Díaz Pilar and Sánchez-Berriel Isabel and Pontiel-Martín Diego and González-Ávila {José Luis}},
keywords = {Sentiment analysis, Context semantics, Grouping Genetic Algorithm, Flexible feature extraction, Twitter},
abstract = {A tweet polarity classifier is presented with four categories: positive, neutral, negative and no opinion. A grouping genetic algorithm performs feature extraction on the reviews. The feature definition is based on entropy and semantic context described as the relative positions between words. The feature selection is flexible because it is customized to each word studied in the reviews. The algorithm has been applied with two corpuses written in Spanish, of 3,413 tweets and more than 63,000 tweets, to classify an evaluation set of 1,899 reviews. The results were evaluated by the metrics M−F1 and accuracy. The algorithm has improved the results of both metrics and on both corpuses compared to the previous literature works, achieving a M−F1 of 0.640 and an accuracy of 0.689. The flexibility property in feature extraction has been the major qualitative improvement of the classifier.}
}
@article{FANNING2024103,
title = {Improving Readability and Automating Content Analysis of Plastic Surgery Webpages With ChatGPT},
journal = {Journal of Surgical Research},
volume = {299},
pages = {103-111},
year = {2024},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2024.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0022480424001756},
author = {James E. Fanning and Maria J. Escobar-Domingo and Jose Foppiani and Daniela Lee and Amitai S. Miller and Jeffrey E. Janis and Bernard T. Lee},
keywords = {Artificial intelligence, Machine learning, Patient education, Readability},
abstract = {Introduction
The quality and readability of online health information are sometimes suboptimal, reducing their usefulness to patients. Manual evaluation of online medical information is time-consuming and error-prone. This study automates content analysis and readability improvement of private-practice plastic surgery webpages using ChatGPT.
Methods
The first 70 Google search results of “breast implant size factors” and “breast implant size decision” were screened. ChatGPT 3.5 and 4.0 were utilized with two prompts (1: general, 2: specific) to automate content analysis and rewrite webpages with improved readability. ChatGPT content analysis outputs were classified as hallucination (false positive), accurate (true positive or true negative), or omission (false negative) using human-rated scores as a benchmark. Six readability metric scores of original and revised webpage texts were compared.
Results
Seventy-five webpages were included. Significant improvements were achieved from baseline in six readability metric scores using a specific-instruction prompt with ChatGPT 3.5 (all P ≤ 0.05). No further improvements in readability scores were achieved with ChatGPT 4.0. Rates of hallucination, accuracy, and omission in ChatGPT content scoring varied widely between decision-making factors. Compared to ChatGPT 3.5, average accuracy rates increased while omission rates decreased with ChatGPT 4.0 content analysis output.
Conclusions
ChatGPT offers an innovative approach to enhancing the quality of online medical information and expanding the capabilities of plastic surgery research and practice. Automation of content analysis is limited by ChatGPT 3.5's high omission rates and ChatGPT 4.0's high hallucination rates. Our results also underscore the importance of iterative prompt design to optimize ChatGPT performance in research tasks.}
}
@article{BERTAGLIA2025100298,
title = {Influencer self-disclosure practices on Instagram: A multi-country longitudinal study},
journal = {Online Social Networks and Media},
volume = {45},
pages = {100298},
year = {2025},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2024.100298},
url = {https://www.sciencedirect.com/science/article/pii/S2468696424000235},
author = {Thales Bertaglia and Catalina Goanta and Gerasimos Spanakis and Adriana Iamnitchi},
keywords = {Influencer marketing, Advertising disclosure, Instagram, Self-disclosure practices, Legal compliance},
abstract = {This paper presents a longitudinal study of more than ten years of activity on Instagram consisting of over a million posts by 400 content creators from four countries: the US, Brazil, Netherlands and Germany. Our study shows differences in the professionalisation of content monetisation between countries, yet consistent patterns; significant differences in the frequency of posts yet similar user engagement trends; and significant differences in the disclosure of sponsored content in some countries, with a direct connection with national legislation. We analyse shifts in marketing strategies due to legislative and platform feature changes, focusing on how content creators adapt disclosure methods to different legal environments. We also analyse the impact of disclosures and sponsored posts on engagement and conclude that, although sponsored posts have lower engagement on average, properly disclosing ads does not reduce engagement further. Our observations stress the importance of disclosure compliance and can guide authorities in developing and monitoring them more effectively.}
}
@article{WOODRING2024103997,
title = {Enhancing privacy policy comprehension through Privacify: A user-centric approach using advanced language models},
journal = {Computers & Security},
volume = {145},
pages = {103997},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103997},
url = {https://www.sciencedirect.com/science/article/pii/S016740482400302X},
author = {Justin Woodring and Katherine Perez and Aisha Ali-Gombe},
keywords = {Privacy, LLM, Privacy policy, Summarization, Machine learning, Software development, NLP, GPT},
abstract = {As the digital age advances, the collection, usage, and dissemination of personal data have become critical concerns for users, regulators, and the cybersecurity community. Questions surrounding the extent of identifiable data collection, its usage, sharing, selling, and the mechanisms of consent are increasingly central to discussions on user data privacy. These issues highlight the need for effective management and comprehension of privacy policies. To this end, this paper introduces Privacify— a production-ready web application designed to enhance the accessibility and understandability of privacy policies, thus empowering users to make more informed decisions about their data. At its backend, Privacify leverages a combination of text segmentation, summarization using Large Language Model (LLM), and map-reduce technologies to facilitate BASE analysis for single-document insights and WRT and REV for comprehensive cross-document analysis. Designed with a user-centric approach, Privacify features an intuitive interface that presents all relevant user privacy information in easy-to-understand language, complete with a detailed explainability component. This design not only simplifies privacy policies but also aids users in effortlessly navigating complex privacy terms, significantly boosting their ability to protect and manage their personal information. Our evaluation employs robust methodologies, including reliability and accuracy assessments, alongside rigorous functionality verification through ROUGE metrics and human analysis, validating the system’s efficacy and performance. Privacify’s architecture promotes scalability, replicability, and seamless deployment, advancing the domain of user data protection through improved privacy comprehension.}
}
@article{FERNANDEZLAGOS2025111664,
title = {PAVEN: A Perceptual Algorithm for Versatile video Encoding using Neural networks},
journal = {Engineering Applications of Artificial Intelligence},
volume = {159},
pages = {111664},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111664},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625016665},
author = {Pablo Fernández-Lagos and Belén Ríos and Hari Kalva and Gabriel Cebrián-Márquez and Guillermo Vigueras and Antonio Jesus Diaz-Honrubia},
keywords = {Neural networks, Perceptual coding, Video coding, Versatile video coding, Subjective quality},
abstract = {This work introduces the Perceptual Algorithm for Versatile video Encoding using Neural Networks (PAVEN), a subjective video coding algorithm designed to reduce the bit rate in videos encoded with the Versatile Video Coding (VVC) standard without compromising subjective video quality. The algorithm uses a deep learning model specifically trained by the authors to account for the specific characteristics of video signals. The trained model outperforms others in the literature by more accurately identifying areas of the frames where viewers are most likely to focus their attention. The output of the deep learning model is further processed to merge all disjoint areas and adapt the result to the Coding Tree Unit (CTU) size in VVC, allowing for greater compression in less important areas. The results show an average reduction in bit rate of 7% while maintaining the same subjective video quality, validated through viewer interviews using the Mean Opinion Score (MOS) metric.}
}
@article{HE2023119713,
title = {Meta-path based graph contrastive learning for micro-video recommendation},
journal = {Expert Systems with Applications},
volume = {222},
pages = {119713},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.119713},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423002142},
author = {Ying He and Gongqing Wu and Desheng Cai and Xuegang Hu},
keywords = {Micro-video recommendation, Graph neural networks, Contrastive learning},
abstract = {Nowadays, micro-video sharing platforms have become popular tools for people creating and viewing micro-videos in daily life. The micro-video recommendation task has attracted significant attention from researchers, recently. The key to a high-quality micro-video recommendation system is learning meaningful user and micro-video representations. Recently, many graph neural networks (GNNs) are proposed to learn node representations in graphs, which could be useful for recommendation tasks. However, we argue that directly utilizing existing GNNs in micro-video recommendations is ill-posed. The reasons are: (1) most previous GNNs fail to capture the heterogeneity of heterogeneous graphs since they are designed for homogeneous graphs; (2) they overemphasize node proximity and may hurt the robustness of node embeddings. In contrast to previous work, we propose a meta-path-based graph contrastive learning network (MPGCL) that learns more meaningful user and video embeddings for recommendation. Specifically, we yield homogeneous graphs for user type and video type to better capture heterogeneity based on a well-designed meta-path-based random walk strategy. Furthermore, to learn more robust node embeddings that are less sensitive to noise, we propose a graph contrastive learning network on different types of homogeneous graphs, which maximizes the consistency between graph representations with different views. We do extensive experiments on three real-world datasets and the results show that our model can learn more meaningful embeddings for users and micro-videos and outperforms the strong baselines.}
}
@article{HU2025130077,
title = {Graph traverse reference network for sign language corpus retrieval in the wild},
journal = {Neurocomputing},
volume = {637},
pages = {130077},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130077},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225007490},
author = {Kun Hu and Fengxiang He and Adam Schembri and Zhiyong Wang},
keywords = {Sign language retrieval, Deep learning, Visual embedding, Graph learning},
abstract = {Sign languages are the primary languages of the deaf community as well as hearing individuals who are unable to speak, which engage the visual-manual modality to convey meanings. In recent years, there has been an explosive growth of sign language videos available from video streaming and social media service platforms. Given the size of these corpora, sign language users often face significant challenges in effectively acquiring the information they need. Therefore, we propose a novel deep learning architecture, namely Graph Traverse Reference Network (GTRN), allowing visual signing queries to retrieve relevant sign language videos (documents) from a large corpus. GTRN introduces a traverse graph, which provides coarse-to-fine reference information in a hierarchical manner from frame-level to body-part-level observations. A reference-based attention is devised to obtain the embedding for a visual input of each level, which allows the computations to be allocated and processed at difference locations regarding local devices and central servers. A contrastive learning strategy optimizes GTRN in pursuit of a joint latent space for the queries and the documents by their meanings. Moreover, GTRN is compatible to leverage existing general visual representation foundation models, by which their resulted embeddings are used as the frame-level reference of GTRN. To the best of our knowledge, it is one of the first studies on using visual signing queries for retrieving sign language videos in a real-world setting and comprehensive experiments were conducted which demonstrated the effectiveness of our proposed method.}
}
@article{GU2024111841,
title = {Modeling multi-behavior sequence via HyperGRU contrastive network for micro-video recommendation},
journal = {Knowledge-Based Systems},
volume = {295},
pages = {111841},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111841},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124004751},
author = {Pan Gu and Haiyang Hu and Guandong Xu},
keywords = {Micro-video recommendation, Multi-behavior recommendation, Contrastive learning, Recurrent neural network},
abstract = {Micro-video prediction with the multi-behavior sequence remains a challenging task for current recommendation systems. Existing approaches tend to model each individual behavior sequence separately to obtain multi-level user preferences. However, they neglected the semantic correlations among different types of behaviors, that is, the ordinal rankings of user satisfaction conveyed through multi-type actions. Additionally, they failed to capture the temporal dependencies among a user’s historical multi-behavioral sequence, especially the dependencies between positive and negative behaviors. To address this issue, we propose a novel HyperGRU contrastive network to model the multi-behavior sequence for micro-video recommendation. We first propose a concept of hypernode to capture semantic dependencies among multiple behaviors. Based on the hypernode, we then design a novel HyperGRU network to extract positive and negative interests from users’ temporal multi-behavior sequence. Beyond that, we train the HyperGRU under the guidance of a contrastive learning framework to make the positive and negative interests discriminating. Technically, we assign labels for the positive and negative interests by modeling the “skip” and “click” sub-sequences separately. Subsequently, contrastive tasks are conducted to encourage the interest representations to be closer to their associated labels than the opposite labels. Finally, the system makes predictions with the input of the disentangled preferences. The experiments conducted on three public real-world datasets demonstrate the effectiveness of our model.}
}
@article{CONTRI2026106461,
title = {Mayors, Facebook and air pollution: A missed opportunity for citizen engagement?},
journal = {Cities},
volume = {168},
pages = {106461},
year = {2026},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2025.106461},
url = {https://www.sciencedirect.com/science/article/pii/S0264275125007620},
author = {Marco Contri and Valentina Marchi and Silvia Fissi and Elena Gori},
keywords = {Citizen engagement, Public engagement, Facebook, Transport policies, Air quality, Italy},
abstract = {According to the World Health Organisation, nearly the entire global population is still exposed to unsafe levels of air pollution. Road transportation is a significant contributor to this issue, prompting supranational and national authorities to implement policies aimed at reducing transport-related emissions. While evidence shows that such policies can significantly improve air quality, their success largely depends on effective citizen engagement. In this context, social media platforms have become one of the most widespread tools for citizen engagement in recent decades. Against this backdrop, this study explores whether the mayors of the Italian regional capitals use their Facebook pages to engage citizens in transport policies aimed at improving air quality and examines the levels of citizen engagement with posts on this topic. Using a dataset of 5009 Facebook posts published by mayors over one year, this study employed a zero-shot classification approach to identify and categorise posts about transport policies. An engagement matrix was then used to explore the levels of citizen engagement achieved by each Facebook page regarding these policies. Our findings lead to three main conclusions. First, despite the significant impact of transportation on human health, mayors devoted only a small number of their posts to transport policies. Second, while the levels of citizen engagement varied notably across pages, mayors primarily used their pages for public communication rather than fostering public participation. Finally, an intriguing pattern emerged between engagement levels and cities' air quality, suggesting a potential link between them and environmental conditions.}
}
@article{MESKO2023,
title = {The ChatGPT (Generative Artificial Intelligence) Revolution Has Made Artificial Intelligence Approachable for Medical Professionals},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48392},
url = {https://www.sciencedirect.com/science/article/pii/S143888712300465X},
author = {Bertalan Mesko},
keywords = {artificial intelligence, digital health, future, technology, ChatGPT, medical practice, large language model, language model, generative, conversational agent, conversation agents, chatbot, generated text, computer generated, medical education, continuing education, professional development, curriculum, curricula},
abstract = {In November 2022, OpenAI publicly launched its large language model (LLM), ChatGPT, and reached the milestone of having over 100 million users in only 2 months. LLMs have been shown to be useful in a myriad of health care–related tasks and processes. In this paper, I argue that attention to, public access to, and debate about LLMs have initiated a wave of products and services using generative artificial intelligence (AI), which had previously found it hard to attract physicians. This paper describes what AI tools have become available since the beginning of the ChatGPT revolution and contemplates how it they might change physicians’ perceptions about this breakthrough technology.}
}
@article{ZANG2023,
title = {Applications of Social Media and Digital Technologies in COVID-19 Vaccination: Scoping Review},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/40057},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123000985},
author = {Shujie Zang and Xu Zhang and Yuting Xing and Jiaxian Chen and Leesa Lin and Zhiyuan Hou},
keywords = {social media, digital health, COVID-19, vaccination, review},
abstract = {Background
Social media and digital technologies have played essential roles in disseminating information and promoting vaccination during the COVID-19 pandemic. There is a need to summarize the applications and analytical techniques of social media and digital technologies in monitoring vaccine attitudes and administering COVID-19 vaccines.
Objective
We aimed to synthesize the global evidence on the applications of social media and digital technologies in COVID-19 vaccination and to explore their avenues to promote COVID-19 vaccination.
Methods
We searched 6 databases (PubMed, Scopus, Web of Science, Embase, EBSCO, and IEEE Xplore) for English-language articles from December 2019 to August 2022. The search terms covered keywords relating to social media, digital technology, and COVID-19 vaccines. Articles were included if they provided original descriptions of applications of social media or digital health technologies/solutions in COVID-19 vaccination. Conference abstracts, editorials, letters, commentaries, correspondence articles, study protocols, and reviews were excluded. A modified version of the Appraisal Tool for Cross-Sectional Studies (AXIS tool) was used to evaluate the quality of social media–related studies. The review was undertaken with the guidance of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews.
Results
A total of 178 articles were included in our review, including 114 social media articles and 64 digital technology articles. Social media has been applied for sentiment/emotion analysis, topic analysis, behavioral analysis, dissemination and engagement analysis, and information quality analysis around COVID-19 vaccination. Of these, sentiment analysis and topic analysis were the most common, with social media data being primarily analyzed by lexicon-based and machine learning techniques. The accuracy and reliability of information on social media can seriously affect public attitudes toward COVID-19 vaccines, and misinformation often leads to vaccine hesitancy. Digital technologies have been applied to determine the COVID-19 vaccination strategy, predict the vaccination process, optimize vaccine distribution and delivery, provide safe and transparent vaccination certificates, and perform postvaccination surveillance. The applied digital technologies included algorithms, blockchain, mobile health, the Internet of Things, and other technologies, although with some barriers to their popularization.
Conclusions
The applications of social media and digital technologies in addressing COVID-19 vaccination–related issues represent an irreversible trend. Attention should be paid to the ethical issues and health inequities arising from the digital divide while applying and promoting these technologies.}
}
@article{NGO2023101865,
title = {Governance and monetary policy impacts on public acceptance of CBDC adoption},
journal = {Research in International Business and Finance},
volume = {64},
pages = {101865},
year = {2023},
issn = {0275-5319},
doi = {https://doi.org/10.1016/j.ribaf.2022.101865},
url = {https://www.sciencedirect.com/science/article/pii/S0275531922002513},
author = {Vu Minh Ngo and Phuc {Van Nguyen} and Huan Huu Nguyen and Huong Xuan {Thi Tram} and Long Cuu Hoang},
keywords = {Public sentiment, Central bank digital currency, Text mining, Governmental factors, Financial market conditions, Monetary policy},
abstract = {Launching the central bank digital currency (CBDC) is increasingly recognized as a key priority by several governments. Unknown are, however, the primary factors of public support for the initiative and CBDC acceptance choices. Moreover, despite the fact that CBDC's success requires substantial public support, there is less empirical data of how the public perceives and speaks about it. This research seeks to fill in these gaps using Facebook data from May 2012 to April 2022 using deep learning algorithms for text mining. This research demonstrates that government performance, inflation rate, economic inequality, and technological literacy have a significant influence on the public's perception of CBDC. The government's support of CBDC is determined by public sentiment, the degree of adoption of decentralized finance (Defi), and monetary policy settings. The degree of wealth inequality and technological literacy are two other demographic elements that influence the government's adoption of CBDC.}
}
@article{PARK2024103705,
title = {GNN-IR: Examining graph neural networks for influencer recommendations in social media marketing},
journal = {Journal of Retailing and Consumer Services},
volume = {78},
pages = {103705},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103705},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924000018},
author = {Jinhee Park and Hyeongjin Ahn and Dongjae Kim and Eunil Park},
keywords = {Influencer marketing, Recommendation, Link prediction, Bipartite graph, YouTube commercial},
abstract = {With the notable growth of the Internet, a number of platforms have emerged and attracted an enormous number of users. Based on the impact of these platforms, some ‘influencers’ are highlighted. These influencers wield significant power, shaping consumer behavior. This influence spawned the concept of influencer marketing, where companies leverage these personalities to advertise their products. YouTube stands out as a prominent platform in this trend. However, considering the limited number of influencers and their concepts, the majority of companies, which hope to conduct their marketing campaigns with influencers face challenges in identifying suitable influencers for their campaigns. With this trend, we introduce GNN-IR, a graph neural network for influencer recommendation, based on the connections between companies and influencers of YouTube, one of the largest content platforms. In developing GNN-IR, we adopted a data-driven methodology utilizing a meticulously curated dataset collected in-house. Our dataset comprises a total of 25,174 relationship entries between advertisers and influencers, involving 1,886 distinct advertisers and 3,812 unique YouTube influencers. It encompasses diverse data modalities, including images, text, and assorted metadata. The data was sourced from two primary platforms: YouTube and ugwanggi. Ugwanggi provided valuable insights into the relationships between advertisers and influencers via their information. Meanwhile, YouTube offered more comprehensive and detailed influencer-centric information. We employed PyTorch Geometric to construct a bipartite graph representing interconnected data. Our recommendation system operates via link prediction, suggesting the Top-k influencers to advertisers based on the calculated connection probability between nodes. To assess GNN-IR's performance, we employed a range of evaluation metrics. For link prediction, we measured Accuracy, Precision, Recall, and F1-score. Additionally, in the recommendation phase, we evaluated Precision@k, Recall@k, and F1-score@k. Using GNN-IR and incorporating profile images from YouTube, keyword features, metadata, and sentiment gleaned from YouTube comments, we achieved Precision levels of 96.51% at k=1 and 93.68% at k=10. Based on the experimental results, several implications and limitations are presented. The collected dataset is publicly available at https://github.com/dxlabskku/GNN-IR.git.}
}
@article{MENON2023e20962,
title = {“Chatting with ChatGPT”: Analyzing the factors influencing users' intention to Use the Open AI's ChatGPT using the UTAUT model},
journal = {Heliyon},
volume = {9},
number = {11},
pages = {e20962},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e20962},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023081707},
author = {Devadas Menon and K Shilpa},
keywords = {ChatGPT, OpenAI, Chatbots, UTAUT, Acceptance and use},
abstract = {Open AI's ChatGPT has emerged as a popular AI language model that can engage in natural language conversations with users. Based on a qualitative research approach using semistructured interviews with 32 ChatGPT users from India, this study examined the factors influencing users' acceptance and use of ChatGPT using the unified theory of acceptance and usage of technology (UTAUT) model. The study results demonstrated that the four factors of UTAUT, along with two extended constructs, i.e. perceived interactivity and privacy concerns, can explain users' interaction and engagement with ChatGPT. The study also found that age and experience can moderate the impact of various factors on the use of ChatGPT. The theoretical and practical implications of the study were also discussed.}
}
@article{HERMANN2024114720,
title = {Artificial intelligence and consumer behavior: From predictive to generative AI},
journal = {Journal of Business Research},
volume = {180},
pages = {114720},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114720},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002248},
author = {Erik Hermann and Stefano Puntoni},
keywords = {Artificial intelligence, Consumer behavior, Algorithms, Predictive AI, Generative AI},
abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI’s remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15 years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.}
}
@article{LI2025111895,
title = {Dual Stimulus–Organism–Response paradigms cross-domain aware model for rumor detection},
journal = {Engineering Applications of Artificial Intelligence},
volume = {160},
pages = {111895},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111895},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625018974},
author = {Yunyun Li and Jiahua Jin},
keywords = {Social media, Rumor detection, Stimulus–Organism–Response theory, Adversarial learning},
abstract = {How to effectively detect rumors on social media has gained much attention in recent years. However, relatively little focus has been given on exploiting psychological crowd signal in user comments left for posts in rumor detection. Therefore, based on Stimulus–Organism–Response (SOR) theory, we first construct the dual Stimulus–Organism–Response paradigms between post and commenting users, and then propose the dual Stimulus–Organism–Response paradigms cross-domain aware model for rumor detection. Particularly, the model is composed of three components: (a) dual SOR paradigms Feature Extractor, which extracts both the factual refutation and emotional resonance SOR paradigm features. We concatenate these two features to form the dual SOR feature. (b) Rumor Classifier. (c) Domain Classifier. In general, the model conducts a minimax game between the rumor classifier and the domain classifier, and learns domain-invariant dual SOR paradigms features for cross-domain rumor classification. Extensive experiments conducted on real-world datasets demonstrates the effectiveness of the proposed model for rumor detection and give explainable results.}
}
@article{MORAVEC2025100691,
title = {Environmental footprint of GenAI – Changing technological future or planet climate?},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {3},
pages = {100691},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100691},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25000411},
author = {Vaclav Moravec and Beata Gavurova and Viliam Kovac},
keywords = {Generative artificial intelligence, ChatGPT, DeepSeek, Artificial intelligence literacy, Climate change, Data centre, Czechia},
abstract = {The beginnings of generative artificial intelligence (GenAI), led by Chat Generative Pre-Trained Transformer (ChatGPT), not only change the behaviour of digital media ecosystem users but also increase the energy consumption of enterprises working with GenAI, which presents them with a fundamental challenge in the era of climate change. This study aims to examine the relationships between the selected aspects of the use of GenAI tools and the environmental perception and behaviour of their users to understand the population's current environmental attitudes towards environmental risks and environmental sustainability. The survey was conducted in October 2024 on a sample of 1,268 respondents of the Czech Republic population. To process the data set, a logistic regression analysis, chi-squared test, Akaike information criterion, and Bayesian information criterion are employed. The results show that the more often people use GenAI tools, the more distant they consider the effects of climate change in time. The low frequency of use of ChatGPT may influence a higher willingness to change popular GenAI tools that are not maintained by environmentally friendly data centres. The frequency of ChatGPT use influences individuals’ perception of the importance of climate-change solving. The more frequently the respondents use artificial intelligence (AI) systems, they less perceive climate change as important. The low frequency of ChatGPT usage is associated with lower willingness to change email provider, transfer own data, leave social networks, stop using a favourite streaming platform and stop using a favourite GenAI platform. The respondents’ attitudes show a visible behavioural change. Internal personal motivation and self-confidence in learning, interest in career and self-confidence when using AI, the behavioural aspects, and the cognitive aspects are altered considerably. Based on the outcomes of the population survey, the study concludes that the issue of environmental friendliness of AI tools should become part of AI literacy that could strengthen population's willingness to use more energy-efficient GenAI platforms. The listed challenges are important in the perspective of the latest technological development, as shown by the discussion on the energy and computational demands of the GenAI platform DeepSeek, which is also discussed in the study.}
}
@article{WEINGARDEN2025,
title = {Low-Burden Detection of Clinical Worsening in Body Dysmorphic Disorder using Smartphone Sensor and Demographic Data},
journal = {Behavior Therapy},
year = {2025},
issn = {0005-7894},
doi = {https://doi.org/10.1016/j.beth.2025.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0005789425000929},
author = {Hilary Weingarden and Vincent Holstein and Geneva K. Jonathan and Michael Armey and Jukka-Pekka Onnela and Sabine Wilhelm},
keywords = {Body dysmorphic disorder (BDD), digital phenotyping, ecological momentary assessment (EMA), suicidal ideation, clinical deterioration},
abstract = {Body dysmorphic disorder (BDD) is characterized by distressing preoccupations with perceived appearance flaws, leading to functional impairment and suicidal ideation (SI). Traditional approaches for monitoring clinical deterioration in BDD include self-reports and clinician assessments, which can miss acute changes in risk due to infrequent administration and recall biases. Alternatively, real-time monitoring via smartphones and wearable devices can enable low-burden early detection of deterioration, identifying intervention opportunities before someone’s condition critically worsens. This study tests the feasibility of using smartphone sensor and demographic data to predict daily clinical acuity. Eighty-two participants with BDD completed ecological momentary assessments (EMA) over 28 days, reporting levels of SI, BDD-related avoidance, and time spent on BDD-related concerns. Smartphone sensor data were collected for three months that overlapped with EMA. Machine learning models were trained to predict same-day levels of SI, avoidance, and time spent on BDD using GPS, accelerometer, and demographic data. We evaluated model performance using mean absolute error, Pearson and Spearman correlations, and permutation tests. Random forest (RF) models using time and random split validation outperformed dummy regressor models across outcomes (maximum SI, mean SI, maximum avoidance, mean avoidance, time-spent on BDD-related behaviors). Pearson correlations for RF models showed strong predictive performance for BDD-related time (r = 0.74-0.75) and mean and max SI (r = 0.70–0.73). Mean and max avoidance was moderately well predicted (r = 0.56–0.62). Step count and demographic factors (e.g., education, living situation), were the most consistent and important features. This study provides initial evidence that smartphone sensor and demographic data can be used to monitor real-time clinical worsening in BDD, without burdening the patient. This work has potential for building just-in-time interventions that are delivered as deterioration onsets, to prevent its escalation. Future research should test these models in real-world datasets collected over longer periods and subsequently explore integration into interventions and clinical decision-making. Trial Registration: ClinicalTrials.gov Identifier: NCT04254575}
}
@article{KRAMER2025,
title = {Living With and Managing Uncomplicated Urinary Tract Infection: Mixed Methods Analysis of Patient Insights From Social Media},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/58882},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125003589},
author = {Melissa L Kramer and Jose Medina Polo and Nishant Kumar and Aruni Mulgirigama and Amina Benkiran},
keywords = {acute cystitis, bladder infection, HCP interactions, urology, patient experience, patient insights, social media, uncomplicated urinary tract infection, urinary tract infection, urinary, women, quality of life, disease management, cystitis, healthcare professional, self-management, patient behavior, UTI},
abstract = {Background
Uncomplicated urinary tract infections (uUTIs) affect more than half of women in their lifetime and can impact on quality of life. We analyzed social media posts discussing uUTIs to gather insights into the patient experience, including aspects of their disease management journey and associated opinions and concerns.
Objective
This study aims to gather patient experience insights by analyzing social media posts that discussed uUTI.
Methods
A search string (“urinary tract infection” [UTI] or “bladder infection” or “cystitis” or “UTI” not “interstitial cystitis”) was used to identify posts from public blogs and patient forums (June 2021 to June 2023). Posts were excluded if they were not written in English or discussed complicated UTI (posts that mentioned “pregnancy” or “pregnant” or “trimester” or “catheter” or “interstitial”). Posts were limited to publicly available sources and anonymized. The primary objective was to gather patient perspectives on key elements of the uUTI experience, including health care professional (HCP) interactions, diagnosis, treatment, and recurrence.
Results
In total, more than 42,000 unique posts were identified (mostly from reddit.com; 29,506/42,265, 70%) and >3600 posts were analyzed. Posts were most commonly from users in the United States (6707/11,180, 60%), the United Kingdom (2261/11,180, 20%), Canada (509/11,180, 5%), Germany (356/11,180, 3%), or India (320/11,180, 3%). Six main themes were identified: symptom awareness and information seeking, HCP interactions, diagnosis and management challenges, management with antibiotics, self-management, and challenges with recurrent UTI. Most posts highlighted the importance of seeking professional medical advice, while some patients raised concerns regarding their HCP interactions and lack of shared decision-making. Patients searched for advice and guidance on the web prior to consulting an HCP, described their symptoms, and discussed lifestyle adjustments. Most patients tried self-management and shared their experiences with nonprescribed treatment options. There was general agreement among posts that antibiotics are necessary to cure UTIs and prevent associated complications.
Conclusions
Social media posts provide valuable insight into the experiences and opinions of patients with uUTIs in Canada, Germany, India, the United Kingdom, and the United States. The insights from this study provide a more complete picture of patient behaviors and highlight the potential for HCP and patient education, as well as better communication through shared decision-making to improve care.}
}
@article{WU2024102756,
title = {Technology shock of ChatGPT, social attention and firm value: Evidence from China},
journal = {Technology in Society},
volume = {79},
pages = {102756},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102756},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X2400304X},
author = {Qinqin Wu and Qinqin Zhuang and Yitong Liu and Longyan Han},
keywords = {ChatGPT, Artificial intelligence, Event study, Difference-in-differences, Stock return, Social attention},
abstract = {The release of ChatGPT has attracted widespread attention and triggered fluctuations in the capital market. This study employs difference-in-differences (DID) and event study (ES) to investigate the effects of ChatGPT's release on the cumulative abnormal return (CAR) of listed companies in China. The results reveal that a series of ChatGPT launch events, including GPT-3.5 and GPT-4, have a significantly positive impact on the firm value of the companies focused on ChatGPT, with dynamic effects. In the initial two months after the release of ChatGPT, the Chinese stock market exhibited an undervaluation of GPT-focused companies, indicating information asymmetry and competitive substitution effect. With the widespread promotion of generative AI, social recognition of ChatGPT's potential value increased. This study verifies the moderation effect of social attention in strengthening ChatGPT's impact, demonstrating that a higher search index for ChatGPT enhances stock returns for GPT-focused companies. Heterogeneity tests reveal that the impact of ChatGPT is significantly positive for large or non-state-owned companies, while small or state-owned companies show no significant effect. From the perspective of labor structure, companies dominated by technical and production personnel experience positive effects, whereas those dominated by sales personnel do not. In the eastern regions with more favorable digital economic innovation environments, companies experience a notably positive impact. This paper provides a theoretical explanation and empirical evidence for the microeconomic impact of generative AI in the Chinese context, offering valuable insights for both government and firms.}
}
@article{DINU20233303,
title = {Veracity Analysis of Romanian Fake News},
journal = {Procedia Computer Science},
volume = {225},
pages = {3303-3312},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.324},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923014825},
author = {Liviu Dinu and Elena Casiana Fusu and Daniela Gifu},
keywords = {fake news detection, Romanian online news, machine learning, classification models},
abstract = {Today, with so much free information online, it becomes increasingly difficult to make sense of what content is based on fact, half-truths or lies. Furthermore, in accordance with the events (e.g., COVID-19) that are increasingly alarming, the speed of false news spread is unprecedented. Of course, fake news impairs social stability and public trust, which calls for increasing demand for their detection. How to spot as faithful as possible fake news? The response that this article gives, by exploring the textual features using artificial intelligence and machine learning. This research addresses the problem of automatic fake news detection for Romanian language. First, we present a new corpus for automatic fake news detection that contains two subsets of 977 and 29 154 news articles in Romanian, separated according to labelling and collection methods. Second, we explore several text-based approaches for automatic fake news detection by using machine learning and artificial intelligence which resulted in an accuracy of 93%.}
}
@article{LI2023120646,
title = {Exposing low-quality deepfake videos of Social Network Service using Spatial Restored Detection Framework},
journal = {Expert Systems with Applications},
volume = {231},
pages = {120646},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120646},
url = {https://www.sciencedirect.com/science/article/pii/S095741742301148X},
author = {Ying Li and Shan Bian and Chuntao Wang and Kemal Polat and Adi Alhudhaif and Fayadh Alenezi},
keywords = {Deepfake detection, Video forensics, Super resolution, Attention mechanism},
abstract = {The increasing abuse of facial manipulation methods, such as FaceSwap, Deepfakes etc., seriously threatens the authenticity of digital images/videos on the Internet. Therefore, it is of great importance to identify the facial videos to confirm the contents and avoid fake news or rumors. Many researchers have paid great attention to the detection of deepfakes and put forward a number of deep-learning-based detection models. The existing approaches mostly face the performance degradation in detecting low-quality(LQ) videos, i.e. heavily compressed or low-resolution videos through some SNS (Social Network Service), resulting in the limitation in real applications. To address this issue, in this paper, a novel Spatial Restore Detection Framework(SRDF) is proposed for improving the detection performance for LQ videos by restoring spatial features. We designed a feature extraction-enhancement block and a mapping block inspired by super-resolution methods, to restore and enhance texture features. An attention module was introduced to guide the texture features restoration and enhancement stage attending to different local areas and restoring the texture features. Besides, an improved isolated loss was put forward to prevent the expansion of a single area concerned. Moreover, we adopted a regional data augmentation strategy to prompt feature restore and enhancement in the region attended. Extensive experiments conducted on two deepfake datasets have validated the superiority of the proposed method compared to the state-of-the-art, especially in the scenarios of detecting low-quality deepfake videos.}
}
@article{AHMED2022100066,
title = {Machine learning models to detect anxiety and depression through social media: A scoping review},
journal = {Computer Methods and Programs in Biomedicine Update},
volume = {2},
pages = {100066},
year = {2022},
issn = {2666-9900},
doi = {https://doi.org/10.1016/j.cmpbup.2022.100066},
url = {https://www.sciencedirect.com/science/article/pii/S2666990022000179},
author = {Arfan Ahmed and Sarah Aziz and Carla T. Toro and Mahmood Alzubaidi and Sara Irshaidat and Hashem Abu Serhan and Alaa A. Abd-alrazaq and Mowafa Househ},
keywords = {Anxiety, Depression, Social media, Social networking, Artificial intelligence, Machine learning, COVID-19},
abstract = {Despite improvement in detection rates, the prevalence of mental health disorders such as anxiety and depression are on the rise especially since the outbreak of the COVID-19 pandemic. Symptoms of mental health disorders have been noted and observed on social media forums such Facebook. We explored machine learning models used to detect anxiety and depression through social media. Six bibliographic databases were searched for conducting the review following PRISMA-ScR protocol. We included 54 of 2219 retrieved studies. Users suffering from anxiety or depression were identified in the reviewed studies by screening their online presence and their sharing of diagnosis by patterns in their language and online activity. Majority of the studies (70%, 38/54) were conducted at the peak of the COVID-19 pandemic (2019–2020). The studies made use of social media data from a variety of different platforms to develop predictive models for the detection of depression or anxiety. These included Twitter, Facebook, Instagram, Reddit, Sina Weibo, and a combination of different social sites posts. We report the most common Machine Learning models identified. Identification of those suffering from anxiety and depression disorders may be achieved using prediction models to detect user's language on social media and has the potential to complimenting traditional screening. Such analysis could also provide insights into the mental health of the public especially so when access to health professionals can be restricted due to lockdowns and temporary closure of services such as we saw during the peak of the COVID-19 pandemic.}
}
@article{AKDOGAN202461,
title = {More than just sentiment: Using social, cognitive, and behavioral information of social media to predict stock markets with artificial intelligence and big data},
journal = {Borsa Istanbul Review},
volume = {24},
pages = {61-82},
year = {2024},
note = {Artificial Intelligence and Financial Markets},
issn = {2214-8450},
doi = {https://doi.org/10.1016/j.bir.2024.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S2214845024001571},
author = {Yunus Emre Akdogan and Adem Anbar},
keywords = {Borsa istanbul, Big data, Machine learning, Deep learning, Sentiment analysis, Twitter},
abstract = {Digital transformation offers unprecedented opportunities to access data on hard-to-measure social aspects. In this digital era, social media platforms have become critical data sources for the social sciences. This study moves beyond traditional finance assumptions of “perfect information,” “rational humans,” and “isolated individuals” by analyzing retail investor behavior using Twitter data. It adopts a human model characterized by incomplete information, bounded rationality, and the influence of social and emotional factors. Tweets shared between January 1, 2012, and February 28, 2020, were collected. A GRU-based context classifier achieved 98% accuracy in identifying tweets related to Borsa Istanbul (BIST). Sentiment classification using a BERT model achieved 91% accuracy for positive and negative classes. Relationships between Twitter-obtained features and BIST indices were analyzed using machine learning methods such as linear regression, Lasso regression, random forest, and XGBoost. The analysis revealed that 91% of the change in the opening value, 63% of the change in trading volume, and 67% in volatility of the BIST 100 index could be attributed to cognitive, behavioral, and social features gleaned from tweets.}
}
@article{XU2025104063,
title = {Dynamic effects of emotions in microblogs on sharing during EID outbreaks: The contingent role of user personality traits},
journal = {Information & Management},
volume = {62},
number = {1},
pages = {104063},
year = {2025},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2024.104063},
url = {https://www.sciencedirect.com/science/article/pii/S0378720624001459},
author = {Liwei Xu and Mingxing Han and Jingguo Wang and Yu Chen and Jiangnan Qiu},
keywords = {Social media, Emotions in microblogs, User sharing, User personality traits, Dynamic effect},
abstract = {Our study empirically examines whether users’ personality traits accentuate or attenuate the influence of emotions in microblogs on users’ sharing behavior over time on a social media platform (Weibo in particular) during emerging infectious disease (EID) outbreaks. We develop a theoretical framework to analyze the dynamic relationship between emotions in microblogs related to EID on users’ sharing with personality traits as moderators. We collected 92,621 microblogs on COVID-19 from Sina Weibo with 501,930 sharing users for hypothesis testing. We leveraged a machine learning method in combination with the vector autoregression model to test our research model. Our results indicate that users with high levels of neuroticism, openness, and agreeableness are more likely to share immediately upon seeing microblogs with negative emotions, while those high in conscientiousness usually share after some time. This study highlights the contingent role of personality traits in the relationship between emotions expressed in microblogs and users’ act of sharing. The dynamic effects (both short-term and long-term) on sharing of emotions in microblogs are contingent upon personality traits. The results help us to understand who shares microblogs, how and why they behave when facing emotional content during EID outbreaks. Our findings enhance the understanding of user behavior on social media platforms and provide actionable insights for potential interventions in response to EID outbreaks.}
}
@article{CHOI2024121589,
title = {Stock price momentum modeling using social media data},
journal = {Expert Systems with Applications},
volume = {237},
pages = {121589},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.121589},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423020912},
author = {Min Choi and Hye Jin Lee and Soh Hyung Park and Sung Whan Jeon and Sungzoon Cho},
keywords = {Alternative data, Social media, Online Stock Message boards, Keyword extraction, Stock market forecasting, Stock price momentum},
abstract = {Alternative data has rapidly gained popularity as a means of observing investor reactions to current stock market events, analyzing sector movements, and developing investment strategies. Signals observed from alternative data may add valuable information to conventional market analysis, especially when there exists some information asymmetry in the market, to which small-cap stocks are particularly sensitive. Our research uses alternative textual data obtained from social media to predict the price momentum of small-cap stocks, which are known to be sensitive to market events and retail investors’ reactions. We directly address the challenges in the analysis of texts, especially in the Korean language, such as the use of jargon, acronyms, and typos, by taking a two-fold approach to preprocessing. Then, we extract the social keywords and label them by two standards: word momentum and correlation with stock price movement. Using these social keywords as social indicators derived from the retail investors trading small-cap stocks, in addition to the conventional technical indicators, we propose a price momentum forecast model which classifies whether the closing price of a given small-cap stock will increase by more than 10% in the next 5 business days. Experimental results show that our approach successfully extracts social keywords that play a significant role in determining the price momentum in the market, and our selected social indicators are intuitive to human understanding. Furthermore, we consider example investment scenarios and run tests by training various classifiers with the social indicators and computing cumulative returns. Our results are very promising and show that the investment scenarios with social indicators outperform the benchmark considerably. We anticipate that our work will expand the scope of using alternative data for stock market analysis and price momentum forecasts by incorporating social indicators extracted from social media.}
}
@article{WANG2025130905,
title = {M3DP: Optimizing 2D vision tasks with minimal 3D object information},
journal = {Neurocomputing},
volume = {652},
pages = {130905},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130905},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225015772},
author = {Ziming Wang and Yanjing Li and Linlin Yang and Xinkai Liang and Xianbin Cao and Qi Wang and Baochang Zhang},
keywords = {Knowledge distillation, 2D–3D cross-modality, Geometric properties, Feature fusion},
abstract = {The availability of 3D data (such as LiDAR, Radar, and other point-cloud data) enriches the exploration of leveraging 3D priors for specific 2D downstream tasks. However, existing methods require aligned 3D data annotation for 2D data, which can be time-consuming and labor-intensive. To reduce this reliance, we propose Minimal 3D object information Prior (M3DP) for 2D vision feature learning using unaligned 3D data as prior. Specifically, M3DP only requires 3D objects and their corresponding classification labels within the same dataset to learn 3D priors, which greatly saves time and labor costs. Moreover, we introduce multiview rotation augmentation (MRA) and two alignments—K-Best-of-N alignment and instance alignment—to encourage 2D representation learning from 3D representations in the unified 2D–3D space. This approach helps the model learn geometric properties. This strategy fully leverages the multi-view geometric information of 3D objects, enabling precise localization and matching in 2D images. Through instance alignment, our method also efficiently facilitates information transfer across different categories of 3D objects. Our method effectively enhances the performance of 2D tasks by learning the geometric properties of 3D objects. Extensive experiments on three datasets demonstrate the superiority of our approach over prior state-of-the-art methods.}
}
@article{PHAM2025100757,
title = {A comprehensive survey with critical analysis for deepfake speech detection},
journal = {Computer Science Review},
volume = {57},
pages = {100757},
year = {2025},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100757},
url = {https://www.sciencedirect.com/science/article/pii/S1574013725000334},
author = {Lam Pham and Phat Lam and Dat Tran and Hieu Tang and Tin Nguyen and Alexander Schindler and Florian Skopik and Alexander Polonsky and Hai Canh Vu},
keywords = {Deepfake speech detection (DSD), Challenge competition, Ensemble, Audio embedding, Pre-trained model},
abstract = {Thanks to advancements in deep learning, speech generation systems now power a variety of real-world applications, such as text-to-speech for individuals with speech disorders, voice chatbots in call centers, cross-linguistic speech translation, etc. While these systems can autonomously generate human-like speech and replicate specific voices, they also pose risks when misused for malicious purposes. This motivates the research community to develop models for detecting synthesized speech (e.g., fake speech) generated by deep-learning-based models, referred to as the Deepfake Speech Detection task. As the Deepfake Speech Detection task has emerged in recent years, there are not many survey papers proposed for this task. Additionally, existing surveys for the Deepfake Speech Detection task tend to summarize techniques used to construct a Deepfake Speech Detection system rather than providing a thorough analysis. This gap motivated us to conduct a comprehensive survey, providing a critical analysis of the challenges and developments in Deepfake Speech Detection (This work is a part of our projects of STARLIGHT, EUCINF, and DEFAME FAKEs). Our survey is innovatively structured, offering an in-depth analysis of current challenge competitions, public datasets, and the deep-learning techniques that provide enhanced solutions to address existing challenges in the field. From our analysis, we propose hypotheses on leveraging and combining specific deep learning techniques to improve the effectiveness of Deepfake Speech Detection systems. Beyond conducting a survey, we perform extensive experiments to validate these hypotheses and propose a highly competitive model for the task of Deepfake Speech Detection. Given the analysis and the experimental results, we finally indicate potential and promising research directions for the Deepfake Speech Detection task.}
}
@article{JIANG2024202,
title = {Preventing the Immense Increase in the Life-Cycle Energy and Carbon Footprints of LLM-Powered Intelligent Chatbots},
journal = {Engineering},
volume = {40},
pages = {202-210},
year = {2024},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2024.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2095809924002315},
author = {Peng Jiang and Christian Sonne and Wangliang Li and Fengqi You and Siming You},
keywords = {Large language models, Intelligent chatbots, Carbon emissions, Energy and environmental footprints, Life-cycle assessment, Global cooperation},
abstract = {Intelligent chatbots powered by large language models (LLMs) have recently been sweeping the world, with potential for a wide variety of industrial applications. Global frontier technology companies are feverishly participating in LLM-powered chatbot design and development, providing several alternatives beyond the famous ChatGPT. However, training, fine-tuning, and updating such intelligent chatbots consume substantial amounts of electricity, resulting in significant carbon emissions. The research and development of all intelligent LLMs and software, hardware manufacturing (e.g., graphics processing units and supercomputers), related data/operations management, and material recycling supporting chatbot services are associated with carbon emissions to varying extents. Attention should therefore be paid to the entire life-cycle energy and carbon footprints of LLM-powered intelligent chatbots in both the present and future in order to mitigate their climate change impact. In this work, we clarify and highlight the energy consumption and carbon emission implications of eight main phases throughout the life cycle of the development of such intelligent chatbots. Based on a life-cycle and interaction analysis of these phases, we propose a system-level solution with three strategic pathways to optimize the management of this industry and mitigate the related footprints. While anticipating the enormous potential of this advanced technology and its products, we make an appeal for a rethinking of the mitigation pathways and strategies of the life-cycle energy usage and carbon emissions of the LLM-powered intelligent chatbot industry and a reshaping of their energy and environmental implications at this early stage of development.}
}
@article{GUO2025130152,
title = {Video-text retrieval based on multi-grained hierarchical aggregation and semantic similarity optimization},
journal = {Neurocomputing},
volume = {638},
pages = {130152},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130152},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225008240},
author = {Jie Guo and Shujie Lan and Bin Song and Mengying Wang},
keywords = {Video-text retrieval, Multi-grained hierarchical aggregation, Semantic similarity optimization, Temporal correlation},
abstract = {Current video-text retrieval approaches face two major challenges. Firstly, the semantic information imbalance between modalities, primarily caused by differences in granularity of inter-modal feature correlations, poses challenges for accurate alignment. Secondly, the presence of irrelevant content, which can be considered as noise, within videos and texts frequently leads to incorrect retrieval results. To address these issues, we propose the multi-grained hierarchical aggregation and semantic similarity optimization network for VTR, which is named as MSNet. MSNet employs a multi-grained hierarchical aggregation module (MHA) we designed to integrate global and local information. It introduces the expectation–maximization contrastive learning (EMCL) strategy and the interactive noise reduction (INR) technique to effectively reduce the impact of noise. Moreover, MHA extracts the optimized frame feature by a contextual frame encoder we designed to mitigate semantic imbalance. Additionally, the proposed semantic similarity optimization module (SSO) refines multi-scale feature interactions. Extensive experiments on benchmark datasets, including MSR-VTT, MSVD and DiDeMo, demonstrate the superior performance and effectiveness of MSNet in VTR.}
}
@article{XIA2025,
title = {The Impact of In-Feed Recommendation on Consumers’ Impulse Buying Behavior on Short Video Platforms},
journal = {Journal of Organizational and End User Computing},
volume = {37},
number = {1},
year = {2025},
issn = {1546-2234},
doi = {https://doi.org/10.4018/JOEUC.385730},
url = {https://www.sciencedirect.com/science/article/pii/S1546223425000358},
author = {Hanmeng Xia and Huiru Yang and Xiaoqian Liu and Xin Zhang},
keywords = {Impulse Buying, Short Video Platforms, Algorithmic Trust, Flow Experience, SOR-ELM Model},
abstract = {ABSTRACT
The widespread adoption of algorithm-driven short video platforms has transformed how users process content and engage in impulsive purchasing. However, current models often fail to capture the multi-dimensional psychological mechanisms that underlie such behavior, particularly the dynamic interplay between content signals, emotional immersion, perceptual intuition, and algorithmic perception. To address these limitations, this study proposes stimulus-organism-response–elaboration likelihood model, an integrated behavioral model that fuses the stimulus–organism–response paradigm with dual-route elaboration (central and peripheral), flow experience, and algorithmic trust. The model differentiates between cognitive and behavioral impulsivity, incorporates post-purchase regret as a feedback mechanism, and models personalization and transparency as precursors to algorithmic attitude and trust.}
}
@article{EKANAYAKE20242941,
title = {Trends in Event Understanding and Caption Generation/Reconstruction in Dense Video: A Review},
journal = {Computers, Materials and Continua},
volume = {78},
number = {3},
pages = {2941-2965},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.046155},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824003515},
author = {Ekanayake Mudiyanselage Chulabhaya Lankanatha Ekanayake and Abubakar Sulaiman Gezawa and Yunqi Lei},
keywords = {Video description, video to text, video caption, sentence reconstruction},
abstract = {Video description generates natural language sentences that describe the subject, verb, and objects of the targeted Video. The video description has been used to help visually impaired people to understand the content. It is also playing an essential role in devolving human-robot interaction. The dense video description is more difficult when compared with simple Video captioning because of the object’s interactions and event overlapping. Deep learning is changing the shape of computer vision (CV) technologies and natural language processing (NLP). There are hundreds of deep learning models, datasets, and evaluations that can improve the gaps in current research. This article filled this gap by evaluating some state-of-the-art approaches, especially focusing on deep learning and machine learning for video caption in a dense environment. In this article, some classic techniques concerning the existing machine learning were reviewed. And provides deep learning models, a detail of benchmark datasets with their respective domains. This paper reviews various evaluation metrics, including Bilingual Evaluation Understudy (BLEU), Metric for Evaluation of Translation with Explicit Ordering (METEOR), Word Mover’s Distance (WMD), and Recall-Oriented Understudy for Gisting Evaluation (ROUGE) with their pros and cons. Finally, this article listed some future directions and proposed work for context enhancement using key scene extraction with object detection in a particular frame. Especially, how to improve the context of video description by analyzing key frames detection through morphological image analysis. Additionally, the paper discusses a novel approach involving sentence reconstruction and context improvement through key frame object detection, which incorporates the fusion of large language models for refining results. The ultimate results arise from enhancing the generated text of the proposed model by improving the predicted text and isolating objects using various keyframes. These keyframes identify dense events occurring in the video sequence.}
}
@article{ALSALEMI2023100741,
title = {A modular recommender system for domestic energy efficiency},
journal = {Environmental Challenges},
volume = {13},
pages = {100741},
year = {2023},
issn = {2667-0100},
doi = {https://doi.org/10.1016/j.envc.2023.100741},
url = {https://www.sciencedirect.com/science/article/pii/S2667010023000653},
author = {Abdullah Alsalemi and Abbes Amira and Hossein Malekmohamadi and Kegong Diao},
keywords = {Energy efficiency, Sustainability, Recommender systems, Artificial intelligence, Modularity},
abstract = {Recommender systems continually impact multiple verticals by introducing automated intelligence to decision making. When applying such Artificial Intelligence (AI) tools to energy efficiency problems, a number of opportunities and challenges present themselves. This paper presents a modular recommender system for improving domestic household energy savings. The recommender relies upon a contextual appliance-level energy dataset from seven appliances in a household. Modularity is incorporated into the system design to create customizable sub-components that adapt to the nature of the data and the end-user's preference, such as modules that recommend based on usage patterns, power consumption, and occupancy. Machine Learning (ML) has been used for automatic appliance profiling and rank-based methods are employed to evaluate the recommender based on relevance scores. Implementation results for generating recommendations for two weeks yield a Root Mean Square Error (RMSE) of 0.2288, Normalized Cumulative Discounted Gain (NCDG) of 0.729 for seven appliances. Future work includes evaluation on edge computing platforms and user testing through a mobile application.}
}
@article{2022367,
title = {Santé mentale, droit international et européen (février et mars 2022)},
journal = {Santé mentale et Droit},
volume = {22},
number = {3},
pages = {367-376},
year = {2022},
issn = {2772-9710},
doi = {https://doi.org/10.1016/j.smed.2022.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S2772971022001425}
}
@article{BRAGA2023820,
title = {An Architecture Proposal for Noncommunicable Diseases Prevention},
journal = {Procedia Computer Science},
volume = {220},
pages = {820-825},
year = {2023},
note = {The 14th International Conference on Ambient Systems, Networks and Technologies Networks (ANT) and The 6th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.03.109},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923006440},
author = {Diana Braga and Daniela Oliveira and Rafaela Rosário and Paulo Novais and José Machado},
keywords = {Intelligent System, Misinformation, Noncommunicable Diseases, Prevention, Online Social Listening},
abstract = {Noncommunicable Diseases (NCDs) are a leading global health challenge, causing 41 million deaths per year. Risk factors include genetics, environmental factors, and lifestyle choices. Adopting healthy lifestyles can prevent or delay the onset of NCDs, but health misinformation can lead people to make poor decisions about their health. To combat this, it is proposed to develop an Intelligent System using Artificial Intelligence techniques to collect and analyze data from social media about health topics to combat misinformation in public health and forecast NCDs, providing guidelines to prevent their spread. Methods: A system´s overall architecture is presented ... An innovative and novel solution that addresses the spread of information concerning health and NCDs contributes to inform public policies and infodemic management strategies}
}
@article{CASALESGARCIA2025101358,
title = {Analyzing aesthetics, attractiveness and color of gastronomic images for user engagement},
journal = {Cognitive Systems Research},
volume = {91},
pages = {101358},
year = {2025},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2025.101358},
url = {https://www.sciencedirect.com/science/article/pii/S1389041725000385},
author = {Vicente Casales-Garcia and Lledó Museros and Ismael Sanz and Luis Gonzalez-Abril},
keywords = {Sentiment analysis, Food-porn, Gastronomy, Social media, Color image processing, Emotions},
abstract = {Foodstragramming refers to how people share images of food through social media in order to have an impact on potential consumers. Hence, foodstragramming images is a way for small and medium enterprises (SMEs) to create loyal customers and promote gastronomic tourism. An approach for analyzing foodstragramming images is presented in this paper and also their related comments published by the Getcookingcanada Instagram account, which belongs to a cooking school. The S-O-R (Stimulus-Organism-Response) model is used to study the emotions and impact on viewers of these Instagram images. Our approach evaluates the user’s preferences according to the gastronomic images and their comments and number of likes. The approach suggests possible moods or emotions that a user can have when looking at these gastronomic images based in the colors of the images, and also it studies the sentiment elicited from the comments. The analysis was performed using a variance-based structural equation modeling method called Partial Least Squares (PLS). The obtained results show a structural model between the sentiment associated to the comments, the number of likes, and moods or emotions that can be extracted from each image. Images that evoke a positive sentiment also have a higher number of likes and comments. Also, it is shown that gastronomic images evoke the adjectives Romantic and Healthy due to the food color of the images. These adjectives produce a positive sentiment, which drive a positive behavioral intention.}
}
@article{HE2025103901,
title = {Few-shot cross domain event discovery in narrative text},
journal = {Information Processing & Management},
volume = {62},
number = {1},
pages = {103901},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103901},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324002607},
author = {Ruifang He and Fei Huang and Jinsong Ma and Jinpeng Zhang and Yongkai Zhu and Shiqi Zhang and Jie Bai},
keywords = {Event discovery, Few-shot domain adaptation, Positive–negative balanced sampling, Parameter adapter},
abstract = {Cross-domain event detection presents notable challenges in the form of data scarcity, and existing few-shot algorithms only consider events whose types are predefined, resulting in low coverage or excessive trivial identification results. To address this issue, this paper proposes the task Few-shot Cross Domain Event Discovery, which includes two subtasks: Domain Event Discovery and Few-shot Domain Adaptation. The former aims to identify the type-agnostic event triggers, and the latter completes domain adaptation with only a few annotated domain samples. Additionally, we introduce a positive–negative balanced sampling mechanism and a novel domain parameter adapter for these two subtasks, respectively. Extensive experiments on the DuEE dataset and the ACE2005 dataset show that our proposed method outperforms the current state-of-the-art method by 6.3% in Mix-F1 score on average. Moreover, we achieve SOTA performance in all domains of the DuEE dataset.}
}
@article{HSIAO2025104285,
title = {Decoding influencer marketing effectiveness on instagram: Insights from image, text, and influencer features},
journal = {Journal of Retailing and Consumer Services},
volume = {85},
pages = {104285},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104285},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925000645},
author = {Yu-Hsiang Hsiao and Yi-Yi Lin},
keywords = {Influencer marketing, Social media, Instagram, Popularity prediction, Machine learning, Taguchi experiments, Odds ratio},
abstract = {Influencer marketing has become a crucial strategy for modern brands. By collaborating with influencers to publish sponsored posts on social media platforms, brands can leverage influencer popularity and follower engagement to enhance brand exposure and attract potential consumers. This study aims to predict the popularity of sponsored posts on Instagram and analyze the factors influencing their effectiveness. To achieve this, four distinct feature sets were extracted from sponsored posts: image visual features, image topic features, text topic features, and influencer features. These features were used individually and in combination as predictive variables to develop models for predicting post popularity using various methods. Experimental results demonstrate that the predictive models achieve strong performance, with the best results obtained when incorporating all four feature sets, highlighting the importance of considering multiple factors in evaluating sponsored post effectiveness. Furthermore, this study employs the Taguchi experiments to analyze the relative contribution of the four feature sets to the post popularity and utilizes odds ratio analysis from logistic regression to provide detailed insights into the impact of individual features. By examining the influence of visual, textual, and influencer-related factors, this study offers valuable guidance for brands in selecting influencers and optimizing post content, providing deeper insights into influencer marketing strategies.}
}
@article{LIM2023100790,
title = {Generative AI and the future of education: Ragnarök or reformation? A paradoxical perspective from management educators},
journal = {The International Journal of Management Education},
volume = {21},
number = {2},
pages = {100790},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100790},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000289},
author = {Weng Marc Lim and Asanka Gunasekara and Jessica Leigh Pallant and Jason Ian Pallant and Ekaterina Pechenkina},
keywords = {Academic integrity, Bard, ChatGPT, Critical analysis, DALL-E, Ethics, Future of education, Generative AI, Generative artificial intelligence, Google, Education, Educator, Management education, Management educator, OpenAI, Paradox, Paradox theory, Ragnarök, Reformation, Transformation, Transformative education},
abstract = {Generative artificial intelligence (AI) has taken the world by storm, with notable tension transpiring in the field of education. Given that Generative AI is rapidly emerging as a transformative innovation, this article endeavors to offer a seminal rejoinder that aims to (i) reconcile the great debate on Generative AI in order to (ii) lay the foundation for Generative AI to co-exist as a transformative resource in the future of education. Using critical analysis as a method and paradox theory as a theoretical lens (i.e., the “how”), this article (i) defines Generative AI and transformative education (i.e., the “ideas”), (ii) establishes the paradoxes of Generative AI (i.e., the “what”), and (iii) provides implications for the future of education from the perspective of management educators (i.e., the “so what”). Noteworthily, the paradoxes of Generative AI are four-fold: (Paradox #1) Generative AI is a ‘friend’ yet a ‘foe’, (Paradox #2) Generative AI is ‘capable’ yet ‘dependent’, (Paradox #3) Generative AI is ‘accessible’ yet ‘restrictive’, and (Paradox #4) Generative AI gets even ‘popular’ when ‘banned’ (i.e., the “what”). Through a position that seeks to embrace rather than reject Generative AI, the lessons and implications that emerge from the discussion herein represent a seminal contribution from management educators on this trending topic and should be useful for approaching Generative AI as a game-changer for education reformation in management and the field of education at large, and by extension, mitigating a situation where Generative AI develops into a Ragnarök that dooms the future of education of which management education is a part of (i.e., the “so what”).}
}
@article{MARENGO2025108375,
title = {Leveraging social media and large language models for scalable alcohol risk assessment: Examining validity with AUDIT-C and post recency effects},
journal = {Addictive Behaviors},
volume = {168},
pages = {108375},
year = {2025},
issn = {0306-4603},
doi = {https://doi.org/10.1016/j.addbeh.2025.108375},
url = {https://www.sciencedirect.com/science/article/pii/S0306460325001364},
author = {Davide Marengo and Francesco Quilghini and Michele Settanni},
keywords = {Large language models, Social media, Risky alcohol consumption, AUDIT-C, Digital phenotyping, Natural language processing},
abstract = {Risky alcohol consumption is a major public health concern, yet significant barriers exist to effective screening. The present study examines the potential of Large Language Models (LLMs) to infer risky alcohol use from social media text. The unobtrusive nature of this approach could provide a more scalable way to assess alcohol risk in large populations. To this aim, we analyzed Facebook status updates from 208 adults from Italy (mean age = 26.8, 70.7 % female) who also completed the Alcohol Use Disorders Identification Test-Consumption (AUDIT-C), a brief validated self-report measure of risky drinking. Two state-of-the-art LLMs, Gemini 1.5 Pro and GPT-4o, were used to assess alcohol risk and to quantify alcohol references. Results demonstrated strong inter-model agreement between risk inferences (ρ = 0.572, p < 0.001). LLM-inferred risk scores showed moderate correlations with AUDIT-C scores (Gemini 1.5 Pro: ρ = 0.344, p < 0.001; GPT-4o: ρ = 0.375, p < 0.001; Average: ρ = 0.405, p < 0.001). These correlations were significantly stronger among participants with recent posts (Average risk score: ρ = 0.500, p < 0.001) than among those without (ρ = 0.294, p = 0.008). The strongest correlation was observed between average LLM-inferred risk scores and AUDIT-C in the recent posts group (disattenuated ρ = 0.606). These findings suggest that LLMs offer a promising tool for identifying risky alcohol use when analyzing recent social media activity. Their accuracy is comparable to some traditional alcohol assessment methods, highlighting their potential to enhance early detection efforts. Limitations and future research directions are discussed.}
}
@article{LIZLOPEZ2024102103,
title = {Generation and detection of manipulated multimodal audiovisual content: Advances, trends and open challenges},
journal = {Information Fusion},
volume = {103},
pages = {102103},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.102103},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523004190},
author = {Helena Liz-López and Mamadou Keita and Abdelmalik Taleb-Ahmed and Abdenour Hadid and Javier Huertas-Tato and David Camacho},
keywords = {Multimedia data manipulation generation, Multimedia data forensics, Deep Learning, Video, Audio, Multimodal},
abstract = {Generative deep learning techniques have invaded the public discourse recently. Despite the advantages, the applications to disinformation are concerning as the counter-measures advance slowly. As the manipulation of multimedia content becomes easier, faster, and more credible, developing effective forensics becomes invaluable. Other works have identified this need but neglect that disinformation is inherently multimodal. Overall in this survey, we exhaustively describe modern manipulation and forensic techniques from the lens of video, audio and their multimodal fusion. For manipulation techniques, we give a classification of the most commonly applied manipulations. Generative techniques can be exploited to generate datasets; we provide a list of current datasets useful for forensics. We have reviewed forensic techniques from 2018 to 2023, examined the usage of datasets, and given a comparative analysis of each modality. Finally, we give another comparison of end-to-end forensics tools for end-users. From our analysis clear trends are found with diffusion models, dataset granularity, explainability techniques, synchronisation improvements, and learning task diversity. We find a roadmap of deep challenges ahead, including multilinguality, multimodality, improving data quality (and variety), all in an adversarial ever-changing environment.}
}
@article{DANIASURAGA2025101053,
title = {Être, ou ne pas Être en ligne? Explorer les Liens entre Profils d’Autoprésentation en Ligne sur les Réseaux Socio-Numériques et l'Estime de Soi chez les Adolescents et Jeunes Adultes},
journal = {European Review of Applied Psychology},
volume = {75},
number = {3},
pages = {101053},
year = {2025},
issn = {1162-9088},
doi = {https://doi.org/10.1016/j.erap.2024.101053},
url = {https://www.sciencedirect.com/science/article/pii/S1162908824000847},
author = {Matthieu Danias-Uraga and Lyda Lannegrand},
keywords = {Autoprésentation en ligne, Estime de soi, Adolescence, Jeunes adultes, Réseaux socio-numériques, Adolescence, Online self-presentation, Self-esteem, Young adults, Digital Technology Use},
abstract = {Résumé
Introduction
Les réseaux socio-numériques sont intégrés dans les usages de la vie quotidienne des adolescents et des jeunes adultes. Si les contextes numériques sont à considérer comme des contextes de développement, il est nécessaire d’identifier la diversité de profils d’usages numériques chez les jeunes. Parmi les usages numériques, la présentation de soi (ou autoprésentation) en ligne est particulièrement importante à l’adolescence.
Objectif
L’objectif de cette étude est d’identifier différents profils d’autoprésentation en ligne chez les adolescents et jeunes adultes et d’en analyser les relations avec une ressource essentielle du fonctionnement humain qu’est l’estime de soi.
Méthode
Les données ont été récoltées auprès d’adolescents lycéens et de jeunes adultes étudiants à l’université de 14–30 ans (N = 1970), grâce à deux questionnaires auto-rapportés, l’un mesurant l’autoprésentation en ligne au travers de 5 dimensions (présentation du soi réel, du soi idéal, du faux-soi d’exploration de rôle, du faux-soi de comparaison, et du faux-soi de supercherie) et l’autre, le niveau d’estime de soi.
Résultats
Des analyses en clusters ont permis l’identification de 6 profils contrastés d’autoprésentation en ligne. Les analyses de variance (ANOVA) et tests de comparaison de moyenne (Tukey) ont conduit à identifier des niveaux moyens d’estime de soi significativement différents en fonction de l’appartenance aux profils d’autoprésentation en ligne. Des analyses complémentaires ont permis d’identifier des surreprésentations au sein des profils en fonction du genre et de la période de développement.
Conclusion
Les jeunes qui s’exposent peu en ligne ou se présentent de manière réaliste ont une meilleure estime d’eux-mêmes, tandis que les jeunes avec des présentations de faux-soi (supercherie et comparaison aux autres) ont des niveaux d’estime de soi plus faibles. Ces résultats conduisent à proposer des perspectives de recherche et d’action dans les domaines de l’éducation et de la santé.
Introduction
Social media platforms are deeply embedded in the daily lives of adolescents and young adults. Considering that digital contexts can be viewed as developmental settings, it is crucial to identify the diverse profiles of digital usage among young people. Among these digital practices, online self-presentation is particularly significant during adolescence.
Objective
This study aims to identify different profiles of online self-presentation among adolescents and young adults and to examine their relationships with a key aspect of human functioning: self-esteem.
Method
Data were collected from adolescents in high school and young adult university students aged 14–30 (N = 1970). Two self-report questionnaires were employed: one measuring online self-presentation (Michikyan et al., 2014) across five dimensions (presentation of real self, ideal self, role exploration false self, comparison false self, and deception false self), and the other assessing self-esteem (Rosenberg, 1965; Vallieres & Vallerand, 1990).
Results
Cluster analyses identified six distinct profiles of online self-presentation. ANOVA and Tukey's post-hoc tests revealed significant differences in mean self-esteem levels across these profiles. Additional analyses highlighted overrepresentations within profiles based on gender and developmental stage.
Conclusion
Young people who present themselves realistically or have minimal online exposure tend to have higher self-esteem, while those engaging in false self-presentation (deception and comparison with others) exhibit lower self-esteem levels. These findings suggest potential avenues for research and intervention in education and health fields.}
}
@article{GMITEREK2025103043,
title = {Generative artificial intelligence in the activities of academic libraries of public universities in Poland},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {3},
pages = {103043},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103043},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000394},
author = {Grzegorz Gmiterek and Sebastian D. Kotuła},
keywords = {Generative artificial intelligence, Artificial intelligence, Academic libraries},
abstract = {The article presents the results of a study conducted, using both survey and content analysis (of the websites and fan pages) of all the libraries of the public universities in Poland to establish their use of generative artificial intelligence. The general findings showed that not all libraries were active in promoting artificial intelligence solutions. Most (57 %) of the libraries supported the inclusion of GAI in the repertoire of library tools, although only 39.3 % dealt with GAI issues. 46 % actively used them despite 50 % of the libraries creating conditions favorable for the use of GAI. Interestingly, 43 % of libraries indicated that they did not think there was a need to use GAI tools with the main reasons given including a lack of staff competencies and the appropriate regulations in the area. For those libraries using GAI or AI, 47 % of them had information about this published on their home pages and 39 % on their fan pages. The most common information found was about the promotion of AI tools, the resources available in the library, organized events (49,67 % of all information) and documents on the subject (36,77 % of the published information).}
}
@article{GUO2025102858,
title = {Dare to Fly? Analyzing psychological reactions and travel attitudes of Chinese social media users post-aviation accidents through text mining},
journal = {Journal of Air Transport Management},
volume = {128},
pages = {102858},
year = {2025},
issn = {0969-6997},
doi = {https://doi.org/10.1016/j.jairtraman.2025.102858},
url = {https://www.sciencedirect.com/science/article/pii/S0969699725001218},
author = {Yunxiao Guo and Jingqiang Tong and Junrong Zhao and Wei Pan and Xiayu Du and Jinghan Hu and Qingfeng Yang and Fangfang Wen and Zhihong Ren},
keywords = {Sudden aviation accident, Text mining, Sentiment analysis, Attitude},
abstract = {Background
Commercial air travel is essential to modern society, but aviation accidents can have profound psychological impacts. The public's emotional responses and attitudes toward air travel are shaped by factors such as the severity of the incident and its social repercussions.
Objectives
The study analyzes how the Chinese public's concerns, emotional responses, attributions, and attitudes toward air travel change following aviation accidents with varying severity and social impact. Additionally, it extends the application of the emotion-social information model in disaster scenarios and online behavior, providing valuable insights for crisis management.
Method
The study employs the LDA topic model to identify public concerns, sentiment analysis with an affective dictionary, and Naive Bayes for emotional attribution. Comments before and after the incidents were analyzed using Wilcoxon rank tests to assess changes in attitudes toward air travel.
Results
Public attention focused on victims, causes, and crew responses. Severe accidents elicited sadness, while less severe incidents prompted disgust and fear. Positive societal impacts from accidents improved emotions but did not significantly affect travel attitudes. Negative emotions led to a notable shift in attitudes toward air travel, while positive emotions had a limited effect.
Conclusions
The study provides valuable insights into the emotional dynamics following aviation accidents, enhancing the understanding of the emotion-social information model. It highlights the lasting impact of negative emotions on travel attitudes and the limited influence of positive emotions, with implications for psychological interventions and crisis management.}
}
@article{DUENASLERIN2025113059,
title = {Deep neural aggregation for recommending items to group of users},
journal = {Applied Soft Computing},
volume = {175},
pages = {113059},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113059},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625003709},
author = {Jorge Dueñas-Lerín and Raúl Lara-Cabrera and Fernando Ortega and Jesús Bobadilla},
keywords = {Group recommender systems, Collaborative filtering, Deep learning},
abstract = {Modern society dedicates a significant amount of time to digital interaction, as social life is more and more related to digital life, the information of groups’ interaction with the elements of the system is increasing. One key tool for the digital society is Recommender Systems, intelligent systems that learn from our past actions to propose new ones that align with our interests. Some of these systems have specialized in learning from the behavior of user groups to make recommendations to a group of individuals who want to perform a joint task. This research presents an innovative approach to representing group user preferences using deep learning techniques, enhancing recommendations for joint tasks. The proposed aggregation model has been evaluated using two different foundational models, GMF and MLP, four different datasets, and nine group sizes. The experimental results demonstrate the improvement achieved by employing the proposed aggregation model compared to the state-of-the-art, and this aggregation strategy can be applied to upcoming models and architectures.}
}
@article{KUMAR2024104462,
title = {A novel aspect of automatic vlog content creation using generative modeling approaches},
journal = {Digital Signal Processing},
volume = {148},
pages = {104462},
year = {2024},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2024.104462},
url = {https://www.sciencedirect.com/science/article/pii/S1051200424000873},
author = {Lalit Kumar and Dushyant Kumar Singh},
keywords = {Computer vision, Deep learning, Generative modeling, Image synthesis, Video synthesis},
abstract = {Generative models have emerged as potential tools for creating high-quality images, videos, and text. This paper explores the application of generative models in automating vlog content creation. It addresses both static and dynamic visual elements, eliminating the need for human intervention. Traditional vlogs often require specific environmental conditions and proper lighting for the vlog creation. To streamline this process, an automated system utilizing the generative models is proposed here. Generative models excel at generating realistic content that seamlessly integrates with real-world content. They enhance overall video quality and introduce creative elements by generating new scenes and backgrounds. This paper categorizes various generative modeling techniques based on frame elements and foreground-background conditions. It offers a comparative analysis of different generative model variants tailored for specific objectives. Furthermore, the paper reviews existing research on generative models for video and image content generation, visual quality enhancement, diversity, and coherence outcomes. Additionally, the paper highlights practical uses of the generative model for content creation in various contexts, such as face swapping, scene translation, and virtual content insertion. The paper also examines the public datasets used to train generative models. These datasets contain diverse visual content such as celebrity images, urban landscapes, and everyday scenes.}
}
@incollection{MUKHTAR202519,
title = {Chapter 2 - Artificial intelligence techniques for human-machine interaction},
editor = {Abdulhamit Subasi and Saeed Mian Qaisar and Humaira Nisar},
booktitle = {Artificial Intelligence and Multimodal Signal Processing in Human-Machine Interaction},
publisher = {Academic Press},
pages = {19-42},
year = {2025},
series = {Artificial Intelligence Applications in Healthcare and Medicine},
isbn = {978-0-443-29150-0},
doi = {https://doi.org/10.1016/B978-0-443-29150-0.00010-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044329150000010X},
author = {Hamid Mukhtar},
keywords = {Human-machine interaction, Artificial intelligence, Robots, Cobots, Industry 5.0, Speech, Emotion, Facial expression, Recognition, Generative AI},
abstract = {This chapter provides a broad overview of various artificial intelligence (AI) techniques employed in human-machine interaction (HMI). It explores a multitude of HMI techniques, each with its unique application area and AI approaches considered for its implementation. This chapter also delves into multimodal interaction and multimodal signal processing, integral parts of HMI. The techniques discussed range in their applications from personal experiences with machines to industrial use cases. Each technique's application area is examined, highlighting how AI enhances efficiency and effectiveness in these areas. Furthermore, the article delves into the AI-specific contemporary approaches used in HMI, such as neural networks and deep learning. This exploration provides an understanding of the integral role AI plays in advancing HMI, paving the way for future research and development in this dynamic field.}
}
@article{NEVADOCATALAN2023103013,
title = {An analysis of fake social media engagement services},
journal = {Computers & Security},
volume = {124},
pages = {103013},
year = {2023},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2022.103013},
url = {https://www.sciencedirect.com/science/article/pii/S0167404822004059},
author = {David Nevado-Catalán and Sergio Pastrana and Narseo Vallina-Rodriguez and Juan Tapiador},
keywords = {Fake engagement services, Social networks, Fraud, Cybercrime, Security economics},
abstract = {Fake engagement services allow users of online social media and other web platforms to illegitimately increase their online reach and boost their perceived popularity. Driven by socio-economic and even political motivations, the demand for fake engagement services has increased in the last years, which has incentivized the rise of a vast underground market and support infrastructure. Prior research in this area has been limited to the study of the infrastructure used to provide these services (e.g., botnets) and to the development of algorithms to detect and remove fake activity in online targeted platforms. Yet, the platforms in which these services are sold (known as panels) and the underground markets offering these services have not received much research attention. To fill this knowledge gap, this paper studies Social Media Management (SMM) panels, i.e., reselling platforms—often found in underground forums—in which a large variety of fake engagement services are offered. By daily crawling 86 representative SMM panels for 4 months, we harvest a dataset with 2.8 M forum entries grouped into 61k different services. This dataset allows us to build a detailed catalog of the services for sale, the platforms they target, and to derive new insights on fake social engagement services and its market. We then perform an economic analysis of fake engagement services and their trading activities by automatically analyzing 7k threads in underground forums. Our analysis reveals a broad range of offered services and levels of customization, where buyers can acquire fake engagement services by selecting features such as the quality of the service, the speed of delivery, the country of origin, and even personal attributes of the fake account (e.g., gender). The price analysis also yields interesting empirical results, showing significant disparities between prices of the same product across different markets. These observations suggest that the market is still undeveloped and sellers do not know the real market value of the services that they offer, leading them to underprice or overprice their services.}
}
@article{CAVNARHELVACI2024105593,
title = {Assessing the accuracy and reliability of ChatGPT’s medical responses about thyroid cancer},
journal = {International Journal of Medical Informatics},
volume = {191},
pages = {105593},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105593},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624002569},
author = {Burcak {Cavnar Helvaci} and Sema Hepsen and Burcu Candemir and Ogulcan Boz and Halil Durantas and Mehdi Houssein and Erman Cakal},
keywords = {Artificial intelligence, Thyroid cancer management, Health communication, Patient education},
abstract = {Purpose
ChatGPT has the potential to offer patient-friendly support. Thyroid carcinoma has become increasingly prevalent in recent years. This study aimed to assess ChatGPT’s accuracy and adequacy in answering questions about information, management, and emotional support related to thyroid cancer.
Methods
We conducted a three-step study. In the first step, ChatGPT responded to 30 questions about thyroid cancer. In the second step, we presented three different cases of thyroid cancer patients and asked ChatGPT about their diagnosis, treatment management, and follow-up. In the third step, we inquired about emotional support for patients and their families. Three expert endocrinologists graded these responses according to ATA guidelines.
Results
We showed that ChatGPT regurgitated extensive knowledge of thyroid cancer (76.66% correct), but only small proportions (6.66%) were labeled as mixed with correct and incorrect/outdated data. However, it was inadequate in the evaluation of clinical cases of thyroid cancer. It mentioned treatment and follow-up recommendations in a general framework, not patient-specific. Also, it provided practical and multifaceted emotional support advice to patients and caregivers regarding the next steps and adjusting to a new diagnosis.
Conclusion
Our study is the first to evaluate the competence and reliability of ChatGPT in thyroid cancer. Although ChatGPT is moderately competent in obtaining information about thyroid cancer, it has not yet been determined to be sufficiently competent and reliable in case management. It has been found effective in guiding patients and their relatives regarding emotional support.}
}
@article{YIN2024121894,
title = {A novel group multi-criteria sorting approach integrating social network analysis for ability assessment of health rumor-refutation accounts},
journal = {Expert Systems with Applications},
volume = {238},
pages = {121894},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.121894},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423023965},
author = {Mengzi Yin and Liyi Liu and Linqi Cheng and Zongmin Li and Yan Tu},
keywords = {Health rumor-refutation ability, Social media accounts, Group multi-criteria sorting, Social network analysis, Optimal clustering algorithm, Minimum discrimination information},
abstract = {Blooming social media platforms provide breeding ground for health rumors. Despite the establishment of accounts by numerous organizations to counter health rumors, the effectiveness of these endeavors exhibits considerable variability. Thus, there exists a pressing need to refine the framework and operation of rumor-refutation accounts. Aiming at enhancing the proficiency of accounts in refuting health rumors on social media platforms and exploring the factors affecting it, this paper proposes a novel group multi-criteria sorting approach integrating social network analysis (SNA) to classify accounts’ health rumor-refutation ability. To commence, an evaluation indicator system for accounts’ health rumor-refutation ability is established using SNA. Subsequently, the indicator values are computed, incorporating methods such as triangular fuzzy number (TFN), a lite bert (ALBERT) pre-trained language model, and PageRank. Furthermore, hesitant fuzzy linguistic term set (HFLTS) and triangular intuitionistic fuzzy number (TIFN) are used to determine the expert weights and indicator weights. After that, on the basis of original best worst method-sort (BWM-Sort), classification boundaries are discovered creatively using optimal clustering (OC), and minimum discrimination information (MDI) is adopted as the objective function for priority assignment. Consequently, an OC-MDI-BWM-Sort method is newly proposed which offers distinct advantages in computational efficiency, information integration, decision-making objectivity, and result effectiveness. Lastly, regarding to four cases of widely circulated rumors, health rumor-refutation ability of 35 accounts on Weibo platform is classified using the proposed method. The findings underscore that merely 8.57% of accounts exhibit stable and good health rumor-refutation ability, while up to 28.57% and 80.00% display poor and inconsistent ability in certain instances. Tailored to accounts with excellent or good, satisfactory or fair, and poor health rumor-refutation ability, respectively, managerial suggestions are provided regarding information expression standards, account operator proficiency, and account cooperation, and all accounts are advised to watch audience behavior.}
}
@article{PARK2025102852,
title = {Reconceptualizing the metaverse: A taxonomy for user experience analysis and insights from real-world platforms},
journal = {Technology in Society},
volume = {81},
pages = {102852},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102852},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25000429},
author = {Sunyoung Park and Dongjae Kim and Euiseog Jeong and Dahye Jeong and Eunil Park},
keywords = {Metaverse, User experience, Taxonomy, Review analysis, Co-occurrence network},
abstract = {While academia and industry share a common interest in the metaverse, there is a notable lack of consensus on its terminology. To bridge this gap, we propose a more suitable method for user experience analysis by integrating academic insights with real-world services. To this end, we developed a user experience-focused taxonomy by synthesizing academic perspectives and validating it across eight real-world platforms. In addition, we employ word co-occurrence network analysis to identify the primary concerns and opinions of real-world users. Our findings reveal that academia conceptualizes the metaverse through an idealized lens, emphasizing technical and functional aspects. However, real-world services do not necessarily adhere to the requirements outlined in academic definitions. For users, key concerns center on platform-specific characteristics, challenges, reliability, and privacy rather than technical factors. These results provide valuable insights by clarifying the metaverse’s definition and advocating for a more user-centered approach to its analysis and development.}
}
@article{2023iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {227},
pages = {iii-x},
year = {2023},
note = {8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(23)01906-3},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923019063}
}
@article{SHABBIR2024e35845,
title = {Beyond boundaries: Navigating the positive potential of ChatGPT, empowering education in underdeveloped corners of the world},
journal = {Heliyon},
volume = {10},
number = {16},
pages = {e35845},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35845},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024118762},
author = {Amna Shabbir and Safdar Rizvi and Muhammad Mansoor Alam and Mazliham Mohd Su'ud},
keywords = {ChatGPT, Artificial intelligence, Higher education, Authentic student work, Ethical writing},
abstract = {In November 2022, ChatGPT3, an advanced AI-powered chatbot, emerged suddenly, generating significant interest in higher education. Concerns arose regarding its potential to complicate the authentication of genuine student work. While some foresaw negative impacts, we advocate a positive outlook, suggesting educators can utilize ChatGPT to cultivate supportive learning environments that enhance students' character development. Our study thoroughly explores ChatGPT's implications for education in underdeveloped countries, examining both opportunities and challenges within AI research in education. We investigate practical applications, and potential benefits, and propose responsible integration strategies for students, teachers, and schools in utilizing ChatGPT for learning and assessment. Emphasizing ethical use, we stress leadership, character development, and authentic assessment as crucial factors. Despite concerns about academic integrity, we highlight ChatGPT's dual nature, it can facilitate cheating but also has the potential to deepen learning experiences. Our research focuses on understanding ChatGPT's impact on education from both student and teacher perspectives, discussing future trends in learning and teaching. The strategic integration of ChatGPT and AI in universities demands ethical foresight, personalized learning strategies, and ongoing research to optimize educational benefits while preserving core values and fostering student development.}
}
@article{SIMSEK2024S-68,
title = {315 GASTROENTEROLOGY SPECIFIC AI MODEL OUTPERFORMS ATTENDING PHYSICIAN CLINICAL NOTES IN A REAL-WORLD DATA EVALUATION},
journal = {Gastroenterology},
volume = {166},
number = {5, Supplement },
pages = {S-68-S-69},
year = {2024},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(24)00654-1},
url = {https://www.sciencedirect.com/science/article/pii/S0016508524006541},
author = {Cem Simsek and Berk Tinaz and Hasan S. Erol and Hikmet Demir and Beyza Atay and Yigit Yazarkan and Hakan Aydinli and Ali B. Bozdogan and Merih D. Toruner and Kimberly F. Schuster and Marvin Ryou and Pichamol Jirapinyo and Christopher C. Thompson}
}