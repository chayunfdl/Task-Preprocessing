@article{FORTUNA2021102524,
title = {How well do hate speech, toxicity, abusive and offensive language classification models generalize across datasets?},
journal = {Information Processing & Management},
volume = {58},
number = {3},
pages = {102524},
year = {2021},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2021.102524},
url = {https://www.sciencedirect.com/science/article/pii/S0306457321000339},
author = {Paula Fortuna and Juan Soler-Company and Leo Wanner},
keywords = {Hate speech, Offensive language, Classification, Generalization},
abstract = {A considerable body of research deals with the automatic identification of hate speech and related phenomena. However, cross-dataset model generalization remains a challenge. In this context, we address two still open central questions: (i) to what extent does the generalization depend on the model and the composition and annotation of the training data in terms of different categories?, and (ii) do specific features of the datasets or models influence the generalization potential? To answer (i), we experiment with BERT, ALBERT, fastText, and SVM models trained on nine common public English datasets, whose class (or category) labels are standardized (and thus made comparable), in intra- and cross-dataset setups. The experiments show that indeed the generalization varies from model to model and that some of the categories (e.g., ‘toxic’, ‘abusive’, or ‘offensive’) serve better as cross-dataset training categories than others (e.g., ‘hate speech’). To answer (ii), we use a Random Forest model for assessing the relevance of different model and dataset features during the prediction of the performance of 450 BERT, 450 ALBERT, 450 fastText, and 348 SVM binary abusive language classifiers (1698 in total). We find that in order to generalize well, a model already needs to perform well in an intra-dataset scenario. Furthermore, we find that some other parameters are equally decisive for the success of the generalization, including, e.g., the training and target categories and the percentage of the out-of-domain vocabulary.}
}
@article{NGUYEN2025,
title = {Decoding Digital Discourse Through Multimodal Text and Image Machine Learning Models to Classify Sentiment and Detect Hate Speech in Race- and Lesbian, Gay, Bisexual, Transgender, Queer, Intersex, and Asexual Community–Related Posts on Social Media: Quantitative Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/72822},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125006703},
author = {Thu T Nguyen and Xiaohe Yue and Heran Mane and Kyle Seelman and Penchala Sai Priya Mullaputi and Elizabeth Dennard and Amrutha S Alibilli and Junaid S Merchant and Shaniece Criss and Yulin Hswen and Quynh C Nguyen},
keywords = {multimodal machine learning, social media analysis, sentiment analysis, hate speech detection, cultural determinants of health, memes, public health, artificial intelligence, AI},
abstract = {Background
A major challenge in sentiment analysis on social media is the increasing prevalence of image-based content, which integrates text and visuals to convey nuanced messages. Traditional text-based approaches have been widely used to assess public attitudes and beliefs; however, they often fail to fully capture the meaning of multimodal content where cultural, contextual, and visual elements play a significant role.
Objective
This study aims to provide practical guidance for collecting, processing, and analyzing social media data using multimodal machine learning models. Specifically, it focuses on training and fine-tuning models to classify sentiment and detect hate speech.
Methods
Social media data were collected from Facebook and Instagram using CrowdTangle, a public insights tool by Meta, and from X via its academic research application programming interface. The dataset was filtered to include only race-related terms and lesbian, gay, bisexual, transgender, queer, intersex, and asexual community–related posts with image attachments, ensuring focus on multimodal content. Human annotators labeled 13,000 posts into 4 categories: negative sentiment, positive sentiment, hate, or antihate. We evaluated unimodal (Bidirectional Encoder Representations from Transformers for text and Visual Geometry Group 16 for images) and multimodal (Contrastive Language-Image Pretraining [CLIP], Visual Bidirectional Encoder Representations from Transformers [VisualBERTs], and an intermediate fusion) models. To enhance model performance, the synthetic minority oversampling technique was applied to address class imbalances, and latent Dirichlet allocation was used to improve semantic representations.
Results
Our findings highlighted key differences in model performance. Among unimodal models, Bidirectional Encoder Representations from Transformer outperformed Visual Geometry Group 16, achieving higher accuracy and macro–F1-scores across all tasks. Among multimodal models, CLIP achieved the highest accuracy (0.86) in negative sentiment detection, followed by VisualBERT (0.84). For positive sentiment, VisualBERT outperformed other models with the highest accuracy (0.76). In hate speech detection, the intermediate fusion model demonstrated the highest accuracy (0.91) with a macro–F1-score of 0.64, ensuring balanced performance. Meanwhile, VisualBERT performed best in antihate classification, achieving an accuracy of 0.78. Applying latent Dirichlet allocation and the synthetic minority oversampling technique improved minority class detection, particularly for antihate content. Overall, the intermediate fusion model provided the most balanced performance across tasks, while CLIP excelled in accuracy-driven classifications. Although VisualBERT performed well in certain areas, it struggled to maintain a precision-recall balance. These results emphasized the effectiveness of multimodal approaches over unimodal models in analyzing social media sentiment.
Conclusions
This study contributes to the growing research on multimodal machine learning by demonstrating how advanced models, data augmentation techniques, and diverse datasets can enhance the analysis of social media content. The findings offer valuable insights for researchers, policy makers, and public health professionals seeking to leverage artificial intelligence for social media monitoring and addressing broader societal challenges.}
}
@article{HELLWIG2025125514,
title = {Exploring large language models for the generation of synthetic training samples for aspect-based sentiment analysis in low resource settings},
journal = {Expert Systems with Applications},
volume = {261},
pages = {125514},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125514},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424023819},
author = {Nils Constantin Hellwig and Jakob Fehle and Christian Wolff},
keywords = {Natural language processing (NLP), Sentiment analysis (SA), Aspect-based sentiment analysis (ABSA), Large language models (LLMs), Synthetic data generation, Low-resource settings, Data augmentation},
abstract = {Aspect-Based Sentiment Analysis (ABSA) is a fine-grained task in sentiment analysis, aiming to identify sentiment expressed towards specific aspects of an entity. This paper explores the use of Large Language Models (LLMs), specifically GPT-3.5-turbo and Llama-3-70B, for generating annotated data in Aspect-Based Sentiment Analysis (ABSA), aiming to address the scarcity of labelled datasets in the field. Two low-resource scenarios are considered, with 25 and 500 manually annotated examples available. In the 25-example scenario, adding synthetic examples generated through few-shot prompting resulted in F1 scores of 81.33 for Aspect Category Detection (ACD) and 71.71 for Aspect Category Sentiment Analysis (ACSA). For the 500-example scenario, synthetic data augmentation showed a notable gain only for the ACSA task, raising the F1 score from 84.54 to 86.70.}
}
@article{GHALY2024166,
title = {Hate Speech Detection in Arabic Text: Survey},
journal = {Procedia Computer Science},
volume = {244},
pages = {166-177},
year = {2024},
note = {6th International Conference on AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.222},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924030230},
author = {Rehab Ghaly and Abeer ElKorany and Cherry A. Ezzat},
keywords = {Hate speech, Arabic Text Analytics, NLP, Social Media Platforms},
abstract = {In light of the continuous expansion of social media content, users have the freedom to express themselves without any boundaries or restrictions over the content. Unfortunately, this has increased the spread of hateful speech among users, which in turn has led to an increase in crimes, murders, and even acts of terrorism. Differentiating hate speech from other offensive language poses a significant challenge, requiring deep linguistic analysis. The task is further complicated by the scarcity of Arabic data resources, which significantly limits the availability of relevant information and the Arabic morphology's richness. This study seeks to conduct a comprehensive review of the current state of research on hate speech-related issues and automatic hate speech detection in Arabic text on social media platforms.}
}
@article{KASTRATI2025110136,
title = {Unlocking language barriers: Assessing pre-trained large language models across multilingual tasks and unveiling the black box with Explainable Artificial Intelligence},
journal = {Engineering Applications of Artificial Intelligence},
volume = {149},
pages = {110136},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110136},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625001368},
author = {Muhamet Kastrati and Ali Shariq Imran and Ehtesham Hashmi and Zenun Kastrati and Sher Muhammad Daudpota and Marenglen Biba},
keywords = {Large language models, Zero-shot classification, Explainable Artificial Intelligence, Sentiment analysis, Emotion recognition},
abstract = {Large Language Models (LLMs) have revolutionized many industrial applications and paved the way for fostering a new research direction in many fields. Conventional Natural Language Processing (NLP) techniques, for instance, are no longer necessary for many text-based tasks, including polarity estimation, sentiment and emotion classification, and hate speech detection. However, training a language model for domain-specific tasks is hugely costly and requires high computational power, thereby restricting its true potential for standard tasks. This study, therefore, provides a comprehensive analysis of the latest pre-trained LLMs for various NLP-related applications without fine-tuning them to evaluate their effectiveness. Five language models are thus employed in this study on six distinct NLP tasks (including emotion recognition, sentiment analysis, hate speech detection, irony detection, offensiveness detection, and stance detection) for 12 languages from low- to medium- and high-resource. Generative Pre-trained Transformer 4 (GPT-4) and Gemini Pro outperform state-of-the-art models, achieving average F1 scores of 70.6% and 68.8% on the Tweet Sentiment Multilingual dataset compared to the state-of-the-art average F1 score of 66.8%. The study further interprets the findings obtained by the LLMs using Explainable Artificial Intelligence (XAI). To the best of our knowledge, it is the first time any study has employed explainability on pre-trained language models.}
}
@article{AZIZ2024102221,
title = {Enhanced UrduAspectNet: Leveraging Biaffine Attention for superior Aspect-Based Sentiment Analysis},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {9},
pages = {102221},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102221},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824003100},
author = {Kamran Aziz and Naveed Ahmed and Hassan Jalil Hadi and Aizihaierjiang Yusufu and Mohammaed Ali Alshara and Yasir Javed and Donghong Ji},
keywords = {Natural language processing, Deep learning, Aspect-based sentiment analysis, Sentiment classification},
abstract = {Urdu, with its rich linguistic complexity, poses significant challenges for computational sentiment analysis. This study presents an enhanced version of UrduAspectNet, specifically designed for Aspect-Based Sentiment Analysis (ABSA) in Urdu. We introduce key innovations including the incorporation of Biaffine Attention into the model architecture, which synergizes XLM-R embeddings, a bidirectional LSTM (BiLSTM), and dual Graph Convolutional Networks (GCNs). Additionally, we utilize dependency parsing to create the adjacency matrix for the GCNs, capturing syntactic dependencies to enhance relational representation. The improved model, termed Enhanced UrduAspectNet, integrates POS and lemma embeddings, processed through BiLSTM and GCN layers, with Biaffine Attention enhancing the extraction of intricate aspect and sentiment relationships. We also introduce the use of BIO tags for aspect term identification, improving the granularity of aspect extraction. Experimental results demonstrate significant improvements in both aspect extraction and sentiment classification accuracy. This research advances Urdu sentiment analysis and sets a precedent for leveraging sophisticated NLP techniques in underrepresented languages.}
}
@article{NIE2024127642,
title = {Modeling implicit variable and latent structure for aspect-based sentiment quadruple extraction},
journal = {Neurocomputing},
volume = {586},
pages = {127642},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127642},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224004132},
author = {Yu Nie and Jianming Fu and Yilai Zhang and Chao Li},
keywords = {Natural language processing, Text mining, Sentiment analysis, Variational model, Latent graph},
abstract = {The realm of aspect-based sentiment analysis (ABSA), which delves into the nuanced sentiment expressions individuals hold towards specific services or products, has demonstrated immense potential in real-world applications. Recently, ABSA has evolved into the development of aspect-based sentiment quadruple extraction (ASQP). ASQP’s objective is to predict four crucial sentiment elements: aspect, sentiment, opinion and category, where such comprehensive approach paints a holistic description of sentiment, facilitating downstream applications. However, prevailing ASQP models suffer from various limitations, such as inefficiency in decoding, inadequate handling of implicit aspects and opinions, and underutilization of structural information. In this paper, we explore an innovative approach to enhance ASQP. Firstly, we adopt a pointer-based non-autoregressive generative framework, enabling the parallel generation of all sentiment quadruples. This approach preserves the advantages of generative methods while significantly boosting decoding efficiency. Additionally, we introduce latent variable learning to model the aspect and opinion elements, effectively enhancing our ability to reason about implicit ASQP components. Furthermore, we propose an aspect-and-opinion-guided latent structure to bolster sentiment-aware context learning. This dynamically induced graph structure adapts to the specific requirements of the task, offering optimal support for ASQP. Our method outperforms current state-of-the-art models on four benchmark ASQP datasets, demonstrating its significant superiority. A detailed analysis highlights the benefits of non-autoregressive decoding in achieving high inference efficiency, the effectiveness of the variational module in capturing implicit sentiment elements, and the value of the dynamically induced latent structure in accurate sentiment feature learning. Moreover, our system excels in producing interpretable predictions.}
}
@article{JIANG2025125556,
title = {IFusionQuad: A novel framework for improved aspect-based sentiment quadruple analysis in dialogue contexts with advanced feature integration and contextual CloBlock},
journal = {Expert Systems with Applications},
volume = {261},
pages = {125556},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125556},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424024230},
author = {Haoyu Jiang and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Xu Gu and Peng Lu},
keywords = {Natural language processing, Aspect-based sentiment analysis, Aspect sentiment quadruple extraction, DiaASQ},
abstract = {Aspect-based sentiment analysis (ABSA) represents a crucial field of natural language processing (NLP). It focuses on deriving detailed sentiment insights from textual content. Dialogue-level aspect-based sentiment quadruple extraction (DiaASQ) is specifically concerned with pinpointing target-aspect-opinion-emotion quadruples within conversations. DiaASQ is important in industries like e-commerce, social media analytics, and customer feedback. However, Current ABSA approaches predominantly focus on single-text scenarios, often overlooking the complexities involved in sentiment analysis within conversational contexts. To fill this gap, this paper presents the IFusionQuad model, which is specifically designed for the DiaASQ task. Our contributions include the innovative integration of CloBlock in ABSA, enhancing feature representation with context-aware weights. The InteractiveNet Fusion Module further advances dialogue understanding by aggregating dialogue-specific features such as threads, speakers, and replies. Components such as CloBlock, gating mechanism, and Biaffine attention effectively mitigate data noise issues, improving the relevance of feature extraction. Empirical evaluation on standard datasets demonstrates that the IFusionQuad model outperforms baseline methods, achieving substantial improvements in quadruple extraction. Specifically, our model shows a 6.59% increase in micro F1 and a 7.05% increase in identification F1 for Chinese datasets, and a 2.65% and 4.69% increase in micro F1 and identification F1, respectively, for English datasets. The results clearly demonstrate our IFusionQuad model’s efficacy, which consistently outperforms baseline models across all evaluation datasets on the DiaASQ task.}
}
@article{HAN2025100105,
title = {Aspect-based sentiment evolution and its correlation with review rounds in multi-round peer reviews: A deep learning approach},
journal = {Data and Information Management},
pages = {100105},
year = {2025},
issn = {2543-9251},
doi = {https://doi.org/10.1016/j.dim.2025.100105},
url = {https://www.sciencedirect.com/science/article/pii/S2543925125000130},
author = {Ruxue Han and Haomin Zhou and Jiangtao Zhong and Chengzhi Zhang},
keywords = {Multiple rounds of peer review, Content mining of review comments, Aspect-based sentiment analysis, Correlation analysis},
abstract = {Mining sentiment information from the textual content of peer review comments offers valuable insights into the scientific evaluation process. However, previous studies are often constrained by coarse-grained analysis and the lack of differentiation across review rounds. Notably, the dynamic shifts in reviewers' focus and sentiment tendencies throughout multiple review stages remain underexplored. To address this gap, the present study investigates the distribution and evolution of aspect-level sentiments and examines their correlation with the number of review rounds. We begin by segmenting the multi-round review comments of 11,063 accepted papers from Nature Communications and identifying fine-grained review aspect clusters. A manually annotated corpus of approximately 5000 review sentences is then constructed. Using this dataset, we train a series of deep learning-based aspect sentiment classification models. Among them, the LCF-BERT-CDM model achieves the best performance, with a Macro-F1 score of 82.65 %. Subsequent statistical analysis reveals a consistent trend: as the number of review rounds increases, the proportion of positive sentiments rises, while negative sentiments decline. Correlation analysis further indicates that aspect sentiment scores are negatively associated with the total number of review rounds. Key aspects exhibiting stronger correlations include “experiments”, “research significance” and “result analysis”.}
}
@article{JIN2024122289,
title = {WordTransABSA: Enhancing Aspect-based Sentiment Analysis with masked language modeling for affective token prediction},
journal = {Expert Systems with Applications},
volume = {238},
pages = {122289},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.122289},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423027914},
author = {Weiqiang Jin and Biao Zhao and Yu Zhang and Jia Huang and Hang Yu},
keywords = {Natural Language Processing, Aspect-based Sentiment Analysis, Masked Language Model, Pre-trained Language Model, Few-shot supervised learning},
abstract = {In recent years, Aspect-based Sentiment Analysis (ABSA) has been a crucial yet challenging task in recognizing textual emotions from text. ABSA has numerous application across various fields, such as social media, commodity review, and movie comment, making it an attractive area of research. Many researchers are working to develop more powerful sentiment analysis models. Currently, most existing ABSA models use the generic pre-trained language models (PLMs) based fine-tuning paradigm, which only utilizes the encoder parameters while discarding the decoder parameters of PLMs. However, this approach fails to leverage the prior knowledge revealed in PLMs effectively. To address these issues, we investigate the potential of the initial pre-training scheme of PLMs to conduct ABSA and thus propose a novel approach in this paper, namely Target Word Transferred ABSA (WordTransABSA). In WordTransABSA, we propose “Word Transferred LM”, a novel sequence-level optimization strategy that transferred target words in sentence into pivot tokens to stimulate better PLM semantic understanding capability. Given a sentence with aspect terms as input, WordTransABSA generates contextually appropriate semantics and predicts the affective tokens on the corresponding positions of the aspect terms. The final sentiment polarity of each aspect term is determined through several sentiment identification strategies that we selected. WordTransABSA takes full advantage of the versatile linguistic knowledge of Pre-trained Language Model, resulting in competitive accuracy compared with recent baselines. The WordTransABSA demonstrates its superiority and effectiveness through extensive experiments in both data-sufficient (full-data supervised learning) and data-insufficient (few-shot learning) scenarios. We have made our code publicly available on GitHub: https://github.com/albert-jin/WordTransABSA.}
}
@article{HASHMI2025125843,
title = {Self-supervised hate speech detection in Norwegian texts with lexical and semantic augmentations},
journal = {Expert Systems with Applications},
volume = {264},
pages = {125843},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125843},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424027106},
author = {Ehtesham Hashmi and Sule Yildirim Yayilgan and Muhammad Mudassar Yamin and Mohamed Abomhara and Mohib Ullah},
keywords = {Hate speech, Natural language processing, Data augmentation, Self-representation learning, Transformers},
abstract = {The proliferation of social media platforms has significantly contributed to the spread of hate speech, targeting individuals based on race, gender, impaired functioning, religion, or sexual orientation. Online hate speech not only provokes prejudice and violence in cyber-space, but it also has profound impacts in real-world communities, eroding social harmony and increasing the risk of physical harm. This necessitates the urgency for effective hate speech detection systems, especially in low-resource languages such as Norwegian, where limited data availability presents additional challenges. This study utilizes the Barlow Twins methodology, applying a self-supervised learning framework to initially develop robust language representations for Norwegian, a language that is typically underrepresented in NLP research. These learned representations are then utilized in a semi-supervised classification task to detect hate speech. Leveraging a combination of text augmentation techniques at both the word and sentence level, along with self-training strategies, our approach demonstrates the potential to efficiently learn meaningful representations with a minimal amount of annotated data. Experimental results show that the Nor-BERT model is well-suited for detecting hate speech within the limited Norwegian data available, consistently outperforming other models. Additionally, Nor-BERT surpassed all deep learning-based models in terms of F1-score.}
}
@article{ALTURAYEIF2025125525,
title = {EASE: An enhanced active learning framework for aspect-based sentiment analysis based on sample diversity and data augmentation},
journal = {Expert Systems with Applications},
volume = {261},
pages = {125525},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125525},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424023923},
author = {Nouf Alturayeif and Irfan Ahmad},
keywords = {Aspect-based sentiment analysis, Active learning, Deep learning},
abstract = {Aspect-Based Sentiment Analysis (ABSA) has received considerable attention in recent studies. Powerful pre-trained models were proposed which can be fine-tuned for many Natural Language Processing (NLP) tasks, including ABSA. However, fine-tuning these models needs a relatively large amount of labeled data. In this research, we propose EASE; an active learning framework to minimize manual labeling effort. We extend the active learning technique by incorporating the concept of sample diversity where similar samples are not selected for labeling. Furthermore, we maximize the utility of these samples by incorporating data augmentation. EASE was evaluated on three benchmark ABSA datasets from three different domains. The results show that the reduction of the number of needed labeled samples ranges from 88% to 94% among the three datasets while maintaining accuracy. Our results show that active learning is an effective approach to reduce manual labeling effort while maintaining comparable performance. Moreover, it is possible to reduce the number of labeled data even further by incorporating sample diversity and data augmentation while maintaining performance.}
}
@article{ZHU2025125295,
title = {Aspect-based sentiment analysis via bidirectional variant spiking neural P systems},
journal = {Expert Systems with Applications},
volume = {259},
pages = {125295},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125295},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424021626},
author = {Chao Zhu and Benshun Yi and Laigan Luo},
keywords = {Aspect-based sentiment analysis, Spiking neural P systems, Natural language processing, Dual attention},
abstract = {In recent years, aspect-based sentiment classification has predominantly relied on artificial neural networks, achieving notable success. However, effectively capturing the contextual semantic relationships between aspects and content has remained challenging. To address this issue, we propose an innovative approach for aspect-based sentiment analysis. Our method uses a Bidirectional Variant Spiking Neural P System (Bi-VSNP) as a context encoding module, integrated with a two-channel mechanism to extract context and aspect features. Furthermore, Our dual attention mechanism leverages the relationship between aspects and context, allowing the model to focus on key sentiment information. We rigorously evaluated our method on publicly available datasets, demonstrating its superior performance over most models based on artificial neural networks as context extraction. Compared to other models utilizing SNP methods, our approach achieves performance improvements of 1.72%, 1.27%, and 1.05% on the Laptop, Restaurant, and Twitter datasets, respectively. These results underscore the efficacy of our approach in aspect-based sentiment classification.}
}
@article{MAGHSOUDI2025114269,
title = {A novel approach to customer segmentation for product development on social media data: integrating aspect-based sentiment analysis and text mining},
journal = {Knowledge-Based Systems},
volume = {328},
pages = {114269},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114269},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125013103},
author = {Mehrdad Maghsoudi and Navid Mohammadi and Mohammadreza Bakhtiari},
keywords = {Data-driven product development, Customer segmentation, User preference, Aspect-based sentiment analysis, Product innovation},
abstract = {This study presents a novel framework for customer segmentation in the laptop market, leveraging Aspect-Based Sentiment Analysis (ABSA) and graph-based community detection to analyze over 1.4 million tweets from X (formerly Twitter). By combining feature-specific sentiment analysis with dynamic user categorization, the research bridges critical gaps in understanding how diverse consumer needs and preferences influence product development strategies. The findings reveal distinct regional variations: consumers in developing markets prioritize affordability and core features like design and battery life, demonstrating higher satisfaction levels, whereas those in developed markets demand advanced specifications, such as high-performance CPUs, GPUs, and thermal management, yet express lower satisfaction due to heightened expectations. Universal pain points, including battery life and charging inefficiencies, highlight cross-market opportunities for innovation. The analysis identifies diverse personas, such as Everyday Office Workers and Student Programmers in developing countries, and Power Users and Connectivity Enthusiasts in developed regions, offering actionable insights for tailoring product features and marketing strategies to meet specific user needs. This research introduces a cutting-edge method for integrating sentiment analysis with user segmentation, enabling manufacturers to align product designs with evolving consumer demands effectively. The study concludes by emphasizing the potential of this framework to drive innovation in new product development while laying a foundation for future research on emerging trends and advanced analytical techniques.}
}
@article{MU2024112166,
title = {HA-GCEN: Hyperedge-abundant graph convolutional enhanced network for hate speech detection},
journal = {Knowledge-Based Systems},
volume = {300},
pages = {112166},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112166},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124008001},
author = {Yufei Mu and Jin Yang and Tianrui Li and Siyu Li and Weiheng Liang},
keywords = {Hate speech detection, Hypergraph, Online social networks, Graph neural networks},
abstract = {The proliferation of online social networks (OSNs) has led to the rampant spread of hate speech. However, traditional detection methods often struggle to effectively detect various forms of hate speech with satisfactory performance, primarily because these methods typically rely on graph-based models that tend to focus on pairwise relationships, thus failing to fully exploit the contextual and user-specific information that could unveil more subtle forms of hate speech. However, establishing a complete graph inevitably introduces considerable computational overhead and redundant information. To overcome these limitations, this study introduces a hyperedge-abundant graph convolutional enhanced network (HA-GCEN) learning framework for hate speech detection (HSD) in OSNs. The proposed hypergraph construction method with a hypergraph convolutional enhanced network primarily consists of three content-, relation-, and semanteme-hyperedge components. These components were designed to enhance context sensitivity, to comprehensively improve the understanding of group relationships and detect latent hate speech. Furthermore, the HA-GCEN was carefully designed to extract high-level correlations from the constructed hypergraph through hypergraph convolutional layers. The efficiency of the proposed method was validated on two benchmark datasets, SemEval2019 task 5 and FUNC, achieving significant improvements over state-of-the-art methods with increases of 5.74% and 2.56% in the F1 score, 5.43% and 1.47% in precision, and 5.98% and 3.47% in recall, respectively. These results attest to HA-GCEN’s advanced feature mining and learning capabilities, demonstrating its potential for more effective HSD within OSNs.}
}
@article{PURWITASARI2023108951,
title = {A stance dataset with aspect-based sentiment information from Indonesian COVID-19 vaccination-related tweets},
journal = {Data in Brief},
volume = {47},
pages = {108951},
year = {2023},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2023.108951},
url = {https://www.sciencedirect.com/science/article/pii/S2352340923000690},
author = {Diana Purwitasari and Cornelius Bagus Purnama Putra and Agus Budi Raharjo},
keywords = {Stance detection, Aspect-based sentiment analysis, Twitter, COVID-19 vaccination},
abstract = {As a platform of social media with high activity, Twitter has seen the discussion of many hot topics related to the COVID-19 pandemic. One such is the COVID-19 vaccination program, which has skeptics in several religious, ethnic, and socioeconomic groups, and Indonesia has one of the largest populations of various ethnicities and religions of countries worldwide. Diverse opinions based on skepticism about the effectiveness of vaccines can increase the number of people who refuse or delay vaccine acceptance. Therefore, it is important to analyze and monitor stances and public opinions on social media, especially on vaccine topics, as part of the long-term solution to the COVID-19 pandemic. This study presents the Indonesian COVID-19 vaccine-related tweets data set that contains stance and aspect-based sentiment information. The data were collected monthly from January to October 2021 using specific keywords. There are nine thousand tweets manually annotated by three independent analysts. We annotated each tweet with three labels of stance and seven predetermined aspects related to Indonesian COVID-19 vaccine-related tweets: services, implementation, apps, costs, participants, vaccine products, and general. The dataset is useful for many research purposes, including stance detection, aspect-based sentiment analysis, topic detection, and public opinion analysis on Twitter, especially on the policies regarding the prevention of pandemics.}
}
@article{LU2025103917,
title = {QAIE: LLM-based Quantity Augmentation and Information Enhancement for few-shot Aspect-Based Sentiment Analysis},
journal = {Information Processing & Management},
volume = {62},
number = {1},
pages = {103917},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103917},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324002760},
author = {Heng-yang Lu and Tian-ci Liu and Rui Cong and Jun Yang and Qiang Gan and Wei Fang and Xiao-jun Wu},
keywords = {Natural language understanding, Information extraction, Aspect-Based Sentiment Analysis, Few-shot learning, Large language models},
abstract = {Aspect-based Sentiment Analysis (ABSA) aims to extract fine-grained sentiment information from online reviews. Few-shot ABSA faces challenges with limited labeled data and recent generative models have outperformed traditional classification models. Existing methods use Question Answering (QA) templates with Text-to-Text Transfer Transformer (T5) to extract sentiment elements, introducing a generative sentiment analysis paradigm. However, these models often fail to fully grasp ABSA rules, generating non-standard or incorrect outputs. This issue also arises with large language models (LLMs) due to insufficient labeled data for tuning and learning. Additionally, ABSA datasets often include many short, uninformative reviews, complicating sentiment element extraction in few-shot scenarios. This paper addresses two major challenges in few-shot ABSA: (1) How to let the generative model well understand the ABSA rules under few-shot scenarios. (2) How to enhance the review text with richer information. We propose a Quantity Augmentation and Information Enhancement (QAIE) approach, leveraging LLMs to generate fluent texts and infer implicit information. First, we propose a quantity augmentation module, which leverages the large language model (LLM) to obtain sufficient labeled data for the generative model to learn the ABSA rules better. Then, we introduce an information enhancement module, which brings more informative input to the generative model by enhancing the information in the review. Comprehensive experiments on five ABSA tasks using three widely-used datasets demonstrate that our QAIE model achieves approximately 10% improvement over state-of-the-art models. Specifically, for the most challenging ASQP task, our LLM-based model is compared with the existing state-of-the-art models on datasets Rest15 and Rest16, achieving F1 gains of 9.42% and 6.45% respectively in the k=5 few-shot setting.}
}
@article{KAMINSKA2023521,
title = {Fuzzy rough nearest neighbour methods for detecting emotions, hate speech and irony},
journal = {Information Sciences},
volume = {625},
pages = {521-535},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.01.054},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523000543},
author = {Olha Kaminska and Chris Cornelis and Veronique Hoste},
keywords = {Natural language processing, Emotion detection, Fuzzy rough sets, Text embeddings},
abstract = {Due to the ever-expanding volumes of information available on social media, the need for reliable and efficient automated text understanding mechanisms becomes evident. Unfortunately, most current approaches rely on black-box solutions rooted in deep learning technologies. In order to provide a more transparent and interpretable framework for extracting intrinsic text characteristics like emotions, hate speech and irony, we propose to integrate fuzzy rough set techniques and text embeddings. We apply our methods to different classification problems originating from Semantic Evaluation (SemEval) competitions, and demonstrate that their accuracy is on par with leading deep learning solutions.}
}
@article{KAZIENKO202343,
title = {Human-centered neural reasoning for subjective content processing: Hate speech, emotions, and humor},
journal = {Information Fusion},
volume = {94},
pages = {43-65},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523000167},
author = {Przemysław Kazienko and Julita Bielaniewicz and Marcin Gruza and Kamil Kanclerz and Konrad Karanowski and Piotr Miłkowski and Jan Kocoń},
keywords = {Content perception, NLP, Subjective NLP tasks, Personalized NLP, Offensive content, Hate speech, Emotion recognition, Humor detection, Learning human representations, Human bias, Text classification, Information fusion},
abstract = {Some tasks in content processing, e.g., natural language processing (NLP), like hate or offensive speech and emotional or funny text detection, are subjective by nature. Each human may perceive some content individually. The existing reasoning methods commonly rely on agreed output values, the same for all recipients. We propose fundamentally different — personalized solutions applicable to any subjective NLP task. Our five new deep learning models take into account not only the textual content but also the opinions and beliefs of a given person. They differ in their approaches to learning Human Bias (HuBi) and fusion with content (text) representation. The experiments were carried out on 14 tasks related to offensive, emotional, and humorous texts. Our personalized HuBi methods radically outperformed the generalized ones for all NLP problems. Personalization also has a greater impact on reasoning quality than commonly explored pre-trained and fine-tuned language models. We discovered a high correlation between human bias calculated using our dedicated formula and that learned by the model. Multi-task solutions achieved better outcomes than single-task architectures. Human and word embeddings also provided additional insights.}
}
@article{LI2026129017,
title = {Extracting structured sentiment quadruples by labeling boundary token pairs for aspect-based sentiment analysis},
journal = {Expert Systems with Applications},
volume = {296},
pages = {129017},
year = {2026},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.129017},
url = {https://www.sciencedirect.com/science/article/pii/S095741742502634X},
author = {You Li and Shaocong Zhang and Yuming Lin and Yongdong Lin and Liang Chang},
keywords = {Structured sentiment analysis, Boundary token pair, Syntactic dependency},
abstract = {Aspect-based sentiment analysis (ABSA) provides accurate and in-depth information about users’ opinions. It has received considerable attention in recent years. Most existing research on ABSA targets extracting the aspect terms, opinion terms and sentiment polarities individually or the combinations of these roles. However, another key opinion role, i.e., opinion holder, has been ignored in these studies. The addition of an opinion holder greatly increases the complexity of the relationships between opinion roles and makes the ABSA task more challenging. In this work, we focus on extracting structured sentiment quadruples from unstructured texts. This forms a more complete picture of the sentiment information through the quadruple of the (opinion) holder, the aspect target term, the corresponding opinion term, and the expressed sentiment. We propose a boundary-sensitive token pair labeling framework (BTPL) for extracting different opinion roles and the corresponding relations in texts. This process can effectively identify the long-span roles and addresses the problem of role overlap between sentiment quadruples. Additionally, BTPL extracts four roles and their corresponding relations synchronously, which avoids error propagation encountered by existing ABSA pipeline methods. Moreover, based on syntactic dependency information, we use the conditional layer normalization module to generate high-quality representations for the candidate token pairs. We conduct extensive experiments on five public datasets to verify the proposed framework. Experimental results show that the proposed BTPL achieves state-of-the-art performances.}
}
@article{DELAPENASARRACEN2023103433,
title = {Systematic keyword and bias analyses in hate speech detection},
journal = {Information Processing & Management},
volume = {60},
number = {5},
pages = {103433},
year = {2023},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2023.103433},
url = {https://www.sciencedirect.com/science/article/pii/S030645732300170X},
author = {Gretel Liz {De la Peña Sarracén} and Paolo Rosso},
keywords = {Hate speech detection, Keyword extraction, Bias analysis, Bias mitigation},
abstract = {Hate speech detection refers broadly to the automatic identification of language that may be considered discriminatory against certain groups of people. The goal is to help online platforms to identify and remove harmful content. Humans are usually capable of detecting hatred in critical cases, such as when the hatred is non-explicit, but how do computer models address this situation? In this work, we aim to contribute to the understanding of ethical issues related to hate speech by analysing two transformer-based models trained to detect hate speech. Our study focuses on analysing the relationship between these models and a set of hateful keywords extracted from the three well-known datasets. For the extraction of the keywords, we propose a metric that takes into account the division among classes to favour the most common words in hateful contexts. In our experiments, we first compared the overlap between the extracted keywords with the words to which the models pay the most attention in decision-making. On the other hand, we investigate the bias of the models towards the extracted keywords. For the bias analysis, we characterize and use two metrics and evaluate two strategies to try to mitigate the bias. Surprisingly, we show that over 50% of the salient words of the models are not hateful and that there is a higher number of hateful words among the extracted keywords. However, we show that the models appear to be biased towards the extracted keywords. Experimental results suggest that fitting models with hateful texts that do not contain any of the keywords can reduce bias and improve the performance of the models.}
}
@article{ALMAHDI2025110296,
title = {Enhancing cross-lingual hate speech detection through contrastive and adversarial learning},
journal = {Engineering Applications of Artificial Intelligence},
volume = {147},
pages = {110296},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110296},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625002969},
author = {Asseel Jabbar Almahdi and Ali Mohades and Mohammad Akbari and Soroush Heidary},
keywords = {Hate speech detection, Cross-lingual, Contrastive learning, Adversarial training, Zero-shot learning},
abstract = {The rise of hate speech on social media platforms, particularly in low-resource languages, necessitates innovative solutions. In response, we introduce a zero and few-shot model combining supervised contrastive learning and adversarial training. To address the scarcity of labeled data in diverse languages, our approach adapts features from well-resourced languages to efficiently detect hate speech in low-resource contexts. The proposed framework first leverages supervised contrastive learning, maximizing the utility of limited labeled data by transferring knowledge from source languages. This adaptation empowers the accurate detection of hate speech in underrepresented languages, optimizing available resources. We then introduce contrastive adversarial training, refining hate speech representations in low-resource languages. This approach ensures a nuanced understanding of hate speech across linguistic boundaries, significantly enhancing the model’s adaptability and accuracy. To validate our approach, we conducted zero-shot and few-shot cross-lingual evaluations in three languages. Our results demonstrate the superiority of the proposed contrastive learning-based models. To ensure reproducibility, the code associated with this paper is available on GitHub (Almahdi, 2024). .}
}
@article{RAZA2024100098,
title = {HarmonyNet: Navigating hate speech detection},
journal = {Natural Language Processing Journal},
volume = {8},
pages = {100098},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100098},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000463},
author = {Shaina Raza and Veronica Chatrath},
keywords = {Hate speech, Transformer-based models, Language models},
abstract = {In the digital era, social media platforms have become central to communication across various domains. However, the vast spread of unregulated content often leads to the prevalence of hate speech and toxicity. Existing methods to detect this toxicity struggle with context sensitivity, accommodating diverse dialects, and adapting to varied communication styles. To tackle these challenges, we introduce an ensemble classifier that leverages the strengths of language models and traditional deep neural network architectures for more effective hate speech detection on social media. Our evaluations show that this hybrid approach outperforms individual models and exhibits robustness against adversarial attacks. Future efforts will aim to enhance the model’s architecture to further boost its efficiency and extend its capability to recognize hate speech across an even wider range of languages and dialects.}
}
@article{KHANDUJA2024200112,
title = {Telugu language hate speech detection using deep learning transformer models: Corpus generation and evaluation},
journal = {Systems and Soft Computing},
volume = {6},
pages = {200112},
year = {2024},
issn = {2772-9419},
doi = {https://doi.org/10.1016/j.sasc.2024.200112},
url = {https://www.sciencedirect.com/science/article/pii/S2772941924000413},
author = {Namit Khanduja and Nishant Kumar and Arun Chauhan},
keywords = {Offensive text, Hate speech, Deep learning, NLP, Transformers, Low-resource languages},
abstract = {In today's digital era, social media has become a new tool for communication and sharing information, with the availability of high-speed internet it tends to reach the masses much faster. Lack of regulations and ethics have made advancement in the proliferation of abusive language and hate speech has become a growing concern on social media platforms in the form of posts, replies, and comments towards individuals, groups, religions, and communities. However, the process of classification of hate speech manually on online platforms is cumbersome and impractical due to the excessive amount of data being generated. Therefore, it is crucial to automatically filter online content to identify and eliminate hate speech from social media. Widely spoken resource-rich languages like English have driven the research and achieved the desired result due to the accessibility of large corpora, annotated datasets, and tools. Resource-constrained languages are not able to achieve the benefits of advancement due to a lack of data corpus and annotated datasets. India has diverse languages that change with demographics and languages that have limited data availability and semantic differences. Telugu is one of the low-resource Dravidian languages spoken in the southern part of India. In this paper, we present a monolingual Telugu corpus consisting of tweets posted on Twitter annotated with hate and non-hate labels and experiments to provide a comparison of state-of-the-art fine-tuned deep learning models (mBERT, DistilBERT, IndicBERT, NLLB, Muril, RNN+LSTM, XLM-RoBERTa, and Indic-Bart). Through transfer learning and hyperparameter tuning, the models are compared for their effectiveness in classifying hate speech in Telugu text. The fine-tuned mBERT model outperformed all other fine-tuned models achieving an accuracy of 98.2. The authors also propose a deployment model for social media accounts.}
}
@article{HUANG2026103543,
title = {Text-Dominant Speech-Enhanced for Multimodal Aspect-Based Sentiment Analysis network},
journal = {Information Fusion},
volume = {126},
pages = {103543},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103543},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525006153},
author = {Xiaoyong Huang and Heli Sun and Xuechun Liu and Jiaruo Wu and Liang He},
keywords = {Multimodal Aspect-Based Sentiment Analysis, Speech enhancement, Visual expression deficiency},
abstract = {Existing Multimodal Aspect-Based Sentiment Analysis techniques primarily focus on associating visual and textual content but often overlook the critical issue of visual expression deficiency, where images fail to provide complete aspect terms and sufficient sentiment signals. To address this limitation, we propose a Multimodal Aspect-Based Sentiment Analysis network that leverages Text-Dominant Speech Enhancement (TDSEN), aiming to alleviate the deficiency in visual expression by synthesizing speech and employing a text-dominant approach. Specifically, we introduce a Text-Driven Speech Enhancement Layer that generates speech with stable timbre to identify all aspect terms, compensate for the lacking parts of visual expression, and provide additional aspect term information and emotional cues. Meanwhile, we design a semantic distance mask matrix to enhance the capability of capturing key information from the textual modality. Furthermore, a text-driven multimodal feature fusion module is incorporated to strengthen the dominant role of text and facilitate multimodal feature interaction and integration for the extraction of the term of the aspect and sentiment recognition. Comprehensive evaluations on the Twitter-2015 and Twitter-2017 benchmarks demonstrate TDSEN’s superiority, achieving absolute improvements of 2.6% and 1.7% over state-of-the-art baselines, with ablation studies confirming the necessity of each component.}
}
@article{KAR2023107143,
title = {Sentimental analysis & Hate speech detection on English and German text collected from social media platforms using optimal feature extraction and hybrid diagonal gated recurrent neural network},
journal = {Engineering Applications of Artificial Intelligence},
volume = {126},
pages = {107143},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107143},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623013271},
author = {Purbani Kar and Swapan Debbarma},
keywords = {Hate speech, Detection, Classification, Pre processing, Feature extraction},
abstract = {Social networking platforms allow users to ask questions, exchange information, opinions, ideas, and promote companies. Social media's massive user-generated text is useful for study, translation, and analysis. Due of their quick spread and detrimental impact, offensive remarks, hate speech, and harassment must be discovered and deleted immediately. In non-English main language environments, code-mixed text makes hate speech detection difficult. Hate speech's thematic emphasis and target-oriented orientation are typically ignored in binary categorization methods. These methods also fail in code-mixing multilingual contexts. In this study, we propose an optimal feature extraction and hybrid diagonal gated recurrent neural network (FE-DGRNN) for hate speech detection and sentiment analysis on code-mixed texts in multiple languages. Our FE-DGRNN technique consists of three processes: preprocessing, improved seagull optimization (ISO) for feature extraction, and hybrid diagonal gated recurrent neural network (Hyb-DGRNN) for hate speech detection and sentiment analysis. We evaluate the performance of our proposed technique using the HASOC 2019 dataset, focusing on English and German. The results demonstrate high accuracy of 95%, 96%, and 92% for English tasks, with Precision and F-measure of 94%, 96%, and 91%. For German tasks, the accuracy is 92% and 93%, with Precision and F-measure of 90% and 91%.}
}
@article{LIU2025110915,
title = {SARA: Span-aware framework with relation-augmented grid tagging for conversational aspect-based sentiment quadruple analysis},
journal = {Engineering Applications of Artificial Intelligence},
volume = {154},
pages = {110915},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110915},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625009157},
author = {Xiaoyong Liu and Miao Hu and Chunlin Xu and Zhiguo Du},
keywords = {Conversational aspect-based sentiment quadruple analysis, Relation-augmented grid tagging, Span-aware memory block},
abstract = {Conversational aspect-based sentiment quadruple analysis (DiaASQ) is an emerging research topic in the field of aspect-based sentiment analysis (ABSA), which aims to extract sentiment quadruples (i.e., target, aspect, opinion, and sentiment polarity) from a given dialogue. In DiaASQ, numerous span quadruples can be observed, where the constituent elements of these quadruples are often dispersed across a single utterance or span multiple utterances within a conversation, posing significant challenges to previous methods. In addition, existing methods typically focus on linking the target term with the opinion term, while overlooking the direct relationship between the aspect term and the opinion term, leading to inaccurate extraction of quadruples. Therefore, this paper proposes a Span-Aware framework with Relation-Augmented grid tagging scheme (SARA) to enhance DiaASQ. Specifically, a novel span-aware memory block is devised to enhance the model’s ability to obtain the long-distance dependency among elements within span quadruples. Furthermore, a new relation-augmented grid tagging scheme is introduced to strengthen the pairing of aspect terms and opinion terms, thereby enhancing the performance of quadruple extraction. Extensive experimental results on two benchmark datasets validate the effectiveness of the proposed approach.}
}
@article{WAN2025112763,
title = {Aspect-based sentiment analysis by knowledge and attention integrated graph convolutional network},
journal = {Applied Soft Computing},
volume = {171},
pages = {112763},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.112763},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625000742},
author = {Bingtao Wan and Peng Wu and Pu Han and Gang Li},
keywords = {Aspect-based sentiment analysis, Graph convolutional networks, Attention mechanism, Knowledge-enabled RoBERTa},
abstract = {Aspect-Based Sentiment Analysis (ABSA) aims to determine the sentiment polarity associated with specific aspects within a sentence. Recent advancements have demonstrated that the application of Graph Convolutional Networks (GCNs) to syntactic graphs yields substantial improvements in performance. However, challenges remain, including inconsistent word segmentation between Pre-trained Language Models (PLMs) and dependency parsers, heterogeneous embeddings for knowledge semantics, and the neglect of varying syntactic and semantic relation strengths. This paper proposes the Knowledge and Attention integrated GCN model (KA-GCN), which addresses the aforementioned issues. In particular, we propose a syntactic graph expansion algorithm to align word segmentation with PLM tokenization, thus resolving the aforementioned segmentation inconsistencies. To address the issue of heterogeneous embedding, we incorporate SentiWordNet knowledge into sentences to generate sentence-knowledge trees, and develop Knowledge-enabled RoBERTa (K-RoBERTa) for consistent encoding representations. Furthermore, we propose a position-aware attention mechanism that calculates attention scores, reflecting the strengths of syntactic and semantic relations. This mechanism also facilitates the generation of aspect-specific sentiment representations. These innovations enable KA-GCN to effectively integrate sentiment and syntactic knowledge, thereby providing an advanced approach to ABSA. Evaluation on public datasets demonstrates that KA-GCN achieves the highest performance in ABSA, with ablation studies confirming the effectiveness of each proposed technique.}
}
@article{KHAN2024e40611,
title = {Predicting the victims of hate speech on microblogging platforms},
journal = {Heliyon},
volume = {10},
number = {23},
pages = {e40611},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e40611},
url = {https://www.sciencedirect.com/science/article/pii/S240584402416642X},
author = {Sahrish Khan and Rabeeh Ayaz Abbasi and Muddassar Azam Sindhu and Sachi Arafat and Akmal Saeed Khattak and Ali Daud and Mubashar Mushtaq},
keywords = {Social media, Hate speech, Twitter, Machine learning, Prediction},
abstract = {Hate speech constitutes a major problem on microblogging platforms, with automatic detection being a growing research area. Most existing works focus on analyzing the content of social media posts. Our study shifts focus to predicting which users are likely to become targets of hate speech. This paper proposes a novel Hate-speech Target Prediction Framework (HTPK) and introduces a new Hate Speech Target Dataset (HSTD), which contains tweets labeled for targets and non-targets of hate speech. Using a combination of Term Frequency-Inverse Document Frequency (TFIDF), N-grams, and Part-of-Speech (PoS) tags, we tested various machine learning algorithms, Naïve Bayes (NB) classifier performs best with an accuracy of 93%, significantly outperforming other algorithms. This research identifies the optimal combination of features for predicting hate speech targets and compares various machine learning algorithms, providing a foundation for more proactive hate speech mitigation on social media platforms.}
}
@article{KOTSAKIS2023e16084,
title = {A web framework for information aggregation and management of multilingual hate speech},
journal = {Heliyon},
volume = {9},
number = {5},
pages = {e16084},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e16084},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023032917},
author = {Rigas Kotsakis and Lazaros Vrysis and Nikolaos Vryzas and Theodora Saridou and Maria Matsiola and Andreas Veglis and Charalampos Dimoulas},
keywords = {Hate speech, Sentiment analysis, Information retrieval, Content management and moderation, Social media, Multilingual, Natural language processing, Machine learning},
abstract = {Social media platforms have led to the creation of a vast amount of information produced by users and published publicly, facilitating participation in the public sphere, but also giving the opportunity for certain users to publish hateful content. This content mainly involves offensive/discriminative speech towards social groups or individuals (based on racial, religious, gender or other characteristics) and could possibly lead into subsequent hate actions/crimes due to persistent escalation. Content management and moderation in big data volumes can no longer be supported manually. In the current research, a web framework is presented and evaluated for the collection, analysis, and aggregation of multilingual textual content from various online sources. The framework is designed to address the needs of human users, journalists, academics, and the public to collect and analyze content from social media and the web in Spanish, Italian, Greek, and English, without prior training or a background in Computer Science. The backend functionality provides content collection and monitoring, semantic analysis including hate speech detection and sentiment analysis using machine learning models and rule-based algorithms, storing, querying, and retrieving such content along with the relevant metadata in a database. This functionality is assessed through a graphic user interface that is accessed using a web browser. An evaluation procedure was held through online questionnaires, including journalists and students, proving the feasibility of the use of the proposed framework by non-experts for the defined use-case scenarios.}
}
@article{LIU2026122684,
title = {SEAD-MGFE-Net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis},
journal = {Information Sciences},
volume = {723},
pages = {122684},
year = {2026},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2025.122684},
url = {https://www.sciencedirect.com/science/article/pii/S0020025525008175},
author = {Wei Liu and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Shangyi Du and Peng Lu},
keywords = {Conversational aspect-based sentiment analysis, Multi-layer tree, Schrödinger equation, Neighborhood-aware, Adaptive dropout},
abstract = {This research focuses on enhancing the extraction of sentiment quadruples consisting of target, aspect, opinion, and sentiment from multi-turn dialogs, which remains a challenging problem in conversational sentiment analysis. Existing methods frequently encounter challenges with complex sentence structures, presence of multiple sentiment quadruples, and interference from irrelevant contextual information. These challenges often result in suboptimal performance. These limitations are addressed by introducing Schrödinger equation-based adaptive dropout multi-granular feature enhancement network (SEAD-MGFE-Net), a novel framework that synergizes multigranular feature extraction with quantum-inspired adaptive regularization. The proposed methodology incorporates a multi-layer tree structure to segment sentences into semantically coherent fragments, thereby improving the alignment between aspect and opinion terms while simultaneously mitigating noise impact. Moreover, we engineer a multi-angle dynamic adjacency learning enhancement module that adeptly captures both local and global features inherent in graph-structured representations. Additionally, we devise an adaptive dropout mechanism based on the Schrödinger equation, facilitating automatic modulation of the regularization strength throughout training. Extensive evaluations on benchmark datasets in both Chinese and English validate the state-of-the-art effectiveness of our proposed SEAD-MGFE-Net model, achieving Micro-F1 scores of 46.53 % (Chinese) and 40.97 % (English), surpassing the strongest baseline models by 2.04 % and 1.57 %, respectively. SEAD-MGFE-Net exhibits efficacy in extracting cross-utterance quadruples and managing long-range dependencies. These findings confirm the effectiveness and broad applicability of SEAD-MGFE-Net for conversational sentiment analysis.}
}
@article{HAZNITRAMA202553,
title = {Methodologies and their comparison in complex compound aspect-based sentiment analysis: A survey},
journal = {AI Open},
volume = {6},
pages = {53-69},
year = {2025},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2025.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666651025000051},
author = {Faiz Ghifari Haznitrama and Ho-Jin Choi and Chin-Wan Chung},
keywords = {Natural language processing, Sentiment analysis, Aspect, Opinion},
abstract = {Sentiment analysis as a part of natural language processing (NLP) has received much attention following the demand to understand people’s opinions. Aspect-based sentiment analysis (ABSA) is a fine-grained task from sentiment analysis that aims to classify the sentiment at the aspect level. Throughout the years, researchers have formulated ABSA into various tasks for different scenarios. Unlike early works, current ABSA tasks utilize many elements to provide more details to produce informative results. However, it is difficult to completely explore the works of ABSA because of the many different tasks, terms, and results. This paper surveyed recent studies on ABSA, specifically on its complex compound tasks. We investigated some key elements, problem formulations, and datasets currently utilized by most ABSA communities. We focused on reviewing the latest methodologies and worked to find the current state-of-the-art methodologies by performing a comparative analysis. From our study, we found that there has been a shift to generative methods in solving the ABSA problem, which signifies the evolving emphasis on holistic, end-to-end approaches. Finally, we identified some open challenges and future directions for ABSA research.}
}
@article{MIN2023214,
title = {Finding hate speech with auxiliary emotion detection from self-training multi-label learning perspective},
journal = {Information Fusion},
volume = {96},
pages = {214-223},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523001045},
author = {Changrong Min and Hongfei Lin and Ximing Li and He Zhao and Junyu Lu and Liang Yang and Bo Xu},
keywords = {Hate speech detection, Emotion detection, Multi-label learning, Multi-task learning},
abstract = {Hate Speech Detection (HSD) aims to identify whether a text contains hate speech content, which often refers to discrimination and is even associated with a hate crime. The mainstream methods jointly train the HSD problem with relevant auxiliary problems, e.g., emotion detection and sentiment analysis, under the paradigm of Multi-Task Learning (MTL). In this paper, we improve HSD by integrating it with emotion detection, since we take inspiration from the potential correlations between hate speech and certain negative emotion states, which have been studied theoretically and empirically. To be specific, we can concatenate their hateful labels and predicted emotion states as pseudo-multiple labels for hate speech samples, formulating a pseudo-Multi-Label Learning (MLL) problem. Beyond the existing MTL-HSD methods, we further incorporate this pseudo-MLL problem and solve it by capturing the correlations between hate speech and negative emotion states, so as to improve the performance of HSD. Based on these ideas, we propose a novel HSD method named the Emotion-correlated Hate Speech DetectOR (EHSor). We conduct extensive experiments to evaluate EHSor, and the results show that it can consistently outperform the existing HSD methods across benchmark datasets.}
}
@article{FONSECA2024e32246,
title = {Analyzing hate speech dynamics on Twitter/X: Insights from conversational data and the impact of user interaction patterns},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e32246},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e32246},
url = {https://www.sciencedirect.com/science/article/pii/S240584402408277X},
author = {António Fonseca and Catarina Pontes and Sérgio Moro and Fernando Batista and Ricardo Ribeiro and Rita Guerra and Paula Carvalho and Catarina Marques and Cláudia Silva},
abstract = {This paper investigates the pervasive issue of hate speech within Twitter/X Portuguese network conversations, offering a multifaceted analysis of its characteristics. This study utilizes a mixed-method approach, combining several methodologies of network analysis (triad census and participation shifts) over the network of interaction between users. Qualitative manual content annotation was applied to the dataset to dissect different patterns of hate speech on the platform. Key findings reveal that the number of users followed by an individual and potentially reads is a relevant predictor for a user's propensity to post aggressive content. We concluded also that during a conversation thread, hate speech happens significantly more within the first 2 h of interaction. Transitivity of interactions and individual expression are considerably lower as more hate speech is prevalent in conversations. Our research confirms that hate speech is usually expressed by external individuals who intrude into conversations. Conversely, the expression of hate speech of indirect type by third parties interfering in conversations is uncommon. We also found that counter-speech discourse is strongly correlated with a type of discourse that typically avoids conflict and is not privately held.}
}
@article{FIRMINO2024121115,
title = {Improving hate speech detection using Cross-Lingual Learning},
journal = {Expert Systems with Applications},
volume = {235},
pages = {121115},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.121115},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423016172},
author = {Anderson Almeida Firmino and Cláudio {de Souza Baptista} and Anselmo Cardoso {de Paiva}},
keywords = {Hate speech detection, Natural language processing, Social media, Cross-Lingual Learning, Deep learning},
abstract = {The growth of social media worldwide has brought social benefits and challenges. One problem we highlight is the proliferation of hate speech on social media. We propose a novel method for detecting hate speech in texts using Cross-Lingual Learning. Our approach uses transfer learning from Pre-Trained Language Models (PTLM) with large corpora available to solve problems in languages with fewer resources for the specific task. The proposed methodology comprises four stages: corpora acquisition, the PTLM definition, training strategies, and evaluation. We carried out experiments using Pre-Trained Language Models in English, Italian, and Portuguese (BERT and XLM-R) to verify which best suited the proposed method. We used corpora in English (WH) and Italian (Evalita 2018) as the source language and the OffComBr-2 corpus in Portuguese (the target language). The results of the experiments showed that the proposed methodology is promising: for the OffComBr-2 corpus, the best state-of-the-art result was obtained (F1-measure = 92%).}
}
@article{PYKL2024123211,
title = {Racists spreader is narcissistic; sexists is Machiavellian Influence of Psycho-Sociological Facets in hate-speech diffusion prediction},
journal = {Expert Systems with Applications},
volume = {247},
pages = {123211},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123211},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424000769},
author = {Srinivas P.Y.K.L and Amitava Das and Viswanath Pulabaigari},
keywords = {Hate-speech, Information diffusion, Psycho-linguistics, Online social networks (OSNs)},
abstract = {Hate speech pertains to the expression of negative emotions by people. The spread of hate speech contributes to societal inequity by imposing adverse consequences on individuals’ emotional and physical well-being, financial circumstances, and overall quality of life, thereby hindering their daily existence. Hence, the development of a hate detection and diffusion prediction system is of utmost importance. The literature study reveals two primary findings regarding the development of a hate speech model. Firstly, it is crucial to understand the potential impact of a hate speech message, specifically the extent to which it influences the users exposed to it. Secondly, numerous researchers have focused on studying information propagation, with a particular emphasis on analysing network topology and structure. This paper introduces psycho-sociological analysis as another approach to understanding hate speech spread on social networks. We develop a hate speech diffusion model considering many psycho-sociological dimensions of social media users. This paper aims to answer a few basic questions: (a) Who starts hateful tweets on social media? (b) Who are the users who share, respond to, or like such posts? (c) Can we build a better hate-speech diffusion model by understanding each user’s psycho-sociological traits towards hateful information? To answer the above questions, we analyse user psycho-sociological traits by studying three different dimensions of user behaviour, i.e., inner personality, societal personality, and dark emotion using the Big5 personality model, Schwartz value model, and the Dark triad behaviour model. We develop a collection of classifiers to detect users’ personality traits. In addition, we proposed a system to predict the spread of hate content on social networks. Several empirical analyses are presented in this paper in order to understand the correlation between human personality and online hateful behaviour. From our empirical analysis of hostile behaviour, several key observations are reported in this paper, a few of which include the following: (i) People with dark triad orientations are mostly the originators of online hate speech, (ii) Those who post sexist tweets are often Machiavellian, (iii) Narcissistic users are more likely to make racist tweets, and (iv) Those who post sexist and racist tweets on social networks are often psychopathic. Using these insights, we have mapped the user behaviour dimension into a vector space called behaviour embedding. This space is used for developing the hate-speech diffusion model. We show that the proposed models also perform better than the state-of-the-art with a significant F1-score margin.}
}
@article{NASCIMENTO2022117032,
title = {Unintended bias evaluation: An analysis of hate speech detection and gender bias mitigation on social media using ensemble learning},
journal = {Expert Systems with Applications},
volume = {201},
pages = {117032},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117032},
url = {https://www.sciencedirect.com/science/article/pii/S095741742200447X},
author = {Francimaria R.S. Nascimento and George D.C. Cavalcanti and Márjory {Da Costa-Abreu}},
keywords = {Hate speech detection, Ensemble learning, Gender bias, Multi-features},
abstract = {Hate speech on online social media platforms is now at a level that has been considered a serious concern by governments, media outlets, and scientists, especially because it is easily spread, promoting harm to individuals and society, and made it virtually impossible to tackle with using just human analysis. Automatic approaches using machine learning and natural language processing are helpful for detection. For such applications, amongst several different approaches, it is essential to investigate the systems’ robustness to deal with biases towards identity terms (gender, race, religion, for example). In this work, we analyse gender bias in different datasets and proposed a ensemble learning approach based on different feature spaces for hate speech detection with the aim that the model can learn from different abstractions of the problem, namely unintended bias evaluation metrics. We have used nine different feature spaces to train the pool of classifiers and evaluated our approach on a publicly available corpus, and our results demonstrate its effectiveness compared to state-of-the-art solutions.}
}
@article{PAN2025103990,
title = {Spanish MTLHateCorpus 2023: Multi-task learning for hate speech detection to identify speech type, target, target group and intensity},
journal = {Computer Standards & Interfaces},
volume = {94},
pages = {103990},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2025.103990},
url = {https://www.sciencedirect.com/science/article/pii/S0920548925000194},
author = {Ronghao Pan and José Antonio García-Díaz and Rafael Valencia-García},
keywords = {Hate speech, Multi-task learning, Zero-Shot Learning, Fine tuning, Text classification, Natural language processing},
abstract = {The rise of digital communication has exacerbated the challenge of tackling harmful speech online, particularly hate speech, which dehumanises individuals or groups on the basis of traits such as race, gender or ethnicity. This study highlights the urgent need for fine-grained detection methods that take into account several subtasks of hate speech detection, including its intensity, determining the groups to which hate speech is directed, and whether the target is an individual or a group. Furthermore, there is a gap in comprehensive Spanish language corpora that cover these subtasks of hate speech detection. Therefore, we created a novel corpus entitled Spanish MTLHateCorpus 2023 to facilitate the analysis of hate speech in these subtasks and evaluated the effectiveness of the multi-task learning strategy evaluating mBART and T5, comparing its results with other Large Language Models using Zero-Shot Learning as a lower bound and an ensemble based on the mode of several Fine-Tuning as an upper bound. The results achieved by the Multi-Task Learning strategy demonstrated its potential to increase model versatility, allowing a single model to effectively tackle multiple tasks while achieving competitive results, particularly in target group recognition. However, the ensemble learning slightly outperforms the Multi-Task Learning strategy.}
}
@article{JAHAN2023126232,
title = {A systematic review of hate speech automatic detection using natural language processing},
journal = {Neurocomputing},
volume = {546},
pages = {126232},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126232},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223003557},
author = {Md Saroar Jahan and Mourad Oussalah},
keywords = {Hate speech detection review, Systematic review, PRISMA hate speech, NLP deep learning review},
abstract = {With the multiplication of social media platforms, which offer anonymity, easy access and online community formation and online debate, the issue of hate speech detection and tracking becomes a growing challenge to society, individual, policy-makers and researchers. Despite efforts for leveraging automatic techniques for automatic detection and monitoring, their performances are still far from satisfactory, which constantly calls for future research on the issue. This paper provides a systematic review of literature in this field, with a focus on natural language processing and deep learning technologies, highlighting the terminology, processing pipeline, core methods employed, with a focal point on deep learning architecture. From a methodological perspective, we adopt PRISMA guideline of systematic review of the last 10 years literature from ACM Digital Library and Google Scholar. In the sequel, existing surveys, limitations, and future research directions are extensively discussed.}
}
@article{ZHANG2025128524,
title = {NLAFE: Non-linear aspect-based sentiment feature enhancement combined with aspect cross attention},
journal = {Expert Systems with Applications},
volume = {290},
pages = {128524},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128524},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425021438},
author = {Jun Zhang and Shilei Wang and Ze Kuang and Fanfan Shen and Jianfeng He and Luping Zhang and Chao Wei and Yanxiang He},
keywords = {Aspect-based sentiment analysis, Sentiment feature enhancement, Nonlinear transformation, External sentiment knowledge, Aspect cross-attention mechanism},
abstract = {Aspect-based sentiment analysis is a complex and detailed task in the field of natural language processing (NLP), focusing on identifying the sentiment polarity associated with specific aspect terms in a given text. Recently, there has been a growing interest in using graph convolutional networks models for advancing research in aspect-based sentiment analysis. However, existing studies often focus solely on independent dependency information learning or rely solely on external knowledge for sentiment feature enhancement, leaving room for improvement in the quality of aspect-based sentiment feature extraction. To address these limitations, this paper proposes a Non-linear Aspect-based Sentiment Feature Enhancement Combined with Aspect Cross Attention (NLAFE) model, which integrates external sentiment knowledge and employs nonlinear transformation to enhance sentiment features, enabling finer-grained differentiation of polarity intensities. Additionally, an aspect cross-attention mechanism is designed to effectively integrate contextual semantic representations with aspect sentiment features, facilitating the learning of semantic associations between aspect terms and contextual words, thereby capturing the global semantic information of the input text sequence. The results demonstrate that the proposed model significantly outperforms baseline models across four benchmark datasets. Compared with models such as R-GAT, SenticGCN, and Hete_GNNs, our model achieves average improvements of 1.15 %, 1.86 %, and 2.7 % in accuracy, and 2.26 %, 2.18 %, and 4.34 % in F1 score, respectively. Moreover, the BERT-based variant, NLAFE + BERT, also shows substantial gains in both accuracy and F1 score compared to other pretrained models.}
}
@article{LIN2024125059,
title = {Addressing class-imbalance challenges in cross-lingual aspect-based sentiment analysis: Dynamic weighted loss and anti-decoupling},
journal = {Expert Systems with Applications},
volume = {257},
pages = {125059},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125059},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424019262},
author = {Nankai Lin and Meiyu Zeng and Xingming Liao and Weizhong Liu and Aimin Yang and Dong Zhou},
keywords = {Cross-lingual aspect-based sentiment analysis, Class-imbalance, Dynamic weighted loss, Anti-decoupling},
abstract = {Numerous attempts have been made to address Aspect-based Sentiment Analysis (ABSA), with a predominant emphasis on English texts. Tackling ABSA in low-resource languages poses a significant challenge. Consequently, recent researchers have turned their attention to Cross-Lingual Aspect-based Sentiment Analysis (XABSA). Research indicates a notable performance disparity among existing XABSA models for different sentiments, creating an evident class-imbalance issue. The class-imbalance issue is a pivotal challenge in XABSA, given the disparities not only between various sentiment categories but also between the representation distributions of the source language (SL) and the target language (TL). To bridge this gap, we present an equilibrium XABSA framework, Equi-XABSA, to alleviate the class-imbalance problem. Our framework employs a dynamic weighted loss (DWL) strategy that adaptively adjusts the model’s focus towards underperforming samples, coupled with an anti-decoupling strategy to enhance semantic integration across languages. Our approach yields an average micro F-score of 63.47 across four languages, marking the most advanced performance in the XABSA task. The experimental findings substantiate that our methodology not only surpasses current models but also effectively mitigates the XABSA class-imbalance problem.}
}
@article{LI2025,
title = {Revealing Patient Dissatisfaction With Health Care Resource Allocation in Multiple Dimensions Using Large Language Models and the International Classification of Diseases 11th Revision: Aspect-Based Sentiment Analysis},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/66344},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125003802},
author = {Jiaxuan Li and Yunchu Yang and Chao Mao and Patrick Cheong-Iao Pang and Quanjing Zhu and Dejian Xu and Yapeng Wang},
keywords = {ICD-11, International Classification of Diseases 11th Revision, disease classification, patient reviews, patient satisfaction, ChatGPT, Sustainable Development Goals, chain of thought, large language model},
abstract = {Background
Accurately measuring the health care needs of patients with different diseases remains a public health challenge for health care management worldwide. There is a need for new computational methods to be able to assess the health care resources required by patients with different diseases to avoid wasting resources.
Objective
This study aimed to assessing dissatisfaction with allocation of health care resources from the perspective of patients with different diseases that can help optimize resource allocation and better achieve several of the Sustainable Development Goals (SDGs), such as SDG 3 (“Good Health and Well-being”). Our goal was to show the effectiveness and practicality of large language models (LLMs) in assessing the distribution of health care resources.
Methods
We used aspect-based sentiment analysis (ABSA), which can divide textual data into several aspects for sentiment analysis. In this study, we used Chat Generative Pretrained Transformer (ChatGPT) to perform ABSA of patient reviews based on 3 aspects (patient experience, physician skills and efficiency, and infrastructure and administration)00 in which we embedded chain-of-thought (CoT) prompting and compared the performance of Chinese and English LLMs on a Chinese dataset. Additionally, we used the International Classification of Diseases 11th Revision (ICD-11) application programming interface (API) to classify the sentiment analysis results into different disease categories.
Results
We evaluated the performance of the models by comparing predicted sentiments (either positive or negative) with the labels judged by human evaluators in terms of the aforementioned 3 aspects. The results showed that ChatGPT 3.5 is superior in a combination of stability, expense, and runtime considerations compared to ChatGPT-4o and Qwen-7b. The weighted total precision of our method based on the ABSA of patient reviews was 0.907, while the average accuracy of all 3 sampling methods was 0.893. Both values suggested that the model was able to achieve our objective. Using our approach, we identified that dissatisfaction is highest for sex-related diseases and lowest for circulatory diseases and that the need for better infrastructure and administration is much higher for blood-related diseases than for other diseases in China.
Conclusions
The results prove that our method with LLMs can use patient reviews and the ICD-11 classification to assess the health care needs of patients with different diseases, which can assist with resource allocation rationally.}
}
@article{ZOU2025111369,
title = {A vision and language hierarchical alignment for multimodal aspect-based sentiment analysis},
journal = {Pattern Recognition},
volume = {162},
pages = {111369},
year = {2025},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2025.111369},
url = {https://www.sciencedirect.com/science/article/pii/S0031320325000299},
author = {Wang Zou and Xia Sun and Qiang Lu and Xuxin Wang and Jun Feng},
keywords = {Multimodal aspect-based sentiment analysis, Visual scene graph, Text dependency graph, Dynamic alignment matrix},
abstract = {In recent years, Multimodal Aspect-Based Sentiment Analysis (MABSA) has garnered attention from researchers. The MABSA technology can effectively perform Aspect Term Extraction (MATE) and Aspect Sentiment Classification (MASC) for Multimodal data. However, current MABSA work focuses on visual semantic information while neglecting the scene structure of images. Additionally, researchers using static alignment matrices cannot effectively capture complex vision features, such as spatial and action features among objects. In this paper, we propose a Vision and Language Hierarchical Alignment method (VLHA) for the MABSA task. The VLHA framework includes three modules: the multimodal structural alignment module, the multimodal semantic alignment module, and the cross-modal MABSA module. Firstly, we process the vision modality into a visual scene graph and image patches, and the text modality into a text dependency graph and word sequences. Secondly, we use the structural alignment module to achieve dynamic alignment learning between the visual scene graph and text dependency graph, and the semantic alignment module to achieve dynamic alignment learning between image patches and word sequences. Finally, we concatenate and fuse structural and semantic features in the cross-modal MABSA module. Additionally, VLHA designs a three-dimensional dynamic alignment matrix to guide the cross-attention for modal interaction learning. We conducted a series of experiments on two Twitter datasets, and the results show that the performance of the VLHA framework outperforms the baseline models. The structure of the visual modality facilitates the model in comprehensively understanding complex visual information.}
}
@article{ZHANG2025279,
title = {Text-Image Feature Fine-Grained Learning for Joint Multimodal Aspect-Based Sentiment Analysis},
journal = {Computers, Materials and Continua},
volume = {82},
number = {1},
pages = {279-305},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.055943},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825000025},
author = {Tianzhi Zhang and Gang Zhou and Shuang Zhang and Shunhang Li and Yepeng Sun and Qiankun Pi and Shuo Liu},
keywords = {Multimodal sentiment analysis, aspect-based sentiment analysis, feature fine-grained learning, graph convolutional network, adjective-noun pairs},
abstract = {Joint Multimodal Aspect-based Sentiment Analysis (JMASA) is a significant task in the research of multimodal fine-grained sentiment analysis, which combines two subtasks: Multimodal Aspect Term Extraction (MATE) and Multimodal Aspect-oriented Sentiment Classification (MASC). Currently, most existing models for JMASA only perform text and image feature encoding from a basic level, but often neglect the in-depth analysis of unimodal intrinsic features, which may lead to the low accuracy of aspect term extraction and the poor ability of sentiment prediction due to the insufficient learning of intra-modal features. Given this problem, we propose a Text-Image Feature Fine-grained Learning (TIFFL) model for JMASA. First, we construct an enhanced adjacency matrix of word dependencies and adopt graph convolutional network to learn the syntactic structure features for text, which addresses the context interference problem of identifying different aspect terms. Then, the adjective-noun pairs extracted from image are introduced to enable the semantic representation of visual features more intuitive, which addresses the ambiguous semantic extraction problem during image feature learning. Thereby, the model performance of aspect term extraction and sentiment polarity prediction can be further optimized and enhanced. Experiments on two Twitter benchmark datasets demonstrate that TIFFL achieves competitive results for JMASA, MATE and MASC, thus validating the effectiveness of our proposed methods.}
}
@article{SANAHMED2025112012,
title = {KurdABSA: Kurdish aspect-based sentiment analysis dataset curation using few-shot learning},
journal = {Data in Brief},
volume = {62},
pages = {112012},
year = {2025},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2025.112012},
url = {https://www.sciencedirect.com/science/article/pii/S2352340925007358},
author = {Rania Azad M. {San Ahmed} and Soran AB. Saeed},
keywords = {Natural language processing, Sentiment analysis, Aspect-based sentiment analysis, Meta-learning, Low-resource, Kurdish language, Sorani dialect},
abstract = {Aspect-Based Sentiment Analysis (ABSA) extends traditional sentiment analysis by not only identifying the overall sentiment of a text but also associating specific sentiments with deeper and granular insights. The main objective of ABSA is to accurately extract relevant aspects and determine the sentiment polarity associated with each. Although extensive research has been conducted on ABSA across various languages, low-resource languages such as Kurdish remain largely underexplored in this domain. To address this gap, the present study introduces the first publicly available aspect-based sentiment analysis dataset for the Sorani dialect of Kurdish, addressing a critical gap in natural language processing (NLP) research for low-resource languages. The dataset has >4000 quadruplet ABSA in the restaurant review domain, written in the Kurdish language (Sorani dialect) using the Perso-Arabic script. A prompt-based few-shot learning model was employed to automatically annotate the dataset with aspect-opinion-category-sentiment quadruples, guided by a manually annotated support set verified by native Kurdish-language experts. This resource is intended for use in machine learning, deep learning, and cross-lingual model adaptation, making it suitable for training, fine-tuning, and benchmarking.}
}
@article{LANGE2025129669,
title = {Curriculum Learning for a Hybrid Approach for Aspect-Based Sentiment Analysis},
journal = {Expert Systems with Applications},
pages = {129669},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.129669},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425032841},
author = {Nana Lange and Flavius Frasincar and Maria Mihaela Truşcǎ},
keywords = {aspect-based sentiment analysis, baby steps curriculum learning, one-pass curriculum learning, online reviews},
abstract = {In the past years, the amount of unstructured online review data has grown exponentially. Many people express their opinions about different aspects of goods and services on the Web. Aspect-Based Sentiment Analysis (ABSA) automatically extracts the sentiments with respect to aspects given in a sentence. We improve the training procedure of the state-of-the-art Hybrid Approach for Aspect-Based Sentiment Analysis with deep contextual word embeddings and hierarchical attention (HAABSA++). In this method, a domain sentiment ontology is used as a main classifier, and if it is not conclusive, a neural network is employed as a back-up. We extend the training of the neural network by incrementally adding more difficult instances, also known as curriculum learning. Restaurant reviews obtained from the SemEval-2015 and SemEval-2016 datasets are used to evaluate the effect of implementing curriculum learning. Using baby steps curriculum learning and a specific curriculum strategy, the accuracy of HAABSA++ is improved from 86.3% to 87.5%.}
}
@article{ALSAGHEER20231009,
title = {Statistical Analysis of Counter-Hate Speech on Voice-based Social Media},
journal = {Procedia Computer Science},
volume = {220},
pages = {1009-1014},
year = {2023},
note = {The 14th International Conference on Ambient Systems, Networks and Technologies Networks (ANT) and The 6th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.03.140},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923006750},
author = {Dana Alsagheer and Hadi Mansourifar and Weidong (Larry) Shi},
keywords = {Counter-hate speech, Significance Test, T-test, Shapiro-Wilk Test},
abstract = {With the high prevalence of offensive language against minorities on social media, counter-hate speech generation is considered an automatic way to tackle this challenge. The counter-hate speech is supposed to appear as a third voice to educate people and keep the social red lines bold without limiting the freedom of speech principles. The counter-hate speech generation is based on the optimistic assumption that any attempt to intervene the hate speech on social media can play a positive role in this context. Beyond that, previous works were ignored to investigate the sequence of comments before and after the counter-hate speech. To the best of our knowledge, no attempt has been made to measure the counter-hate speech impact on voice-based social media from a statistical point of view. In this paper, we take the first step in this direction by measuring the counter-hate speech impact on the following comments in terms of Google Perspective Scores. Furthermore, our experiments show that counter-hate speech can cause negative impacts, a phenomenon called psychological reactance.}
}
@article{DONG2025125933,
title = {PGSO: Prompt-based Generative Sequence Optimization network for aspect-based sentiment analysis},
journal = {Expert Systems with Applications},
volume = {265},
pages = {125933},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125933},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424028008},
author = {Hao Dong and Wei Wei},
keywords = {Aspect-based sentiment analysis, Generative language model, Sequence optimization},
abstract = {Recently, generative pre-training based models have demonstrated remarkable results on Aspect-based Sentiment Analysis (ABSA) task. However, previous works overemphasize crafting various templates to paraphrase training targets for enhanced decoding, ignoring the internal optimizations on generative models. Despite notable results achieved by these target-oriented optimization methods, they struggle with the complicated long texts since the implicit long-distance relation, e.g., aspect-opinion relation, is difficult to extract under the position embedding mechanism in generative models. Thus, in this paper, we first clarify the causes of the problem and introduce two sequence optimization strategies: the rule-based static optimization and the score-based dynamic optimization. The rule-based approach relies on handcraft priority of dependency relation to reorder the context, while the score-based algorithm dynamically regulates the contextual sequence by calculating word position scores using neural network. Based on the dynamic optimization structure, we further propose a unified Prompt-based Generative Sequence Optimization network (named PGSO), which jointly optimizes the training target as well as the generative model. Specifically, PGSO contains two components, namely, prompt construction and sequence regulator. The former constructs a task-specific prompt based on unsupervised training objects to fully utilize the pre-trained model. The latter jointly leverages semantic, syntactic and original-sequence information to dynamically regulate contextual sequence. Our experiments conducted on four ABSA tasks across multiple benchmarks indicate that PGSO outperforms state-of-the-art methods, with an average improvement of 3.52% in F1 score.}
}
@article{LI2025131037,
title = {Enhancing syntactic and semantic features via TextGINConv and Kolmogorov–Arnold networks for aspect-based sentiment analysis},
journal = {Neurocomputing},
volume = {651},
pages = {131037},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131037},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225017096},
author = {Xiaoru Li and Yuxia Lei},
keywords = {Aspect-based sentiment analysis, Graph convolutional network, KAN gated fusion},
abstract = {Aspect-based sentiment analysis identifies the sentiment polarity of a given aspect in a sentence. Recent advances have demonstrated the effectiveness of combining syntactic dependency structures with graph convolutional networks. However, traditional graph convolutional networks usually have a simpler message passing mechanism that may describe the relationship between nodes only through the adjacency matrix, often ignoring messages passed by edge features and performing sentiment analysis without considering the specific semantic information of different aspects. In this paper, we innovatively propose a syntactic and semantic enhancement network model for aspect-based sentiment analysis (ESSGKA). To be specific, we combine a self-attention mechanism with an aspect-oriented attention mechanism, enabling the simultaneous learning of aspect-related semantics and the overall semantics of the sentence. TextGINConv focuses more on edge features, which are leveraged to facilitate dense message passing. To enhance the fusion of two distinct feature messages, we propose a novel gated fusion framework based on Kolmogorov–Arnold networks. Extensive experiments on four publicly available datasets show that our model is more competitive than state-of-the-art models.}
}
@article{IBRAHIM2024243,
title = {An Adaptive Hate Speech Detection Approach Using Neutrosophic Neural Networks for Social Media Forensics},
journal = {Computers, Materials and Continua},
volume = {79},
number = {1},
pages = {243-262},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.047840},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824003771},
author = {Yasmine M. Ibrahim and Reem Essameldin and Saad M. Darwish},
keywords = {Hate speech detection, whale optimization, neutrosophic sets, social media forensics},
abstract = {Detecting hate speech automatically in social media forensics has emerged as a highly challenging task due to the complex nature of language used in such platforms. Currently, several methods exist for classifying hate speech, but they still suffer from ambiguity when differentiating between hateful and offensive content and they also lack accuracy. The work suggested in this paper uses a combination of the Whale Optimization Algorithm (WOA) and Particle Swarm Optimization (PSO) to adjust the weights of two Multi-Layer Perceptron (MLPs) for neutrosophic sets classification. During the training process of the MLP, the WOA is employed to explore and determine the optimal set of weights. The PSO algorithm adjusts the weights to optimize the performance of the MLP as fine-tuning. Additionally, in this approach, two separate MLP models are employed. One MLP is dedicated to predicting degrees of truth membership, while the other MLP focuses on predicting degrees of false membership. The difference between these memberships quantifies uncertainty, indicating the degree of indeterminacy in predictions. The experimental results indicate the superior performance of our model compared to previous work when evaluated on the Davidson dataset.}
}
@article{ZHANG2025122299,
title = {GAL: A global aspect local extraction mechanism for aspect-based sentiment classification},
journal = {Information Sciences},
volume = {717},
pages = {122299},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2025.122299},
url = {https://www.sciencedirect.com/science/article/pii/S0020025525004311},
author = {Zhiqiang Zhang and Xiaoming Li and Hongpeng Bai and Meilian Zheng and Kun Huang},
keywords = {Aspect-based sentiment classification, Information extraction, Multihead self-attention mechanism, Local context focus},
abstract = {Aspect-based sentiment classification (ABSC) is a subtask of aspect-based sentiment analysis (ABSA) that aims to predict the sentiment polarity of different aspects within a sentence. Existing research focuses primarily on combining two semantic features: the context of the sentence with the features of the aspect or the context of the sentence with local context features. However, these two-by-two combinations of extracting global or local contextual and aspectual features suffer from the limitation of insufficient semantic feature information and do not take full advantage of the feature information of the other in each piece of data. To address this issue, this paper presents a global aspect local (GAL) extraction mechanism designed to integrate global, aspect, and local context information to increase the accuracy of sentiment polarity prediction. This study designs and implements the GAL mechanism, which incorporates a multihead self-attention mechanism, local context focus, and a multilayer attention mechanism, utilizing pretrained models for text encoding. Experimental results on the SemEval-2014 Task 4 Subtask 2 dataset and the ACL Twitter social dataset demonstrate that our GAL mechanism improves accuracy by nearly 2% and the F1 score by 3% in fine-grained sentiment classification tasks compared with recent methods, verifying its effectiveness and superiority.}
}
@article{WANKHADE2024112249,
title = {A survey on aspect base sentiment analysis methods and challenges},
journal = {Applied Soft Computing},
volume = {167},
pages = {112249},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112249},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624010238},
author = {Mayur Wankhade and Chaitanya Kulkarni and Annavarapu Chandra Sekhara Rao},
keywords = {Aspect based sentiment analysis, Sentiment analysis, Deep learning, Transfer learning, Text classification, Opinion analysis, Text mining, Machine learning},
abstract = {Sentiment analysis has spread to virtually every industry, including service, finance, e-commerce, consumer goods, telecommunications, health care, political campaigns, social events, and elections. Aspect-based sentiment analysis (ABSA) enables the automatic extraction of sentiment information from textual information or phrases that are deeply embedded. To address ABSA in various situations, numerous tasks for assessing various sentiment components and associated relationships. Our proposed ABSA workflow divides into broad categories: ABSA task as a single and compound, deep learning approach for ABSA. Specifically, we present a novel taxonomy for ABSA that organizes existing studies based on the axes of sentimental components of relevance, with a focus on modern improvements in complex ABSA tasks. In contrast to earlier ABSA studies that focused on a single sentiment element, numerous ABSA tasks involving numerous components have been examined in recent years in order to capture more comprehensive aspect-level sentiment polarity. Nonetheless, a comprehensive examination of the various ABSA objectives and their corresponding results is still lacking, a gap that this survey aims to address. In addition, trends in ABSA research are noted, and how the ABSA area can be progressed in the future prospective.}
}
@article{MODY2023108832,
title = {A curated dataset for hate speech detection on social media text},
journal = {Data in Brief},
volume = {46},
pages = {108832},
year = {2023},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2022.108832},
url = {https://www.sciencedirect.com/science/article/pii/S2352340922010356},
author = {Devansh Mody and YiDong Huang and Thiago Eustaquio {Alves de Oliveira}},
keywords = {Hate speech, Cyberhate, Cyberbullying, Natural language processing, Online Hate},
abstract = {Social media platforms have become the most prominent medium for spreading hate speech, primarily through hateful textual content. An extensive dataset containing emoticons, emojis, hashtags, slang, and contractions is required to detect hate speech on social media based on current trends. Therefore, our dataset is curated from various sources like Kaggle, GitHub, and other websites. This dataset contains hate speech sentences in English and is confined into two classes, one representing hateful content and the other representing non-hateful content. It has 451,709 sentences in total. 371,452 of these are hate speech, and 80,250 are non-hate speech. An augmented balanced dataset with 726,120 samples is also generated to create a custom vocabulary of 145,046 words. The total number of contractions considered in the dataset is 6403. The total number of bad words usually used in hateful content is 377. The text in each sentence of the final dataset, which is utilized for training and cross-validation, is limited to 180 words. The generated contractions dataset can be used for any projects in the area of NLP for data preprocessing. The augmented dataset can help to reduce the number of out-of-vocabulary words, and the hate speech dataset can be used as a classifier to detect hate or no hate on social media platforms.}
}
@article{XU2025100136,
title = {Aspect-based sentiment classification with BERT and AI feedback},
journal = {Natural Language Processing Journal},
volume = {10},
pages = {100136},
year = {2025},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2025.100136},
url = {https://www.sciencedirect.com/science/article/pii/S2949719125000123},
author = {Lingling Xu and Weiming Wang},
keywords = {Aspect-based sentiment classification, Data augmentation, Masked aspect term prediction, AI feedback},
abstract = {Data augmentation has been widely employed in low-resource aspect-based sentiment classification (ABSC) tasks to alleviate the issue of data sparsity and enhance the performance of the model. Unlike previous data augmentation approaches that rely on back translation, synonym replacement, or generative language models such as T5, the generation power of large language models is explored rarely. Large language models like GPT-3.5-turbo are trained on extensive datasets and corpus to capture semantic and contextual relationships between words and sentences. To this end, we propose Masked Aspect Term Prediction (MATP), a novel data augmentation method that utilizes the world knowledge and powerful generative capacity of large language models to generate new aspect terms via word masking. By incorporating AI feedback from large language models, MATP increases the diversity and richness of aspect terms. Experimental results on the ABSC datasets with BERT as the backbone model show that the introduction of new augmented datasets leads to significant improvements over baseline models, validating the effectiveness of the proposed data augmentation strategy that combines AI feedback.}
}
@article{ALSAQQA2024224,
title = {A Survey of Hate Speech Detection for Arabic Social Media: Methods and Datasets},
journal = {Procedia Computer Science},
volume = {251},
pages = {224-231},
year = {2024},
note = {15th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 14th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare EUSPN/ICTH 2024},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.11.104},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924033386},
author = {Samar Al-Saqqa and Arafat Awajan and Bassam Hammo},
keywords = {Hate speech, deep learning, transfer learning, word embedding, BERT, word2Vec},
abstract = {The last decade has witnessed an increase in harmful content on social media. The great proliferation of hate speech and other forms of aggressive language serves as evidence of this trend. The significant growth of user-generated content has prompted researchers to explore advanced techniques for hate speech detection, and most social media platforms have implemented measures to prevent posts targeting individuals or groups based on characteristics such as race, ethnicity, religion, gender, or nationality. This survey summarizes the methods used for hate speech detection in Arabic contexts, focusing on machine learning, deep learning, and transfer learning approaches. Furthermore, it presents Arabic datasets specifically constructed for this task, and identifies existing research gaps, offering insights to guide future studies in this field.}
}
@article{KWON2026104397,
title = {Aspect-based sentiment analysis through zero-shot text classification and impact-asymmetry analysis},
journal = {International Journal of Hospitality Management},
volume = {133},
pages = {104397},
year = {2026},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104397},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925003251},
author = {Wooseok Kwon},
keywords = {Aspect-based sentiment analysis, Zero-shot learning, Large language model, Kano model, Impact-asymmetry analysis, User-generated content},
abstract = {This study proposes innovative methods integrating aspect-based sentiment analysis (ABSA) using zero-shot text classification (ZSTC) into the impact-asymmetry analysis. Although ABSA is essential to enrich a thorough understanding of customer behavior, applying it to hospitality and tourism management is challenging because matching sentiment valence with an aspect category is complicated, and annotated datasets are scarce. The ZSTC suggested by this study leverages pre-trained large language models and addresses these challenges in hospitality and tourism management contexts. Furthermore, impact-asymmetry analysis based on the Kano model investigates the asymmetric relationships between the identified aspects and customer satisfaction. It classifies them into satisfiers, dissatisfiers, or hybrids and prioritizes them to support managerial decision-making. A case study analyzing TripAdvisor reviews during the COVID-19 pandemic is provided to demonstrate the usefulness of the proposed methodology. This study's findings offer theoretical and practical contributions to the academic and business sectors.}
}
@article{AZIZ2024102035,
title = {CoreNLP dependency parsing and pattern identification for enhanced opinion mining in aspect-based sentiment analysis},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {4},
pages = {102035},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102035},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824001241},
author = {Makera Moayad Aziz and Azuraliza Abu Bakar and Mohd Ridzwan Yaakub},
keywords = {Aspect-based sentiment analysis, Sentiment analysis, Dependency parsing, Data processing, Deep learning},
abstract = {Aspect-Based Sentiment Analysis (ABSA) aims to identify the sentiment expressed towards a specific feature or aspect of a given text. Although certain ABSA techniques employ syntactic information to capture the connection between the opinion target and the sentiment word, they often do not incorporate data processing techniques such as dependency parsing, which can be beneficial in accurately capturing the sentiment expressed towards the opinion target. In this paper a method for ABSA that employs both syntax and semantic information and incorporates dependency parsing(Semantic-Syntactic Dependency Parsing (SSDP) Method) with Core Natural Language Processing (CoreNLP) which is a natural language processing library for processing the input text and identifying patterns effectively (according to the CoreNLP relations and part of speech tagging(POS)) to extract the critical relations that accurately reflect the sentiment conveyed regarding the opinion target is proposed. The results show that the proposed pattern captured approximately 75% of the data, and the rest were classified via Long Short-Term Memory (LSTM) based on semantic information. We illustrated the efficacy of SSDP, through experiments on the SemEval14,Semval15 and Semval16 datasets, which include two datasets (laptops and restaurants) carefully categorized by a human annotator into categories of positive, negative, or neutral attitudes. The experimental results reveal that SSDP is superior to the other state-of-the-art ABSA approaches, that use syntax information but do not utilize data processing techniques. Additionally, we highlight the limitations of ABSA methods that do not incorporate syntax information and the potential improvements that can be made through the use of data processing.}
}
@article{PUTRA2024239,
title = {Advanced BERT-CNN for Hate Speech Detection},
journal = {Procedia Computer Science},
volume = {234},
pages = {239-246},
year = {2024},
note = {Seventh Information Systems International Conference (ISICO 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.02.170},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924003569},
author = {Cendra Devayana Putra and Hei-Chia Wang},
keywords = {BERT, Convolution Layer, Context Embedding, Hate Speech Detection},
abstract = {Hate Speech already been phenomenal expansion over the past decade. The paper proposed a new model that combines advanced CNN and Bidirectional Encoder Representations from Transformers (BERT) context embedding to predict hate speech in social media. This research trained contextual embedding on the datasets and used the learned information to identify objectionable language and hate speech in text. The paper evaluated supervised machine learning classifiers for bigoted and offensive content on Twitter using two datasets and found that advanced CNN context embeddings produced superior results. This research generated optimistic outcomes, which achieves 73% F1-score for Davidson dataset and 56% F1-score for TRAC-1 dataset}
}
@article{HUANG2025128705,
title = {Enhancing aspect-based sentiment analysis with linking words-guided emotional augmentation and hybrid learning},
journal = {Neurocomputing},
volume = {612},
pages = {128705},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128705},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224014760},
author = {Deling Huang and Ling Ren and Zanxiong Li},
keywords = {Aspect-based sentiment analysis, Data augmentation, Adversarial training, Contrastive learning},
abstract = {Aspect-based sentiment analysis (ABSA) is a sophisticated task in the field of natural language processing that aims to identify emotional tendencies related to specific aspects of text. However, ABSA often faces significant data shortages, which limit the availability of annotated data for training and affects the robustness of models. Moreover, when a text contains multiple emotional dimensions, these dimensions can interact, complicating the judgments of emotional polarity. In response to these challenges, this study proposes an innovative training framework: Linking words-guided multidimensional emotional data augmentation and adversarial contrastive training (LWEDA-ACT). Specifically, this method alleviates the issue of data scarcity by synthesizing additional training samples using four different text generators. To obtain the most representative samples, we selected them by calculating sentence entropy. Meanwhile, to reduce potential noise, we introduced linking words to ensure text coherence. Additionally, by applying adversarial training, the model is able to learn generalized feature representations to handle minor input perturbations, thereby enhancing its robustness and accuracy in complex emotional dimension interactions. Through contrastive learning, we constructed positive and negative sample pairs, enabling the model to more accurately identify and distinguish the sentiment polarity of different aspect terms. We conducted comprehensive experiments on three popular ABSA datasets, namely Restaurant, Laptop, and Twitter, and compared our method against the current state-of-the-art techniques. The experimental results demonstrate that our approach achieved an accuracy improvement of +0.98% and a macro F1 score increase of +0.52% on the Restaurant dataset. Additionally, on the challenging Twitter dataset, our method improved accuracy by +0.77% and the macro F1 score by +1.14%.}
}
@article{WU2025102304,
title = {Confront hate with AI: how AI-generated counter speech helps against hate speech on social Media?},
journal = {Telematics and Informatics},
volume = {101},
pages = {102304},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102304},
url = {https://www.sciencedirect.com/science/article/pii/S0736585325000668},
author = {Chuanhui Wu and Yifan Wang and Yuchen Zhang and Houcai Wang and Yufei Pang},
keywords = {AI, Hate speech, Counterspeech, Social media, Identity disclosure},
abstract = {In the digital age, the interconnected nature of social media has accelerated the exchange of information, knowledge, and ideas. However, it has also amplified the spread of hate speech. Although user-generated content is considered a potential solution to online hate speech, it also presents challenges such as inefficiency, error rates, and ethical risks to users. Therefore, this study focuses on the impact of AI-generated counterspeech on user engagement intention to confront hate speech on social media. Through a pilot study and three experiments (N = 809), we empirically demonstrate the effectiveness of AI-generated counterspeech. Study 1 shows that participants are more willing to engage in counterspeech when it is present than in hate speech with no counterspeech. Study 2 reveals that empathy-based counterspeech elicits greater engagement than fact-based counterspeech and that AI-generated counterspeech has a stronger impact on user engagement intention. Study 3 indicates that participants are more willing to engage with AI-generated counterspeech when the AI identity is not disclosed. Perceived trust mediates the effects of generator types and identity disclosure on user engagement. Our findings provide empirical evidence of the application of AI in online hate speech governance and offer practical insights for social media platforms.}
}
@article{MEHRA2023101063,
title = {Unexpected surprise: Emotion analysis and aspect based sentiment analysis (ABSA) of user generated comments to study behavioral intentions of tourists},
journal = {Tourism Management Perspectives},
volume = {45},
pages = {101063},
year = {2023},
issn = {2211-9736},
doi = {https://doi.org/10.1016/j.tmp.2022.101063},
url = {https://www.sciencedirect.com/science/article/pii/S2211973622001283},
author = {Payal Mehra},
keywords = {Leisure tourism, Foreign tourists, Behavioral intentions, Asia, ABSA, Emotion analysis, Sentiment analysis},
abstract = {Scholarly work regarding tourist behavior requires more empirical support especially concerning methods to extract emotions and sentiments from user-generated comments on social media. Research on predicting behavioral intentions of foreign tourists who faced culture shock (or unexpected surprise) has been under-represented in tourism literature. This paper used Aspect Based Sentiment Analysis (ABSA) and Emotion analysis (EA) to predict tourist behavior from User Generated Comments (UGCs) post their travel in three Asian countries. Findings reveal the presence of a sizeable inactive group of tourists who were indifferent towards post-travel behavioral intentions. The study recommends destination managers to consider managing tourist emotions, specifically sad surprise, in the travel phase of the tourists to strategically manage the post-travel behavior of tourists on social media. A conceptual model has been presented to operationalise these constructs to broadly predict destination optimism and destination pessimism proclivities of the tourists.}
}
@article{SUBRAMANIAN2023110,
title = {A survey on hate speech detection and sentiment analysis using machine learning and deep learning models},
journal = {Alexandria Engineering Journal},
volume = {80},
pages = {110-121},
year = {2023},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2023.08.038},
url = {https://www.sciencedirect.com/science/article/pii/S1110016823007238},
author = {Malliga Subramanian and Veerappampalayam {Easwaramoorthy Sathiskumar} and G. Deepalakshmi and Jaehyuk Cho and G. Manikandan},
keywords = {Hate speech detection, Sentiment analysis, Machine learning, Deep learning, Inclusive online},
abstract = {In today's digital era, the rise of hate speech has emerged as a critical concern, driven by the rapid information-sharing capabilities of social media platforms and online communities. As the internet expands, the proliferation of harmful content, including hate speech, presents considerable obstacles in ensuring a secure and inclusive online environment. In response to this challenge, researchers have embraced machine learning and deep learning methods to create automated systems that can effectively detect hate speech and conduct sentiment analysis, offering potential solutions to address this pressing issue. This survey article provides a comprehensive overview of recent advancements in hate speech detection and sentiment analysis using machine learning and deep learning models. We present an in-depth analysis of various methodologies and datasets employed in this domain. Additionally, we explore the unique challenges faced by these models in accurately identifying and classifying hate speech and sentiment in online text. Finally, we outline areas where more study is needed and suggest potential new avenues for exploration in the field of hate speech identification and sentiment analysis. Using the results of this survey, we hope to encourage the development of more effective machine learning and deep learning-based solutions to curb hate speech and promote a more inclusive online environment.}
}
@article{LI2025131155,
title = {PMN: A prototype network based metric framework for solving aspect-based sentiment analysis tasks},
journal = {Neurocomputing},
volume = {653},
pages = {131155},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131155},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225018272},
author = {Chenhao Li and Wenti Huang and Yunfei Chen and Tingxuan Chen and Zhan Yang and Jun Long},
keywords = {Sentiment analysis, Few-shot learning, Prototypical network, Metric framework},
abstract = {Aspect-based Sentiment Analysis (ABSA) aims to identify aspect terms and analyze sentiment by associating them with corresponding sentiment polarity and opinion words. Existing approaches primarily involve four key components: aspect term extraction, aspect category classification, opinion term extraction, and sentiment polarity classification, each giving rise to multiple fine-grained tasks. These tasks complicate the construction and annotation of foundational datasets. However, due to the heavy reliance on manual annotations and the limited applicability of domain-specific datasets, this study introduces a few-shot learning approach. It constructs a prototype network based on these four tasks. Despite the interdependencies among various ABSA tasks, exploring their potential relationships remains limited. This research centers on a quadruple (QUAD) cognitive task framework, evaluating the complexity of ABSA tasks from this perspective. We propose a Prototype Metric Network that enhances the mapping capabilities of the prototype network through three distinct distance metrics, effectively addressing challenges arising from data scarcity and the constrained scope of multiple ABSA tasks. Experimental results demonstrate that our model outperforms state-of-the-art algorithms, providing a more complete and accurate extraction of significant sentiment targets.}
}
@article{ROY2022101386,
title = {Hate speech and offensive language detection in Dravidian languages using deep ensemble framework},
journal = {Computer Speech & Language},
volume = {75},
pages = {101386},
year = {2022},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2022.101386},
url = {https://www.sciencedirect.com/science/article/pii/S0885230822000250},
author = {Pradeep Kumar Roy and Snehaan Bhawal and Chinnaudayar Navaneethakrishnan Subalalitha},
keywords = {Dravidian language, Hate speech, Offensive language, Transfer learning, BERT, Deep learning, Low-resource},
abstract = {Social networking platforms gained widespread popularity and are used for various activities like: promoting products, sharing news, achievements and many more. On the other hand, it is also used for spreading rumors, bullying people, and abusing certain groups of people with hateful words. The hate and offensive posts must be detected and removed as early as possible from the social platforms because such posts are spread very quickly and tend to have a lot of negative impacts on human beings. In the last few years, offensive content and hate speech detection has become popular topic of research. Detecting hate speech on social platforms has many challenges, one of them being the use of code-mixed language. Majority of the social media users usually post their messages in code-mixed languages such as Hindi–English, Tamil–English, Malayalam–English, Telugu–English and others. In this exhaustive study, we explore and compare the use of various machine learning and deep learning approaches. An ensemble model by combining the outcomes of transformer and deep learning-based models is suggested to detect hate speech and offensive language on social networking platforms. The experimental outcomes of the proposed weighted ensemble framework outperformed state-of-the-art models by achieving 0.802 and 0.933 weighted F1-score for Malayalam and Tamil code-mixed datasets.}
}
@article{WU2026101822,
title = {Multi-task unified model for Chinese aspect-based sentiment analysis},
journal = {Computer Speech & Language},
volume = {95},
pages = {101822},
year = {2026},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2025.101822},
url = {https://www.sciencedirect.com/science/article/pii/S0885230825000476},
author = {Yuewei Wu and Jialu Wang and Xiaoli Feng and Zhaoliang Wu and Jiakai Peng and Fulian Yin},
keywords = {Aspect-based sentiment analysis, Chinese comments, Machine reading comprehension, Multi-task learning},
abstract = {Aspect-Based Sentiment Analysis (ABSA) is crucial for in-depth mining and analysis of opinion expressions and sentiment tendencies in massive user review texts. Most of the existing researches on ABSA in Chinese only consider a single contextual semantic feature, while ignoring syntactic dependency feature, and rarely addresses the realization of multiple tasks in the same model. From the perspective of multi-task unification, this paper proposes a multi-task unified model for Chinese aspect-based sentiment analysis (MTUC-ABSA), which integrates Bi-directional Long Short-Term Memory (Bi-LSTM) and Graph Convolutional Network (GCN) to learn multiple features between context and sentiment elements, and uses the unified Machine Reading Comprehension (MRC) paradigm to build a multi-task model, which mainly focuses on the aspect sentiment triplet extraction (ASTE) task. Experimental results on real data sets show that our method can effectively improve the accuracy of aspect-based sentiment analysis compared with other existing methods.}
}
@article{LIU2025111297,
title = {Integrating multiple syntactic structures for enhanced aspect-based sentiment analysis},
journal = {Engineering Applications of Artificial Intelligence},
volume = {158},
pages = {111297},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111297},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625012990},
author = {Hongtao Liu and Kang Xiong and Sanqi Wu and Pengju Cao and Kefei Cheng and Xueyan Liu},
keywords = {Aspect-based sentiment analysis, Graph convolutional network, Large language model, Syntactic structure},
abstract = {Aspect-based sentiment analysis is a fine-grained sentiment analysis task that focuses on determining the sentiment polarity of specific aspect words within a sentence. Traditional methods relying solely on dependency trees as syntactic structures have limitations in representing complex sentence structures and handling domain-specific data. To address the limitations, we propose Multiple Syntactic Relational Interaction Graph Convolutional Network (MSRI-GCN). This approach combines syntactic dependency trees with aspect-specific relational graph structures derived from Large Language Models (LLMs) like Chat Generative Pre-trained Transformer, preserving global syntactic information and enriching local aspect-specific information. Our method computes the number of paths between nodes using the dependency tree’s adjacency matrix and augments this with the syntactic relations from the reconstructed relational graph. Additionally, we utilize the multi-head attention mechanism to capture semantic relations. By learning the features of aspects and contexts through these dual relations, our model adaptively integrates both syntactic and semantic information. We conducted extensive experiments on five benchmark datasets demonstrate that our model significantly outperforms existing models.}
}
@article{HE2025112782,
title = {CABiLSTM-BERT: Aspect-based sentiment analysis model based on deep implicit feature extraction},
journal = {Knowledge-Based Systems},
volume = {309},
pages = {112782},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112782},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124014163},
author = {Bo He and Ruoyu Zhao and Dali Tang},
keywords = {Aspect-based sentiment analysis, Natural language processing, BERT, Transfer learning, Sentiment analysis},
abstract = {Aspect-based sentiment analysis (ABSA) models typically focus on learning contextual syntactic information and dependency relations. However, these models often struggle with losing or forgetting implicit feature information from shallow and intermediate layers during the learning process, potentially compromising classification performance. We consider the implicit feature information in each layer of the model to be equally important for processing. So, this paper proposes the CABiLSTM-BERT model, which aims to fully leverage implicit features at each layer to address this information loss problem and improve accuracy. The CABiLSTM-BERT model employs a frozen BERT pre-trained model to extract text word vector features, reducing overfitting and accelerating training. These word vectors are then processed through CABiLSTM, which preserves implicit feature representations of input sequences and LSTMs in each direction and layer. The model applies convolution to merge all features into a set of embedding representations after highlighting important features through multi-head self-attention calculations for each feature group. This approach minimizes information loss and maximizes utilization of important implicit feature information at each layer. Finally, the feature representations undergo average pooling before passing through the sentiment classification layer for polarity prediction. The effectiveness of the CABiLSTM-BERT model is validated using five publicly available real-world datasets and evaluated using metrics such as accuracy and Macro-F1. Results demonstrate the model's efficacy in addressing ABSA tasks.}
}
@article{CHOUDHARY20252817,
title = {Hate Speech Detection: Leveraging LLM-GPT2 with Fine-Tuning and Multi-Shot Techniques},
journal = {Procedia Computer Science},
volume = {258},
pages = {2817-2825},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.542},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925016461},
author = {Mahima Choudhary and Basant Agarwal and Vishnu Goyal},
keywords = {Hate-Speech, LLM, GPT2, Fine-Tuning, Multiple Shot Technique},
abstract = {Hate Speech can be referred as any type of communication that can degrade, discriminates against or prejudice or incites violence against groups or individual based on certain factors such as religion, race, nationality, skin color, gender etc. It is very crucial to detect hate speech to stop the harm or violence against targeted individuals or groups and to create safe and inclusive environment. In this paper, the performance of two large language model-based approaches were investigated. In the first approach, fine-tuning of GPT-2 model was performed using a hate-speech dataset and then evaluated the fine-tuned GPT model for hate speech detection. In the second approach, n-shot learning based approaches were used for value of n as zero, one and two, where prompt designing was done first and then ask the GPT model to detect if the given text is expressing hate based on the given prompt on test data. All the experiments were carried out on publicly available ‘HatEval’ dataset. Experimental results show that few(n) shot learning does not necessarily surpass lesser(<n) shot learning techniques in GPT-2 because it depends on the prompt, which contains instruction and selected examples for shots as zero-shot technique has better performance than one and two-shot. Also, the fine-tuning the GPT-2 model performs better than zero-shot technique in this task. Source code and other data is available at https://github.com/mahimacs/GPT2-for-Hate-Speech-Detection.}
}
@article{PRASAD2026108635,
title = {FoodABSANet: Developing an adaptive graph convolutional neural network for aspect-based sentiment analysis of food reviews with a weighted polarity score},
journal = {Computational Biology and Chemistry},
volume = {120},
pages = {108635},
year = {2026},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2025.108635},
url = {https://www.sciencedirect.com/science/article/pii/S1476927125002968},
author = {Akkireddi Vara Prasad and K. Vedavathi},
keywords = {Aspect-Based Sentiment Analysis, Term Frequency-Inverse Document Frequency, Weighted Polarity Score, Adaptive Graph Convolutional Neural Network, Determined Random Parameter-based Puzzle Optimization Algorithm},
abstract = {-Aspect-Based Sentiment Analysis (ABSA) is considered a unique variant, which intends to identify the opinions regarding delicate topics. However, it is a neglected topic of study, ABSA attempts to find out the sentiment polarity on particular characteristics within statements, enabling more precise mining of consumers' emotional polarities regarding various aspects. The conversion of the conventional rating-aided recommendation approach into an effective aspect-aided procedure is made easier by this evaluation. The ABSA in hotel ratings serves as an essential. ABSA analyses an extensive choice of comments that expand a far trouble-free good, poor opinions that delve into particular factors addressed in the analysis. However, ABSA struggles to maintain numerous aspects that influence one another. In the past few years, deep learning techniques have been employed to analyze text emotion with outstanding outcomes.}
}
@article{ROY2025102409,
title = {Ensuring safety in digital spaces: Detecting code-mixed hate speech in social media posts},
journal = {Data & Knowledge Engineering},
volume = {156},
pages = {102409},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102409},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000047},
author = {Pradeep Kumar Roy and Abhinav Kumar},
keywords = {Hate speech, Code-mixed, Telugu-English, Social network, Deep learning, Transfer learning},
abstract = {Social networks strive to offer positive content to users, yet a considerable amount of inappropriate material, such as rumors, fake news, and hate speech, persists. Despite significant efforts to detect and prevent hate speech early, it remains widespread due to issues like misspellings and mixed language in posts. To address these challenges, this research utilizes advanced algorithms like CNN, LSTM, and BERT to develop an automated system for detecting hate speech in Telugu-English code-mixed posts. Additionally, evaluating the effectiveness of data translation and transliteration approaches for detecting hate in mixed language. Results indicate that the transliteration approach achieves the highest accuracy, with a performance of 75% accuracy, surpassing raw and translated data by 1% and 3%, respectively. The proposed system may effectively minimizes hate speech and offensive content on social media platforms, resulting in an enhanced user experience. From a managerial perspective, this research presents numerous benefits, such as improved content moderation, optimized resource allocation, data-driven decision-making, enhanced user satisfaction, strengthened reputation management, and greater scalability. These advancements underscore the potential of utilizing advanced technologies to address complex challenges in social media management.}
}
@article{CHENG2025107864,
title = {Aspect-based sentiment analysis based on multi-granularity graph convolutional network},
journal = {Neural Networks},
volume = {192},
pages = {107864},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2025.107864},
url = {https://www.sciencedirect.com/science/article/pii/S0893608025007440},
author = {Yanfen Cheng and Minghui Yuan and Fan He and Xun Shao and Jiajun Wu},
keywords = {Natural language processing, Aspect-based sentiment analysis, Graph convolutional network, Dependency tree, Constituency tree},
abstract = {Aspect sentiment classification (ASC) is a subtask of Aspect-based sentiment analysis (ABSA), and its goal is to predict the sentiment polarity corresponding to specific aspect word within a sentence. Existing ABSA methods have achieved impressive predictive performance by not only leveraging attention mechanism to capture semantic association information within sentences, but also employing graph convolutional network (GCN) to exploit the syntactic structure information of dependency and constituency trees. However, these methods still have two main shortcomings: (1) they overlook the utilization of local sentiment features in the constituency tree, focusing only on global sentiment features; and (2) they fail to comprehensively utilize the syntactic information from both dependency and constituency trees. To address these issues, we propose a novel multi-granularity graph convolutional network (MGCN), which comprises three main components: an attention layer, a mask matrix layer, and a GCN layer. In the attention layer, we constructed semantic association matrices using an attention mechanism to explore the semantic associations between words and overall sentence semantics. In the mask matrix layer, we designed hierarchical rule-based multi-granularity constituency tree mask matrices (CM) to extract sentiment features from local to global levels within the constituency tree. Additionally, to obtain a more comprehensive syntactic features set, we fully fused the structural characteristics of the dependency and constituency trees to create multi-granularity fusion mask matrices (FM), which were further enhanced by the semantic association matrices. Finally, in the GCN layer, we performed convolution operations on the enhanced FM to strengthen the node representations. Experiments on the SemEval 2014 and Twitter datasets demonstrated effectiveness of MGCN.}
}
@article{LIU2023121031,
title = {A cross-lingual transfer learning method for online COVID-19-related hate speech detection},
journal = {Expert Systems with Applications},
volume = {234},
pages = {121031},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.121031},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423015336},
author = {Lin Liu and Duo Xu and Pengfei Zhao and Daniel Dajun Zeng and Paul Jen-Hwa Hu and Qingpeng Zhang and Yin Luo and Zhidong Cao},
keywords = {COVID-19, Deep learning, Cross-lingual, Hate speech detection, Natural language processing},
abstract = {During the COVID-19 pandemic, online social media platforms such as Twitter facilitate the exchange of information among people. However, the prevalence of “infodemic” such as online hate speech has exacerbated social rifts, discrimination, prejudice and even hate crimes. Timely and effective detection of the hate speech will help create a healthy public opinion environment. Most of the current COVID-19-related hate speech research focuses on a single language, such as English. In this paper, we introduce a cross-lingual transfer learning method, aiming to contribute to hate speech detection in low-resource languages. We propose a deep learning based model to classify hate speech with a pre-trained language model for multilingual text embedding. Data augmentation and cross-lingual contrastive learning are then utilized to further improve the performance of cross-lingual knowledge transfer. To evaluate our method, we collected three publicly available annotated COVID-19-related hate speech datasets on Twitter, i.e., two in English and one in German. Furthermore, a Chinese dataset based on Weibo is constructed to expand multilingual data. The experimental results across three languages illustrate the effectiveness of our method for cross-lingual hate speech detection. Test F1-scores of our method for English, Chinese, German as transfer target languages can reach up to 0.728, 0.799 and 0.612 respectively, which are on average better than other baselines.}
}
@article{TAJ2025110632,
title = {Aspect-based sentiment analysis for software requirements elicitation using fine-tuned Bidirectional Encoder Representations from Transformers and Explainable Artificial Intelligence},
journal = {Engineering Applications of Artificial Intelligence},
volume = {151},
pages = {110632},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110632},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625006323},
author = {Soonh Taj and Sher Muhammad Daudpota and Ali Shariq Imran and Zenun Kastrati},
keywords = {Software requirement elicitation, Sentiment analysis, Aspect Category Detection, Aspect Category Polarity, App reviews, Fine-tuned Bidirectional Encoder Representations from Transformers, Explainable Artificial Intelligence},
abstract = {Aspect-Based Sentiment Analysis (ABSA) of app reviews allows a better understanding of user preferences regarding specific product features and helps the development team elicit requirements effectively. The existing literature faces challenges such as limited focus on the automation of Requirement Elicitation (RE), insufficient task-specific fine-tuning of models such as Bidirectional Encoder Representations from Transformers (BERT), and lack of interpretability owing to the black-box nature of these models. Therefore, our work makes the following significant contributions to address these challenges: (1) development and evaluation of a robust method based on ABSA for the automation of the RE process; (2) optimization of ABSA using BERT fine-tuning for enhanced performance, which includes conducting a comprehensive ablation study to obtain the best hyperparameters that guarantee the best model performance and robustness; and (3) integration of Explainable Artificial Intelligence (XAI) techniques for enhanced BERT model interpretability. Our work was evaluated on the ABSA Warehouse of Apps REviews (AWARE) dataset, a specifically tailored dataset for the RE process. Our study outperformed baseline models such as the Support Vector Machine (SVM), Convolutional Neural Network (CNN), and BERT, and achieved an average F1-Score of 0.83 for the Aspect Category Detection (ACD) task and 0.94 for the Aspect Category Polarity (ACP) task. In addition, we employed XAI using Locally Interpretable Model-Agnostic Explanations (LIME) to explain the BERT model prediction results, which aids in the improved visualization and interpretability of the app review analysis for the automated RE process.}
}
@article{EID2024202,
title = {A-MASA: Arabic Multi-Domain Aspect-Based Sentiment Analysis Datasets},
journal = {Procedia Computer Science},
volume = {244},
pages = {202-211},
year = {2024},
note = {6th International Conference on AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.193},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924029946},
author = {Yomna Eid and Hala Zayed and Walaa Medhat},
keywords = {Aspects Extraction, Arabic Aspect-Based Sentiment Analysis, Natural language processing, Datasets},
abstract = {The rapid growth of Natural Language Processing (NLP) applications has gained interest in various languages, including Arabic. One critical NLP task is Aspect-Based Sentiment Analysis (ABSA). ABSA involves identifying the sentiment expressed toward specific aspects or attributes of entities mentioned in a piece of text, rather than determining the overall sentiment. Despite the increased use of Semitic languages like Arabic in NLP over the past decade, there remains a lack of resources and datasets in Arabic, particularly in dialectical Arabic. Additionally, existing ABSA datasets are often limited to a single domain, which does not support all types of ABSA, such as multi-domain ABSA, nor do they allow for testing a model's generalization capabilities. This study addresses these limitations by constructing multi-domain ABSA datasets in Arabic for the tasks of aspect extraction and aspect polarity detection. The datasets include both real and synthetic data, covering dialectical and modern standard Arabic, and comprising 6,500 records across five domains. These datasets can be utilized in single-domain, cross-domain, and multi-domain experiments for ABSA. Furthermore, we evaluated the constructed datasets using various transformer-based models and assessed the impact of generating synthetic data on the diversity and balance of the data, as well as on model performance. The results reported in this research demonstrate that the data is valid for use in ABSA tasks. Moreover, the models used for evaluation achieved competitive or superior results compared to existing models on various datasets. Additionally, the annotation guidelines we created are presented as recommended practices applicable to different tasks. All datasets used in this study are publicly available for research purposes.}
}
@article{JIA2025127353,
title = {Multi-axis fusion with optimal transport learning for multimodal aspect-based sentiment analysis},
journal = {Expert Systems with Applications},
volume = {280},
pages = {127353},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127353},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425009753},
author = {Li Jia and Tinghuai Ma and Huan Rong and Liyuan Gao and Yufeng Zhang and Victor S. Sheng},
keywords = {Multi-modal sentiment analysis, Optimal transport learning, Multi-axis multimodal fusion, Aspect-based sentiment analysis},
abstract = {Multimodal aspect-based sentiment analysis explores sentiment trends in opinion aspects from multiple heterogeneous modal data. Many existing methods ignore the gap between different modality representations, resulting in poor performance of classification models. While joint learning-based approaches have achieved great successes, designing a method that balances computational resources and classification performance to interact with textual and visual modalities remains challenging. To address these issues, we design a Multi-Axis Fusion network with Optimal Transport learning (MAFOT) for multimodal aspect-based sentiment analysis, which introduces the optimal transport kernel embedding (OTKE) to realize unimodal input feature transformation and the multi-axis fusion module (MAFM) to perform multimodal feature fusion from horizontal, vertical, and channel directions. Specifically, we utilize the pre-trained models to obtain unimodal feature representations (e.g., sentences, opinion aspects, and associated images). Subsequently, we use the optimal transport kernel method to embed the heterogeneous unimodal features into public subspaces, which have non-linear transformation capabilities that can reduce the representation gap. Then, the multi-axis fusion module is designed to integrate multimodal information, which is processed from different axes using a multilayer perceptrons learner. Extensive experiments conducted on the publicly datasets demonstrate that the proposed model MAFOT is more competitive against the SOTA baseline models.}
}
@article{JIN2025111654,
title = {Aspect-based sentiment analysis with semantic and syntactic enhanced multi-layer fusion model},
journal = {Engineering Applications of Artificial Intelligence},
volume = {159},
pages = {111654},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111654},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625016562},
author = {Song Jin and Qing He and Yuji Wang and Nisuo Du and Wenjing Lei},
keywords = {Artificial intelligence, Aspect-based sentiment analysis, Natural language processing, Graph convolutional network, Feature fusion},
abstract = {Aspect-based sentiment analysis (ABSA) aims to identify the sentiment polarity of specific aspect words or phrases in a sentence. Although recent studies have used attention mechanisms or syntactic relations of dependency trees to establish links between aspect terms and sentences, these approaches are imperfect in effectively fusing syntactic and semantic contextual information. Therefore, in this paper, we propose a novel multi-layer fusion model (MLFM) based on artificial intelligence (AI) techniques to efficiently fuse semantic and syntactic information for sentiment analysis. In the model, we first propose a new bi-graph convolutional network module for aspect term-centered aspect nodal attention (Aspect-NA) to enhance Semantic and Syntactic learning. Within Aspect-NA, we introduce dependency embedding and propose a dual embedding update mechanism that pays more attention to the influence of dependency types and semantics. In addition, we propose an adaptive hierarchical cross-attention (AHCA) for fusing the semantic information of aspect term with their associated syntactic features. AHCA not only effectively fuses features between syntax and semantics of the context, but also carries out the key features. We conducted experiments on six benchmark datasets, and the results show that our proposed model outperforms most baseline methods. The code and datasets involved in this paper are provided on https://github.com/jims-bug/MLFM.git.}
}
@article{SHARMA202535,
title = {Detecting Hate Speech for Hindi-English Code-Mix Text Data Using Dual Contrastive Learning},
journal = {Procedia Computer Science},
volume = {259},
pages = {35-43},
year = {2025},
note = {Sixth International Conference on Futuristic Trends in Networks and Computing Technologies (FTNCT06), held in Uttarakhand, India},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.03.304},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925010488},
author = {Amit Sharma and Rajni Bhalla},
keywords = {Hate speech Detection, NLP, Machine Learning, Sentiment Analysis, code-mixed data, Dual Contrastive Learning},
abstract = {A bigger problem in today’s world is hate speech on internet, especially as social media sites like Facebook and Twitter rapidly grow. It includes any speech or writing that makes fun of or calls for violence against people or groups because of things that make them unique, like race, religion, gender, or sexual orientation. This paper looks at how to find hate speech in Hindi-English Code-mixed text data using both Traditional machine learning (ML) models and Dual Contrastive Learning (DCL) method. Word embeddings, TF-IDF, and pre-trained SentBERT techniques were used along with other methods to prepare and examine the data. Traditional ML models like KNN, DT, and LR are tested in the study. These models get accuracy rates of 73.63%, 79.78%, and 85.50%, respectively. The proposed DCL model does better than these, as its accuracy rate is 86% and its F1-Score is 91%. The results show that pre-trained SentBERT could help better as extracting the feature in code-mixed data. The accuracy, on the other hand, shows that there is room for improvement. Adding more advanced deep learning and natural language processing methods could make the model even better.}
}
@article{KAPIL2025100133,
title = {A transformer based multi task learning approach to multimodal hate speech detection},
journal = {Natural Language Processing Journal},
volume = {11},
pages = {100133},
year = {2025},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2025.100133},
url = {https://www.sciencedirect.com/science/article/pii/S2949719125000093},
author = {Prashant Kapil and Asif Ekbal},
keywords = {Multi-task learning, UNITER, CLIP, AUC-ROC, F1 score},
abstract = {Online hate speech has become a major social issue in recent years, affecting both individuals and society as a whole. Memes are a multimodal kind of internet hate speech that is growing more common. Online memes are often entertaining and harmless. The seemingly innocent meme, on the other hand, transforms into a multimodal form of hate speech—a hateful meme—when specific types of text, graphics, or combinations of both are used. The spread of these harmful or undesirable memes has the potential to disrupt societal peace. Therefore, it is vital to limit inappropriate memes on social media. Multimodal hate speech identification is an inherently difficult and open question. It necessitates collaborative language, visual perception, and multimodal reasoning. This line of research has been progressed in this work by building a multi-task learning-based multimodal system for detecting hateful memes by training four hateful meme data sets concurrently. This MTL framework, which consists of Contrastive Language Image Pretraining (CLIP), UNiversal Image-TExt Representation Learning (UNITER), and BERT, was trained collaboratively to transfer common knowledge while simultaneously training four meme datasets. The results show that the recommended strategy outperforms unimodal and multimodal approaches on four multilingual benchmark datasets, with considerable AUC-ROC, accuracy, and F1-score. The ablation studies are undertaken to emphasise the impact of the sub-component in the MTL model. The confusion matrix is shown as quantitative analysis.}
}
@article{SMID2025103073,
title = {Cross-lingual aspect-based sentiment analysis: A survey on tasks, approaches, and challenges},
journal = {Information Fusion},
volume = {120},
pages = {103073},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103073},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525001460},
author = {Jakub Šmíd and Pavel Král},
keywords = {Cross-lingual aspect-based sentiment analysis, Aspect-based sentiment analysis, Sentiment analysis, Opinion mining, Cross-lingual transfer, Machine learning, Pre-trained language models},
abstract = {Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task that focuses on understanding opinions at the aspect level, including sentiment towards specific aspect terms, categories, and opinions. While ABSA research has seen significant progress, much of the focus has been on monolingual settings. Cross-lingual ABSA, which aims to transfer knowledge from resource-rich languages (such as English) to low-resource languages, remains an under-explored area, with no systematic review of the field. This paper aims to fill that gap by providing a comprehensive survey of cross-lingual ABSA. We summarize key ABSA tasks, including aspect term extraction, aspect sentiment classification, and compound tasks involving multiple sentiment elements. Additionally, we review the datasets, modelling paradigms, and cross-lingual transfer methods used to solve these tasks. We also examine how existing work in monolingual and multilingual ABSA, as well as ABSA with LLMs, contributes to the development of cross-lingual ABSA. Finally, we highlight the main challenges and suggest directions for future research to advance cross-lingual ABSA systems.}
}
@article{SHARMA2022102760,
title = {Ceasing hate with MoH: Hate Speech Detection in Hindi–English code-switched language},
journal = {Information Processing & Management},
volume = {59},
number = {1},
pages = {102760},
year = {2022},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2021.102760},
url = {https://www.sciencedirect.com/science/article/pii/S0306457321002417},
author = {Arushi Sharma and Anubha Kabra and Minni Jain},
keywords = {Cyber hate, Social media, Data simulations, Bert, MuRIL, Transfer learning, Text classification, And machine learning},
abstract = {Warning: This manuscript may contain upsetting language. Social media has become a bedrock for people to voice their opinions worldwide. Due to the greater sense of freedom with the anonymity feature, it is possible to disregard social etiquette online and attack others without facing severe consequences, inevitably propagating hate speech. The current measures to sift the online content and offset the hatred spread do not go far enough. One factor contributing to this is the prevalence of regional languages in social media and the paucity of language flexible hate speech detectors. The proposed work focuses on analyzing hate speech in Hindi–English code-switched language. Our method explores transformation techniques to capture precise text representation. To contain the structure of data and yet use it with existing algorithms, we developed ‘MoH’ or (Map Only Hindi), which means ‘Love’ in Hindi. ‘MoH’ pipeline which consists of language identification, Roman to Devanagari Hindi transliteration using a knowledge base of Roman Hindi words, and finally employs the fine-tuned Multilingual Bert, and MuRIL language models. We conducted several quantitative experiment studies on three datasets, and evaluated performance using Precision, Recall and F1 metrics. The first experiment studies ‘MoH’ mapped text’s performance with classical machine learning models and shows an average increase of 13% in F1 scores. The second compares the proposed work’s scores with those of the baseline models and shows a rise in performance by 6%. Finally, the third compares the proposed ‘MoH’ technique with various data simulations using the existing transliteration library. Here, ‘MoH’ outperforms the rest by 15%. Our results demonstrate a significant improvement in the state-of-the-art scores on all three datasets.}
}
@article{KIBRIYA2024109153,
title = {Towards safer online communities: Deep learning and explainable AI for hate speech detection and classification},
journal = {Computers and Electrical Engineering},
volume = {116},
pages = {109153},
year = {2024},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109153},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624000818},
author = {Hareem Kibriya and Ayesha Siddiqa and Wazir Zada Khan and Muhammad Khurram Khan},
keywords = {Hate speech detection, Social media, Deep learning, Explainable Artificial Intelligence, Machine learning, Toxic comments, Hate speech},
abstract = {The internet and social media facilitate widespread idea sharing but also contribute to cyber-crimes and harmful behaviors, notably the dissemination of abusive and hateful speech, which poses a significant threat to societal cohesion. Hence, prompt and accurate detection of such harmful content is crucial. To address this issue, our study introduces a fully automated end-to-end model for hate speech detection and classification using Natural Language Processing and Deep Learning techniques. The proposed architecture comprising embedding, Convolutional, bidirectional Recurrent Neural Network, and bidirectional Long Short Term Memory layers, achieved the highest accuracy of 98.5%. Additionally, we employ explainable AI techniques, such as SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME), to gain insights into the performance of the proposed framework. This comprehensive approach meets the pressing demand for swift and precise detection and categorization of harmful online content.}
}
@article{PRONOZA2021102674,
title = {Detecting ethnicity-targeted hate speech in Russian social media texts},
journal = {Information Processing & Management},
volume = {58},
number = {6},
pages = {102674},
year = {2021},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2021.102674},
url = {https://www.sciencedirect.com/science/article/pii/S0306457321001606},
author = {Ekaterina Pronoza and Polina Panicheva and Olessia Koltsova and Paolo Rosso},
keywords = {Hate speech detection, Ethnic hate, Russian language, Deep learning},
abstract = {Ethnicity-targeted hate speech has been widely shown to influence on-the-ground inter-ethnic conflict and violence, especially in such multi-ethnic societies as Russia. Therefore, ethnicity-targeted hate speech detection in user texts is becoming an important task. However, it faces a number of unresolved problems: difficulties of reliable mark-up, informal and indirect ways of expressing negativity in user texts (such as irony, false generalization and attribution of unfavored actions to targeted groups), users’ inclination to express opposite attitudes to different ethnic groups in the same text and, finally, lack of research on languages other than English. In this work we address several of these problems in the task of ethnicity-targeted hate speech detection in Russian-language social media texts. This approach allows us to differentiate between attitudes towards different ethnic groups mentioned in the same text – a task that has never been addressed before. We use a dataset of over 2,6M user messages mentioning ethnic groups to construct a representative sample of 12K instances (ethnic group, text) that are further thoroughly annotated via a special procedure. In contrast to many previous collections that usually comprise extreme cases of toxic speech, representativity of our sample secures a realistic and, therefore, much higher proportion of subtle negativity which additionally complicates its automatic detection. We then experiment with four types of machine learning models, from traditional classifiers such as SVM to deep learning approaches, notably the recently introduced BERT architecture, and interpret their predictions in terms of various linguistic phenomena. In addition to hate speech detection with a text-level two-class approach (hate, no hate), we also justify and implement a unique instance-based three-class approach (positive, neutral, negative attitude, the latter implying hate speech). Our best results are achieved by using fine-tuned and pre-trained RuBERT combined with linguistic features, with F1-hate=0.760, F1-macro=0.833 on the text-level two-class problem comparable to previous studies, and F1-hate=0.813, F1-macro=0.824 on our unique instance-based three-class hate speech detection task. Finally, we perform error analysis, and it reveals that further improvement could be achieved by accounting for complex and creative language issues more accurately, i.e., by detecting irony and unconventional forms of obscene lexicon.}
}
@article{AGARWAL2023120564,
title = {Accelerating automatic hate speech detection using parallelized ensemble learning models},
journal = {Expert Systems with Applications},
volume = {230},
pages = {120564},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120564},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423010667},
author = {Shivang Agarwal and Ankur Sonawane and C. Ravindranath Chowdary},
keywords = {Hate speech detection, Ensemble learning, Social media},
abstract = {With increasing number of social media users and online engagement, it is essential to study hate speech propagation on social media platforms (SMPs). Automatic hate speech detection on social media is of utmost importance as hate speech can create discomfort among users and potentially generate a strong reaction in society. Ensemble learning algorithms are helpful in addressing sentiment-based classification due to their fault tolerance and efficiency. However, a simple, scalable, and robust framework is required to deal with large-scale data efficiently and accurately. Therefore, we propose parallelization to the standard ensemble learning algorithms to speed up the automatic hate speech detection on SMPs. In this study, we parallelize bagging, A-stacking, and random sub-space algorithms and test their serial and parallel versions on the standard high-dimensional datasets for hate speech detection. The experiments are performed using six datasets that address hate speech propagation during events like the COVID-19 pandemic, the US presidential election (2020), and the farmers’ protest in India (2021). Our parallel models observe a significant speedup with high efficiency, claiming that the proposed models are suitable for the considered application. Also, one of the main motivations of this study is to highlight the importance of generalization by testing the models under the cross-dataset environment. We observed that the accuracy is not affected while parallelizing the algorithms compared with serial algorithms executing on a single machine.}
}
@article{AGGARWAL2024124278,
title = {Exposing the Achilles’ heel of textual hate speech classifiers using indistinguishable adversarial examples},
journal = {Expert Systems with Applications},
volume = {254},
pages = {124278},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124278},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424011448},
author = {Sajal Aggarwal and Dinesh Kumar Vishwakarma},
keywords = {Adversarial attack, Glyphs, Hate speech, Offensive language, Transformers, Natural Language Processing (NLP)},
abstract = {The accessibility of online hate speech has increased significantly, making it crucial for social-media companies to prioritize efforts to curb its spread. Although deep learning models demonstrate vulnerability to adversarial attacks, whether models fine-tuned for hate speech detection exhibit similar susceptibility remains underexplored. Textual adversarial attacks involve making subtle alterations to the original samples. These alterations are designed so that the adversarial examples produced can effectively deceive the target model, even when correctly classified by human observers. Though many approaches have been proposed to conduct word-level adversarial attacks on textual data, they face the obstacle of preserving the semantic coherence of texts during the generation of adversarial counterparts. Moreover, the adversarial examples produced are often easily distinguishable by human observers. This work presents a novel methodology that uses visually confusable glyphs and invisible characters to generate semantically and visually similar adversarial examples in a black-box setting. In the hate speech detection task context, our attack was effectively applied to several state-of-the-art deep learning models, fine-tuned on two benchmark datasets. The major contributions of this study are: (1) demonstrating the vulnerability of deep learning models fine-tuned for hate speech detection; (2) a novel attack framework based on a simple yet potent modification strategy; (3) superior outcomes in terms of accuracy degradation, attack success rate, average perturbation, semantic similarity, and perplexity when compared to existing baselines; (4) strict adherence to prescribed linguistic constraints while formulating adversarial samples; and (5) preservation of ground truth label while perturbing original input using imperceptible adversarial examples.}
}
@article{SRIVASTAVA2025832,
title = {Leveraging Deep Learning for Comprehensive Multilingual Hate Speech Detection},
journal = {Procedia Computer Science},
volume = {252},
pages = {832-840},
year = {2025},
note = {4th International Conference on Evolutionary Computing and Mobile Sustainable Networks},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.044},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925000444},
author = {Atul Kumar Srivastava and Mitali Srivastava and Sanchali Das and Vikas Jain and Tej Bahadur Chandra},
keywords = {Hate speech, Deep Learning, Word Embedding, Logistic Regression, Support Vector Machine},
abstract = {Multilingual hate speech detection is a developing field of investigation that concentrates on the challenge of recognizing harmful content in various languages. With the explosive growth of social media platforms and the worldwide character of cyber communication, identifying hate speech in many language situations has become crucial. Existing detection models often struggle with language-specific nuances, cultural differences, and limited resources for less commonly spoken languages. This article conducts a widespread investigation of multilingual hate speech across 11 languages sourced from various datasets. By utilizing methods such as natural language processing (NLP), machine learning, and deep learning, researchers aim to create models that can effectively generalize across different languages. In low-resource scenarios, simpler models like LASER embeddings combined with logistic regression outperform ELMo-based models in high-resource contexts. The main objective of this research work lies in demonstrating promising results across a range of languages by integrating deep learning algorithms with multilingual pre-trained language models such as LASER and ELMo.}
}
@article{BADRI2022769,
title = {Combining FastText and Glove Word Embedding for Offensive and Hate speech Text Detection},
journal = {Procedia Computer Science},
volume = {207},
pages = {769-778},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.132},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922010134},
author = {Nabil Badri and Ferihane Kboubi and Anja Habacha Chaibi},
keywords = {Inappropriate content classification, Machine, Deep learning, Neural networks, NLP, Glove, FastText word embeddings},
abstract = {Over the past decade, increased use of social media has led to an increase in hate content. To address this issue new solutions must be implemented to filter out this kind of inappropriate content. Because manual filtering is difficult, several studies have been conducted in order to automate the process. This paper introduces a method based on a combination of Glove and FastText word embedding as input features and a BiGRU model to identify hate speech from social media websites. The obtained results show that our proposed model (BiGRU Glove FT) is effective in detecting inappropriate content. This model detect hate speech on OLID dataset, using an effective learning process that classifies the text into offensive and not offensive language. The performance of the system attained 84%, 87%, 93%, 90% accuracy, precision, recall, and f1-score respectively.}
}
@article{GU2025127308,
title = {Information-assisted and sentiment relation-driven for aspect-based sentiment analysis},
journal = {Expert Systems with Applications},
volume = {278},
pages = {127308},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127308},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425009303},
author = {Tiquan Gu and Zhenzhen He and Zhe Li and Yaling Wan},
keywords = {Sentiment analysis, Commonsense information, Multitask learning, ConceptNet},
abstract = {Aspect-based sentiment analysis aims to extract fine-grained sentiment information for different aspects in a review sentence. While existing methods have explored various ways to model the relationships between aspect terms and context, they often overlook the sentiment connection between aspect terms and the sentiment expressed by the review sentence itself. The sentiment tone of the sentence typically reflects the reviewer’s preferences and focus on certain aspects. Capturing this sentiment relationship allows the model to gain a more comprehensive understanding of the reviewer’s emotional experience and attitude. In this paper, we propose an information-assisted and sentiment relation-driven multitask learning network (IASD-ML) to address this gap. We define and label the relationship between aspect polarity and sentence polarity, treating it as an auxiliary task to learn the reviewer’s emotional context and the emotional associations between aspects and sentences. To the best of our knowledge, this is the first attempt to extract the sentiment relationship between aspect terms and sentence sentiment as an auxiliary classification task. Furthermore, relying solely on coarse-grained emotional cues from context is often insufficient to fully capture semantic and implicit relationships. To address this, we incorporate external commonsense path information to assist in extracting fine-grained sentiment cues and background information. Specifically, we use an external sentiment lexicon to label emotional words in the sentence, treating aspect terms as head entities and emotional words as tail entities, and retrieve commonsense path information from the ConceptNet knowledge base. By combining word dependencies with commonsense path information, we construct a commonsense aware graph network to further strengthen the emotional connections between aspect terms and sentiment words. Experimental results on benchmark datasets demonstrate that our approach has a solid competitive advantage.}
}
@article{ZOU2025129472,
title = {Large language model augmented syntax-aware domain adaptation method for aspect-based sentiment analysis},
journal = {Neurocomputing},
volume = {625},
pages = {129472},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129472},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225001444},
author = {Haochen Zou and Yongli Wang},
keywords = {Aspect-based sentiment analysis, Domain adaptation, Large language model, Syntax-aware Transformer, Soft prompt learning},
abstract = {Cross-domain aspect-based sentiment analysis aims to leverage knowledge from the source domain to identify the sentiment polarity towards a given aspect attribute in the text content from the target domain. Existing domain adaptation approaches either focus on acquiring domain-independent shared feature representations or adjusting the obtained feature distribution to the target domain, which fails to address critical domain-specific attributes, leading to misaligned feature representations. We propose a large language model augmented syntax-aware domain adaptation method that integrates advanced large language models with structured syntactic knowledge to recognize semantic attributes and address the lack of syntax sensitivity in large language models. A domain topic predictor based on adversarial training is developed to enhance the robustness and generalization of the framework across different domains. Additionally, automatic soft prompt learning is conducted based on analysed domain topics and task-relevant feature representations for domain-specific fine-tuning, aiding the architecture in conveying domain-specific semantic information in the cross-domain environment. The feature aggregation approach dynamically fuses six categories of analysed feature representations for fine-grained sentiment classification. To the best of our knowledge, this study represents the pioneering effort to systematically leverage syntactic and cross-domain characteristics to enhance pre-trained large language models in addressing cross-domain aspect-based sentiment analysis tasks. Experimental results on publicly available benchmark datasets validate the effectiveness of the proposed architecture.}
}
@article{JIANG2025129140,
title = {ReZG: Retrieval-augmented zero-shot counter narrative generation for hate speech},
journal = {Neurocomputing},
volume = {620},
pages = {129140},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.129140},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224019118},
author = {Shuyu Jiang and Wenyi Tang and Xingshu Chen and Rui Tang and Haizhou Wang and Wenxian Wang},
keywords = {Constrained text generation, Dialog, Constrained decoding, Hate speech, Pre-trained language model, Retrieval augmentation},
abstract = {The proliferation of hate speech (HS) on social media poses a serious threat to societal security. Automatic counter narrative (CN) generation, as an active strategy for HS intervention, has garnered increasing attention in recent years. Existing methods for automatically generating CNs mainly rely on re-training or fine-tuning pre-trained language models (PLMs) on human-curated CN corpora. Unfortunately, the annotation speed of CN corpora cannot keep up with the growth of HS targets, while generating specific and effective CNs for unseen targets remains a significant challenge for the model. To tackle this issue, we propose Retrieval-Augmented Zero-shot Generation (ReZG) to generate CNs with high-specificity for unseen targets. Specifically, we propose a multi-dimensional hierarchical retrieval method that integrates stance, semantics, and fitness, extending the retrieval metric from single dimension to multiple dimensions suitable for the knowledge that refutes HS. Then, we implement an energy-based constrained decoding mechanism that enables PLMs to use differentiable knowledge preservation, countering, and fluency constraint functions instead of in-target CNs as control signals for generation, thereby achieving zero-shot CN generation. With the above techniques, ReZG can integrate external knowledge flexibly and improve the specificity of CNs. Experimental results show that ReZG exhibits stronger generalization capabilities and outperforms strong baselines with significant improvements of 2.0%+ in the relevance and 4.5%+ in the countering success rate metrics.}
}
@article{KIA20242704,
title = {From Monolingual to Multilingual: Enhancing Hate Speech Detection with Multi-channel Language Models},
journal = {Procedia Computer Science},
volume = {246},
pages = {2704-2713},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.401},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924024402},
author = {Mahsa Abazari Kia and Dorsa Samiee},
keywords = {Deep Learning, Hate speech detection, BERT, Social Networking Services, Transfer Learning, Cross-lingual Classification},
abstract = {The rise of social networking services (SNS) has reshaped communication dynamics in cyberspace, yet it has also exacerbated the proliferation of online hate speech due to the anonymity and fluidity these platforms offer. With manual hate speech detection by human annotators proving costly and time-intensive, the imperative for developing automated recognition algorithms is evident. Leveraging knowledge transfer through fine-tuning pre-trained language models has emerged as a promising strategy in natural language processing. Notably, Bidirectional Encoder Representations from Transformers (BERT) and HateBERT, a domain-specific variant, stand out for their ability to glean deep bidirectional representations from extensive corpora. This paper introduces a multichannel model integrating these two language models for multilingual hate speech detection. Furthermore, we explore the efficacy of augmenting input data through translation, ensuring compatibility with the English requirement of the HateBERT model. By evaluating our approach on three non-English datasets alongside an English dataset, we demonstrate achieving state-of-the-art or comparable performance, underscoring the effectiveness of our methodology in combating hate speech across linguistic barriers.}
}
@article{IBROHIM2023e18647,
title = {Hate speech and abusive language detection in Indonesian social media: Progress and challenges},
journal = {Heliyon},
volume = {9},
number = {8},
pages = {e18647},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e18647},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023058553},
author = {Muhammad Okky Ibrohim and Indra Budi},
keywords = {Hate speech, Abusive language, Indonesian social media},
abstract = {Nowadays Hate Speech and Abusive Language (HSAL) have spread extensively over social media. The easy use of social media allows people to abuse the media to spread HSAL. Hate speech and abusive language in social media must be detected because they can trigger conflict among citizens. Not only in social media, but HSAL also often trigger conflict in real life. In recent years, many scholars have researched HSAL detection in various languages and media. However, there are still many tasks on HSAL detection that need to be done to develop a better HSAL detection system. This paper discusses a summary of Indonesian HSAL detection research, conducted by utilizing the Kitchenham systematic literature review method. Based on our summary, we found that most Indonesian HSAL research still uses the classic machine-learning approach with classic text representation features that experimented on the Twitter text dataset. We also found several challenges and tasks that need to be addressed to build a better HSAL detection system in Indonesian social media that can detect the hate speech target, category, and levels; and the hate speech buzzer, thread starter, and fake account spreader.}
}
@article{ZHANG2025111934,
title = {Simplified syntax-guided domain-shared representation learning for cross-domain aspect-based sentiment analysis},
journal = {Engineering Applications of Artificial Intelligence},
volume = {160},
pages = {111934},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111934},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625019360},
author = {Jiqun Zhang and Yan Xiang},
keywords = {Cross-domain, Aspect-based sentiment analysis, Simplified syntax, Simplified syntax-guided, Domain-shared representation learning},
abstract = {Cross-domain aspect-based sentiment analysis (ABSA) aims to identify aspect terms and their sentiment polarities in the target domain using annotated data from the source domain. Previous studies have shown that leveraging syntactic knowledge can partially bridge domain gaps. However, routine syntactic labels are diverse and fail to directly reflect the connection between aspects and opinions. This limitation hinders their ability to assist the model in perceiving aspects-sentiments in different domains. To overcome this challenge, we present a cross-domain ABSA approach based on simplified syntactic-guided representation learning. Initially, we design a dependency syntax simplification strategy that unifies syntactic labels of aspect terms and their corresponding opinion terms. We employ these simplified syntactic labels to guide the model's self-supervised learning process, thereby obtaining the domain-shared representations from unlabeled data in both the source and target domains. Using the domain-shared representation, we train the model on annotated data from the source domain and then apply it to make predictions in the target domain. Experimental results across ten transfer tasks using four public datasets demonstrate that our proposed method consistently outperforms other baseline models.}
}
@article{ZHU2025113707,
title = {Aspect-based context iterative network with hyperbolic tangent function for aspect-based sentiment classification},
journal = {Applied Soft Computing},
volume = {184},
pages = {113707},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113707},
url = {https://www.sciencedirect.com/science/article/pii/S156849462501018X},
author = {Chao Zhu and Benshun Yi and Laigan Luo},
keywords = {Multiple iteration, Aspect-based sentiment analysis, Hyperbolic tangent function, Natural language processing},
abstract = {In the domain of natural language processing, sentiment analysis emerges as a pivotal undertaking. Especially, aspect-based sentiment classification has garnered significant attention in recent years, as it can identify and evaluate emotions related to specific aspects within sentences. Existing approaches typically achieve satisfactory results by extracting keyword information from the context to identify polarity. However, a common challenge faced by these methods is the inclusion of irrelevant words in the extracted keywords, leading to decreased classification accuracy. To tackle this issue, we propose an aspect-based context multiple iteration approach, which leverages the correlation between aspects and context and employs the multi-head attention mechanism to iteratively extract contextual keywords. By doing so, we aim to mitigate the interference of irrelevant words and enhance the accuracy of sentiment classification. Additionally, we address the peculiarities of hard samples by introducing a novel loss function that cleverly incorporates the hyperbolic tangent function and allows for improved model accuracy. To validate the effectiveness of our proposed approach, we conduct extensive experiments on four widely datasets and demonstrate the efficacy of our model in improving sentiment classification.}
}
@article{CARRASCO2024129,
title = {Enhancing Restaurant Management through Aspect-Based Sentiment Analysis and NLP Techniques},
journal = {Procedia Computer Science},
volume = {237},
pages = {129-137},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.088},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011049},
author = {Paulo Carrasco and Sandra Dias},
keywords = {Natural Language Processing (NLP), Sentiment Analysis, Online Reviews, Gastronomic Sector, Aspect-Based Sentiment Analysis (ABSA)},
abstract = {This paper presents a flexible and automated methodology for extracting and analyzing customer sentiment in the restaurant industry through online reviews. The proposed approach is evaluated on a sample dataset of 1000 reviews, as well as applied within an accompanying web application that utilizes a large corpus of 880,000 reviews from 1581 restaurants located in the Algarve region. By leveraging advanced Natural Language Processing (NLP) techniques such as Aspect-Based Sentiment Analysis (ABSA), this study seeks to accurately classify customer sentiments according to specific attributes related to food quality, service, ambiance, pricing and location. To assess its performance against human classification processes, the results demonstrate that the proposed methodology effectively replicates them with three alternative approaches for attribute extraction and classification being presented; among which BART model consistently outperforms DeBERTa while ChatGPT achieves highest F1 Score. Named RestMON Algarve, the developed web application will allow restaurant managers to extract and analyze customer sentiment from online reviews; track attribute evolution over time; compare performance between competing restaurants - thus providing relevant insights into enhancing customer satisfaction levels leading towards overall success in hospitality industry.}
}
@article{FU2024112233,
title = {An implicit aspect-based sentiment analysis method using supervised contrastive learning and knowledge embedding},
journal = {Applied Soft Computing},
volume = {167},
pages = {112233},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112233},
url = {https://www.sciencedirect.com/science/article/pii/S156849462401007X},
author = {Junsen Fu and Xianyong Li and Yihong Zhu and Yajun Du and Yongquan Fan and Xiaoliang Chen and Dong Huang and Shumin Wang},
keywords = {Aspect-based sentiment analysis, Implicit sentiment, Knowledge embedding, Supervised contrastive learning},
abstract = {Aspect-based sentiment analysis aims to analyze and understand people’s opinions from different aspects. Some comments do not contain explicit opinion words but still convey a clear human-perceived emotional orientation, which is known as implicit sentiment. Most previous research relies on contextual information from a text for implicit aspect-based sentiment analysis. However, little work has integrated external knowledge with contextual information. This paper proposes an implicit aspect-based sentiment analysis model combining supervised contrastive learning with knowledge-enhanced fine-tuning on BERT (BERT-SCL+KEFT). In the pre-training phase, the model utilizes supervised contrastive learning (SCL) on large-scale sentiment-annotated corpora to acquire sentiment knowledge. In the fine-tuning phase, the model uses a knowledge-enhanced fine-tuning (KEFT) method to capture explicit and implicit aspect-based sentiments. Specifically, the model utilizes knowledge embedding to embed external general knowledge information into textual entities by using knowledge graphs, enriching textual information. Finally, the model combines external knowledge and contextual features to predict the implicit sentiment in a text. The experimental results demonstrate that the proposed BERT-SCL+KEFT model outperforms other baselines on the general implicit sentiment analysis and implicit aspect-based sentiment analysis tasks. In addition, ablation experimental results show that the proposed BERT-SCL+KEFT model without the knowledge embedding module or supervised contrastive learning module significantly decreases performance, indicating the importance of these modules. All experiments validate that the proposed BERT-SCL+KEFT model effectively achieves implicit aspect-based sentiment classification.}
}
@article{HASAN2024111107,
title = {Aspect based sentiment analysis datasets for Bangla text},
journal = {Data in Brief},
volume = {57},
pages = {111107},
year = {2024},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2024.111107},
url = {https://www.sciencedirect.com/science/article/pii/S2352340924010692},
author = {Mahmudul Hasan and Md. Rashedul Ghani and K.M. Azharul Hasan},
keywords = {Sentiment analysis, Aspect based sentiment analysis, Bangla sentiment analysis, Opinion mining, Natural language processing},
abstract = {Sentiment analysis is becoming rapidly important for exploring social media Bangla text. The lack of sufficient resources is considered to be an important challenge for Aspect Based Sentiment Analysis (ABSA) of the Bangla language. The ABSA is a technique that divides the text and defines its sentiment based on its aspects. In this paper, we developed a high-quality Bangla ABSA annotated dataset namely BANGLA_ABSA. The datasets are labelled with aspects category and their respective sentiment polarity to do the ABSA task in Bangla. Four open domains namely Restaurant, Movie, Mobile phone, and Car are considered to make the dataset. The datasets are called Restaurant_ABSA, Movie_ABSA, Mobile_phone_ABSA, and Car_ABSA respectively that contain 801, 800, 975, and 1149 comments. All the comments are either complex or compound sentences. We created the dataset manually and annotated the same by exerting opinions. We organized the dataset as three tuples in Excel format namely 〈Id, Comment, {Aspect category, Sentiment Polarity}〉. These data are very important that facilitate the efficient handling of sentiment for any machine learning and deep learning research, especially for Bangla text.}
}
@article{PERERA2023e19097,
title = {A comparative study of the characteristics of hate speech propagators and their behaviours over Twitter social media platform},
journal = {Heliyon},
volume = {9},
number = {8},
pages = {e19097},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e19097},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023063053},
author = {Suresha Perera and Nadeera Meedin and Maneesha Caldera and Indika Perera and Supunmali Ahangama},
keywords = {Social media platform, Hate speech propagators, Hate user characteristics, Sentiment analysis},
abstract = {The internet and social media have facilitated diverse communication genres, enabling widespread and rapid opinions-sharing. However, hate speech imposes a contemporary challenge on individuals and communities, given the user anonymity, freedom, and inadequate regulation. Therefore, it is imperative to identify the perpetrators responsible for spreading hate content and examine their behaviour to prevent and mitigate the negative impact. This study aimed to compare the characteristics of hate speech propagators and their behaviour with non-hate users on Twitter for the first time in Sri Lanka. The intrinsic and extrinsic profile features were extensively analyzed, employing Sinhala and English text analysis techniques. A corpus of 102882 posts from 530 hate and non-hate Twitter user profiles was selected for the study. This study investigates the unique characteristics of hate speech propagators and non-hate users by examining their profile self-presentation, conducting social network analysis, and analyzing sentiment and emotion through linguistic analysis. Hate users often refrained from expression, with infrequent account verification and geotagging. They tend to have a higher follower and following counts and more favourites, group memberships, and statuses than non-hate users. However, general Twitter user engagement with hate users was significantly low, with fewer likes, retweets, and replies. The limited involvement of normal users with hate content indicates that audiences can be effectively utilized to combat hate speech. The sentiment analysis between languages showed polarisation of negative tweets towards Sinhala, with the synergistic effect of English language users using positive sentiment to spread hate content. The novel findings shed light on the characteristics of hate users, facilitating their early detection and moderation of hate speech and aiding in developing algorithms to rank and categorize hate users using artificial intelligence. Moreover, it can be used for policy reforms, awareness programmes, and building social cohesion while combating hate speech.}
}
@article{PAN20242849,
title = {Comparing Fine-Tuning, Zero and Few-Shot Strategies with Large Language Models in Hate Speech Detection in English},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {140},
number = {3},
pages = {2849-2868},
year = {2024},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2024.049631},
url = {https://www.sciencedirect.com/science/article/pii/S1526149224000493},
author = {Ronghao Pan and José {Antonio García-Díaz} and Rafael Valencia-García},
keywords = {Hate speech detection, zero-shot, few-shot, fine-tuning, natural language processing},
abstract = {Large Language Models (LLMs) are increasingly demonstrating their ability to understand natural language and solve complex tasks, especially through text generation. One of the relevant capabilities is contextual learning, which involves the ability to receive instructions in natural language or task demonstrations to generate expected outputs for test instances without the need for additional training or gradient updates. In recent years, the popularity of social networking has provided a medium through which some users can engage in offensive and harmful online behavior. In this study, we investigate the ability of different LLMs, ranging from zero-shot and few-shot learning to fine-tuning. Our experiments show that LLMs can identify sexist and hateful online texts using zero-shot and few-shot approaches through information retrieval. Furthermore, it is found that the encoder-decoder model called Zephyr achieves the best results with the fine-tuning approach, scoring 86.811% on the Explainable Detection of Online Sexism (EDOS) test-set and 57.453% on the Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter (HatEval) test-set. Finally, it is confirmed that the evaluated models perform well in hate text detection, as they beat the best result in the HatEval task leaderboard. The error analysis shows that contextual learning had difficulty distinguishing between types of hate speech and figurative language. However, the fine-tuned approach tends to produce many false positives.}
}
@article{ALMASAUD2024102264,
title = {On the robustness of arabic aspect-based sentiment analysis: A comprehensive exploration of transformer-based models},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {10},
pages = {102264},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102264},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824003537},
author = {Alanod AlMasaud and Heyam H. Al-Baity},
keywords = {Aspect-based sentiment analysis, Sustainability, Sentiment analysis, Opinion mining, Pre-trained language models, Arabic, Natural language processing, Machine learning, BERT, Transformer},
abstract = {In the era of rapid technological advancement, users generate an overwhelming volume of data on social media networks and e-commerce platforms daily. This data, rich in opinions, sentiments, values, and habits, holds immense value for both consumers and businesses. Leveraging this unstructured data manually is error-prone and time-consuming. The field of Sentiment Analysis automates the process of analyzing human opinions from this data. Sentiment Analysis classifies text into positive, negative, or neutral sentiments. However, it confines text classification to a single sentiment polarity, providing a broad overview without accounting for specific aspects. With the growing demand for data analysis, this standard sentiment polarity classification is no longer sufficient. Aspect-Based Sentiment Analysis has emerged to dig deeper into the text, uncovering perspectives and points of view. It can identify multiple aspects in text with corresponding sentiment polarity. Therefore, interest in this field has increased and many research efforts have been devoted recently to tackle this problem for the English language. Unfortunately, there is a scarcity of Arabic research in this field. This study will address the aforementioned deficiency by investigating the potential of four transformer models namely, AraBERT v2.0, ArBERT, MARBERT, and Multilingual BERT in enhancing the accuracy of Aspect-Based Sentiment Analysis for Arabic texts using two dedicated corpora (AraMA and AraMAMS). The extensive experiments revealed that the proposed approach achieved its expected effect surpassing the results of previous studies in the field. The best results of Aspect Category Detection and Aspect Sentiment Classification tasks in AraMA corpus were obtained by using AraBERT v2.0 with F1-Measure result equals to 95.75% and 92.83% respectively. In addition, the best result of Aspect Category Detection and Aspect Sentiment Classification tasks in AraMAMS corpus were achieved by using AraBERT v2.0 with F1-Measure result equals to 95.54% and 89.52% respectively.}
}
@article{MAMTA2025101668,
title = {Quality achhi hai (is good), satisfied! Towards aspect based sentiment analysis in code-mixed language},
journal = {Computer Speech & Language},
volume = {89},
pages = {101668},
year = {2025},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2024.101668},
url = {https://www.sciencedirect.com/science/article/pii/S0885230824000512},
author = { Mamta and Asif Ekbal},
keywords = {Code-mixing, BERT, Semi-supervised, Aspect term extraction, Un-supervised, Aspect sentiment classification},
abstract = {Social media, e-commerce, and other online platforms have witnessed tremendous growth in multilingual users. This requires addressing the code-mixing phenomenon, i.e. mixing of more than one language for providing a rich native user experience. User reviews and comments may benefit service providers in terms of customer management. Aspect based Sentiment Analysis (ABSA) provides a fine-grained analysis of these reviews by identifying the aspects mentioned and classifies the polarities (i.e., positive, negative, neutral, and conflict). The research in this direction has mainly focused on resource-rich monolingual languages like English, which does not suffice for analyzing multilingual code-mixed reviews. In this paper, we introduce a new task to facilitate the research on code-mixed ABSA. We offer a benchmark setup by creating a code-mixed Hinglish (i.e., mixing of Hindi and English) dataset for ABSA, which is annotated with aspect terms and their sentiment values. To demonstrate the effective usage of the dataset, we develop several deep learning based models for aspect term extraction and sentiment analysis, and establish them as the baselines for further research in this direction. 11Codes and the complete dataset have been made available on https://www.iitp.ac.in/~ai-nlp-ml/resources.html and at Github repository: https://github.com/20118/ABSA-MIX.}
}