@article{JAOUADI2024123429,
title = {A survey on influence maximization models},
journal = {Expert Systems with Applications},
volume = {248},
pages = {123429},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123429},
url = {https://www.sciencedirect.com/science/article/pii/S095741742400294X},
author = {Myriam Jaouadi and Lotfi {Ben Romdhane}},
keywords = {Influence maximization, Social networks, Static networks, Dynamic networks, Influential nodes},
abstract = {Influence maximization is an important research area in social network analysis where researchers are concerned with detecting influential nodes. The detection of influential nodes is of great interest in several disciplines including computer science, opinion propagation, political movements, or economics, where systems are often modeled as graphs. The Influence Maximization problem is proved NP-hard. This computational complexity is justified by two main factors. The first factor is about the important size of social networks. Modern social networks like TikTok and Facebook have reached an unprecedented number of users. Dynamic social networks, whose topology or/and informational content is able to evolve, represent the second factor. Maximizing influence in such networks remains a significant task. In this light, several methods have been proposed. Being motivated by this fact, we provide in this paper a detailed survey of influence maximization approaches. Our main concern is to provide a taxonomy of existing models in both static and dynamic networks. In addition, we provide a comparison of the state-of-the-art approaches according to a clear categorization. New trends for detecting influential nodes are also discussed. We provide then some challenges as well as future directions.}
}
@article{LI2023126441,
title = {A survey of graph neural network based recommendation in social networks},
journal = {Neurocomputing},
volume = {549},
pages = {126441},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126441},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223005647},
author = {Xiao Li and Li Sun and Mengjie Ling and Yan Peng},
keywords = {Graph neural network, Recommendation systems, Social networks, Survey, Social recommendation},
abstract = {With the widespread popularization of social network platforms, user-generated content and other social network data are growing rapidly. It is difficult for social users to select interested contents from the numerous social data. To alleviate information overload problem and enhance overall user experience of social networks, recommendation systems relying on historical behavioural data and social friendship relations of users, are widely used in social networks. Although researches on social recommendations have been conducted in recent years, recommendation systems of social networks still suffer from several challenges, such as data sparsity and lower performance. Since graph neural network has huge advantages in graph data learning by aggregating neighbors representations of the central node, it has been gathering pace in recent years. In this survey, we review graph neural network based literature for solving recommendation problems in social networks. We first introduce backgrounds of graph neural network and recommendation systems in social networks. Then, for different types of recommendation problems in social networks, we review different graph neural network based recommendation methods briefly. In particular, we first review GNN-based methods for general social recommendation and then review GNN-based methods for different social recommendation scenarios (such as friend recommendation and point-of-interest recommendation). Finally, we briefly discuss promising future directions of the graph neural network based recommendation in social networks.}
}
@article{LI2022116591,
title = {Entity knowledge transfer-oriented dual-target cross-domain recommendations},
journal = {Expert Systems with Applications},
volume = {195},
pages = {116591},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.116591},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422000872},
author = {Yakun Li and Qiang Wu and Lei Hou and Juanzi Li},
keywords = {Transfer learning, Dual-attention mechanism, Deep belief network, Cross-domain recommendations},
abstract = {Cross-domain recommendations can assist users in selecting suitable items in the target domain by aggregating or transferring the abundant available data from the auxiliary domain, which has gradually become a promising research area. However, most existing recommendations are only single-target cross-domain recommendations, and ignore the analysis of entity-side (user side or item side) knowledge, resulting in recommender systems suffering from low accuracy of rating predictions. To address these concerns, we propose a novel Entity Knowledge Transfer-oriented Dual-Target Cross-Domain Recommendations (EKTDCR) to improve the prediction performance of these two domains simultaneously in our paper. Specifically, the latent factor and denoising autoencoder techniques are first utilized to extract and learn entity interaction embedding and entity-side embedding respectively, in separate domains, which are the basis of the proposed EKTDCR approach for dual-domain knowledge transfer and model training. Then, based on the previous entity embeddings, a dual-attention mechanism consisting of intra-domain attention and inter-domain attention modules is designed to transfer user preference knowledge to achieve entity feature fusion across domains. In addition, a deep belief network model is adopted to better train the proposed EKTDCR method, and the learnable regularization constraints are further considered to achieve dual-target cross-domain recommendations. Extensive experiments on four real-world datasets demonstrate that our EKTDCR approach can improve the recommendation performance of both domains simultaneously and significantly outperform the state-of-the-art single-domain and cross-domain baseline methods.}
}
@article{LI2022294,
title = {Graph convolutional network meta-learning with multi-granularity POS guidance for video captioning},
journal = {Neurocomputing},
volume = {472},
pages = {294-305},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.12.137},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221016118},
author = {Ping Li and Pan Zhang and Xianghua Xu},
keywords = {Graph convolutional networks, Meta-learning, Video captioning, Multi-granularity part-of-speech},
abstract = {Video as information carrier has gained overwhelming popularity in city surveillance and social networks, such as WeChat, Weibo, and TikTok. To bridge the semantic gap between video content (e.g., user and landmark building) and textual information (e.g., user location), video captioning has emerged as an attracting technique in recent years. Existing works mostly focus on sentence-level Part-of-Speech (POS) information and use Long Short-Term Memory (LSTM) as encoder, which neglects word or phrase-level POS information and also fails to globally consider long-range temporal relations among video frames. To address the drawbacks, we leverage multi-granularity POS guidance to learn Graph Convolutional Network (GCN) via meta-learning, abbreviated as GMMP (GCN Meta-learning with Multi-granularity POS), for generating high-quality captions for videos. It models temporal dependency by treating frames as nodes in the graph, and captures POS information of words and phrases by multi-granularity POS attention mechanism. We adopt meta-learning to better learn GCN by maximizing the reward of generated caption in a reinforcement task and also the probability of ground-truth caption in a supervised task, simultaneously. Experiments have verified the advantages of our GMMP model on several benchmark data sets.}
}
@article{XU2024122995,
title = {Reverse-graph enhanced graph neural networks for session-based recommendation},
journal = {Expert Systems with Applications},
volume = {245},
pages = {122995},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.122995},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423034978},
author = {Hao Xu and Bo Yang and Xiangkun Liu},
keywords = {Session-based recommendation, Data augmentation, Graph neural networks},
abstract = {Session-based recommendation (SBR) aims to predict the next item based on anonymous sessions, which has become a hot research area in recent years. A variety of SBR models have been proposed, and the graph neural network (GNN)-based models are shown to achieve the state-of-the-art performance in SBR. In our research, we observe that there is a decrease in the performance of SBR models for sessions with short length, which hinders the overall performance of SBR models. To alleviate this problem, we propose to add some virtual item(s) into short sessions as the supplementary contextual information to improve model performance. The main challenge lies in how to predict the appropriate virtual item(s) to be added in short sessions. In this paper, we propose Reverse-graph Enhanced Graph Neural Networks (RGE-GNN), a new GNN-based model for SBR. In RGE-GNN, we first construct a reverse graph of a session (RGS) to capture the complex reverse transition relation between items in the session. After that, the reverse prediction is proposed to be conducted to predict the appropriate virtual item(s). As a result, richer information could be carried by the enhanced session, which could lead to higher recommendation accuracy. In addition, to ensure that more relevant virtual item(s) should be added into a session, we propose a preference memory mechanism (PMM) to obtain the expected preference of each session. Extensive experiments conducted on three real-world datasets demonstrate that RGE-GNN outperforms the baselines including the recent SBR models.}
}
@article{WANG2023101799,
title = {BDBRC: A Chinese military entity recognition model combining context contribution and residual dilatation convolutional networks},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {35},
number = {10},
pages = {101799},
year = {2023},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101799},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823003531},
author = {Jintao Wang and Jiayi Qu and Zuyi Zhao and Yulong Yin},
keywords = {Knowledge graph, Entity recognition, Joint recognition, Deep learning},
abstract = {Military information is gradually overloaded due to the diversity of sources and the exponential growth in quantity, which greatly affects the accuracy of intelligence personnel in extracting and analyzing military information. The modern warfare approach has also evolved from the traditional physical domain to the cognitive domain, and competing for advantages in the cognitive domain has become a key objective of combat. Therefore, constructing domain knowledge graphs and mining the relationships between data play an important role in cognitive domain analysis. In this paper, we propose a convolutional network recognition method based on improved two-layer bi-directional BiLSTM networks named the BERT-α BiLSTMs-RECNN-CRF (BDBRC) model. For the difficulties of military entities generally having long names and low extraction accuracy, as well as the existence of a large number of composite entities that are difficult to recognize, an improved two-layer BiLSTM model is devised first. In view of the fact that the BiLSTMs model always extracts features equally in long-distance text sequences without actually considering the different influences of different sentence contexts, contribution factor a is added to extract the contribution of the above and below to the target entity in different sentences respectively. Then, aiming at the strong problem of the domain of military news texts and the high level of inter-entity ambiguity, we propose a method that utilizes a modified convolutional network (RECNN) for partial feature extraction and jointly with a modified two-layer BiLSTM network for entity recognition. The experiment on the self-constructed dataset shows that the F1 value of the model proposed in this paper reaches 93.18%, and the F1 value, P, and H of our model are all better than the baseline model, which verifies the performance of the model. At the same time, we use public data sets MSRA and CLUB2020, and the experimental results show that the model proposed in this paper also has a good performance in the public data set, verifying the universality of the model. It can provide methodological support for the construction of the military knowledge graph.}
}
@article{LIU2024102300,
title = {Emotion detection for misinformation: A review},
journal = {Information Fusion},
volume = {107},
pages = {102300},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102300},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524000782},
author = {Zhiwei Liu and Tianlin Zhang and Kailai Yang and Paul Thompson and Zeping Yu and Sophia Ananiadou},
keywords = {Sentiment analysis, Emotion detection, Misinformation, Rumor, Fake news, Stance detection},
abstract = {With the advent of social media, an increasing number of netizens are sharing and reading posts and news online. However, the huge volumes of misinformation (e.g., fake news and rumors) that flood the internet can adversely affect people’s lives, and have resulted in the emergence of rumor and fake news detection as a hot research topic. The emotions and sentiments of netizens, as expressed in social media posts and news, constitute important factors that can help to distinguish fake news from genuine news and to understand the spread of rumors. This article comprehensively reviews emotion-based methods for misinformation detection, with a particular focus on advanced fusion methods. We begin by explaining the strong links between emotions and misinformation. We subsequently provide a detailed analysis of a range of misinformation detection methods that employ a variety of emotion, sentiment and stance-based features, and describe their strengths and weaknesses. Finally, we discuss a number of ongoing challenges in emotion-based misinformation detection based on large language models, and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability.}
}
@article{WEI2025114047,
title = {MFDB: Multimodal feature fusion and dynamic behavior modeling for interactive recommendation systems},
journal = {Knowledge-Based Systems},
volume = {326},
pages = {114047},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114047},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125010925},
author = {Rongxuan Wei and Jiaming Lan and Kangkang Li and Yu Luo and Yongbin Hu},
keywords = {Recommendation system, Reinforcement learning, BERT, GNN, SlateQ},
abstract = {Recommendation systems have shown its potential in online shopping and video push. However, previous methods struggle to effectively capture the dynamic changes in user behavior sequences while integrating multi-source heterogeneous data, resulting in difficulties in achieving precise, context-sensitive, and sustainably adaptive personalized recommendations that meet user needs. To address these challenges, this study introduces the MFDB (Multimodal Feature Fusion and Dynamic Behavior Modeling) framework, a novel approach based on interactive recommendation strategies. The MFDB framework employs Graph Neural Networks (GNN) and Transformer architectures to model multimodal item data and users’ long-term and short-term preferences, respectively. By conceptualizing multimodal contextual information as states and framing the recommendation process as a sequential decision-making procedure, the framework utilizes reinforcement learning techniques to guide model updates, dynamically incorporating user feedback and behavioral trajectories to ensure that decision-making aligns with user preferences. Extensive experimental results demonstrate that MFDB significantly outperforms various advanced baseline methods across multiple metrics on two real-world datasets, validating its ability to adaptively model user behavior characteristics and efficiently integrate multimodal data sources. This provides robust support for the development of recommendation systems with enhanced robustness and contextual sensitivity.}
}
@article{RENDONSEGADOR2023318,
title = {CrimeNet: Neural Structured Learning using Vision Transformer for violence detection},
journal = {Neural Networks},
volume = {161},
pages = {318-329},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.048},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000606},
author = {Fernando J. Rendón-Segador and Juan A. Álvarez-García and Jose L. Salazar-González and Tatiana Tommasi},
keywords = {Deep learning, Neural Structured Learning, Vision Transformer, Violence detection, Adversarial Learning},
abstract = {The state of the art in violence detection in videos has improved in recent years thanks to deep learning models, but it is still below 90% of average precision in the most complex datasets, which may pose a problem of frequent false alarms in video surveillance environments and may cause security guards to disable the artificial intelligence system. In this study, we propose a new neural network based on Vision Transformer (ViT) and Neural Structured Learning (NSL) with adversarial training. This network, called CrimeNet, outperforms previous works by a large margin and reduces practically to zero the false positives. Our tests on the four most challenging violence-related datasets (binary and multi-class) show the effectiveness of CrimeNet, improving the state of the art from 9.4 to 22.17 percentage points in ROC AUC depending on the dataset. In addition, we present a generalisation study on our model by training and testing it on different datasets. The obtained results show that CrimeNet improves over competing methods with a gain of between 12.39 and 25.22 percentage points, showing remarkable robustness.}
}
@article{LI2025105083,
title = {Multi-ARCL: Multimodal adaptive relay-based distributed continual learning for encrypted traffic classification},
journal = {Journal of Parallel and Distributed Computing},
volume = {201},
pages = {105083},
year = {2025},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2025.105083},
url = {https://www.sciencedirect.com/science/article/pii/S0743731525000504},
author = {Zeyi Li and Minyao Liu and Pan Wang and Wangyu Su and Tianshui Chang and Xuejiao Chen and Xiaokang Zhou},
keywords = {Encrypted traffic classification, Continual learning, Machine unlearning, Distributed learning, Multimodal learning},
abstract = {Encrypted Traffic Classification (ETC) using Deep Learning (DL) faces two bottlenecks: homogeneous network traffic representation and ineffective model updates. Currently, multimodal-based DL combined with the Continual Learning (CL) approaches mitigate the above problems but overlook silent applications, whose traffic is absent due to guideline violations leading developers to cease their operation and maintenance. Specifically, silent applications accelerate the decay of model stability, while new and active applications challenge model plasticity. This paper presents Multi-ARCL, a multimodal adaptive replay-based distributed CL framework for ETC. The framework prioritizes using crypto-semantic information from flows' payload and flows' statistical features to represent. Additionally, the framework proposes an adaptive relay-based continual learning method that effectively eliminates silent neurons and retrains new samples and a limited subset of old ones. Exemplars of silent applications are selectively removed during new task training. To enhance training efficiency, the framework uses distributed learning to quickly address the stability-plasticity dilemma and reduce the cost of storing silent applications. Experiments show that ARCL outperforms state-of-the-art methods, with an accuracy improvement of over 8.64% on the NJUPT2023 dataset.}
}
@article{KONG2025127276,
title = {Broad information diffusion modelling for sharing link click prediction using knowledge graphs},
journal = {Expert Systems with Applications},
volume = {277},
pages = {127276},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127276},
url = {https://www.sciencedirect.com/science/article/pii/S095741742500898X},
author = {Xiangjie Kong and Can Shu and Lingyun Wang and Hanlin Zhou and Linan Zhu and Jianxin Li},
keywords = {Knowledge graph, Information diffusion, Recommendation, Graph neural network},
abstract = {In the new media era, users actively share and diffuse information across social networks, creating complex patterns of broad information diffusion (BID) that differ significantly from traditional recommendation scenarios. Existing models are primarily designed for deep information diffusion (DID) with sequential cascades and struggle to address BID challenges, including the sparse graph structure, weak temporal correlation, and ambiguity in user preferences. To bridge this gap, we propose K-BID, a knowledge-driven framework tailored for BID scenarios. K-BID integrates semantic and social graph information through a two-phase ‘Match & Rank’ approach. The matching phase retrieves candidate voters using social relationships and personalized preferences, whereas the ranking phase refines predictions by modelling temporal dynamics. Experiments on real-world datasets demonstrate the superiority of K-BID over state-of-the-art methods, achieving significant improvements of 14.02%, 16.80%, and 16.99% in Precision, MRR, and AUC respectively, for the ‘Soc.’ objective with K=5. Our work advances the understanding of BID scenarios and offers a practical solution for optimizing information dissemination in social platforms.}
}
@article{ZHAO2021102488,
title = {Pyramid regional graph representation learning for content-based video retrieval},
journal = {Information Processing & Management},
volume = {58},
number = {3},
pages = {102488},
year = {2021},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2020.102488},
url = {https://www.sciencedirect.com/science/article/pii/S0306457320309766},
author = {Guoping Zhao and Mingyu Zhang and Yaxian Li and Jiajun Liu and Bingqing Zhang and Ji-Rong Wen},
keywords = {Graph embedding, Video retrieval, Regional graph, Pyramid feature map},
abstract = {Conventionally, it is common that video retrieval methods aggregate the visual feature representations from every frame as the feature of the video, where each frame is treated as an isolated, static image. Such methods lack the power of modeling the intra-frame and inter-frame relationships for the local regions, and are often vulnerable to the visual redundancy and noise caused by various types of video transformation and editing, such as adding image patches, adding banner, etc. From the perspective of video retrieval, a video’s key information is more often than not convoyed by geometrically centered, dynamic visual content, and static areas often reside in regions that are farther from the center and often exhibit heavy visual redundancies temporally. This phenomenon is hardly investigated by conventional retrieval methods. In this article, we propose an unsupervised video retrieval method that simultaneously models intra-frame and inter-frame contextual information for video representation with a graph topology that is constructed on top of pyramid regional feature maps. By decomposing a frame into a pyramid regional sub-graph, and transforming a video into a regional graph, we use graph convolutional networks to extract features that incorporate information from multiple types of context. Our method is unsupervised and only uses the frame features extracted by pre-trained network. We have conducted extensive experiments and have demonstrated that the proposed method outperforms state-of-the-art video retrieval methods.}
}
@article{JIANG2025125556,
title = {IFusionQuad: A novel framework for improved aspect-based sentiment quadruple analysis in dialogue contexts with advanced feature integration and contextual CloBlock},
journal = {Expert Systems with Applications},
volume = {261},
pages = {125556},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125556},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424024230},
author = {Haoyu Jiang and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Xu Gu and Peng Lu},
keywords = {Natural language processing, Aspect-based sentiment analysis, Aspect sentiment quadruple extraction, DiaASQ},
abstract = {Aspect-based sentiment analysis (ABSA) represents a crucial field of natural language processing (NLP). It focuses on deriving detailed sentiment insights from textual content. Dialogue-level aspect-based sentiment quadruple extraction (DiaASQ) is specifically concerned with pinpointing target-aspect-opinion-emotion quadruples within conversations. DiaASQ is important in industries like e-commerce, social media analytics, and customer feedback. However, Current ABSA approaches predominantly focus on single-text scenarios, often overlooking the complexities involved in sentiment analysis within conversational contexts. To fill this gap, this paper presents the IFusionQuad model, which is specifically designed for the DiaASQ task. Our contributions include the innovative integration of CloBlock in ABSA, enhancing feature representation with context-aware weights. The InteractiveNet Fusion Module further advances dialogue understanding by aggregating dialogue-specific features such as threads, speakers, and replies. Components such as CloBlock, gating mechanism, and Biaffine attention effectively mitigate data noise issues, improving the relevance of feature extraction. Empirical evaluation on standard datasets demonstrates that the IFusionQuad model outperforms baseline methods, achieving substantial improvements in quadruple extraction. Specifically, our model shows a 6.59% increase in micro F1 and a 7.05% increase in identification F1 for Chinese datasets, and a 2.65% and 4.69% increase in micro F1 and identification F1, respectively, for English datasets. The results clearly demonstrate our IFusionQuad model’s efficacy, which consistently outperforms baseline models across all evaluation datasets on the DiaASQ task.}
}
@article{WANG2025104287,
title = {How does blockchain mitigate false advertising in live streaming E-commerce? A tripartite stochastic evolutionary game approach},
journal = {Journal of Retailing and Consumer Services},
volume = {85},
pages = {104287},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104287},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925000669},
author = {Ruipeng Wang and Yuhong Tai},
keywords = {Live-streaming e-commerce, Blockchain technology, False advertising, Stochastic evolutionary game, Simulation analysis},
abstract = {The rapid rise of live-streaming e-commerce, particularly in China, has transformed consumer shopping experiences; however, it has also introduced challenges such as false advertising and distorted product information. This study explores how blockchain technology can address these issues within the live-streaming e-commerce ecosystem. Using a tripartite evolutionary game model involving e-commerce platforms, merchants, and consumers, we apply stochastic differential equations to analyze the stability of strategic behaviors and dynamics of false advertising. Key findings include: (1) In high-commission environments, platforms and merchants are better aligned, increasing the likelihood of merchants adopting truthful advertising strategies. (2) In high-profit environments, the temptation for merchants to engage in false advertising rises, prompting platforms to adopt blockchain technology to maintain transparency. (3) Although blockchain technology adoption enhances platform reputation over the long term, its direct impact on merchants’ advertising strategies is limited. (4) Regulatory measures such as fines and consumer reporting rewards promote blockchain technology adoption and reduce false advertising. These findings provide valuable insights for enhancing the credibility of live-streaming e-commerce and offer guidance for platforms on balancing technology adoption with regulatory efforts to foster sustainable industry development.}
}
@article{LI2025114527,
title = {Social capital matters: Towards comprehensive user preference for product recommendation with deep learning},
journal = {Decision Support Systems},
volume = {198},
pages = {114527},
year = {2025},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2025.114527},
url = {https://www.sciencedirect.com/science/article/pii/S0167923625001289},
author = {Weiyue Li and Ming Gao and Bowei Chen and Jingmin An and Yeming Gong},
keywords = {Social recommendation, Social capital, Design science, Deep learning, Online decision-making},
abstract = {Social recommender systems help address data sparsity in user–product interactions by leveraging social relationships to infer user preferences. However, existing models often overlook the role of social capital that influence decision-making in social commerce. Social capital consists of structural, relational, and cognitive dimensions, all of which shape user preferences. To better understand these influences, we propose a multi-task learning framework named DeepSC that integrates social capital theory into preference modeling. Its user preference learning module extracts structural features through graph-based pre-training, learns relational features from dynamic user embeddings, and models cognitive features using a hypergraph attention network. Additionally, the dual graph-based product feature learning module enhances cognitive feature extraction by incorporating product co-interactions. DeepSC is optimized through a joint learning objective, combining point-wise and pair-wise learning with an auxiliary social link prediction task to refine user representations. Experiments on three e-commerce datasets demonstrate that DeepSC significantly outperforms the state-of-the-art recommendation models, highlighting the effectiveness of integrating social capital into social preference learning. Our research advances social recommendation by providing a social capital theory-driven approach to modeling user behavior in digital commerce.}
}
@article{ZHOU2026100818,
title = {Sequential recommender systems: A methodological taxonomy and research frontiers},
journal = {Computer Science Review},
volume = {59},
pages = {100818},
year = {2026},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100818},
url = {https://www.sciencedirect.com/science/article/pii/S1574013725000942},
author = {Yanbo Zhou and Gang-Feng Ma and Xilin Wen and Xu-Hua Yang and Yi-Cheng Zhang},
keywords = {Sequential recommendation, Sequential modeling, Deep learning, Temporal dynamic, Network model, Contrastive learning, LLMs},
abstract = {In the era of information overload, sequential recommender systems have emerged as pivotal tools for modeling user preferences through dynamic behavioral pattern mining. These systems transcend conventional recommendation paradigms by explicitly modeling temporal dependencies in user–item interactions, preference evolution, and contextual dynamics. This study presents a methodologically structured taxonomy of sequential recommender systems through four analytical dimensions: (1) Sequential Modeling, which includes methods ranging from statistical techniques to deep learning architectures to understand user behavior patterns; (2) Temporal Dynamics Modeling, which involves time-aware collaborative filtering and deep temporal modeling; (3) Network-Enhanced Modeling, which leverages graph neural networks, heterogeneous graphs, dynamic graphs, and hypergraphs to explore structural dependencies; and (4) Robust Representation Learning, which encompasses contrastive mechanisms and techniques driven by large language models (LLMs). These algorithms focus on different aspects of sequential recommendation, including but not limited to capturing dynamic interests, modeling long- and short-term preferences, and addressing issues such as data sparsity, noise, and bias, which affect the performance and user experience of recommender systems in practical applications. Furthermore, we summarize and discuss promising future research directions to provide theoretical and methodological insights. The constructed taxonomy not only organizes existing methodological innovations, but also reveals fundamental limitations in current evaluation protocols, providing a roadmap for advancing both theoretical foundations and practical applications in this domain.}
}
@article{GUPTA2025127864,
title = {Investigating the impact of sentiments on stock market using digital proxies: Current trends, challenges, and future directions},
journal = {Expert Systems with Applications},
volume = {285},
pages = {127864},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127864},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425014861},
author = {Tapas Gupta and Shridev Devji and Ashish Kumar Tripathi},
keywords = {Stock market prediction, Social media, Digital news, Machine learning, Deep learning, Large language models},
abstract = {Social media and online news have emerged as significant sources of market sentiment, influencing stock market dynamics globally. With the growing availability of digital data, the current research focus is on leveraging advanced computational techniques for sentiment-driven stock market prediction. The era of financial forecasting has been revolutionized by integrating cutting-edge technologies such as Machine Learning, Deep Learning, and Large Language Models. In this paper, a comprehensive survey of 108 research articles has been undertaken to explore the recent advancements in these technologies, with a focus on utilizing sentiment data extracted from social media platforms and news sources. The technology-wise state-of-the-art findings, current trends, challenges, and literature gaps in this domain are analyzed, and potential future directions are proposed to address these gaps. Additionally, publicly available benchmark datasets for social media and news sentiment indices are compiled and analyzed, with insights into their limitations and potential improvements. A comparative evaluation of prediction methods across heterogeneous user-generated datasets is performed, identifying the most effective techniques for various data types and problem formulations. Recommendations are offered for selecting suitable techniques based on the nature of the data and the specific problem formulation. By incorporating the latest advancements in the field of sentiment analysis and stock market prediction, this work provides actionable insights for researchers and practitioners, advancing the understanding and development of sentiment-driven financial forecasting.}
}
@article{SU2025104352,
title = {Images and deep learning in human and urban infrastructure interactions pertinent to sustainable urban studies: Review and perspective},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {136},
pages = {104352},
year = {2025},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2024.104352},
url = {https://www.sciencedirect.com/science/article/pii/S1569843224007106},
author = {Pengxiang Su and Yingwei Yan and Hao Li and Hangbin Wu and Chun Liu and Wei Huang},
keywords = {Data fusion, Image data, Deep learning, Foundation models, SDG, Urban studies},
abstract = {As global urbanization intensifies, conflicts between humans and urban infrastructure increasingly affect socio-economic and environmental sustainability. Recently, using image data and deep learning to investigate the interactions between humans and urban infrastructure has been a popular approach since the fast development of Artificial Intelligence (AI). However, the convergence of data fusion, deep learning, and human-urban infrastructure interaction studies remains underexplored. Here we systematically analyze 3,552 papers from 2013 to 2023 that use image data to investigate the intersection area of data fusion, deep learning, and human and urban infrastructure interactions, aiming to elucidate the relationships among these three key elements. We found that the cross-applications of deep learning in the papers reviewed are not standardized. Given the trend of diversified data fusion, data fusion about real-world dynamic interactions is scarce. Lastly, four potential future research directions are identified: (1) understanding the dynamic and complex interaction processes; (2) exploring the potential and standards for the application of deep learning; (3) focusing more on research concerning cities in the Global South; (4) establishing suitable training datasets for the interaction between urban infrastructures and humans, which may provide valuable insights for applying foundation models in future urban studies.}
}
@article{LIU2025108770,
title = {Predicting online group opinions: A hypergraph-enhanced structure deep clustering with LSTM},
journal = {Computers in Human Behavior},
volume = {172},
pages = {108770},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108770},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225002171},
author = {Jiayu Liu and Qingsheng Liu and He Li and Wang Shen and Yongqiang Sun and Lu Yu and Linlin Zhu and Qianru Shi},
keywords = {Online group opinion prediction, Hypergraph social modeling, Cognitive feature representation, Triadic reciprocal determinism, Sentiment dynamics, LSTM, Behavioral data mining},
abstract = {Understanding how group opinions form, shift, and polarize in online networks is critical for maintaining healthy public discourse and addressing the psychological drivers of digital behavior. While recent advances in computational modeling have improved prediction, most methods rely on pairwise graph structures that fail to capture higher-order dynamics and lack integration with behavioral theory. To bridge this gap, we propose a psychologically grounded deep learning framework that combines hypergraph-enhanced structural clustering (HG-SDCN) with long short-term memory (LSTM) networks. Guided by Bandura's triadic reciprocal determinism, we construct a cognitive feature set encompassing environmental context, individual cognition, and behavioral expression—framing social behavior as an emergent property of cognitive–environmental interaction. The HG-SDCN module models complex group relations through hypergraph convolution and dual self-supervision, yielding improved group detection. Subsequently, LSTM is used to capture temporal sentiment trajectories, outperforming traditional ARIMA in predictive accuracy. Beyond prediction, our model offers conceptual insights into the formation and evolution of digital group cognition. By fusing psychological theory with deep learning, this interdisciplinary framework informs the design of socially aware AI systems, platform governance strategies, and interventions to counter online polarization.}
}
@article{ZHU2023324,
title = {Dynamic global structure enhanced multi-channel graph neural network for session-based recommendation},
journal = {Information Sciences},
volume = {624},
pages = {324-343},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.10.025},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522011446},
author = {Xiaofei Zhu and Gu Tang and Pengfei Wang and Chenliang Li and Jiafeng Guo and Stefan Dietze},
keywords = {Recommendation system, Session-based recommendation, Graph neural network, Behavior modeling, Attention model, Representation learning},
abstract = {Session-based recommendation is a challenging task, which aims at making recommendation for anonymous users based on in-session data, i.e. short-term interaction data. Most session-based recommendation methods only model user’s preferences with the current session sequence, which ignore rich information from a global perspective. Meanwhile, previous works usually apply GNN to capture the transformation relationship between items, however the graph used in GNN is built through a static mode, which may introduce noise to the graph structure if user’s preferences shift. In this paper, we propose a novel method called Dynamic Global Structure Enhanced Multi-channel Graph Neural Network (DGS-MGNN) to learn accurate representations of items from multiple perspectives. In DGS-MGNN, we propose a novel GNN model named Multi-channel Graph Neural Network to generate the local, global and consensus graphs dynamically and learn more informative representations of items based on the corresponding graph. Meanwhile, in order to reduce the noise information within sessions, we utilize the graph structure to assist the attention mechanism to filter noisy information within each session, so as to generate an accurate intention representation for the user. Finally, combined with a repeat and explore module, a more accurate prediction probability distribution is generated. We conduct extensive experiments on three widely used datasets, and the results demonstrate that DGS-MGNN is consistently superior to the state-of-the-art baseline models.}
}
@article{ZHAO2024102552,
title = {Multimodal Aspect-Based Sentiment Analysis: A survey of tasks, methods, challenges and future directions},
journal = {Information Fusion},
volume = {112},
pages = {102552},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102552},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524003300},
author = {Tianyu Zhao and Ling-ang Meng and Dawei Song},
keywords = {Multimodal sentiment analysis, Multimodal Named Entity Recognition, Multimodal Aspect Based Sentiment Analysis, Multimodal Category Based Sentiment Analysis},
abstract = {With the development of social media, users increasingly tend to express their sentiments (broadly including sentiment polarities, emotions and sarcasm, etc.) associated with fine-grained aspects (e.g., entities) in multimodal content (mostly encompassing images and texts). Consequently, automated recognition of sentiments within multimodal content over different aspects, namely Multimodal Aspect-Based Sentiment Analysis (MABSA), has recently become an emergent research area. This paper assesses the state-of-the-art methods in MABSA based on a systematic taxonomy over different subtasks of MABSA. It compiles advanced models for each task and offers a concise overview of popular datasets and evaluation standards. Finally, we discuss the limitations of current research and highlight promising future research directions.}
}
@article{HE2023119615,
title = {A novel graph-based feature interaction model for click-through rate prediction},
journal = {Information Sciences},
volume = {649},
pages = {119615},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119615},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523012008},
author = {Qianlong He and Feng Zhou and Linyan Gu and Zhibin Yuan},
keywords = {Factorization machine, Feature interaction, Graph topology, Graph deep learning, Recommender system},
abstract = {Click-through rate (CTR) prediction is a crucial issue in recommender systems. In addition, data sparsity is a notable challenge for recommender systems compared to other applications. To overcome it, many learning-based models are studied to model feature interactions and improve CTR prediction. However, current inflexible and non-explicit feature combination methods have limitations that hinder accurate prediction. To address this issue, we propose a sophisticated feature interaction model based on a graph and factorization machine (FM). In this model, each node in the graph corresponds to a raw feature, the edge and its weight between two nodes are determined by the learnable latent vectors in the FM. This interaction method integrates the flexible and explicit representative ability of the graph with the learnability of the FM. Furthermore, it can be combined with most learning-based CTR prediction models to improve their performance. To verify this viewpoint, we apply it to improve three prominent models, including one deep-forest-based model and two deep-learning-based models, and compare them with the state-of-the-art techniques. Experimental results show that they significantly outperform to the original ones, and are competitive with the comparison models.}
}
@article{HUANG202389,
title = {Dual-LightGCN: Dual light graph convolutional network for discriminative recommendation},
journal = {Computer Communications},
volume = {204},
pages = {89-100},
year = {2023},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2023.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S014036642300097X},
author = {Wenqing Huang and Fei Hao and Jiaxing Shang and Wangyang Yu and Shengke Zeng and Carmen Bisogni and Vincenzo Loia},
keywords = {Graph convolution neural network, Personalized recommendation, Dual-LightGCN, Discriminative recommendation, IoT},
abstract = {In recent years, graph neural networks have played a very important role in graph data analysis, and the application of graph convolutional networks (GCN) to recommender systems has been extensively investigated by recent studies. GCNs also recently demonstrated their potential to be analyzed from the point of view of Explainable Artificial Intelligence because of their underlying structure. However, most of the existing GCN-based methods are aggregated of information in one scale space and did not consider aggregation of information in multi-scale space. On this basis, this paper proposes an innovative dual light graph convolutional network model called Dual-LightGCN, which explicitly filters out items disliked by users to ensure more discriminative recommendation. Particularly, our model divides the original user–item interaction graph into two bipartite subgraphs, one subgraph is used to model the preferences between users and items, while the other is used to model the dislike relationships between them. For these two subgraphs, the LightGCN model recommendation is performed on them respectively. In the Movielens-1M dataset, the F1-score in Dual-LightGCN has increased by an average of 26%. We conducted a comprehensive evaluation of the proposed method on two datasets of different sizes and compared it with several state-of-the-art recommendation algorithms, and the results showed that the accuracy and F1-score results were significantly higher than those of other recommendation algorithms. The significantly low computational time required makes the proposed method suitable for successful deployment in various IoT scenarios.}
}
@article{SHEN2026129566,
title = {Forecasting tourism stock index dynamics: a multiscale deep learning framework integrating emerging media data},
journal = {Expert Systems with Applications},
volume = {298},
pages = {129566},
year = {2026},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.129566},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425031811},
author = {Feng Shen and Shuai Huang and Wanqing Zhao and Dao Lan},
keywords = {Tourism stock index, Time series forecasting, Emerging media data, Multiscale decomposition, Deep learning},
abstract = {This study introduces a novel multiscale and multivariable deep learning framework for tourism stock index forecasting. To address the research gap concerning emerging media’s impact on the tourism sector, our study innovatively integrate multi-source data, including Douyin (China’s prominent short video platform), into our predictive model. Our methodology employs a multiscale decomposition strategy to streamline feature extraction complexity, coupled with an enhanced temporal convolutional network model incorporating soft-thresholding denoising to mitigate noise interference. Furthermore, we implement an adaptive differentiated prediction strategy to optimize model flexibility. Empirical analysis utilizing the CSI Tourism Stock Index demonstrates that our proposed model outperforms benchmark models in both predictive accuracy and stability, thereby validating its efficacy in tourism stock index forecasting.}
}
@article{CHEN2025127373,
title = {Does user interest matter? Exploring the impact of ignoring user interests in recommendations},
journal = {Expert Systems with Applications},
volume = {279},
pages = {127373},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127373},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425009959},
author = {Lijia Chen and Chang Sun and Yan-Li Lee and Qingsong Pu and Xinru Chen and Jia Liu and Yajun Du and Wen-Bo Xie},
keywords = {Recommender systems, Graph neural networks, User interests, Recommendation diversity},
abstract = {User interests have long been a critical factor in recommender systems, serving as a key criterion for recommendations. Existing interest-based recommendation prioritize matching items to users’ interests, often overlooking the importance of the intrinsic characteristics of items. This can lead to recommendations that, while aligned with user interests, fail to address the user’s specific preferences for item intrinsic characteristics, reducing satisfaction and trust in the system. In this paper, we propose an interest disentangling recommendation algorithm (IDG). During the model-training phase, user interactions with items are disentangled into user preference for items’ intrinsic characteristics and interest groups associated with those items. During the prediction phase, downplay the user’s preferences for items’ interest groups and focus more on their preferences for the items’ intrinsic characteristics. Extensive experiments show that, on average, IDG outperforms the ten baselines by 15.9%, 34.2%, 25% and 32.8% in terms of HR@20, NDCG@20, PRE@20, and ILS@20, respectively, across three real datasets. Further experiments show that items recommended by the IDG algorithm are more concentrated within the same interest groups. However, IDG effectively enhances the diversity of items within the recommendation list, quantified by item similarity.}
}
@article{ZHANG2023282,
title = {A Multitask learning model for multimodal sarcasm, sentiment and emotion recognition in conversations},
journal = {Information Fusion},
volume = {93},
pages = {282-301},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523000040},
author = {Yazhou Zhang and Jinglin Wang and Yaochen Liu and Lu Rong and Qian Zheng and Dawei Song and Prayag Tiwari and Jing Qin},
keywords = {Multimodal sarcasm recognition, Sentiment analysis, Emotion recognition, Multitask learning, Affective computing},
abstract = {Sarcasm, sentiment and emotion are tightly coupled with each other in that one helps the understanding of another, which makes the joint recognition of sarcasm, sentiment and emotion in conversation a focus in the research in artificial intelligence (AI) and affective computing. Three main challenges exist: Context dependency, multimodal fusion and multitask interaction. However, most of the existing works fail to explicitly leverage and model the relationships among related tasks. In this paper, we aim to generically address the three problems with a multimodal joint framework. We thus propose a multimodal multitask learning model based on the encoder–decoder architecture, termed M2Seq2Seq. At the heart of the encoder module are two attention mechanisms, i.e., intramodal (Ia) attention and intermodal (Ie) attention. Ia attention is designed to capture the contextual dependency between adjacent utterances, while Ie attention is designed to model multimodal interactions. In contrast, we design two kinds of multitask learning (MTL) decoders, i.e., single-level and multilevel decoders, to explore their potential. More specifically, the core of a single-level decoder is a masked outer-modal (Or) self-attention mechanism. The main motivation of Or attention is to explicitly model the interdependence among the tasks of sarcasm, sentiment and emotion recognition. The core of the multilevel decoder contains the shared gating and task-specific gating networks. Comprehensive experiments on four bench datasets, MUStARD, Memotion, CMU-MOSEI and MELD, prove the effectiveness of M2Seq2Seq over state-of-the-art baselines (e.g., CM-GCN, A-MTL) with significant improvements of 1.9%, 2.0%, 5.0%, 0.8%, 4.3%, 3.1%, 2.8%, 1.0%, 1.7% and 2.8% in terms of Micro F1.}
}
@article{GAO2023113957,
title = {Live streaming recommendations based on dynamic representation learning},
journal = {Decision Support Systems},
volume = {169},
pages = {113957},
year = {2023},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2023.113957},
url = {https://www.sciencedirect.com/science/article/pii/S0167923623000325},
author = {Ge Gao and Hongyan Liu and Kang Zhao},
keywords = {Machine learning, Design science, Recommender systems, Consumer path},
abstract = {As an emerging form of social media, live streaming services (e.g., Twitch and Clubhouse) allow users to interact with hosts and peers in real time while enjoying shows or participating in discussions. These platforms are also dynamic, with shows or discussions changing quickly inside a room and users frequently switching between rooms. To improve user engagement and experience on such platforms, we design a new recommendation model named Dynamic Representations for Live Streaming Rooms (DRIVER) to provide room recommendations. Guided by the Integrated Framework for Consumer Path Modeling and the social affordance theory, DRIVER infers dynamic representations of live streaming rooms by leveraging users’ behavior paths in entering, staying in, and leaving rooms. One contribution of our model is a new and efficient dynamic learning framework to model instantaneous and ever-changing inter-room relationships by considering individual users’ behavior paths after leaving a room. Also supported by social affordance theory, another methodological novelty of our model is to capture dynamic characteristics of a room by incorporating features of the current audience inside the room. Experiments on real-world datasets from two different types of live streaming platforms demonstrate that DRIVER outperforms state-of-the-art representation learning methods and sequential recommender systems. The proposed method also has implications for recommender system design in other contexts, in which items are characterized by users’ dynamic behavior paths and ongoing social interactions.}
}
@article{LIANG2024111037,
title = {Graph spiking neural network for advanced urban flood risk assessment},
journal = {iScience},
volume = {27},
number = {11},
pages = {111037},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.111037},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224022624},
author = {Zhantu Liang and Xuhong Fang and Zhanhao Liang and Jian Xiong and Fang Deng and Tadiwa Elisha Nyamasvisva},
keywords = {Earth sciences, Computer science, Engineering},
abstract = {Summary
Urban flooding significantly impacts city planning and resident safety. Traditional flood risk models, divided into physical and data-driven types, face challenges like data requirements and limited scalability. To overcome these, this study developed a model combining graph convolutional network (GCN) and spiking neural network (SNN), enabling the extraction of both spatial and temporal features from diverse data sources. We built a comprehensive flood risk dataset by integrating social media reports with weather and geographical data from six Chinese cities. The proposed Graph SNN model demonstrated superior performance compared to GCN and LSTM models, achieving high accuracy (85.3%), precision (0.811), recall (0.832), and F1 score (0.821). It also exhibited higher energy efficiency, making it scalable for real-time flood prediction in various urban environments. This research advances flood risk assessment by efficiently processing heterogeneous data while reducing energy consumption, offering a sustainable solution for urban flood management.}
}
@article{YAO2024104183,
title = {LCMA-Net: A light cross-modal attention network for streamer re-identification in live video},
journal = {Computer Vision and Image Understanding},
volume = {249},
pages = {104183},
year = {2024},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104183},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224002649},
author = {Jiacheng Yao and Jing Zhang and Hui Zhang and Li Zhuo},
keywords = {Live video, Streamer, Re-identification, Light cross-modal attention network, Light cross-modal pooling attention},
abstract = {With the rapid expansion of the we-media industry, streamers have increasingly incorporated inappropriate content into live videos to attract traffic and pursue interests. Blacklisted streamers often forge their identities or switch platforms to continue streaming, causing significant harm to the online environment. Consequently, streamer re-identification (re-ID) has become of paramount importance. Streamer biometrics in live videos exhibit multimodal characteristics, including voiceprints, faces, and spatiotemporal information, which complement each other. Therefore, we propose a light cross-modal attention network (LCMA-Net) for streamer re-ID in live videos. First, the voiceprint, face, and spatiotemporal features of the streamer are extracted by RawNet-SA, Π-Net, and STDA-ResNeXt3D, respectively. We then design a light cross-modal pooling attention (LCMPA) module, which, combined with a multilayer perceptron (MLP), aligns and concatenates different modality features into multimodal features within the LCMA-Net. Finally, the streamer is re-identified by measuring the similarity between these multimodal features. Five experiments were conducted on the StreamerReID dataset, and the results demonstrated that the proposed method achieved competitive performance. The dataset and code are available at https://github.com/BJUT-AIVBD/LCMA-Net.}
}
@article{WEN2023123,
title = {Dynamic interactive multiview memory network for emotion recognition in conversation},
journal = {Information Fusion},
volume = {91},
pages = {123-133},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2022.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S1566253522001786},
author = {Jintao Wen and Dazhi Jiang and Geng Tu and Cheng Liu and Erik Cambria},
keywords = {Emotion recognition in conversation, Multimodal fusion, Dynamic interactive multiview memory network},
abstract = {When available, multimodal data is key for enhanced emotion recognition in conversation. Text, audio, and video in dialogues can facilitate and complement each other in analyzing speakers’ emotions. However, it is very challenging to effectively fuse multimodal features to understand the detailed contextual information in conversations. In this work, we focus on dynamic interactions during the information fusion process and propose a Dynamic Interactive Multiview Memory Network (DIMMN) model to integrate interaction information for recognizing emotions. Specifically, the information fusion within DIMMN is through multiple perspectives (combining different modalities). We designed multiview layers in attention networks to enable the model to mine the crossmodal dynamic dependencies between different groups in the process of dynamic modal interaction. In order to learn the long-term dependency information, temporal convolutional networks are introduced to synthesize contextual information of a single person. Then, the gated recurrent units and memory networks are used to model the global session to detect contextual dependencies for multi-round, multi-speaker interactive emotion information. Experimental results on IEMOCAP and MELD demonstrate that DIMMN achieves better and comparable performance to the state-of-the-art methods, with an accuracy of 64.7% and 60.6%, respectively.}
}
@article{ZHANG2025101769,
title = {CARES: A Hybrid Caregivers Recommendation System Using Deep Learning and Knowledge Graphs},
journal = {Internet of Things},
pages = {101769},
year = {2025},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2025.101769},
url = {https://www.sciencedirect.com/science/article/pii/S2542660525002835},
author = {Qiaoyun Zhang and Sze-Han Wang and Chung-Chih Lin and Chih-Yung Chang and Diptendu Sinha Roy},
keywords = {Recommendation, DCN, XGBoost, Knowledge graph},
abstract = {Recommendation systems have prospered by leveraging user-item interactions and their features for personalized recommendations. Recent advancements in deep learning further enhance these recommendation systems with powerful backbones for learning from user-item data. However, solely depending on these interactions often leads to the cold-start problem, where items lacking historical data cannot be effectively recommended. Additionally, the issue of high similarity between user and item features frequently goes unresolved. This paper introduces a Hybrid Caregiver Recommendation mechanism, called CARES, designed to recommend suitable caregivers for postpartum women using deep learning and knowledge graphs. Initially, the proposed CARES utilizes Extreme Gradient Boosting (XGBoost) to identify important features, addressing the issue of feature similarity. Then it employs K-Means clustering to group postpartum women and caregivers based on similar features. Subsequently, it utilizes a Deep & Cross Network (DCN) to automatically learn feature interactions and constructs knowledge graphs to tackle the cold start problem. The proposed CARES also integrates exploration and exploitation strategies to balance the accuracy and diversity of recommendations. The proposed CARES compares with existing mechanisms on real datasets, and the simulation results demonstrate its effectiveness in terms of precision, recall, and F1-Score.}
}
@article{LYU2024866,
title = {Intelligent Algorithm Big Data Analysis in Personalized Film and Television Recommendation Algorithms},
journal = {Procedia Computer Science},
volume = {247},
pages = {866-873},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.105},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924029053},
author = {Lin Lyu and Chuanming Ma},
keywords = {Personalized Film and Television Recommendation, Intelligent Algorithms, Adversarial Generative Network, Singular Value Decomposition},
abstract = {Many people can't receive accurate push according to their personal preferences when watching movies and TV (television) plays like Tiktok, and the recommendation accuracy of the existing movie and TV recommendation systems in the market is not high. This article comprehensively analyzed the relevant theories and methods of intelligent algorithms and big data analysis, and explored their specific applications in personalized film and television recommendations. Emphasis was placed on recommendation algorithms based on Generative Adversarial Networks (GANs), and big data analysis techniques such as user behavior mining and association analysis were introduced. This research found that the algorithm achieved the highest accuracy of 99% in personalized film and television recommendation, and could provide more accurate and personalized recommendation results by learning user behavior and film and television content characteristics. Big data analysis technology can explore user interests and preferences, discover associations and similarities between users, and build more accurate and personalized recommendation models.}
}
@article{XU2022109246,
title = {Category-aware Multi-relation Heterogeneous Graph Neural Networks for session-based recommendation},
journal = {Knowledge-Based Systems},
volume = {251},
pages = {109246},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109246},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122006207},
author = {Hao Xu and Bo Yang and Xiangkun Liu and Wenqi Fan and Qing Li},
keywords = {Session-based recommendation, Graph neural network, Category information, Heterogeneous graph},
abstract = {Session-based recommendation (SBR) is one of the hot research areas in recent years. Various SBR models have been proposed, of which graph neural network (GNN)-based models are shown to have the state-of-the-art performance. Items’ category information is an important piece of information and should be utilized in SBR models to improve model performance. In this paper, we introduce a principle way to incorporate items’ category information for SBR. More specifically, we propose a new SBR model, Category-aware Multi-relation Heterogeneous Graph Neural Networks (CM-HGNN). In CM-HGNN, we first propose to construct an item–category heterogeneous graph (ICHG) to model both category–category relation and item–category relation. More specifically, we propose to transform the sequential information contained in a session into a heterogeneous graph with both item nodes and category nodes, by which items and categories can learn from each other and the items belonging to the same category can also perceive one another. As a result, multiple interests in a session could be more effectively captured. Then, a multi-relation heterogeneous graph convolution method is proposed to extract the multiple relation information contained in the ICHG. Extensive experiments are conducted on three widely used real-world datasets, and the results suggest that the proposed CM-HGNN outperforms the state-of-the-art SBR models.}
}
@article{XIU2026103472,
title = {Dual-layer cross-modal alignment recommendation based on the diffusion model},
journal = {Information Fusion},
volume = {125},
pages = {103472},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103472},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525005457},
author = {Yuhan Xiu and Xiangrong Tong},
keywords = {Multimodal recommendation, Cross-modal alignment, Imbalanced data, Self-supervised learning, Graph convolution network},
abstract = {Multimodal recommendation systems have attracted attention for effectively integrating multimodal information, such as user behavior, product images, and text. Existing methods usually mitigate the issue of multimodal data imbalance and inconsistency through data augmentation and alignment strategies. However, they fail to fully mine the information of each modality and introduce semantic bias during the alignment process, resulting in the loss of user behavior information and the difficulty of capturing modality associations and user preferences. To address that, this paper proposes a dual-layer cross-modal alignment recommendation based on the diffusion model (DCAR-DM). Specifically, the approach uses the diffusion model to generate a user-item interaction graph with the same number of interactions for each modality and then reconstructs it by filtering the interactions that best match the user’s interests for each modality through the modality contribution regulation mechanism. Then, DCAR-DM generates final user and item embeddings by aggregating modality information through graph convolutional networks (GCN). In addition, DCAR-DM uses a dual-layer cross-modal alignment mechanism to guide modality alignment. The feature alignment layer represents modalities as Gaussian distributions and minimizes the mean and standard deviation to align the inter-modal features. The behavior alignment layer further aligns the modality features by leveraging the real user-item interaction behaviors through contrastive learning to correct the semantic bias generated during the feature alignment process. The experimental results demonstrate the effectiveness of DCAR-DM on three public datasets.}
}
@article{DENG2024120406,
title = {A novel joint neural collaborative filtering incorporating rating reliability},
journal = {Information Sciences},
volume = {665},
pages = {120406},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120406},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524003190},
author = {Jiangzhou Deng and Qi Wu and Songli Wang and Jianmei Ye and Pengcheng Wang and Maokang Du},
keywords = {Deep neural network, Intuitionistic fuzzy sets, Noise detection, Reliability, Recommender system},
abstract = {Deep learning-based recommendations have demonstrated impressive performance in improving recommendation accuracy. However, such approaches mainly utilize implicit feedback to predict user preferences and neglect the adverse impact of explicit preference noise, which affects the robustness and reliability of model training. To consider the reliability of both rating input and output, we propose a novel joint deep neural recommendation framework that incorporates rating reliability derived solely from ratings to provide reliable recommendations for active users. Firstly, we introduce a noise detection method based on intuitionistic fuzzy sets to identify incorrect ratings from the perspective of fuzzy preferences and label them to generate a binary rating reliability matrix. Subsequently, we propose a joint deep neural framework that integrates rating reliability to simultaneously capture the high-order features of users and items, yielding predictions with their corresponding reliability probabilities. Finally, to achieve a balance between accuracy and reliability for recommendations, we design a reliability threshold selection strategy based on K-means clustering to find an appropriate threshold. Experimental results on three widely used datasets show that our model achieves an average improvement of 9.4% and 8.0% in the metrics Recall and NDCG, respectively, compared with the closest competitor. This paper provides new insights for integrating rating reliability into a deep neural network to enhance the performance of recommender systems.}
}
@incollection{2024563,
title = {Index},
editor = {Kenneth S. Ramos},
booktitle = {Comprehensive Precision Medicine (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {563-580},
year = {2024},
isbn = {978-0-12-824256-8},
doi = {https://doi.org/10.1016/B978-0-12-824010-6.09989-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128240106099895}
}
@article{ZHAO2025113035,
title = {Graph attention contrastive learning with missing modality for multimodal recommendation},
journal = {Knowledge-Based Systems},
volume = {311},
pages = {113035},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113035},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125000826},
author = {Wenqian Zhao and Kai Yang and Peijin Ding and Ce Na and Wen Li},
keywords = {Multimodal recommendation, Missing modality, Contrastive learning, Graph neural network},
abstract = {Multimodal recommendation plays an important role in many online content-sharing platforms. Most existing reported approaches of multimodal recommendation employ user-interaction graphs or auxiliary graphs (e.g., user–user or item–item relation graphs) to augment user and/or item representations. However, real-world data suffer the problem of missing modality which affects recommendation performance. In this paper, we propose the Graph Attention Contrastive Learning with Missing Modality (MMGACL) model utilizing modality complementation and modality fusion of modality-aware user–item graphs to enhance recommendations. In particular, we construct user–item bipartite graphs for each modality and extract item subgraphs, leveraging contextual information to enhance item representations. Thereafter, we employ a bimodal attention mechanism to provide complementary information across modalities and fuse different modalities. The fused item representations are combined with user–item interactions to complement user information. Finally, we perform graph contrastive learning on the completed global graph to maximize mutual information between users and items and learn more accurate embedding representations. Extensive experiments on four benchmark datasets demonstrate the effective performance of our proposed model versus several state-of-the-art methods in scenarios with missing modality.}
}
@article{SINHA2025101877,
title = {Harnessing machine learning in contemporary tobacco research},
journal = {Toxicology Reports},
volume = {14},
pages = {101877},
year = {2025},
issn = {2214-7500},
doi = {https://doi.org/10.1016/j.toxrep.2024.101877},
url = {https://www.sciencedirect.com/science/article/pii/S2214750024002609},
author = {Krishnendu Sinha and Nabanita Ghosh and Parames C. Sil},
keywords = {Machine learning, Algorithms, Smoking, Tobacco, Vapes, Cancer},
abstract = {Machine learning (ML) has the potential to transform tobacco research and address the urgent public health crisis posed by tobacco use. Despite the well-documented health risks, cessation rates remain low. ML techniques offer innovative solutions by analyzing vast datasets to uncover patterns in smoking behavior, genetic predispositions, and effective cessation strategies. ML can predict smoking-induced non-communicable diseases (SiNCDs) like lung cancer and postmenopausal osteoporosis by identifying biomarkers and genetic profiles, generating personalized predictions, and guiding interventions. It also improves prediction of infant tobacco smoke exposure, distinguishes secondhand and thirdhand smoke, and enhances protection strategies for children. Data-driven, personalized approaches using ML track real-time data for personalized feedback and offer timely interventions, continuously improving cessation strategies. Overall, ML provides sophisticated predictive models, enhances understanding of complex biological mechanisms, and enables personalized interventions, demonstrating significant potential in the fight against the tobacco epidemic.}
}
@article{LI2024119815,
title = {Graph neural networks with deep mutual learning for designing multi-modal recommendation systems},
journal = {Information Sciences},
volume = {654},
pages = {119815},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119815},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523014007},
author = {Jianing Li and Chaoqun Yang and Guanhua Ye and Quoc Viet Hung Nguyen},
keywords = {Investment recommendation, Institutional investors, Deep mutual learning, Multi-modal recommendation, Knowledge distillation},
abstract = {Recommendation services play a pivotal role in financial decision-making and multimedia content services, as they suggest investment operations and personalized items to users, typically characterized by multi-modal features such as visual, textual, and acoustic attributes. Graph Neural Networks (GNNs), demonstrating the immense potential for graph representation learning and recommendation systems, are capable of learning user/item embeddings by taking into account the graph topological structure and the multi-modal node features. Yet, a substantial number of multi-modal recommendation studies have seemingly ignored the inherent bias among different modalities during feature fusion, consequently leading to sub-optimal embeddings for items with multi-modal features. To mitigate this issue, we propose a novel multi-modal recommendation framework that integrates GNNs with deep mutual learning techniques, termed GNNMR. GNNMR uses the mutual knowledge distillation technique to collaboratively train multiple uni-modal bipartite user-item graphs. Each GNN is trained specifically on the uni-modal user-item bipartite graph, which is separated from the original multi-modal user-item bipartite graph, to generate uni-modal embeddings. These uni-modal embeddings then act as mutual supervision signals, allowing the model to uncover and synchronize the latent semantic relationships among different modalities. Subsequently, the model can conduct inference in an ensemble manner, leveraging uni-modal embeddings from diverse modalities. Experimental results on two real-world datasets demonstrate that the proposed GNNMR outperforms other multi-modal recommendation methods in the Top-K recommendation task.}
}
@article{LIN2026109223,
title = {An efficient dual-balanced-influence optimization approach for target influence maximization in complex networks},
journal = {Communications in Nonlinear Science and Numerical Simulation},
volume = {152},
pages = {109223},
year = {2026},
issn = {1007-5704},
doi = {https://doi.org/10.1016/j.cnsns.2025.109223},
url = {https://www.sciencedirect.com/science/article/pii/S1007570425006343},
author = {Feiyu Lin and Xi Wang and Zhen Su and Ziyun Li and Jie Zhao and Yang Liu},
keywords = {Complex networks, Vital nodes identification, Social networks, Collective influence},
abstract = {The rapid proliferation of online social networks has sharpened the demand for audience-specific information dissemination, i.e., maximizing influence within a predefined target group while suppressing spill-over to non-targets. We formalize this requirement as the random-distributed target influence maximization problem and present High Dual-Balanced Influence (HDBI), a powerful algorithm for seed-node selection for such problem. HDBI combines two novel estimators: combined approximate theoretical infection probability, which analytically gauges a candidate’s expected reach inside the target community by coupling local topology with diffusion dynamics; and weighted collective influence, which anticipates collateral exposure by aggregating the propagation capacities of neighboring non-target nodes. These estimators are then used for HDBI which iteratively selects seeds with maximal on-target impact and minimal off-target leakage. Extensive experiments on eight real-world networks of diverse scale and structure, complemented by large synthetic benchmarks, show that HDBI achieves substantially higher target coverage and lower non-target activation than state-of-the-art baselines, while maintaining superior computational efficiency. The proposed framework therefore offers a principled and scalable foundation for precision marketing, public-service messaging, and other applications requiring fine-grained control over influence propagation.}
}
@article{MUNOZ2025104243,
title = {The role of recommendation algorithms in the formation of disinformation networks},
journal = {Information Processing & Management},
volume = {62},
number = {6},
pages = {104243},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104243},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325001840},
author = {Pau Muñoz and Raúl Barba-Rojas and Fernando Díez and Alejandro Bellogín},
keywords = {Social networks, Disinformation, Content diffusion, Accountability},
abstract = {Disinformation on social networks, especially those that share media content, remains a critical issue with far-reaching societal implications. Although extensive research has addressed the prevalence and mitigation of false information, the specific impact of recommendation algorithms on the creation and consolidation of disinformation networks has not been thoroughly examined. In this work, we bridge this gap by simulating how various recommendation techniques — ranging from basic yet foundational approaches such as popularity-based and content-based methods — shape network dynamics and facilitate disinformation spread. These classical algorithms are essential building blocks of modern hybrid and task-specific recommender systems; understanding their effects is thus crucial for assessing systemic risks. Using a dataset comprising tweets from 275 disinformation agents and 275 legitimate journalism agents, we conduct a realistic simulation grounded in probabilistic click models of user behavior and real-world social media data. Our findings reveal that certain recommendation approaches can significantly reinforce the cohesion and visibility of disinformation networks, thereby amplifying their reach. These results underscore the necessity for algorithmic accountability and the design of ethically responsible recommender systems to maintain information integrity on social platforms.}
}
@article{WANG2026104284,
title = {DiffSBR: A diffusion model for session-based recommendation},
journal = {Information Processing & Management},
volume = {63},
number = {1},
pages = {104284},
year = {2026},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104284},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325002250},
author = {Zihe Wang and Bo Jin},
keywords = {Session-based recommendation, Diffusion model, Graph neural network, User preference modeling},
abstract = {Session-based recommendation (SBR) focuses on recommending items to anonymous users within short interaction sequences. Existing solutions focus on modeling item representations as fixed embedding vectors within the discriminative learning paradigm, which fail to accurately capture the diverse preferences that user exhibit during dynamic decision-making. We argue that users in the anonymous environment can fundamentally be regarded as a normative implicit group, exhibiting both homogeneous preference and heterogeneous preference when selecting items. To tackle this, we propose a Diffusion Model for Session-based Recommendation (DiffSBR). Specifically, we first model the aforementioned user diverse preferences from both local and global views. Next, we introduce a cluster-aware diffusion model, which directly represents heterogeneous preference clusters as distribution through forward and reverse processes, while indirectly influencing homogeneous preference via the attention mechanism in the final prediction stage, thereby improving the learning of item and session representations and enhancing the next-item recommendation. Experimental results show that DiffSBR outperforms the strong baseline, demonstrating that this sampling-allocation approach accurately reflects the uncertainty and variability in user preferences.}
}
@article{GUO2024109213,
title = {Dual-view multi-modal contrastive learning for graph-based recommender systems},
journal = {Computers and Electrical Engineering},
volume = {116},
pages = {109213},
year = {2024},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109213},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624001411},
author = {Feipeng Guo and Zifan Wang and Xiaopeng Wang and Qibei Lu and Shaobo Ji},
keywords = {Multi-modal, Self-supervised learning, Recommender systems, Contrastive learning, Graph neural network},
abstract = {Personalized recommender systems play a crucial role in various online content-sharing platforms (e.g., TikTok). The learning of representations for multi-modal content is pivotal in current graph-based recommender systems. Existing works aim to enhance recommendation accuracy by leveraging multi-modal features (e.g., image, sound, text) as side information for items. However, this approach falls short in fully discerning users' fine-grained preferences across different modalities. To tackle this limitation, this paper introduces the Dual-view Multi-Modal contrastive learning Recommendation model (DMM-Rec). DMM-Rec employs self-supervised learning to guide the learning of user and item representations within the multi-modal context. Specifically, to capture users' preferences for different modalities, we propose specific-modal contrastive learning. Simultaneously, to capture users' cross-modal preferences, cross-modal contrastive learning is introduced to uncover interdependencies in users' preferences across modalities. The contrastive learning tasks not only adaptively explore potential relations between modalities but also address the data sparsity challenge in recommender systems. Extensive experiments conducted on three datasets and compared against ten baselines demonstrate that DMM-Rec outperforms the strongest baseline by an average of 6.81%. These results underscore the effectiveness of considering multi-modal content in improving recommender systems.}
}
@article{ASRI2026102594,
title = {Adaptive Personalized Recommendation Systems: A systematic Review},
journal = {Information Systems},
volume = {135},
pages = {102594},
year = {2026},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2025.102594},
url = {https://www.sciencedirect.com/science/article/pii/S030643792500078X},
author = {Bachir Asri and Sara Qassimi and Said Rakrak},
keywords = {Adaptive recommender systems, Personalized recommender systems, Recommender systems, Evolving preferences, Systematic review},
abstract = {Recommender systems assist users in navigating the vast selection of choices by offering personalized suggestions based on preferences. Originally used in e-commerce and streaming services, these systems are now applied in various sectors such as healthcare, education, and more, making them increasingly important. Despite their growth, recommender systems still face challenges, especially when addressing users whose preferences change over time. This paper presents a review of recent research on recommender systems that deliver personalized and adaptive recommendations for users with evolving preferences. Analyzing 97 studies published between 2020 and 2024, the review categorizes them across multiple dimensions to address key research questions. The findings reveal a diverse landscape of evaluation metrics, datasets, adaptation mechanisms, and application domains within adaptive personalized recommender systems (AdPRSs), with MovieLens as the most widely used dataset and the attention mechanism as the predominant adaptation approach. Furthermore, the review introduces a novel categorization of AdPRSs based on adaptation mechanism. By synthesizing current research, this review highlights key challenges faced in the field and identifies future directions for enhancing the efficiency and effectiveness of AdPRSs. These insights are of significant value to both practitioners and academic researchers, providing a foundation for advancing the development and optimization of AdPRSs.}
}
@article{COOK202555,
title = {The dual faces of social media: connectivity and fraud in the digital age},
journal = {SAM Advanced Management Journal},
volume = {90},
number = {1},
pages = {55-74},
year = {2025},
issn = {2996-6078},
doi = {https://doi.org/10.1108/SAMAMJ-05-2024-0027},
url = {https://www.sciencedirect.com/science/article/pii/S299660782500004X},
author = {Jack Cook and Jared Scott Cook},
keywords = {Law, Ethics, Digital forensics, Social media, Social issues, Forensic analysis},
abstract = {Purpose
This paper aims to explore fraud’s pervasive nature and social media’s critical role in modern forensic investigations. As fraudsters increasingly exploit social media, investigators must continuously educate themselves on emerging means of effectively identifying, collecting and analyzing social media data. This paper highlights the role of social media in detecting and preventing fraud by providing digital evidence. It outlines the forensic process – evidence identification, collection and examination – and emphasizes using commercial and open-source tools to gather, analyze and secure evidence. The research contributes insights into the evolving fraud detection techniques using social media.
Design/methodology/approach
This paper uses a narrative review (Sylvester et al., 2013).
Findings
Social media can aid fraud investigations by revealing suspect behaviors (witness tampering in The Prosecutor v. Jean-Pierre Bemba Gombo), networks (Operation Firewall) and communications, offering real-time data, and providing evidence of fraudulent activities through messages, connections and posts (US v. Brooklyn Men). An extensive review of commercial forensic software packages highlights their utility in preserving and verifying social media data’s authenticity for legal proceedings. In addition, the paper discusses open-source tools like HTTrack and TweetBeaver.
Research limitations/implications
An extensive review of commercial forensic software packages highlights their utility in preserving and verifying social media data’s authenticity for legal proceedings. In addition, the paper discusses open-source tools like HTTrack and TweetBeaver. Future research directions discussed include the development of advanced SOCMINT tools, AI and machine learning integration and examining how social media policy changes impact forensic investigations.
Practical implications
The social media forensic analysis procedure includes these steps: forensic investigator orientation, fraud identification, due diligence search, collection and preservation of social media data, technical search and forensic analysis. The paper also addresses the challenge posed by increasing awareness among criminals, who may alter their online behaviors to evade detection.
Originality/value
All content in this paper is original in its creation.}
}
@article{BAYOUDH2024102217,
title = {A survey of multimodal hybrid deep learning for computer vision: Architectures, applications, trends, and challenges},
journal = {Information Fusion},
volume = {105},
pages = {102217},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.102217},
url = {https://www.sciencedirect.com/science/article/pii/S156625352300533X},
author = {Khaled Bayoudh},
keywords = {Applications, Computer vision, Multimodal hybrid deep learning, Sensory modalities},
abstract = {In recent years, deep learning algorithms have rapidly revolutionized artificial intelligence, particularly machine learning, enabling researchers and practitioners to extend previously hand-crafted feature extraction procedures. In particular, deep learning uses adaptive learning processes to learn more complex and informative patterns from datasets of varying sizes. With the increasing availability of multimodal data streams and recent advances in deep learning algorithms, multimodal deep learning is on the rise. This requires the development of complex models that can process and analyze multimodal information in a consistent manner. However, unstructured data can come in many different forms (also known as modalities). Extracting relevant features from this data remains an ambitious goal for deep learning researchers. According to the literature, most deep learning systems consist of a single architecture (i.e., standalone deep learning). When two or more deep learning architectures are combined over multiple sensory modalities, the result is called a multimodal hybrid deep learning model. Since this research direction has received much attention in the field of deep learning, the purpose of this survey is to provide a broader overview of the topic. In this paper, we provide a comprehensive review of recent advances in multimodal hybrid deep learning, including a thorough analysis of the most commonly developed hybrid architectures. In particular, one of the main challenges in multimodal hybrid analysis is the ability of these architectures to systematically integrate cross-modal features in hybrid designs. Therefore, we propose a generic framework for multimodal hybrid learning that focuses mainly on fusion methods. We also identify trends and challenges in multimodal hybrid learning and provide insights and directions for future research. Our findings show that multimodal hybrid learning can perform well in a variety of challenging computer vision applications and tasks.}
}
@article{HAJAJ2024124166,
title = {The art of time-bending: Data augmentation and early prediction for efficient traffic classification},
journal = {Expert Systems with Applications},
volume = {252},
pages = {124166},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124166},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424010327},
author = {Chen Hajaj and Porat Aharon and Ran Dubin and Amit Dvir},
keywords = {Internet traffic classification, Data augmentation, Long Short-Term Memory (LSTM) networks},
abstract = {The accurate identification of internet traffic is crucial for network management. However, the use of encryption techniques and constant changes in network protocols make it difficult to extract useful features for traffic classification. Additionally, there may be limited data availability and a lack of diversity within the dataset, which poses further challenges. To address these issues, our research proposes a novel solution that uses an innovative data augmentation technique. This approach leverages the capabilities of LSTM networks to create synthetic data points that closely resemble real traffic data. By doing so, we can significantly enrich the dataset used for training and improve classification efficiency. We conducted thorough experiments to validate our approach and found that combining LSTM-generated data with actual traffic data leads to notable improvements in classification efficiency. We demonstrated the effectiveness of our methodology using academic and commercial datasets. Our classifier, trained on the generated data, showed a performance boost of 6%. Moreover, when classifying with only half of the time, thus utilizing half of the signal, our approach achieved a notable 4% improvement compared to the original classifier. The inclusion of augmented samples within the training set led to a noticeable improvement in both accuracy and F1-score. These findings compellingly demonstrate our data augmentation strategy’s practical utility and efficiency in earlier prediction with improved performance for encrypted traffic classification systems.}
}
@article{WANG2025130170,
title = {Multimodal understanding of human values in videos: A benchmark dataset and PLM-based method},
journal = {Neurocomputing},
volume = {638},
pages = {130170},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130170},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225008422},
author = {Yuchen Wang and Zhulin Tao and He Chang and Nanxin Huang and Libiao Jin and Xiaofang Luo},
keywords = {Human values, Multimodal, Value understanding, Video understanding, PLM, Transformer},
abstract = {Multimodal content has become the mainstream communication medium in video sharing platforms such as TikTok and Twitter, containing rich values information. Understanding human values is of great significance to multimodal content analysis and can be applied to downstream tasks such as recommendation systems and value alignment. However, current studies on human values mainly focus on text and lack a multimodal perspective. In this work, we present a new multimodal human values video dataset called VVALUES, which contains 5,104 annotated videos along with their titles. The dataset is labeled with coarse-grained polarity tags of positive and neutral, and fine-grained tags including 13 classes of value vocabulary. Based on VVALUES, we further develop a pre-trained language model (PLM)-based multimodal method adopting a dual-transformer variant for value recognition, MMVR. Extensive experiments demonstrate that our method significantly improves the performance of understanding values in videos. To the best of our knowledge, we are the first to try to incorporate human values in video understanding, and VVALUES is the first multimodal video dataset for human values.}
}
@article{WANG2024103675,
title = {A cross modal hierarchical fusion multimodal sentiment analysis method based on multi-task learning},
journal = {Information Processing & Management},
volume = {61},
number = {3},
pages = {103675},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103675},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324000359},
author = {Lan Wang and Junjie Peng and Cangzhi Zheng and Tong Zhao and Li’an Zhu},
keywords = {Multi-modality, Sentiment analysis, Cross-modal interactions, Multi-task learning},
abstract = {Humans often express affections and intentions through multiple forms when communicating, involving text, audio, and vision modalities. Using a single modality to determine the sentiment state may be biased, but combining multiple clues can fully explore more comprehensive information. Effective fusion of heterogeneous data is one of the core problems of multimodal sentiment analysis. Most cross-modal fusion strategies inevitably bring noisy information, resulting in low-quality joint feature representations and impacting the accuracy of sentiment classification. Considering the unique cues of modality-specific, common information between modalities, and sentiment variability among different layers, we introduce multi-task learning and propose a cross-modal hierarchical fusion method for multimodal sentiment analysis. The model combines unimodal, bimodal, and trimodal tasks to enhance multimodal feature representation for the final sentiment prediction. We conduct extensive experiments on CH-SIMS, CMU-MOSI, and CMU-MOSEI, where the first one is in Chinese and the last two are in English. The results demonstrate the generalizability of the proposed method. It effectively improves the accuracy of sentiment analysis while reducing the adverse impact of the noise compared to the existing models.}
}
@article{TANG2022109204,
title = {Time enhanced graph neural networks for session-based recommendation},
journal = {Knowledge-Based Systems},
volume = {251},
pages = {109204},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109204},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122005986},
author = {Gu Tang and Xiaofei Zhu and Jiafeng Guo and Stefan Dietze},
keywords = {Session-based recommendation, Graph neural network, Highway network, Temporal interest attention network},
abstract = {Session-based recommendation (SBR) is a challenging task, aiming at recommending items according to the behavior of anonymous users. Previous research efforts mainly focus on capturing sequential transitions between consecutive items via recurrent neural networks (RNN) or modeling the complex transitions between non-adjacent items based on graph neural networks (GNN). Although these works have achieved encouraging performance on solving the session-based recommendation problem, few efforts have been dedicated to exploring the rich information related to the shifts of user interests within the transition relationships, which is the research gap we attempt to bridge in this work. In this paper, we propose a novel model, named Time Enhanced Graph Neural Networks (TE-GNN), which attempts to capture the complex user interest shift patterns within sessions. In TE-GNN, we construct a Time Enhanced Session Graph (TES-Graph) where transition relationships between items are treated adaptively with respect to the degree of user interest drift. In addition, a novel Temporal Graph Convolutional Network (T-GCN) is designed to learn item embeddings based on the TES-Graph. Moreover, we also introduce a Temporal Interest Attention Network (TIAN) to model the complex transition of items with a common user interest. Extensive experiments have been conducted on four widely used benchmark datasets, i.e., Diginetica, Tmall, Nowplaying, and Retailrocket, and the results show that our proposed approach TE-GNN significantly outperforms previous state-of-the-art baseline methods. The implementation of TE-GNN is available in https://github.com/GuTang1997/TE-GNN.}
}
@article{REN2025104108,
title = {Temporal-spatial hierarchical contrastive learning for misinformation detection: A public-behavior perspective},
journal = {Information Processing & Management},
volume = {62},
number = {4},
pages = {104108},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104108},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325000500},
author = {Gang Ren and Li Jiang and Tingting Huang and Ying Yang and Taeho Hong},
keywords = {Misinformation detection, Hierarchical contrastive learning, Graph convolutional networks, Cross-view fusion},
abstract = {The widespread dissemination of misinformation on social media platforms significantly affects public security. Current methods for detecting misinformation predominantly rely on semantic information and social context features. However, they often neglect the intricate noise issues and unreliable information interactions resulting from diverse public behaviors, such as cognitive biases, user prejudices, and bot activity. To tackle these challenges, we propose an approach named TSHCL (temporal-spatial hierarchical contrastive learning) for automatic misinformation detection from the public-behavior perspective. First, the integration of a graph convolutional network (GCN)-based autoencoder architecture with a hybrid augmentation method is designed to model typical public behaviors. Next, node-level contrastive learning is designed to maintain the heterogeneity of comments in the spatial view under the influence of complex public behaviors. Finally, cross-view graph-level contrastive learning is designed to promote collaborative learning between the temporal sequence view of events and the spatial propagation structure view. By conducting temporal-spatial hierarchical contrastive learning, the model effectively retains crucial node information and facilitates the interaction of temporal-spatial information. Extensive experiments conducted on real datasets from MCFEND and Weibo demonstrate that our model surpasses the state-of-the-art models. Our proposed model can effectively alleviate the noise and unreliable information interaction caused by public behavior, and enrich the research perspective of misinformation detection.}
}
@article{ZHANG2025104076,
title = {A Local context enhanced Consistency-aware Mamba-based Sequential Recommendation model},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {104076},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104076},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325000184},
author = {Zhu Zhang and Bo Yang and Yimeng Lu},
keywords = {Sequential recommendation, Mamba, Consistency training, Graph neural network, Contrastive learning},
abstract = {Sequential recommendation (SR) focuses on capturing users’ interests from their historical behaviors. Transformer-based SR models have demonstrated promising performance by leveraging self-attention for sequential modeling. Recently, Mamba, a novel sequential model, has shown competitive performance compared to Transformers. In SR tasks, item representation learning involves both global and local context information. While several existing SR models attempt to address this integration, they suffer from inferior performance or computational inefficiency. Moreover, existing Mamba-based SR model appears to capture only the global context information. Given Mamba’s merits in enhancing model performance and efficiency, there is substantial potential to more effectively integrate both global and local context information within a Mamba-based framework. Additionally, consistency training, which is pivotal for enhancing model performance, remains underexplored in existing SR models. To tackle these challenges, we propose a Local Context Enhanced Consistency-aware Mamba-based Sequential Recommendation Model (LC-Mamba). LC-Mamba captures both global and local context information to improve recommendation performance. Specifically, LC-Mamba leverages a GNN-based sequence encoder to extract information from local neighbors for each item (local context information) in a graph view, while utilizing a Mamba-based sequence encoder to capture dependencies between items in the sequence (global context information) in a sequential view. Furthermore, we introduce consistency training, including model-level and representation-level consistency, to further enhance performance. Specifically, we incorporate R-Drop regularization into the Mamba-based sequence encoder to mitigate the inconsistency between training and inference caused by random dropout (model-level consistency). Additionally, we leverage contrastive learning to enhance consistency between the item representations learned from the sequential and graph views (representation-level consistency). Extensive experiments on three widely used datasets illustrate that LC-Mamba outperforms baseline models in HR and NDCG, achieving up to a 31.03% improvement in NDCG. LC-Mamba can be applied to real-world applications such as e-commerce and content platforms.}
}
@article{TANG2025116967,
title = {A novel evolutionary deep reinforcement learning algorithm for the influence maximization problem in multilayer social networks},
journal = {Chaos, Solitons & Fractals},
volume = {200},
pages = {116967},
year = {2025},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2025.116967},
url = {https://www.sciencedirect.com/science/article/pii/S0960077925009804},
author = {Jianxin Tang and Chenshuo Li and Lijun Liu and Tianpeng Xu and Yabing Yao},
keywords = {Multilayer social networks, Influence maximization, Cross-layer independent cascade model, Multilayer network embedding, Differential evolution, Deep reinforcement learning},
abstract = {How to identify a set of influential individuals that can ensure the most information diffusion in multilayer social networks remains a fundamental yet underexplored issue of the influence maximization problem. Existing solutions mostly simplify or even neglect the heterogeneous characteristics of individuals from different layers, and the inter-layer propagation dynamics of the information spreading in the multilayer social networks. To address such challenges, a cross-layer independent cascade model is proposed to capture the inter-layer information cascading effect. Furthermore, this paper proposes a differential evolution-aided deep reinforcement learning (DEDRL) algorithm to identify the optimal seed set for the influence maximization in multilayer networks. More specifically, a multilayer network embedding mechanism is conceived to learn node embeddings of multilayer networks and the differential evolution is integrated with deep reinforcement learning to evolve a population composed of deep Q network weight parameters. Experimental evaluations conducted on both synthetic and real-world multilayer networks demonstrate the effectiveness of the proposed DEDRL and show an average performance improvement of 3.8% compared to the state-of-the-art algorithms.}
}
@article{HE2023119713,
title = {Meta-path based graph contrastive learning for micro-video recommendation},
journal = {Expert Systems with Applications},
volume = {222},
pages = {119713},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.119713},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423002142},
author = {Ying He and Gongqing Wu and Desheng Cai and Xuegang Hu},
keywords = {Micro-video recommendation, Graph neural networks, Contrastive learning},
abstract = {Nowadays, micro-video sharing platforms have become popular tools for people creating and viewing micro-videos in daily life. The micro-video recommendation task has attracted significant attention from researchers, recently. The key to a high-quality micro-video recommendation system is learning meaningful user and micro-video representations. Recently, many graph neural networks (GNNs) are proposed to learn node representations in graphs, which could be useful for recommendation tasks. However, we argue that directly utilizing existing GNNs in micro-video recommendations is ill-posed. The reasons are: (1) most previous GNNs fail to capture the heterogeneity of heterogeneous graphs since they are designed for homogeneous graphs; (2) they overemphasize node proximity and may hurt the robustness of node embeddings. In contrast to previous work, we propose a meta-path-based graph contrastive learning network (MPGCL) that learns more meaningful user and video embeddings for recommendation. Specifically, we yield homogeneous graphs for user type and video type to better capture heterogeneity based on a well-designed meta-path-based random walk strategy. Furthermore, to learn more robust node embeddings that are less sensitive to noise, we propose a graph contrastive learning network on different types of homogeneous graphs, which maximizes the consistency between graph representations with different views. We do extensive experiments on three real-world datasets and the results show that our model can learn more meaningful embeddings for users and micro-videos and outperforms the strong baselines.}
}
@article{TANG2025102002,
title = {Probing the fitness landscape of the influential nodes for the influence maximization problem in social networks},
journal = {Swarm and Evolutionary Computation},
volume = {97},
pages = {102002},
year = {2025},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2025.102002},
url = {https://www.sciencedirect.com/science/article/pii/S2210650225001609},
author = {Jianxin Tang and Jiaqiang Fu and Xinyue Li and Lele Geng and Juan Pang},
keywords = {Social network, Influence maximization, Fitness landscape, Decision support, Differential evolution},
abstract = {Influence Maximization (IM) is a key issue of information dissemination and has been proved to be an NP-hard problem. However, traditional methods always suffer from low efficiency, poor scalability, and tend to fall into local optima. Probing the promising distribution regions of the potential influential nodes from the macroscopic perspective is necessary and helpful in understanding the influence propagation. To address such challenges, this paper makes attempt to depict the fitness landscape distribution of the expected influence of the social individuals in the network from a novel perspective. An entropy measure is introduced as a decision criterion and a fitness landscape-guided differential evolution optimization (FLDE) is proposed. Firstly, the distribution of the potential solution regions is depicted by characterizing the fitness landscape designed specially for IM problem. Next, a guiding strategy based on the fitness landscape is conceived to drive the differential evolution towards more promising solution regions by avoiding the entrapment in local optima. Experiments conducted on six real social networks and three synthetic networks indicate that the FLDE outperforms the state-of-the-art baselines by an average of 16% in influence spread and shows strong scalability when dealing with different types of networks.}
}
@article{ZHENG2024124894,
title = {Modeling multi-factor user preferences based on Transformer for next point of interest recommendation},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124894},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124894},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424017615},
author = {Yongshang Zheng and Xu Zhou},
keywords = {Location-based social network, Next POI recommendation, Graph neural network, Transformer},
abstract = {With the rapid development of the mobile network and the gradual popularization of mobile devices, more and more users try to find attractive places to visit through WeChat, Twitter applications. In this trend, personalized next point of interest(POI) recommendation in the Location-based Social Network (LBSN) has become the focus of research and practice. Most existing studies capture user interest changes between different days (i.e. weekend and weekday), however, they ignore seasonal factors in time transition and category factors and thus fail to capture seasonal-level and category-level movement patterns in users’ mobile trajectories. Besides, they neglect the relevance between POIs from all users’ trajectory and fail to generate expressive POI embedding representation without constructing trajectory graph, which will reduce the accuracy of the next POI recommendation. To address the issues above, a next POI recommendation method for modeling Multi-factor User Preferences based on Transformer (MUPT) is developed, which consists of a global POI relationship modeling, a local multi-factor user preference modeling and a prediction module. It first learns the collaborative information of users with similar behavior to generate expressive POI embedding representation. Then it captures the personalized movement patterns of users at the POI, category and time levels based on Transformer mechanism in the local module. Especially the seasonal and other fine-grained information on the time series are learned in the time preference modeling part. The prediction module designed tracks the relationship between multi-level motion pattern representation of user check-in behavior and the next POI accessed by the user, and it finally obtains user’s preference probability for next POIs. An extensive experiment has been conducted on four datasets, and the experimental results analysis demonstrates that our proposed MUPT method is superior to other methods in terms of accuracy(ACC), mean reciprocal rank(MRR) and normalized discounted cumulative gain(NDCG).}
}
@article{KIM2025128240,
title = {Graph-based technology recommendation system using GAT-NGCF},
journal = {Expert Systems with Applications},
volume = {288},
pages = {128240},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128240},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425018597},
author = {Min-Seung Kim and Yong-Ju Jang and Tae-Eung Sung},
keywords = {GAT, NGCF, Representation learning, Technology management, Technology recommendation system},
abstract = {This study proposes a GAT-NGCF-based technology recommendation system to improve firms’ technological innovation capabilities and facilitate technology transfer. The system leverages Graph Attention Networks (GAT) to generate optimal representations of firms and patents, which are then applied in a firm–patent interaction graph using Neural Graph Collaborative Filtering (NGCF) to recommend the most suitable patents for transfer. Experiments conducted on 6,797 technology transfer and valuation cases demonstrated high performance, achieving a Recall@5 of 0.9984 and NDCG@5 of 0.9972. Notably, the proposed system outperformed State-Of-The-Art (SOTA) models in collaborative filtering, reinforcing its effectiveness. The system offers customized technology recommendations that align with firms’ technological needs and is expected to play a key role in supporting technology transfer and commercialization strategies through open innovation.}
}
@article{GU2024111841,
title = {Modeling multi-behavior sequence via HyperGRU contrastive network for micro-video recommendation},
journal = {Knowledge-Based Systems},
volume = {295},
pages = {111841},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111841},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124004751},
author = {Pan Gu and Haiyang Hu and Guandong Xu},
keywords = {Micro-video recommendation, Multi-behavior recommendation, Contrastive learning, Recurrent neural network},
abstract = {Micro-video prediction with the multi-behavior sequence remains a challenging task for current recommendation systems. Existing approaches tend to model each individual behavior sequence separately to obtain multi-level user preferences. However, they neglected the semantic correlations among different types of behaviors, that is, the ordinal rankings of user satisfaction conveyed through multi-type actions. Additionally, they failed to capture the temporal dependencies among a user’s historical multi-behavioral sequence, especially the dependencies between positive and negative behaviors. To address this issue, we propose a novel HyperGRU contrastive network to model the multi-behavior sequence for micro-video recommendation. We first propose a concept of hypernode to capture semantic dependencies among multiple behaviors. Based on the hypernode, we then design a novel HyperGRU network to extract positive and negative interests from users’ temporal multi-behavior sequence. Beyond that, we train the HyperGRU under the guidance of a contrastive learning framework to make the positive and negative interests discriminating. Technically, we assign labels for the positive and negative interests by modeling the “skip” and “click” sub-sequences separately. Subsequently, contrastive tasks are conducted to encourage the interest representations to be closer to their associated labels than the opposite labels. Finally, the system makes predictions with the input of the disentangled preferences. The experiments conducted on three public real-world datasets demonstrate the effectiveness of our model.}
}
@article{LI2023120963,
title = {HKGCL: Hierarchical graph contrastive learning for multi-domain recommendation over knowledge graph},
journal = {Expert Systems with Applications},
volume = {233},
pages = {120963},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120963},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423014653},
author = {Yakun Li and Lei Hou and Dongmei Li and Juanzi Li},
keywords = {Multi-domain recommendation, Contrastive learning, Knowledge graph},
abstract = {Multi-domain recommendation (MDR) aims to improve the recommendation performance in all target domains simultaneously by leveraging rich data from relevant domains. However, conventional approaches either only rely on sparse interactions in each separate scenario, or simply combine multiple shared recommendation solutions, resulting in MDR systems still suffering from severely low recommendation accuracy. To tackle the above issues, we propose a novel recommendation model called Hierarchical Graph Contrastive Learning for Multi-Domain Recommendation over Knowledge Graph (HKGCL). Different from previous MDR models, our HKGCL can treat each relevant domain as a hierarchy in the interaction network. Based on the LightGCN aggregation strategy, a hierarchical message passing mechanism over the knowledge graph is designed to aggregate hierarchical knowledge representations for users and items. Then, a hierarchical node dropping scheme is proposed as our data augmentation technique on different hierarchical views to obtain more self-supervised semantic signals. Subsequently, three graph contrastive learning tasks in multiple and separate domains are proposed to explore domain-shared and domain-specific preference features for target users, respectively. Additionally, a novel Multi-domain Bayesian Personalized Ranking (MBPR) approach is proposed to assist in training our multi-task learning framework. Extensive experiments conducted on two real-world datasets demonstrate the consistent superiority of our proposed HKGCL over various state-of-the-art baselines, and also verify that the HKGCL can achieve strong performance on sparse interaction scenarios.}
}
@article{TAO2020102277,
title = {MGAT: Multimodal Graph Attention Network for Recommendation},
journal = {Information Processing & Management},
volume = {57},
number = {5},
pages = {102277},
year = {2020},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2020.102277},
url = {https://www.sciencedirect.com/science/article/pii/S0306457320300182},
author = {Zhulin Tao and Yinwei Wei and Xiang Wang and Xiangnan He and Xianglin Huang and Tat-Seng Chua},
keywords = {Personalized recommendation, Graph, Gate mechanism, Attention mechanism, Micro-videos},
abstract = {Graph neural networks (GNNs) have shown great potential for personalized recommendation. At the core is to reorganize interaction data as a user-item bipartite graph and exploit high-order connectivity among user and item nodes to enrich their representations. While achieving great success, most existing works consider interaction graph based only on ID information, foregoing item contents from multiple modalities (e.g., visual, acoustic, and textual features of micro-video items). Distinguishing personal interests on different modalities at a granular level was not explored until recently proposed MMGCN (Wei et al., 2019). However, it simply employs GNNs on parallel interaction graphs and treats information propagated from all neighbors equally, failing to capture user preference adaptively. Hence, the obtained representations might preserve redundant, even noisy information, leading to non-robustness and suboptimal performance. In this work, we aim to investigate how to adopt GNNs on multimodal interaction graphs, to adaptively capture user preference on different modalities and offer in-depth analysis on why an item is suitable to a user. Towards this end, we propose a new Multimodal Graph Attention Network, short for MGAT, which disentangles personal interests at the granularity of modality. In particular, built upon multimodal interaction graphs, MGAT conducts information propagation within individual graphs, while leveraging the gated attention mechanism to identify varying importance scores of different modalities to user preference. As such, it is able to capture more complex interaction patterns hidden in user behaviors and provide a more accurate recommendation. Empirical results on two micro-video recommendation datasets, Tiktok and MovieLens, show that MGAT exhibits substantial improvements over the state-of-the-art baselines like NGCF (Wang, He, et al., 2019) and MMGCN (Wei et al., 2019). Further analysis on a case study illustrates how MGAT generates attentive information flow over multimodal interaction graphs.}
}
@article{ZHANG2025130393,
title = {Multimodal misinformation detection based on the multi-granularity consistency},
journal = {Neurocomputing},
volume = {644},
pages = {130393},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130393},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225010653},
author = {Shibo Zhang and Hongchang Chen and Shuxin Liu and Ran Li and HaoCong Jiang and Liang Dong},
keywords = {Multimodal misinformation detection, Multimodal content analysis, Multimodal feature fusion, Social media analysis},
abstract = {In the current era of information proliferation, social media platforms frequently present multimodal data that may propagate misinformation. To address this challenge, computer vision techniques have been increasingly applied to online misinformation detection. Existing approaches often concentrate on learning deep semantic features from text and images without sufficiently exploring coherent alignments across multiple granular levels. This could hinder the construction of a comprehensive multimodal detection framework for misinformation detection. To overcome these issues, in this paper, we propose a three-level granularity consistency detection framework that explores image-text alignments at fine-grained, medium-grained, and coarse-grained levels. Meanwhile, we delve into the hierarchical structures of two modalities as well as the intricate semantic relationships between them. Specifically, our framework models token-level consistency through a multi-head cross-attention mechanism, phrase-level consistency via a graph neural network (GNN), and global-level consistency using a contrastive language-image pre-training model (CLIP), respectively. An adaptive fusion module then integrates these consistency features across all three granularities, enabling more nuanced and robust multimodal misinformation detection. Extensive experiments conducted on multiple benchmark datasets demonstrate that our approach substantially improves the performance of multimodal misinformation detection.}
}
@article{YIN2025103935,
title = {Enhancing video rumor detection through multimodal deep feature fusion with time-sync comments},
journal = {Information Processing & Management},
volume = {62},
number = {1},
pages = {103935},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103935},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324002942},
author = {Ming Yin and Wei Chen and Dan Zhu and Jijiao Jiang},
keywords = {Rumor verification, Multimodal fusion, Video content analysis, Time-sync comment},
abstract = {Rumors in videos have a stronger propagation compared to traditional text or image rumors. Most current studies on video rumor detection often rely on combining user and video modal information while neglecting the internal multimodal aspects of the video and the relationship between user comments and local segment of the video. To address this problem, we propose a method called Time-Sync Comment Enhanced Multimodal Deep Feature Fusion Model (TSC-MDFFM). It introduces time-sync comments to enhance the propagation structure of videos on social networks, supplementing missing contextual or additional information in videos. Time-sync comments focus on expressing users' views on specific points in time in the video, which helps to obtain more valuable segments from videos with high density information. The time interval from one keyframe to the next in a video is defined as a local segment. We thoroughly described this segment using time-sync comments, video keyframes, and video subtitle texts. The local segment sequences are ordered based on the video timeline and assigned time information, then fused to create the local feature representation of the video. Subsequently, we fused the text features, video motion features, and visual features of video comments at the feature level to represent the global features of the video. This feature not only captures the overall propagation trend of video content, but also provides a deep understanding of the overall features of the video. Finally, we will integrate local and global features for video rumor classification, to combine the local and global information of the video. We created a dataset called TSC-VRD, which includes time-sync comments and encompasses all visible information in videos. Extensive experimental results have shown superior performance of our proposed model compared to existing methods on the TSC-VRD dataset.}
}
@article{BANSAL2024109417,
title = {A hybrid filtering for micro-video hashtag recommendation using graph-based deep neural network},
journal = {Engineering Applications of Artificial Intelligence},
volume = {138},
pages = {109417},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109417},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624015756},
author = {Shubhi Bansal and Kushaan Gowda and Mohammad Zia Ur Rehman and Chandravardhan Singh Raghaw and Nagendra Kumar},
keywords = {Hashtag recommendation, Micro-videos, Graph neural network, Multimodal data analysis},
abstract = {Due to the growing volume of user-generated content, hashtags are employed as topic indicators to manage content efficiently on social media platforms. However, finding these vital topics is challenging in micro-videos since they contain substantial information in a short duration. Existing methods that recommend hashtags for micro-videos primarily focus on content and personalization while disregarding user’s modality-specific tagging preferences. Moreover, the cold-start user issue prevails in hashtag recommendation systems. Considering the above, we propose a hybrid filtering-based MIcro-video haSHtag recommendatiON (MISHON) system to recommend hashtags for micro-videos. We construct a heterogeneous graph to model user’s modality-specific tagging patterns by establishing links with constituent modalities of previous micro-videos, further encompassing user-to-user and modality-to-modality interactions. We then refine modality-specific and user representations using message-passing strategy to recommend pertinent hashtags for micro-videos. The empirical results on three real-world datasets demonstrate that MISHON attains a comparative enhancement of 3.6%, 2.8%, and 6.5% concerning the F1-score, respectively. To address cold-start problem, we propose a content and social influence-based technique to recommend hashtags that are not only relevant to content but also popular, thereby empowering cold-start users to broaden their network and content visibility. The proposed solution shows a relative improvement of 15.8% in the F1-score over its content-only counterpart.}
}
@article{PARK2024103705,
title = {GNN-IR: Examining graph neural networks for influencer recommendations in social media marketing},
journal = {Journal of Retailing and Consumer Services},
volume = {78},
pages = {103705},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103705},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924000018},
author = {Jinhee Park and Hyeongjin Ahn and Dongjae Kim and Eunil Park},
keywords = {Influencer marketing, Recommendation, Link prediction, Bipartite graph, YouTube commercial},
abstract = {With the notable growth of the Internet, a number of platforms have emerged and attracted an enormous number of users. Based on the impact of these platforms, some ‘influencers’ are highlighted. These influencers wield significant power, shaping consumer behavior. This influence spawned the concept of influencer marketing, where companies leverage these personalities to advertise their products. YouTube stands out as a prominent platform in this trend. However, considering the limited number of influencers and their concepts, the majority of companies, which hope to conduct their marketing campaigns with influencers face challenges in identifying suitable influencers for their campaigns. With this trend, we introduce GNN-IR, a graph neural network for influencer recommendation, based on the connections between companies and influencers of YouTube, one of the largest content platforms. In developing GNN-IR, we adopted a data-driven methodology utilizing a meticulously curated dataset collected in-house. Our dataset comprises a total of 25,174 relationship entries between advertisers and influencers, involving 1,886 distinct advertisers and 3,812 unique YouTube influencers. It encompasses diverse data modalities, including images, text, and assorted metadata. The data was sourced from two primary platforms: YouTube and ugwanggi. Ugwanggi provided valuable insights into the relationships between advertisers and influencers via their information. Meanwhile, YouTube offered more comprehensive and detailed influencer-centric information. We employed PyTorch Geometric to construct a bipartite graph representing interconnected data. Our recommendation system operates via link prediction, suggesting the Top-k influencers to advertisers based on the calculated connection probability between nodes. To assess GNN-IR's performance, we employed a range of evaluation metrics. For link prediction, we measured Accuracy, Precision, Recall, and F1-score. Additionally, in the recommendation phase, we evaluated Precision@k, Recall@k, and F1-score@k. Using GNN-IR and incorporating profile images from YouTube, keyword features, metadata, and sentiment gleaned from YouTube comments, we achieved Precision levels of 96.51% at k=1 and 93.68% at k=10. Based on the experimental results, several implications and limitations are presented. The collected dataset is publicly available at https://github.com/dxlabskku/GNN-IR.git.}
}
@article{WANG2024103091,
title = {Network traffic classification based on federated semi-supervised learning},
journal = {Journal of Systems Architecture},
volume = {149},
pages = {103091},
year = {2024},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2024.103091},
url = {https://www.sciencedirect.com/science/article/pii/S1383762124000286},
author = {ZiXuan Wang and ZeYi Li and MengYi Fu and YingChun Ye and Pan Wang},
keywords = {Federated learning, Semi-supervised learning, Network traffic classification, Deep learning},
abstract = {Traffic Classification (TC) has been applied to a wide range of applications, from security monitoring to quality of service (QoS) provisioning in network Internet Service Providers (ISPs). In recent years, many researchers have applied Machine Learning (ML) or Deep Learning (DL) to TC, namely AI-TC. However, AI-TC methods face significant challenges, including high data dependency, exhaustively costly traffic labeling, and network subscribers’ privacy. This paper proposes a TC framework for smart home networks using Federated Learning (FL) that protects traffic data privacy by performing local training and inference of TC models. Firstly, we design a DPI-based traffic labeling method on edge home gateways as FL nodes, which enables these nodes to have data labeling capability while protecting data privacy. Then, a semi-supervised TC model based on an autoencoder (AE) is proposed to reduce the dependence of the model on labeled traffic samples. Finally, an XAI-based method is utilized to interpret the model to ensure its explainability. We validate the proposed method on public and real datasets using benchmarking methods. The experimental results show that the method can achieve high performance using a small number of samples while protecting data privacy and improving the model’s credibility. Experimental code can be found in the following url: https://github.com/PrinceXuan12138/HGW-TC-Experimental-code.}
}
@article{SORGATZ2024216,
title = {Virtual-tutoring-supported teaching for Geometrical Product Specification},
journal = {Procedia CIRP},
volume = {129},
pages = {216-221},
year = {2024},
note = {18th CIRP Conference on Computer Aided Tolerancing (CAT2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.038},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124011740},
author = {Anna Sorgatz and Juliane Schuldt and Sophie Gröger},
keywords = {virtual tutoring, learning platform, gamificatio;, Geometrical Product Specification, ISO GPS system;, maturity model},
abstract = {The digitalisation of education has developed in many areas in recent years with applications like web-based training and virtual seminars. In technical teaching areas, however, they are often only available as stand-alone solutions. Due to the possibilities brought about by the rapidly progressing development of artificial intelligence, the potential for digital teaching must be recognised and used. It is necessary to establish demand-oriented, intelligent control loops that support communication, knowledge transfer and learning level control. This will enable future generations to learn individually and thus increase the efficiency and sustainability of the teaching-learning process. As part of a current research project, a multimedia study format for the field of production measurement technology is being designed at Chemnitz University of Technology. A virtual tutor is an innovative element that guides, reminds, supports, informs, collects points and motivates learners individually with gamification elements. This paper presents the requirements, implementation possibilities and transferability of the current research of virtual-tutor-supported teaching to Geometrical Product Specification. It shows how knowledge elements of the ISO GPS system are linked with new digital teaching-learning methods that promote interaction between the participants and especially the transfer into applicable knowledge. In addition, examples of gamification elements are presented.}
}
@article{CHEN2025111385,
title = {BTG-RF: Recognizing Douyin payment behaviors based on behavioral traffic graph analysis},
journal = {Computer Networks},
volume = {269},
pages = {111385},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111385},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625003524},
author = {Yan Chen and Xiaoyan Hu and Xinghai Chen and Guang Cheng and Ruidong Li and Hua Wu},
keywords = {Douyin, Network traffic analysis, Behavior recognition, Behavioral traffic graph},
abstract = {Douyin’s extensive user base has led to an increase in malicious activities targeting Douyin’s payment behaviors, posing significant challenges to security. Analyzing Douyin user behavior through network traffic can provide practical strategies for managing Douyin traffic and preventing malicious activities. Existing mobile user behavior identification methods often ignore the need for segmenting continuous user behavior traffic in the real world and typically rely on manual feature selection, limiting their practicality. To address these challenges, we propose BTG-RF, a Douyin payment behavior recognition method based on behavioral traffic graph analysis. To achieve accurate user behavior segmentation, BTG-RF employs a behavior segmentation method that utilizes a specified time threshold and a merging strategy based on Douyin user behavior characteristics to divide continuous Douyin user behavior traffic into burst traffic segments representing distinct user behaviors. Then, it incorporates network interaction traffic information to construct Behavioral Traffic Graphs (BTG) for these burst segments and applies Graph Autoencoder (GAE) for graph vector learning. Finally, the graph vectors are fed into a Random Forest (RF) model for final classification. We conduct experiments on a self-collected labeled dataset of Douyin payment behaviors, and the results demonstrate that BTG-RF achieves a recognition recall of 99.49% in Douyin payment behavior recognition, surpassing other mainstream methods.}
}
@article{GREEN2025,
title = {Collecting and Sharing Person-Centered AI Clinical Summaries Across Frailty Services Provided by the National Health Service and Voluntary, Community, and Social Enterprise: Protocol for a Co-Design and Feasibility Study},
journal = {JMIR Research Protocols},
volume = {14},
year = {2025},
issn = {1929-0748},
doi = {https://doi.org/10.2196/68511},
url = {https://www.sciencedirect.com/science/article/pii/S1929074825006006},
author = {Kieran Green and Sheena Asthana and Oscar Josue Ponce-Ponte and John Downey and Joanne Watson},
keywords = {artificial intelligence, AI, health care, future, medical documentation, data interoperability, person-centered care, multidisciplinary team, care coordination},
abstract = {Background
Due to its association with multimorbidity, frailty gives rise to multidimensional needs for different services. Too often, patient preferences and service encounter information are not adequately shared.
Objective
This developmental study aims to co-design, collect, and analyze encounter data from multiple community and primary-based multidisciplinary teams (MDTs) providing services for people with frailty to develop prototype large language models that can generate clinical and person-centered care summaries.
Methods
Engaging stakeholders in 2 primary care networks, we will co-design the large language model to ensure it meets local needs and preferences as well as infrastructure, information governance, and regulation requirements. General practitioners will identify 50 patients with frailty requiring MDT engagement. Three consecutive encounters between the patients and different members of MDTs will then be audio-recorded. Recordings will be transcribed into text for concept design and model pretraining. These data combine stakeholder engagement insights to develop sensitive artificial intelligence (AI) models responding to stakeholders’ needs, workflows, and preferences. To generate the person-centered summaries, we will test 2 approaches to modeling the encounter data: graph-based modeling and hierarchical transformers. The AI-generated summaries will be compared to human-written summaries of the same encounter data and assessed for accuracy, quality, fluency, and person-centeredness. They will also be shared with the original MDT members for validation. We will capture inputs, processes, and outcomes across all key phases of the implementation journey to identify capability requirements, determinants of implementation (including key challenges and best practices to overcome them), and the value added by the technology.
Results
This protocol aims to review implementation evidence and engage stakeholders in co-design. This work package will aid the development of contextually sensitive, longitudinal, and AI-generated person-centered summarization tools. Model development will aim to achieve longitudinal person-centered summaries tested against MDT standards. If deemed suitable for deployment, optimum ways of integrating these summaries into shared care records will be explored with local key system leaders. Model evaluations will provide conclusive insights into such technologies’ benefits and risks. As of August 2025, this study has not yet been funded, nor has ethical approval for the project been obtained. Consequently, dates of data collection and numbers of recruited participants are not applicable at this time.
Conclusions
Our protocol provides a robust method of co-designing, evaluating, and implementing a longitudinal AI medical summary tool. Including key stakeholders at multiple stages facilitates an iterative development strategy that is designed to solve implementation challenges as they emerge. This project fits within our long-term vision to deliver a multimodal AI tool that saves clinicians time and deepens the health care professional–patient relationship. Future studies should include a larger patient sample, video-recorded health care professional–patient encounters, and a more extensive longitudinal evaluation.
International Registered Report Identifier (IRRID)
PRR1-10.2196/68511}
}
@article{WU2025113057,
title = {CoT-driven framework for short text classification: Enhancing and transferring capabilities from large to smaller model},
journal = {Knowledge-Based Systems},
volume = {311},
pages = {113057},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113057},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125001042},
author = {Hui Wu and Yuanben Zhang and Zhonghe Han and Yingyan Hou and Lei Wang and Siye Liu and Qihang Gong and Yunping Ge},
keywords = {Short text classification, Large language models, Chain-of-thought},
abstract = {Short Text Classification (STC) is crucial for processing and understanding the brief but substantial content prevalent on contemporary digital platforms. The STC encounters difficulties in grasping the semantic and syntactic intricacies, an issue that is apparent in traditional pre-trained language models. Although Graph Convolutional Networks enhance performance by integrating external knowledge bases, these methods are limited by the quality and extent of the knowledge applied. Recently, the emergence of Large Language Models (LLMs) and Chain-of-Thought (CoT) has significantly improved the performance of complex reasoning tasks. However, some studies have highlighted the limitations of their application in fundamental NLP tasks. Consequently, this study first employs CoT to investigate and enhance the capabilities of LLMs in STC tasks. We propose the Syntactic and Semantic Enrichment CoT (SSE-CoT) method, effectively decomposing the STC tasks into four distinct steps: (i) essential concept identification, (ii) common-sense knowledge retrieval, (iii) text rewriting, and (iv) classification. Furthermore, recognizing resource constraints in sectors like finance and healthcare, we then introduce the CoT-Driven Multi-Task Learning (CDMT) framework to extend these capabilities to smaller models. This framework begins by extracting rationales from LLMs and subsequently fine-tunes smaller models to optimize their performance. Extensive experimentation across six short-text benchmarks validated the efficacy of the proposed methods. In particular, SSE-CoT achieved state-of-the-art performance with substantial improvements on all datasets, particularly on the Ohsumed and TagMyNews datasets.}
}
@article{JAVED2024110808,
title = {Towards the future of bot detection: A comprehensive taxonomical review and challenges on Twitter/X},
journal = {Computer Networks},
volume = {254},
pages = {110808},
year = {2024},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110808},
url = {https://www.sciencedirect.com/science/article/pii/S1389128624006406},
author = {Danish Javed and NZ Jhanjhi and Navid Ali Khan and Sayan Kumar Ray and Alanoud Al Mazroa and Farzeen Ashfaq and Shampa Rani Das},
keywords = {Harmful Twitter Bots (HTB), Twitter, X, Bot detection},
abstract = {Harmful Twitter Bots (HTBs) are widespread and adaptable to a wide range of social network platforms. The use of social network bots on numerous social network platforms is increasing. As the popularity and utility of social networking bots grow, the attacks using social network-based automated accounts are getting more coordinated, resulting in crimes that might endanger democracy, the financial market, and public health. HTB designers develop their bots to elude detection while academics create several algorithms to identify social media bot accounts. This field is active and necessitates ongoing improvement due to the never-ending cat-and-mouse game. X, previously known as Twitter, is among the biggest social network platforms that has been plagued by automated accounts. Even though new research is being conducted to tackle this issue, the number of bots on Twitter keeps on increasing. In this research, we establish a robust theoretical foundation in the continuously evolving domain of Harmful Twitter Bot (HTB) detection by analyzing the existing HTB detection techniques. Our research provides an extensive literature review and introduces an enhanced taxonomy that has the potential to help the scientific community form better generalizations for HTB detection. Furthermore, we discuss this domain's obstacles and open challenges to direct and improve future research. As far as we are aware, this study marks the first comprehensive examination of HTB detection that includes articles published between June 2013 and August 2023. The review's findings include a more thorough classification of detection approaches, a spotlight on ways to spot Twitter bots, and a comparison of recent HTB detection methods. Moreover, we provide a comprehensive list of publicly available datasets for HTB detection. As bots evolve, efforts must be made to raise awareness, equip legitimate users with information, and help future researchers in the field of social network bot detection.}
}
@article{XU2021114176,
title = {Detecting suicide risk using knowledge-aware natural language processing and counseling service data},
journal = {Social Science & Medicine},
volume = {283},
pages = {114176},
year = {2021},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2021.114176},
url = {https://www.sciencedirect.com/science/article/pii/S0277953621005086},
author = {Zhongzhi Xu and Yucan Xu and Florence Cheung and Mabel Cheng and Daniel Lung and Yik Wa Law and Byron Chiang and Qingpeng Zhang and Paul S.F. Yip},
keywords = {Online counseling services, Suicide prevention, Natural language processing, Knowledge graph, Artificial intelligence},
abstract = {Rationale
Detecting users at risk of suicide in text-based counseling services is essential to ensure that at-risk individuals are flagged and prioritized.
Objective
The objective of this study is to develop a domain knowledge-aware risk assessment (KARA) model to improve our ability of suicide detection in online counseling systems.
Methods
We obtained the largest known de-identified dataset from an emotional support system established in Hong Kong, comprising 5682 Cantonese conversations between help-seekers and counselors. Of those, 682 conversations disclosed crisis intentions of suicide. We constructed a suicide-knowledge graph, representing suicide-related domain knowledge as a computer-processible graph. Such knowledge graph was embedded into a deep learning model to improve its ability to identify help-seekers in crisis. As the baseline, a standard NLP model was applied to the same task. 80% of the study samples were randomly sampled to train model parameters. The remaining 20% were used for model validation. Evaluation metrics including precision, recall, and c-statistic were reported.
Results
Both KARA and the baseline achieved high precision (0.984 and 0.951, shown in Table 2) and high recall (0.942 and 0.947) towards non-crisis cases. For crisis cases, however, KARA model achieved a much higher recall than the baseline (0.870 vs 0.791). The c-statistics of KARA and the baseline were 0.815 and 0.760, respectively.
Conclusion
KARA significantly outperformed standard NLP models, demonstrating good translational value and clinical relevance.}
}
@article{WU2024123860,
title = {Reconstructive network under contrastive graph rewards for video summarization},
journal = {Expert Systems with Applications},
volume = {250},
pages = {123860},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123860},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424007267},
author = {Guangli Wu and Shanshan Song and Xingyue Wang and Jing Zhang},
keywords = {Video summarization, Reinforcement learning, Graph contrastive learning, Mutual information},
abstract = {Video summarization aims to condense video content by extracting pivotal frames or shots. Most existing methods focus on maximizing the intersection between predicted summary and ground truth, overlooking whether users can infer the content of the original video from the summary. Additionally, these approaches heavily rely on annotated data, posing limitations. Therefore, we propose a reconstructive network under contrastive graph rewards for video summarization, comprising a summary generator and a video reconstructor. The summary generator employs graph contrastive learning to distill essential video information to generate summary. Meanwhile, the video reconstructor employs reinforcement learning within an unsupervised training framework to optimize the summary generator, addressing the shortage of annotated video data in summarization tasks. Leveraging reconstruction loss, our approach ensures that predicted summary encapsulate main video content and inter-shots dependencies. Notably, we innovatively devise a mutual information maximization reconstruction reward function to preserve shared information between the summary and the original video, facilitating users in comprehending the original video content. We conduct massive experiments on the TVSum and SumMe datasets, and our network achieved F1 scores of 58.8% and 48.0%, respectively. Experimental results validate the superiority of our method over both state-of-the-art unsupervised and many supervised video summarization techniques.}
}
@article{LI2025100707,
title = {Analysis of social networks content to identify fake news using stacked combination of deep neural networks},
journal = {Egyptian Informatics Journal},
volume = {30},
pages = {100707},
year = {2025},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2025.100707},
url = {https://www.sciencedirect.com/science/article/pii/S1110866525001008},
author = {Yujie Li and Yushui Xiao and Yong Huang and Rui Ma},
keywords = {Fake News Identification, Social Networks Analysis, Stacked Ensemble Learning, Deep Neural Networks},
abstract = {In today’s fast-paced world, the unprecedented expansion of social networks and the huge volume of information has made automatic detection of fake news an undeniable necessity. The dissemination of fake news and misinformation can have a devastating impact on public opinion and social decision-making. This challenge requires new and powerful approaches in the fields of deep learning and natural language processing to accurately and quickly identify fake news and prevent its dissemination. For that purpose, this current work presents a new and efficient solution to detecting and spotting spurious news on social media. This method, through deep text content analysis and the employment of advanced deep learning techniques, aims to provide an expansive and accurate response to solve this problem. The proposed method consists of three determining steps: 1) The input data is initially prepared for the next steps using preprocessing techniques. This is done through noise removal, text normalization, and data conversion into a format that can be processed by deep learning models. 2) A hybrid method is then used to extract text features, which is a combination of a list of statistical features (e.g., text length, word count, and links), GloVe-based semantic features (to represent the word relationships), and Character N-Grams (CNG) (to improve misspelling and linguistic anomaly robustness). 3) Finally, for each set of features, a particular deep model is trained to predict based on each component. Specifically, a Multilayer Perceptron (MLP) model is used for statistical feature analysis, and Convolutional Neural Network (CNN) models are used for GloVe and CNG features. Both models generate individual predictions from the input features presented to them, and the predicted labels and the posterior probability vector for each of the models are combined to output a vector to be forwarded to the meta-learner (a MLP model). By learning patterns in the combinations of outputs and the probability vectors of the individual base models, the MLP model can correctly identify fake news or real news. Experimental results conducted on two authentic datasets, GossipCop and Politifact, show that our proposed method achieves 99.45 % and 97.40 % accuracies, respectively. This achievement indicates the very good and effective performance of our method in detecting fake news on both datasets.}
}
@article{DIAO2023109614,
title = {EC-GCN: A encrypted traffic classification framework based on multi-scale graph convolution networks},
journal = {Computer Networks},
volume = {224},
pages = {109614},
year = {2023},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2023.109614},
url = {https://www.sciencedirect.com/science/article/pii/S1389128623000592},
author = {Zulong Diao and Gaogang Xie and Xin Wang and Rui Ren and Xuying Meng and Guangxing Zhang and Kun Xie and Mingyu Qiao},
keywords = {Encrypted traffic classification, Graph neural networks, Packet sequence learning},
abstract = {The sharp increase in encrypted traffic brings a huge challenge to traditional traffic classification methods. Combining deep learning with time series analysis techniques is a recent trend in solving this problem. Most of these approaches only capture the temporal correlation within a flow. The accuracy and robustness are unsatisfactory, especially in an unstable network environment with high packet loss and reordering. How to learn a representation with a strong generalization ability for each encrypted traffic flow remains a key challenge. Our detailed analysis indicates that there is a graph with particular local structures corresponding to each type of encrypted traffic flow. Inspired by this observation, we propose a novel deep learning framework called EC-GCN to classify encrypted traffic flows based on multi-scale graph convolutional neural networks. We first provide a novel lightweight layer that only relies on the metadata and encodes each encrypted traffic flow into graph representations. So that our framework can be independent of different encryption protocols. Then we design a novel graph pooling and structure learning layer to dynamically extract the multi-graph representations and improve the capabilities to adapt to complex network environments. EC-GCN is an end-to-end classification model that learns representative spatial–temporal traffic features hidden in a traffic time series and then classifies them in a unified framework. Our comprehensive experiments on three real-world datasets indicate that EC-GCN can achieve up to 5%–20% accuracy improvement and outperforms state-of-the-art methods.}
}
@article{JIANG2024104162,
title = {MCT-VHD: Multi-modal contrastive transformer for video highlight detection},
journal = {Journal of Visual Communication and Image Representation},
volume = {101},
pages = {104162},
year = {2024},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2024.104162},
url = {https://www.sciencedirect.com/science/article/pii/S1047320324001172},
author = {Yinhui Jiang and Sihui Luo and Lijun Guo and Rong Zhang},
keywords = {Multi-modal, Video highlight detection, Transformer, Contrastive learning},
abstract = {Autonomous highlight detection aims to identify the most captivating moments in a video, which is crucial for enhancing the efficiency of video editing and browsing on social media platforms. However, current efforts primarily focus on visual elements and often overlook other modalities, such as text information that could provide valuable semantic signals. To overcome this limitation, we propose a Multi-modal Contrastive Transformer for Video Highlight Detection (MCT-VHD). This transformer-based network mainly utilizes video and audio modalities, along with auxiliary text features (if exist) for video highlight detection. Specifically, We enhance the temporal connections within the video by integrating a convolution-based local enhancement module into the transformer blocks. Furthermore, we explore three multi-modal fusion strategies to improve highlight inference performance and employ a contrastive objective to facilitate interactions between different modalities. Comprehensive experiments conducted on three benchmark datasets validate the effectiveness of MCT-VHD, and our ablation studies provide valuable insights into its essential components.}
}
@article{RAVI2024200456,
title = {Ideological orientation and extremism detection in online social networking sites: A systematic review},
journal = {Intelligent Systems with Applications},
volume = {24},
pages = {200456},
year = {2024},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2024.200456},
url = {https://www.sciencedirect.com/science/article/pii/S2667305324001303},
author = {Kamalakkannan Ravi and Jiann-Shiun Yuan},
keywords = {Extremism detection, Machine learning, Natural language processing, Predictive models, Social media, User-generated content},
abstract = {The rise of social networking sites has reshaped digital interactions, becoming fertile grounds for extremist ideologies, notably in the United States. Despite previous research, understanding and tackling online ideological extremism remains challenging. In this context, we conduct a systematic literature review to comprehensively analyze existing research and offer insights for both researchers and policymakers. Spanning from 2005 to 2023, our review includes 110 primary research articles across platforms like Twitter (X), Facebook, Reddit, TikTok, Telegram, and Parler. We observe a diverse array of methodologies, including natural language processing (NLP), machine learning (ML), deep learning (DL), graph-based methods, dictionary-based methods, and statistical approaches. Through synthesis, we aim to advance understanding and provide actionable recommendations for combating ideological extremism effectively on online social networking sites.}
}
@article{LIU2022469,
title = {Multi-perspective social recommendation method with graph representation learning},
journal = {Neurocomputing},
volume = {468},
pages = {469-481},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.10.050},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221015368},
author = {Hai Liu and Chao Zheng and Duantengchuan Li and Zhaoli Zhang and Ke Lin and Xiaoxuan Shen and Neal N. Xiong and Jiazhang Wang},
keywords = {Recommender system, Diverse social relation, Graph convolutional network, Representation learning},
abstract = {Social recommender systems (SRS) aim to study how social relations influence users’ choices and how to use them for better learning users embeddings. However, the diversity of social relationships, which is instructive to the propagation of social influence, has been rarely explored. In this paper, we propose a graph convolutional network based representation learning method, namely multi-perspective social recommendation (MPSR), to construct hierarchical user preferences and assign friends’ influences with different levels of trust from varying perspectives. We further utilize the attributes of items to partition and excavate users’ explicit preferences and employ complementary perspective modeling to learn implicit preferences of users. To measure the trust degree of friends from different perspectives, the statistical information of users’ historical behavior is utilized to construct multi-perspective social networks. Experimental results on two public datasets of Yelp and Ciao demonstrate that the MPSR significantly outperforms the state-of-the-art methods. Further detailed analysis verifies the importance of mining explicit characteristics of users and the necessity for diverse social relationships, which show the rationality and effectiveness of the proposed model. The source Python code will be available upon request.}
}
@article{YU2024114272,
title = {Live streaming channel recommendation based on viewers' interaction behavior: A hypergraph approach},
journal = {Decision Support Systems},
volume = {184},
pages = {114272},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2024.114272},
url = {https://www.sciencedirect.com/science/article/pii/S0167923624001052},
author = {Li Yu and Wei Gong and Dongsong Zhang},
keywords = {Interaction behavior, Live streaming, Recommender systems, Hypergraph, Graph neural networks},
abstract = {Live streaming has become increasingly popular in recent years. Viewers of live streaming channels can interact with live streamers through various behaviors, such as sending virtual gifts and Danmaku. It is very critical to accurately model such viewers' behaviors, which reflect their interest, for recommending live streaming channels. However, existing studies on live streaming channel recommendation usually model viewers' interaction behaviors through traditional graphs where an edge only connects two nodes, which cannot capture interaction relationships between multi-viewers and multi-channels. In this study, we propose a novel approach to live streaming recommendation based on Viewers' Interaction Behavior Modeled by Hypergraphs (VIBM-Hyper). Specifically, VIBM-Hyper first constructs two hypergraphs to model viewers' interaction behaviors, including a channel-oriented behavior hypergraph and a viewer-oriented behavior hypergraph. Then, it employs a hypergraph convolution technique to learn the representations of viewers and live streaming channels, respectively, which are finally used to predict a viewer's preference for a certain live streaming channel. We analyzed viewers' multiple types of behaviors in live streaming channels and conducted empirical evaluation to investigate the effectiveness of VIBM-Hyper with two real-world datasets. The evaluation results demonstrate its superior performance in live streaming channel recommendation in comparison to the state-of-the-art methods.}
}
@article{WEI2024103776,
title = {FUMMER: A fine-grained self-supervised momentum distillation framework for multimodal recommendation},
journal = {Information Processing & Management},
volume = {61},
number = {5},
pages = {103776},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103776},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001365},
author = {Yibiao Wei and Yang Xu and Lei Zhu and Jingwei Ma and Jiangping Huang},
keywords = {Multimodal recommendation, Self-supervised learning, Contrastive learning, Momentum model, Fine-grained representation},
abstract = {The considerable semantic information contained in multimodal data is increasingly appreciated by industry and academia. To effectively leverage multimodal information, existing multimodal recommendation methods mainly build multimodal auxiliary graphs to improve the representation of users and items. However, the weak value density of multimodal data inevitably leads to serious noise issues, making it difficult to effectively exploit valuable information from the multimodal contents. To address this issue, we propose a novel Fine-grained Self-supervised Mom entum Distillation Framework (FUMMER) for multimodal recommendations. Specifically, we propose a Transformer-based Fine-grained Feature Extractor (TFFE) and a Momentum Distillation (MoD) structure that incorporates intra- and inter-modal contrastive learning to fully pre-train TFFE for fine-grained feature extraction. Additionally, we design a structure-aware fine-grained contrastive learning module to fully exploit the self-supervised signals from fine-grained structural features. Extensive experiments on three real-world datasets show that our method outperforms state-of-the-art multimodal recommendation methods. Further experiments verify that the fine-grained feature extraction method we propose can serve as a pre-trained model, enhancing the performance of recommendation methods effectively by learning the fine-grained feature representations of items. The code is publicly available at https://github.com/BIAOBIAO12138/FUMMER.}
}
@article{HUANG2022108463,
title = {DIAG: A Deep Interaction-Attribute-Generation model for user-generated item recommendation},
journal = {Knowledge-Based Systems},
volume = {243},
pages = {108463},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.108463},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122001915},
author = {Ling Huang and Bi-Yi Chen and Hai-Yi Ye and Rong-Hua Lin and Yong Tang and Min Fu and Jianyi Huang and Chang-Dong Wang},
keywords = {Recommendation, User-generated item, User-item interaction, User-item generation, Item attribute, Item-item co-generation network, Deep learning},
abstract = {Most existing recommendation methods assume that all the items are provided by separate producers rather than users. However, it could be inappropriate in some recommendation tasks since users may generate some items. Considering the user–item generation relation may benefit recommender systems that only use implicit user–item interactions. However, it may suffer from a dramatic imbalance. The number of user–item generation relations may be far smaller than the number of user–item interactions because each item is generated by at most one user. At the same time, this item can be interacted with by many users. To overcome the challenging imbalance issue, we propose a novel Deep Interaction-Attribute-Generation (DIAG) model. It integrates the user–item interaction relation, the user–item generation relation, and the item attribute information into one deep learning framework. The novelty lies in the design of a new item–item co-generation network for modeling the user–item generation information. Then, graph attention network is adopted to learn the item feature vectors from the user–item generations and the item attribute information by considering the adaptive impact of one item on its co-generated items. Extensive experiments conducted on two real-world datasets confirm the superiority of the DIAG method.}
}
@article{HE2026103632,
title = {LMVD: A large-scale multimodal vlog dataset for depression detection in the wild},
journal = {Information Fusion},
volume = {126},
pages = {103632},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103632},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525007043},
author = {Lang He and Kai Chen and Junnan Zhao and Yimeng Wang and Ercheng Pei and Haifeng Chen and Jiewei Jiang and Shiqing Zhang and Jie Zhang and Zhongmin Wang and Tao He and Prayag Tiwari},
keywords = {Depression detection, Transformer, Vlog, Multimodal, Deep learning},
abstract = {Depression profoundly impacts multiple dimensions of an individual’s life, including personal and social functioning, academic achievement, occupational productivity, and overall quality of life. With recent advancements in affective computing, deep learning technologies have been increasingly adopted to identify patterns indicative of depression. However, due to concerns over participant privacy, data in this domain remain scarce, posing significant challenges for the development of robust discriminative models for depression detection. To address this limitation, we build a Large-scale Multimodal Vlog Dataset (LMVD) for depression recognition in real-world settings. The LMVD dataset comprises 1,823 video samples, totaling approximately 214 h of content, collected from 1,475 participants across four major multimedia platforms: Sina Weibo, Bilibili, TikTok, and YouTube. In addition, we introduce a novel architecture, MDDformer, specifically designed to capture non-verbal behavioral cues associated with depressive states. Extensive experimental evaluations conducted on LMVD demonstrate the superior performance of MDDformer in depression detection tasks. We anticipate that LMVD will become a valuable benchmark resource for the research community, facilitating progress in multimodal, real-world depression recognition. The dataset and source code will be made publicly available at: https://github.com/helang818/LMVD.}
}
@article{MISHRA2024108241,
title = {Shielding against online harm: A survey on text analysis to prevent cyberbullying},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108241},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108241},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624003993},
author = {Akanksha Mishra and Sharad Sinha and Clint Pazhayidam George},
keywords = {Cybercrime, Feature extraction, Text mining, Machine learning, Natural language processing, Social media},
abstract = {Cyberbullying poses a digital threat to society. In this survey, we explain what cyberbullying is and its various forms. We focus on social media platforms and instant messaging apps that are susceptible to cyberbullying, discussing how we can identify such behavior in these spaces. Moving on, we conduct a systematic review of publicly available datasets in different languages, exploring techniques for data preprocessing, feature representation, and methodologies used in textual analysis for cyberbullying detection. We specifically look at natural language-based and platform-specific preprocessing methods. We also cover popular feature representation techniques like sentiment analysis, user information, text summarization, symbols, images, and word embedding for detecting cyberbullying. Next, we categorize existing techniques, including machine learning and neural networks, highlighting research gaps. Additionally, we discuss the challenges associated with current datasets and methods. This survey aims to provide early researchers with insights into cyberbullying literature and guide them in exploring potential research directions.}
}
@article{LI2025107726,
title = {DTGBA: A stronger graph backdoor attack with dual triggers},
journal = {Neural Networks},
volume = {190},
pages = {107726},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2025.107726},
url = {https://www.sciencedirect.com/science/article/pii/S0893608025006069},
author = {Ding Li and Hui Xia and Xin Li and Rui Zhang and Mingda Ma},
keywords = {Graph neural networks, Backdoor attacks, Node classification, Robustness},
abstract = {Graph backdoor attacks can significantly degrade the performance of graph neural networks (GNNs). Specifically, during the training phase, graph backdoor attacks inject triggers and target class labels into poisoned nodes to create a backdoored GNN. During the testing phase, triggers are added to target nodes, causing them to be misclassified as the target class. However, existing graph backdoor attacks lack sufficient imperceptibility and can be easily resisted by random edge dropping-based defense, limiting their effectiveness. To address these issues, we propose Dual Triggers Graph Backdoor Attack (DTGBA). Initially, we deploy an imperceptible injected trigger generator and multiple discriminators, driving the imperceptibility of the injected triggers through adversarial game between them. Additionally, we introduce a feature mask learner to extract the high-impact and low-impact feature dimensions of the target class’s nodes, and then create feature-based triggers by modifying the key feature dimensions of poisoned/target nodes, ensuring that the backdoor implantation can still be effective even if the injected triggers are removed by random edge dropping. Finally, we conduct extensive experiments to demonstrate that DTGBA achieves superior performance. Our code is available at https://github.com/SnowStone-DingLi/DTGBA-main.}
}
@article{FENG2025103217,
title = {Crafting user-centric prompts for UI generations based on Kansei engineering and knowledge graph},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103217},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103217},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625001107},
author = {Xuejing Feng and Huifang Du and Jun Ma and Haofen Wang and Lijuan Zhou and Meng Wang},
keywords = {Human-centered AI, User interface generations, Prompt engineering, Knowledge graph, Kansei engineering},
abstract = {Text-to-image (T2I) models are emerging as a powerful tool for designers to create user interface (UI) prototypes from natural language inputs (i.e., prompts). However, the discrepancy between designer inputs and model-preferred prompts makes it challenging for designers to consistently deliver effective results to end users. To bridge this gap, we introduce a novel hybrid method that assists designers in crafting user-centric prompts for T2I models, ensuring that the generated UIs align with end-user expectations. First, this method merges text mining and Kansei Engineering (KE) to analyze online user reviews and construct a Knowledge Graph (KG), mapping the intricate relationships between diverse affective requirements of users, design features, and corresponding text prompts for UI generation. Then, our approach automatically transforms designer inputs into model-preferred prompts through entity mention recognition and entity linking during the human-AI collaborative design process. Finally, we validate the proposed approach with a case study on automotive human–machine interface design. Experimental results demonstrate that our approach achieves high performance in perceived efficiency, satisfaction, and expectation disconfirmation. Overall, this study represents a step forward in integrating human and AI contributions in design and innovation within engineering disciplines, enabling AI to inspire, develop, and reinforce human creativity from a human factors perspective.}
}
@article{WANG2023110056,
title = {GraphPowerNet: Graph-based power consumption profiling for mobile phone applications},
journal = {Computer Networks},
volume = {237},
pages = {110056},
year = {2023},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2023.110056},
url = {https://www.sciencedirect.com/science/article/pii/S1389128623005017},
author = {Xiao Wang and Xudong Wang},
keywords = {Power consumption, Mobile phone application, Graph learning, Graph neural network, Application usage behavior profiling},
abstract = {Mobile phone power analysis provides an approach to user behavior profiling. Existing work conducts the analysis on either a single module or total power consumption, and ignores the correlation between modules. However, such correlation is vital in capturing usage patterns. To this end, graph neural networks (GNNs) are leveraged to explore such relationships among different modules. Since GNNs rely on pre-defined graph structures for message propagation, they cannot be applied directly to the scenario where the graph structure needs to be discovered. To resolve this issue, an approach called GraphPowerNet is developed. Firstly, a pseudo label-acquisition mechanism is used to cluster power consumption data into multiple virtual usage patterns that serve as supervisory information. Next, a graph learning module is designed to automatically extract the correlations among mobile phone modules. Based on the learned graph and the power consumption data, a graph convolutional model is adopted to conduct graph classification. Finally, the power consumption data is profiled by both the classification result and the graph structure. Experimental results on real world data show that the F1-score of application usage behavior classification is higher than 95%. Moreover, interpretability analysis shows that the graph learned via GraphPowerNet has strong practical significance.}
}
@article{IHNAINI2024102263,
title = {Semantic similarity on multimodal data: A comprehensive survey with applications},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {10},
pages = {102263},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102263},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824003525},
author = {Baha Ihnaini and Belal Abuhaija and Ebenezer Atta Mills and Massudi Mahmuddin},
keywords = {Semantic Similarity, Similarity Measures, Multimodal Semantic Similarity, Semantic Similarity Applications, Machine Learning, And Deep Learning},
abstract = {Recently, the revival of the semantic similarity concept has been featured by the rapidly growing artificial intelligence research fueled by advanced deep learning architectures enabling machine intelligence using multimodal data. Thus, semantic similarity in multimodal data has gained substantial attention among researchers. However, the existing surveys on semantic similarity measures are restricted to a single modality, mainly text, which significantly limits the capability to understand the intelligence of real-world application scenarios. This study critically reviews semantic similarity approaches by shortlisting 223 vital articles from the leading databases and digital libraries to offer a comprehensive and systematic literature survey. The notable contribution is to illuminate the evolving landscape of semantic similarity and its crucial role in understanding, interpreting, and extracting meaningful information from multimodal data. Primarily, it highlights the challenges and opportunities inherent in different modalities, emphasizing the significance of advancements in cross-modal and multimodal semantic similarity approaches with potential application scenarios. Finally, the survey concludes by summarizing valuable future research directions. The insights provided in this survey improve the understanding and pave the way for further innovation by guiding researchers in leveraging the strength of semantic similarity for an extensive range of real-world applications.}
}
@article{WEI2025104089,
title = {DCCMA-Net: Disentanglement-based cross-modal clues mining and aggregation network for explainable multimodal fake news detection},
journal = {Information Processing & Management},
volume = {62},
number = {4},
pages = {104089},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104089},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325000317},
author = {Siqi Wei and Zheng Wang and Meiling Li and Xuanning Liu and Bin Wu},
keywords = {Multimodal fake news detection, Disentangled representation learning, Cross-modal clues exploration, Explainable machine learning},
abstract = {Multimodal fake news detection is significant in safeguarding social security. Compared with single-text news, multimodal news data contains rich cross-modal clues that can improve the detection effectiveness: modality-common semantic enhancement, modality-specific semantic complementation, and modality-specific semantic inconsistency. However, most existing studies ignore the disentanglement of modality-specific and modality-common semantics but treat them as an entangled whole. Consequently, these studies can only implicitly explore the interactions between modalities, resulting in a lack of explainability. To address that, we propose a Disentanglement-based Cross-modal Clues Mining and Aggregation Network for explainable fake news detection, called DCCMA-Net. Specifically, DCCMA-Net decomposes each modality into two distinct representations: a modality-common representation that captures shared semantics across modalities, and a modality-specific representation that captures unique semantics within each modality. Then, leveraging these disentangled representations, DCCMA-Net explicitly and comprehensively mines three cross-modal clues: modality-common semantic enhancement, modality-specific semantic complementation, and modality-specific semantic inconsistency. Since not all clues play an equal role in the decision-making process, DCCMA-Net proposes an adaptive attention aggregation module to assign contribution weights to different clues. Finally, DCCMA-Net aggregates these clues based on their contribution weights to obtain highly discriminative news representations for detection, and highlights the most contributive clues as explanations for the detection results. Extensive experiments demonstrate that DCCMA-Net outperforms existing methods, achieving detection accuracy improvements of 2.53%, 4.01%, and 3.99% on Weibo, PHEME, and Gossipcop datasets, respectively. Moreover, the explainability accuracy of DCCMA-Net exceeds that of current state-of-the-art methods on the Weibo dataset.}
}
@article{LI2025129609,
title = {A novel rumor detection method focusing on social psychology with graph attention network},
journal = {Neurocomputing},
volume = {626},
pages = {129609},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129609},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225002814},
author = {Lina Li and Guoxing Liu and Yu Liu and Qinghe Yu and Cheng Luo and Nianfeng Li},
keywords = {Rumor detection, Social psychology, Graph attention networks, Feature fusion, Large language models},
abstract = {The proliferation of online social media has led to an increase in the spread of rumors. Current rumor detection methods have not adequately considered the impact of social psychology and have neglected to integrate text features with other characteristics. This paper introduces a multi-feature fusion rumor detection model, Social Psychology-based Graph ATtention network (SPGAT), designed to enhance the accuracy of rumor detection. In this model, social psychological features are extracted using large language models, encompassing user emotion, social identity, group emotional resonance, and social influence. These features aim to deeply capture the essential attributes of rumors. Concurrently, a multi-head dynamic graph attention convolutional network is constructed. This network amalgamates complex structural features with essential features, thereby effectively capturing spatial propagation features and significant features while paying attention to the high-dimensional hidden features of rumors. Furthermore, a neural network is designed to comprehensively integrate the high-dimensional features of rumors, and rumor detection is achieved through a fully connected layer. Extensive experiments are conducted on three public datasets. Compared to the latest typical detection methods, the proposed method demonstrates certain advantages. Specifically, the accuracy and F1 score of rumor detection are improved by 5.87% and 4.4% on average on Weibo, PHEME 5, and PHEME 9 datasets compared to the latest baselines, respectively. Meanwhile, we verify and analyze the key role of socio-psychological characteristics in rumor propagation, which provides strong support for an in-depth understanding of the rumor propagation mechanism.}
}
@article{YU2023113894,
title = {Collaborative group embedding and decision aggregation based on attentive influence of individual members: A group recommendation perspective},
journal = {Decision Support Systems},
volume = {165},
pages = {113894},
year = {2023},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2022.113894},
url = {https://www.sciencedirect.com/science/article/pii/S0167923622001658},
author = {Li Yu and Youfang Leng and Dongsong Zhang and Shuheng He},
keywords = {Group decision making, Group recommendation, Graph neural network, Attention mechanism, Deep learning},
abstract = {A key group decision making task is to aggregate individual preferences. Conventional group decision methods adopt pre-defined and fixed strategies to aggregate individuals' preferences, which can be ineffective due to the varying importance and influence of individual group members. Recent studies have proposed to assign different weights to individual members automatically based on the level of consistency of their ratings with group assessment outcomes. However, they ignored the high-order influence relationship among individual group members on group decision making. In this study, from a group recommendation perspective, we propose a novel collaborative Group Embedding and Decision Aggregation (GEDA) approach by leveraging the graph neural network technique to address those limitations. Specifically, GEDA first deploys a graph convolution operation on user-item interaction and group-item interaction graphs to generate embedding representations of members, groups, and items. A novel multi-attention (MA) module then learns each member's decision weight by simultaneously considering the relationships among members for aggregating individual preferences into group preferences. The empirical evaluation using two real-world datasets demonstrates the advantage of the proposed GEDA model over the state-of-the-art group recommendation models.}
}
@article{SHI2025121934,
title = {Influence contribution ratio estimation in social networks},
journal = {Information Sciences},
volume = {703},
pages = {121934},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2025.121934},
url = {https://www.sciencedirect.com/science/article/pii/S0020025525000660},
author = {Yingdan Shi and Jingya Zhou and Congcong Zhang and Zhenyu Hu},
keywords = {Influence estimation, Social networks, Influence contribution ratio, Influence maximization},
abstract = {Social networks are becoming an ideal choice for marketing activities and advertising campaigns due to the explosive growth of social network users. In these advertising campaigns, influential users, such as celebrities, often post or repost the ads to help disseminate product information through the ‘word-of-mouth’ effect in social networks. It is significant to allocate remuneration fairly to these influential users based on their contributions to disseminating ads. To address this, we propose a concept called the influence contribution ratio, which represents the contribution ratio of each influential user to an advertising campaign. We introduce two types of coalitional games to depict the process of influence diffusion from multiple levels, namely macro and micro coalitional games, and propose a metric called InfConR based on the Shapley value in coalitional game theory to measure the influence contribution ratio fairly. A naive method to calculate the InfConR value for each user is to use a Monte Carlo (MC) simulation to enumerate a certain number of cascades for the advertising campaign. However, this method is too time-consuming and not realistic. Therefore, we propose a scheme called ICR, which involves two components: 1) sampling algorithms for InfConR in the Independent Cascade (IC) model and Liner Threshold (LT) model, respectively, and 2) an algorithm with approximation guarantees to minimize the sampling number. Our experiments on four real-world datasets demonstrate the superiority and effectiveness of our scheme.}
}
@article{SUN2022323,
title = {Motifs-based recommender system via hypergraph convolution and contrastive learning},
journal = {Neurocomputing},
volume = {512},
pages = {323-338},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.09.102},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222011948},
author = {Yundong Sun and Dongjie Zhu and Haiwen Du and Zhaoshuo Tian},
keywords = {Self-supervised learning, Graph neural networks, Hypergraph, Contrastive learning},
abstract = {Recently, the strategy of leveraging various motifs to model social semantic information and using self-supervised learning tasks to boost recommendation performance has been proven to be very promising. In this paradigm, each channel describes a common motif (e.g., a triangular social motif) via hypergraph convolution. Richer motifs can be encoded through multiple channels, and self-supervised learning can leverage this multichannel information to build self-supervised tasks (such as contrastive learning tasks), which can greatly improve the recommendation performance in scenarios without enough data labels. However, accurately determining the relationships between different channels and fully utilizing them, while maintaining the uniqueness of each channel, is a problem that has not been well studied or resolved in this field. This paper explores and verifies the disadvantages of directly constructing contrastive learning tasks on different channels with practical experiments and proposes a scheme of interactive modeling and matching representation across different channels. This is the first such attempt in the field of recommender systems, and we believe that this paper will inspire future self-supervised learning research based on multichannel information. To solve this problem, we propose a cross-motif matching representation model based on attentive interaction, which can efficiently model the relationships between cross-motif information. Based on this, we also propose a hierarchical self-supervised learning model that realizes self-supervised learning within and between channels, respectively, which improves the ability of self-supervised learning tasks to autonomously mine different levels of potential information. We have conducted abundant experiments, and various metrics on multiple public datasets show that the method proposed in this paper significantly outperforms the state-of-the-art methods, regardless of the general or cold-start scenario. In the model variant analysis experiment, the benefits of the cross-motif matching representation model and the hierarchical self-supervised model proposed in this paper are also fully verified.}
}
@article{KHEDAIRIA20251267,
title = {A Co-Attention Mechanism into a Combined GNN-Based Model for Fake News Detection},
journal = {Computers, Materials and Continua},
volume = {85},
number = {1},
pages = {1267-1285},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.066601},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825007775},
author = {Soufiane Khedairia and Akram Bennour and Mouaaz Nahas and Aida Chefrour and Rashiq Rafiq Marie and Mohammed Al-Sarem},
keywords = {Fake news detection, co-attention mechanism, user preferences, GNNs},
abstract = {These days, social media has grown to be an integral part of people’s lives. However, it involves the possibility of exposure to “fake news,” which may contain information that is intentionally or inaccurately false to promote particular political or economic interests. The main objective of this work is to use the co-attention mechanism in a Combined Graph neural network model (CMCG) to capture the relationship between user profile features and user preferences in order to detect fake news and examine the influence of various social media features on fake news detection. The proposed approach includes three modules. The first one creates a Graph Neural Network (GNN) based model to learn user profile properties, while the second module encodes news content, user historical posts, and news sharing cascading on social media as user preferences GNN-based model. The inter-dependencies between user profiles and user preferences are handled through the third module using a co-attention mechanism for capturing the relationship between the two GNN-based models. We conducted several experiments on two commonly used fake news datasets, Politifact and Gossipcop, where our approach achieved 98.53% accuracy on the Gossipcop dataset and 96.77% accuracy on the Politifact dataset. These results illustrate the effectiveness of the CMCG approach for fake news detection, as it combines various information from different modalities to achieve relatively high performances.}
}
@article{LI2022103077,
title = {Lifecycle research of social media rumor refutation effectiveness based on machine learning and visualization technology},
journal = {Information Processing & Management},
volume = {59},
number = {6},
pages = {103077},
year = {2022},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.103077},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322001789},
author = {Zongmin Li and Xinyu Du and Ye Zhao and Yan Tu and Benjamin Lev and Lu Gan},
keywords = {Rumor refutation effectiveness, Social media, Lifecycle, XGBoostRegressor},
abstract = {Rumor refutation is a common method to control rumors to address potential risks. This paper studies the social media rumor refutation effectiveness lifecycle (SMRREL), focusing on three important characteristics (i.e., lifespan, peak value, and distribution) to provide support for (1) enhancing the persistence and intensity of rumor refutation effectiveness and (2) investigating the changing law of rumor refutation effectiveness. In total, 77,080 comment records, 55,847 forward records, and other pertinent data of 251 rumor refutation microblogs from an official rumor refutation platform are collected to perform analysis. To explore how the lifespan and peak value of SMRREL are influenced by the possible affecting factors, five regressors (i.e., RFRegressor, AdaBoostRegressor, XGBoostRegressor, LGBMRegressor, and CatBoostRegressor) are trained based on the collected data. The XGBoostRegressor shows the best performance, and the results are shown and explained using SHapley Additive exPlanations (SHAP). To investigate the distribution of SMRREL, lifecycle graphs of rumor refutation effectiveness are summarized and divided into three types, i.e., Outburst, Multiple Peaks, and Steep Slope. Finally, based on the results of the SMRREL analysis, corresponding decision-making recommendations are proposed to make better persistence and intensity of rumor refutation effectiveness.}
}
@article{WEI2023110908,
title = {Frequency inception based graph neural network for relation prediction in knowledge graphs},
journal = {Knowledge-Based Systems},
volume = {278},
pages = {110908},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110908},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123006585},
author = {Feifei Wei and Kuizhi Mei},
keywords = {Knowledge graph competition prediction, Deep representation learning, Frequency inception},
abstract = {Recently, knowledge graphs have been broadly studied using approaches such as translation-based models and convolutional neural networks. Although such approaches can express powerful and rich embeddings, graphs are naturally suitable for irregular data. Thus, they can model knowledge graphs with structured data and aggregate considerable information. However, graphs are subject to incompleteness, leading to unconnected knowledge graphs. To address this problem, we propose a framework called frequency-inception-based graph neural network (FiGNN) for relation prediction in knowledge graphs. It exploits a graph to aggregate the most beneficial information through mathematical analysis. Specifically, combined with the relations and inception parameters, each channel of a node and its neighbours dynamically contribute to next-layer channel information, which can extract underlying signals of different channels and neighbouring nodes. Moreover, the representation ability of the nodes is enhanced and over-smoothing is alleviated. We validate the effectiveness of the proposed network on various benchmark datasets. The experimental results demonstrate that our network achieves substantial improvements and substantially outperforms state-of-the-art methods.}
}
@article{ZHANG2025977,
title = {A Cross Attention Transformer-Mixed Feedback Video Recommendation Algorithm Based on DIEN},
journal = {Computers, Materials and Continua},
volume = {82},
number = {1},
pages = {977-996},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.058438},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825000190},
author = {Jianwei Zhang and Zhishang Zhao and Zengyu Cai and Yuan Feng and Liang Zhu and Yahui Sun},
keywords = {Video recommendation, user interest, cross-attention, transformer},
abstract = {The rapid development of short video platforms poses new challenges for traditional recommendation systems. Recommender systems typically depend on two types of user behavior feedback to construct user interest profiles: explicit feedback (interactive behavior), which significantly influences users’ short-term interests, and implicit feedback (viewing time), which substantially affects their long-term interests. However, the previous model fails to distinguish between these two feedback methods, leading it to predict only the overall preferences of users based on extensive historical behavior sequences. Consequently, it cannot differentiate between users’ long-term and short-term interests, resulting in low accuracy in describing users’ interest states and predicting the evolution of their interests. This paper introduces a video recommendation model called CAT-MF Rec (Cross Attention Transformer-Mixed Feedback Recommendation) designed to differentiate between explicit and implicit user feedback within the DIEN (Deep Interest Evolution Network) framework. This study emphasizes the separate learning of the two types of behavioral feedback, effectively integrating them through the cross-attention mechanism. Additionally, it leverages the long sequence dependence capabilities of Transformer technology to accurately construct user interest profiles and predict the evolution of user interests. Experimental results indicate that CAT-MF Rec significantly outperforms existing recommendation methods across various performance indicators. This advancement offers new theoretical and practical insights for the development of video recommendations, particularly in addressing complex and dynamic user behavior patterns.}
}
@article{KANG2025110634,
title = {Explainable graph convolutional network based on catastrophe theory and its application to group activity recognition},
journal = {Engineering Applications of Artificial Intelligence},
volume = {150},
pages = {110634},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110634},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625006347},
author = {Junpeng Kang and Jing Zhang and Lin Chen and Hui Zhang and Li Zhuo},
keywords = {Graph convolutional network, Explainable, Catastrophe theory, Over-smoothing, Group activity recognition},
abstract = {Graph convolutional networks (graph models for short) are crucial for understanding model decisions through mathematical white-box interpretation, which can radically improve the performance and credibility of downstream artificial intelligence applications. To address the limitations of existing interpretability of over-smoothing and over-squashing, we propose an explainable graph model based on nonlinear catastrophe theory and apply it to group activity recognition to validate the usefulness of interpretability. (1) We introduce catastrophe mathematical theory to explore the internal processes of graph models and construct the explainable dynamical equations of the graph convolutional network; (2) When graph node features lose uniqueness, leading to over-smoothing, which reduces the discriminative power of the graph model, we propose a mathematical method to predict over-smoothing; (3) In response to the over-squashing of the node feature values that is excessively compressed, we design a channel expansion unit to extend the transmission paths of graph nodes and alleviate the over-squashing in the graph structure. Finally, we apply our model to group activity recognition tasks to capture complex interactions within groups. We obtain the competitive results on five publicly available graph structure datasets (Actor, Chameleon, Texas, Cornell, Cora) and our self-built group activity dataset. Our model can effectively capture node and graph-level features with stronger generalization capabilities. For complex and diverse real-world group activity data, our model offers intuitive graph-level explanations for group activity analysis. Through the analysis of over-smoothing and over-squashing, our method extends new theoretical approaches in explainable artificial intelligence.}
}
@incollection{MUKHTAR202519,
title = {Chapter 2 - Artificial intelligence techniques for human-machine interaction},
editor = {Abdulhamit Subasi and Saeed Mian Qaisar and Humaira Nisar},
booktitle = {Artificial Intelligence and Multimodal Signal Processing in Human-Machine Interaction},
publisher = {Academic Press},
pages = {19-42},
year = {2025},
series = {Artificial Intelligence Applications in Healthcare and Medicine},
isbn = {978-0-443-29150-0},
doi = {https://doi.org/10.1016/B978-0-443-29150-0.00010-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044329150000010X},
author = {Hamid Mukhtar},
keywords = {Human-machine interaction, Artificial intelligence, Robots, Cobots, Industry 5.0, Speech, Emotion, Facial expression, Recognition, Generative AI},
abstract = {This chapter provides a broad overview of various artificial intelligence (AI) techniques employed in human-machine interaction (HMI). It explores a multitude of HMI techniques, each with its unique application area and AI approaches considered for its implementation. This chapter also delves into multimodal interaction and multimodal signal processing, integral parts of HMI. The techniques discussed range in their applications from personal experiences with machines to industrial use cases. Each technique's application area is examined, highlighting how AI enhances efficiency and effectiveness in these areas. Furthermore, the article delves into the AI-specific contemporary approaches used in HMI, such as neural networks and deep learning. This exploration provides an understanding of the integral role AI plays in advancing HMI, paving the way for future research and development in this dynamic field.}
}
@article{TANG2024102183,
title = {GCNT: Identify influential seed set effectively in social networks by integrating graph convolutional networks with graph transformers},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {8},
pages = {102183},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102183},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824002726},
author = {Jianxin Tang and Jitao Qu and Shihui Song and Zhili Zhao and Qian Du},
keywords = {Social network analysis, Influence maximization, Graph transformers, Graph convolutional networks},
abstract = {Exploring effective and efficient strategies for identifying influential nodes from social networks as seeds to promote the propagation of influence remains a crucial challenge in the field of influence maximization (IM), which has attracted significant research efforts. Deep learning-based approaches have been adopted as an alternative promising solution to the IM problem. However, a robust model that captures the associations between network information and node influence needs to be investigated, while concurrently considering the effects of the overlapped influence on training labels. To address these challenges, a GCNT model, which integrates Graph Convolutional Networks with Graph Transformers, is introduced in this paper to capture the intricate relationships among the topology of the network, node attributes, and node influence effectively. Furthermore, an innovative method called Greedy-LIE is proposed to generate labels to alleviate the issue of overlapped influence spread. Moreover, a Mask mechanism specially tailored for the IM problem is presented along with an input embedding balancing strategy. The effectiveness of the GCNT model is demonstrated through comprehensive experiments conducted on six real-world networks, and the model shows its competitive performance in terms of both influence maximization and computational efficiency over state-of-the-art methods.}
}
@article{HUANG2023119126,
title = {Multi-scale modeling temporal hierarchical attention for sequential recommendation},
journal = {Information Sciences},
volume = {641},
pages = {119126},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119126},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523007119},
author = {Nana Huang and Ruimin Hu and Xiaochen Wang and Hongwei Ding},
keywords = {User behavior sequences, Multi-scale modeling, Sequential recommendation, Temporal hierarchical attention, Micro-video},
abstract = {Multi-scale modeling of items interacting in a sequence of users' historical behaviors in a sequential recommendation task is crucial. In real scenarios, the user's choice of items depends not only on static preferences (long-term interests) but also on recent dynamic preferences (short-term interests). In recent years, micro-video sharing platforms have been very favorable, and correspondingly, more efficient recommendation method will be needed to support users in finding their interested micro-videos (items). Compared to traditional online videos (such as YouTube), micro-videos are created by grassroots users, shot by smartphones, are short (typically tens of seconds), and have fewer tags or descriptive text, which makes recommending it a challenging task. In this work, we explore how to model users' historical behavior sequences at multiple scales to predict their click-through rates on micro-videos and then determine whether to recommend them to users. We present a novel Multi-scale Modeling Temporal Hierarchical Attention (MMTHA) method for modeling users' behavior sequences inspired by recent deep network-based approaches. Specifically, firstly, we capture users' short-term dynamic interests using temporal windows; secondly, we utilize a category-level attention mechanism to describe the coarse-grained interests of users and an item-level attention mechanism to capture the fine-grained interests of users; thirdly, we employ a forward multi-headed self-attention mechanism to identify and integrate long-term correlations between previously segmented temporal windows. We conducted extensive experiments on two publicly available datasets to verify their effectiveness. The experimental results show that our proposed MMTHA model achieves state-of-the-art performance in all tests.}
}
@incollection{WAIKHOM2023107,
title = {Chapter Three - An empirical investigation on BigGraph using deep learning},
editor = {Ripon Patgiri and Ganesh Chandra Deka and Anupam Biswas},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {128},
pages = {107-133},
year = {2023},
booktitle = {Principles of Big Graph: In-depth Insight},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2021.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0065245821000607},
author = {Lilapati Waikhom and Ripon Patgiri},
keywords = {Deep learning, BigGraph, Graph convolutional network, Medical data},
abstract = {The sparse nature of BigGraphs makes tasks like Graph Classification, Node Classification, and Link Prediction very challenging. Furthermore, homogeneous or heterogeneous characteristics of data in BigGraph make it challenging to do real-time operations. This paper examines some approaches for the mentioned tasks on BigGraph that outperform the previous state-of-the-art approaches. We also empirically investigate these algorithms on various datasets. These comparisons of the various Graph-based deep neural network architectures such as Graph Convolutional Network (GCN), Deep Graph Convolutional Neural Network (DGCNN), etc., on datasets like Mutag, Proteins, etc., shows that deep architecture learns enough patterns. We also show the experimental results that reveal which architecture performs best on a dataset for a given graph-based task.}
}